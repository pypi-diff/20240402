# Comparing `tmp/struphy-2.2.0.tar.gz` & `tmp/struphy-2.3.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "struphy-2.2.0.tar", last modified: Thu Feb 22 17:41:14 2024, max compression
+gzip compressed data, was "struphy-2.3.0.tar", last modified: Tue Apr  2 13:29:54 2024, max compression
```

## Comparing `struphy-2.2.0.tar` & `struphy-2.3.0.tar`

### file list

```diff
@@ -1,352 +1,354 @@
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.578498 struphy-2.2.0/
--rw-rw-rw-   0 root         (0) root         (0)     1115 2024-02-22 10:12:47.000000 struphy-2.2.0/LICENSE
--rw-r--r--   0 root         (0) root         (0)     3659 2024-02-22 17:41:14.574498 struphy-2.2.0/PKG-INFO
--rwxrwxrwx   0 root         (0) root         (0)      779 2024-02-22 10:12:47.000000 struphy-2.2.0/README.md
--rw-rw-rw-   0 root         (0) root         (0)     2422 2024-02-22 16:46:49.000000 struphy-2.2.0/pyproject.toml
--rw-rw-rw-   0 root         (0) root         (0)      124 2024-02-22 17:41:14.578498 struphy-2.2.0/setup.cfg
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.522498 struphy-2.2.0/src/
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.526498 struphy-2.2.0/src/struphy/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.530498 struphy-2.2.0/src/struphy/bsplines/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/bsplines/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    20754 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/bsplines/bsplines.py
--rw-rw-rw-   0 root         (0) root         (0)    22248 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/bsplines/bsplines_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)     4855 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/bsplines/evaluation_kernels_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    14460 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/bsplines/evaluation_kernels_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    34494 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/bsplines/evaluation_kernels_3d.py
--rw-rw-rw-   0 root         (0) root         (0)     6266 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/bsplines/shapefunc_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.530498 struphy-2.2.0/src/struphy/bsplines/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/bsplines/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     7222 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/bsplines/tests/test_bsplines_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    22218 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/bsplines/tests/test_eval_spline_mpi.py
--rw-rw-rw-   0 root         (0) root         (0)     2210 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/compile_struphy.mk
--rw-rw-rw-   0 root         (0) root         (0)      434 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/conftest.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.530498 struphy-2.2.0/src/struphy/console/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/console/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     9689 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/console/compile.py
--rw-rw-rw-   0 root         (0) root         (0)    28053 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/console/main.py
--rw-rw-rw-   0 root         (0) root         (0)      939 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/console/params.py
--rw-rw-rw-   0 root         (0) root         (0)     1343 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/console/pproc.py
--rw-rw-rw-   0 root         (0) root         (0)     7461 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/console/profile.py
--rw-rw-rw-   0 root         (0) root         (0)     6740 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/console/run.py
--rw-rw-rw-   0 root         (0) root         (0)    14953 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/console/test.py
--rw-rw-rw-   0 root         (0) root         (0)     1312 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/console/units.py
--rw-rw-rw-   0 root         (0) root         (0)     2595 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/dependencies.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.534498 struphy-2.2.0/src/struphy/diagnostics/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/diagnostics/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     5593 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/diagnostics/console_diagn.py
--rw-rw-rw-   0 root         (0) root         (0)    13985 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/diagnostics/continuous_spectra.py
--rw-rw-rw-   0 root         (0) root         (0)    12210 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/diagnostics/diagn_tools.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.534498 struphy-2.2.0/src/struphy/diagnostics/paraview/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/diagnostics/paraview/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    13277 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/diagnostics/paraview/mesh_creator.py
--rw-rw-rw-   0 root         (0) root         (0)     3004 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/diagnostics/paraview/vtk_writer.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.534498 struphy-2.2.0/src/struphy/dispersion_relations/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/dispersion_relations/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    38270 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/dispersion_relations/analytic.py
--rw-rw-rw-   0 root         (0) root         (0)     3881 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/dispersion_relations/base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.534498 struphy-2.2.0/src/struphy/eigenvalue_solvers/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     5540 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/derivatives.py
--rw-rw-rw-   0 root         (0) root         (0)     5136 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/kernels_2d.py
--rw-rw-rw-   0 root         (0) root         (0)     7722 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/kernels_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    23321 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/kernels_projectors_global.py
--rw-rw-rw-   0 root         (0) root         (0)    34341 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/kernels_projectors_global_mhd.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.538498 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/
--rw-rw-rw-   0 root         (0) root         (0)    32191 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/MHD_eigenvalues_cylinder_1D.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.538498 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    15856 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)     8521 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kernels_control_variate.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.538498 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     7080 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)    20939 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_kernels_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)    11250 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)     1618 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_cv_kernel_2.py
--rw-rw-rw-   0 root         (0) root         (0)    21155 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_kernels_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)     9994 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_control_variate.py
--rw-rw-rw-   0 root         (0) root         (0)     8890 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_cvker.py
--rw-rw-rw-   0 root         (0) root         (0)    32983 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_kernels_control_variate.py
--rwxrwxrwx   0 root         (0) root         (0)     9189 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/emw_operators.py
--rw-rw-rw-   0 root         (0) root         (0)     3606 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/inner_products_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    11738 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/inner_products_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    12358 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/inner_products_3d.py
--rw-rw-rw-   0 root         (0) root         (0)     3432 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/l2_error_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    17672 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/l2_error_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    17438 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/l2_error_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    16554 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/mass_matrices_3d_pre.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.538498 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    18036 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_arrays.py
--rw-rw-rw-   0 root         (0) root         (0)    14708 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bb_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)    25336 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bv_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)    46819 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_massless_linear_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    27150 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_vv_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)   138353 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.538498 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.542498 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    10395 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local.py
--rw-rw-rw-   0 root         (0) root         (0)    22026 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local_mhd.py
--rw-rw-rw-   0 root         (0) root         (0)   144069 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/mhd_operators_3d_local.py
--rw-rw-rw-   0 root         (0) root         (0)    72812 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/projectors_local.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.542498 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    94146 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_L2_projector_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)    26256 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_L2.py
--rw-rw-rw-   0 root         (0) root         (0)    33024 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_local.py
--rw-rw-rw-   0 root         (0) root         (0)   129599 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_local_projector_kernel.py
--rw-rw-rw-   0 root         (0) root         (0)     8105 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/mass_matrices_1d.py
--rw-rw-rw-   0 root         (0) root         (0)    19797 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/mass_matrices_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    21575 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/mass_matrices_3d.py
--rw-rw-rw-   0 root         (0) root         (0)     9602 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/mhd_axisymmetric_main.py
--rw-rw-rw-   0 root         (0) root         (0)     2347 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/mhd_axisymmetric_pproc.py
--rw-rw-rw-   0 root         (0) root         (0)    45855 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/mhd_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    70280 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/mhd_operators_core.py
--rw-rw-rw-   0 root         (0) root         (0)    85337 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/projectors_global.py
--rw-rw-rw-   0 root         (0) root         (0)    93566 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/spline_space.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.542498 struphy-2.2.0/src/struphy/eigenvalue_solvers/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    45719 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/eigenvalue_solvers/tests/test_legacy_mhd_projectors.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.542498 struphy-2.2.0/src/struphy/examples/
--rw-rw-rw-   0 root         (0) root         (0)     2309 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/examples/_draw_parallel.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.542498 struphy-2.2.0/src/struphy/feec/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/feec/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     1873 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/banded_to_stencil_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    20467 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/basis_projection_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    50819 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/basis_projection_ops.py
--rw-rw-rw-   0 root         (0) root         (0)    21004 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/linear_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    58037 2024-02-22 13:49:49.000000 struphy-2.2.0/src/struphy/feec/mass.py
--rw-rw-rw-   0 root         (0) root         (0)    21782 2024-02-22 14:45:47.000000 struphy-2.2.0/src/struphy/feec/mass_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    21034 2024-02-22 13:49:49.000000 struphy-2.2.0/src/struphy/feec/preconditioner.py
--rw-rw-rw-   0 root         (0) root         (0)    24876 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/feec/projectors.py
--rw-rw-rw-   0 root         (0) root         (0)    76118 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/psydac_derham.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.546498 struphy-2.2.0/src/struphy/feec/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/feec/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    26231 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_basis_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    20660 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_basis_ops.py
--rw-rw-rw-   0 root         (0) root         (0)     8465 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_derham.py
--rw-rw-rw-   0 root         (0) root         (0)    10976 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_eval_field.py
--rw-rw-rw-   0 root         (0) root         (0)     8780 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_l2_projectors.py
--rw-rw-rw-   0 root         (0) root         (0)     9740 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_lowdim_nel_is_1.py
--rw-rw-rw-   0 root         (0) root         (0)    38634 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_mass_matrices.py
--rw-rw-rw-   0 root         (0) root         (0)     1941 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_noise_init.py
--rw-rw-rw-   0 root         (0) root         (0)     3969 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_toarray_struphy.py
--rw-rw-rw-   0 root         (0) root         (0)     3915 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/test_tosparse_struphy.py
--rw-rw-rw-   0 root         (0) root         (0)     3506 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/tests/xx_test_preconds.py
--rw-rw-rw-   0 root         (0) root         (0)    14826 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/utilities.py
--rw-rw-rw-   0 root         (0) root         (0)     8978 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/feec/utilities_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.546498 struphy-2.2.0/src/struphy/fields_background/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.546498 struphy-2.2.0/src/struphy/fields_background/electric_equil/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/electric_equil/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)      654 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/fields_background/electric_equil/analytical.py
--rw-rw-rw-   0 root         (0) root         (0)     1671 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/fields_background/electric_equil/base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.546498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    27965 2024-02-22 10:12:47.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/base.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.546498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/eqdsk/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/eqdsk/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.554498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/eqdsk/data/
--rw-rw-rw-   0 root         (0) root         (0)  8579339 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/eqdsk/data/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     9280 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py
--rw-rw-rw-   0 root         (0) root         (0)    67673 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/equils.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.554498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.522498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.554498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/
--rw-rw-rw-   0 root         (0) root         (0)    65028 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
--rw-rw-rw-   0 root         (0) root         (0)     7253 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/parameter.ini
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.554498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/
--rw-rw-rw-   0 root         (0) root         (0)    89724 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
--rw-rw-rw-   0 root         (0) root         (0)     7276 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/parameter.ini
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.554498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/
--rw-rw-rw-   0 root         (0) root         (0)   161316 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
--rw-rw-rw-   0 root         (0) root         (0)     7249 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/parameter.ini
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.554498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/output/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/output/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/output/vtk/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/output/vtk/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/fields_background/mhd_equil/vmec/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/mhd_equil/vmec/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/fields_background/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/fields_background/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     7364 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/tests/test_gvec_equil.py
--rw-rw-rw-   0 root         (0) root         (0)    37618 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/tests/test_mhd_equils.py
--rw-rw-rw-   0 root         (0) root         (0)     6396 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/fields_background/tests/test_numerical_mhd_equil.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/geometry/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/geometry/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    69583 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/geometry/base.py
--rw-rw-rw-   0 root         (0) root         (0)    34140 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/geometry/domains.py
--rw-rw-rw-   0 root         (0) root         (0)    27141 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/geometry/evaluation_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/geometry/map_coef/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/geometry/map_coef/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    33000 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/geometry/mappings_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/geometry/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/geometry/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    40368 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/geometry/tests/test_domain.py
--rw-rw-rw-   0 root         (0) root         (0)    17783 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/geometry/transform_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    10422 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/geometry/utilities.py
--rw-rw-rw-   0 root         (0) root         (0)     3359 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/geometry/utilities_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/initial/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/initial/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     8348 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/initial/eigenfunctions.py
--rw-rw-rw-   0 root         (0) root         (0)    19337 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/initial/perturbations.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/initial/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/initial/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    15320 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/initial/tests/test_init_perturbations.py
--rw-rw-rw-   0 root         (0) root         (0)     2114 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/initial/utilities.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.558498 struphy-2.2.0/src/struphy/io/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/io/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.562498 struphy-2.2.0/src/struphy/io/batch/
--rw-rw-rw-   0 root         (0) root         (0)     1073 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/batch/batch_cobra.sh
--rw-rw-rw-   0 root         (0) root         (0)     1302 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/batch/p_016.sh
--rw-rw-rw-   0 root         (0) root         (0)     1531 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/batch/p_032.sh
--rw-rw-rw-   0 root         (0) root         (0)     1531 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/batch/p_064.sh
--rw-rw-rw-   0 root         (0) root         (0)     1534 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/batch/p_128.sh
--rw-rw-rw-   0 root         (0) root         (0)     1534 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/batch/p_256.sh
--rw-rw-rw-   0 root         (0) root         (0)     1535 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/batch/p_512.sh
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.562498 struphy-2.2.0/src/struphy/io/inp/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/io/inp/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.562498 struphy-2.2.0/src/struphy/io/inp/longer_examples/
--rw-rw-rw-   0 root         (0) root         (0)     4789 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/longer_examples/params_TAE_tokamak.yml
--rw-rw-rw-   0 root         (0) root         (0)     5573 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/longer_examples/params_hybridmhdvlasovcc.yml
--rw-rw-rw-   0 root         (0) root         (0)     5359 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/longer_examples/params_hybridmhdvlasovpc.yml
--rw-rw-rw-   0 root         (0) root         (0)     3632 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/longer_examples/params_linearextendedmhd.yml
--rw-rw-rw-   0 root         (0) root         (0)     6153 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_landau.yml
--rwxrwxrwx   0 root         (0) root         (0)     5865 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_streaming_weibel.yml
--rw-rw-rw-   0 root         (0) root         (0)     6152 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_weibel.yml
--rw-rw-rw-   0 root         (0) root         (0)     8030 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/parameters.yml
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.562498 struphy-2.2.0/src/struphy/io/inp/tutorials/
--rw-rw-rw-   0 root         (0) root         (0)     5564 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/tutorials/params_02.yml
--rw-rw-rw-   0 root         (0) root         (0)     5049 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/tutorials/params_03.yml
--rw-rw-rw-   0 root         (0) root         (0)     2095 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/tutorials/params_04a.yml
--rw-rw-rw-   0 root         (0) root         (0)     3073 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/tutorials/params_04b.yml
--rw-rw-rw-   0 root         (0) root         (0)     5171 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/tutorials/params_05a.yml
--rw-rw-rw-   0 root         (0) root         (0)     5423 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/inp/tutorials/params_05b.yml
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.562498 struphy-2.2.0/src/struphy/io/out/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/io/out/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     4889 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/output_handling.py
--rw-rw-rw-   0 root         (0) root         (0)    17207 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/io/setup.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.562498 struphy-2.2.0/src/struphy/kinetic_background/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/kinetic_background/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     4088 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/kinetic_background/base.py
--rw-rw-rw-   0 root         (0) root         (0)    26509 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/kinetic_background/maxwellians.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.562498 struphy-2.2.0/src/struphy/linear_algebra/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/linear_algebra/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     7831 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/linear_algebra/linalg_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    11750 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/linear_algebra/linalg_kron.py
--rw-rw-rw-   0 root         (0) root         (0)     3718 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/linear_algebra/schur_solver.py
--rw-rw-rw-   0 root         (0) root         (0)     8558 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/linear_algebra/stencil_dot_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    14375 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/linear_algebra/stencil_transpose_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.562498 struphy-2.2.0/src/struphy/linear_algebra/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/linear_algebra/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    11273 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/linear_algebra/tests/test_stencil_dot_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    11179 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/linear_algebra/tests/test_stencil_transpose_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)     8835 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/main.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.566498 struphy-2.2.0/src/struphy/models/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/models/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    60504 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/models/base.py
--rw-rw-rw-   0 root         (0) root         (0)    23453 2024-02-22 13:49:49.000000 struphy-2.2.0/src/struphy/models/fluid.py
--rw-rw-rw-   0 root         (0) root         (0)    49335 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/models/hybrid.py
--rw-rw-rw-   0 root         (0) root         (0)    45632 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/models/kinetic.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.566498 struphy-2.2.0/src/struphy/models/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/models/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     2039 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/models/tests/test_fluid_models.py
--rw-rw-rw-   0 root         (0) root         (0)     1975 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/models/tests/test_hybrid_models.py
--rw-rw-rw-   0 root         (0) root         (0)     1904 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/models/tests/test_kinetic_models.py
--rw-rw-rw-   0 root         (0) root         (0)     1506 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/models/tests/test_toy_models.py
--rw-rw-rw-   0 root         (0) root         (0)     2093 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/models/tests/test_xxpproc.py
--rw-rw-rw-   0 root         (0) root         (0)     6288 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/models/tests/util.py
--rw-rw-rw-   0 root         (0) root         (0)    30839 2024-02-22 13:49:49.000000 struphy-2.2.0/src/struphy/models/toy.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.566498 struphy-2.2.0/src/struphy/pic/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/pic/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.566498 struphy-2.2.0/src/struphy/pic/accumulation/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/pic/accumulation/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    75625 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/pic/accumulation/accum_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    94197 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/pic/accumulation/accum_kernels_gc.py
--rw-rw-rw-   0 root         (0) root         (0)    19951 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/accumulation/filler_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)   267901 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/pic/accumulation/particle_to_mat_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    18526 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/pic/accumulation/particles_to_grid.py
--rw-rw-rw-   0 root         (0) root         (0)    40889 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/base.py
--rw-rw-rw-   0 root         (0) root         (0)    11184 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/particles.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.570498 struphy-2.2.0/src/struphy/pic/pushing/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/pic/pushing/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    81932 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/pushing/eval_kernels_gc.py
--rw-rw-rw-   0 root         (0) root         (0)     9602 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/pushing/pusher.py
--rw-rw-rw-   0 root         (0) root         (0)   115565 2024-02-22 13:11:06.000000 struphy-2.2.0/src/struphy/pic/pushing/pusher_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)   131100 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/pushing/pusher_kernels_gc.py
--rw-rw-rw-   0 root         (0) root         (0)    21808 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/pushing/pusher_utilities_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)     2055 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/sampling_kernels.py
--rw-rw-rw-   0 root         (0) root         (0)    14808 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/sobol_seq.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.570498 struphy-2.2.0/src/struphy/pic/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/pic/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     3078 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_accum_vec_H1.py
--rw-rw-rw-   0 root         (0) root         (0)    18048 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_accumulation.py
--rw-rw-rw-   0 root         (0) root         (0)     3569 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_draw_parallel.py
--rw-rw-rw-   0 root         (0) root         (0)    15922 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_mat_vec_filler.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.570498 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    19407 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/accumulation.py
--rw-rw-rw-   0 root         (0) root         (0)    51401 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/accumulation_kernels_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    22384 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/mappings_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    14097 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/mappings_3d_fast.py
--rw-rw-rw-   0 root         (0) root         (0)    11105 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/pusher.py
--rw-rw-rw-   0 root         (0) root         (0)    64954 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_pos.py
--rw-rw-rw-   0 root         (0) root         (0)    17905 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_vel_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    38066 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_vel_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    14177 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/spline_evaluation_2d.py
--rw-rw-rw-   0 root         (0) root         (0)    33253 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/spline_evaluation_3d.py
--rw-rw-rw-   0 root         (0) root         (0)    31829 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/tests/test_pushers.py
--rw-rw-rw-   0 root         (0) root         (0)     5867 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/utilities.py
--rw-rw-rw-   0 root         (0) root         (0)    33579 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/pic/utilities_kernels.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/polar/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/polar/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    16535 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/polar/basic.py
--rw-rw-rw-   0 root         (0) root         (0)    51750 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/polar/extraction_operators.py
--rw-rw-rw-   0 root         (0) root         (0)    32197 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/polar/linear_operators.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/polar/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/polar/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     4973 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/polar/tests/test_legacy_polar_splines.py
--rw-rw-rw-   0 root         (0) root         (0)    13320 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/polar/tests/test_polar.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/post_processing/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/post_processing/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     6362 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/post_processing/cprofile_analyser.py
--rw-rw-rw-   0 root         (0) root         (0)    18373 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/post_processing/post_processing_tools.py
--rw-rw-rw-   0 root         (0) root         (0)     6489 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/post_processing/pproc_struphy.py
--rw-rw-rw-   0 root         (0) root         (0)     5300 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/post_processing/profile_struphy.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/post_processing/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/post_processing/tests/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/propagators/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/propagators/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     4646 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/propagators/base.py
--rw-rw-rw-   0 root         (0) root         (0)    69711 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/propagators/propagators_coupling.py
--rw-rw-rw-   0 root         (0) root         (0)   142478 2024-02-22 13:49:49.000000 struphy-2.2.0/src/struphy/propagators/propagators_fields.py
--rw-rw-rw-   0 root         (0) root         (0)    53384 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/propagators/propagators_markers.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/propagators/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/propagators/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)    11818 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/propagators/tests/test_fields_propagators.py
--rw-rw-rw-   0 root         (0) root         (0)   618985 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/psydac-0.1.9-py3-none-any.whl
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/tutorials/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/tutorials/__init__.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/tutorials/longer_examples/
--rw-rw-rw-   0 root         (0) root         (0)     8055 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/tutorials/longer_examples/TAE_tokamak.py
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/tutorials/longer_examples/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     6985 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/tutorials/longer_examples/linearextendedmhd.py
--rw-rw-rw-   0 root         (0) root         (0)     4093 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/tutorials/longer_examples/linearmhdvlasov_cc.py
--rw-rw-rw-   0 root         (0) root         (0)     4093 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/tutorials/longer_examples/linearmhdvlasov_pc.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy/tutorials/tests/
--rw-rw-rw-   0 root         (0) root         (0)        0 2024-02-22 17:41:00.000000 struphy-2.2.0/src/struphy/tutorials/tests/__init__.py
--rw-rw-rw-   0 root         (0) root         (0)     1916 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/tutorials/tests/test_tutorials.py
--rw-rw-rw-   0 root         (0) root         (0)      347 2024-02-22 10:12:48.000000 struphy-2.2.0/src/struphy/tutorials/utilities.py
-drwxr-xr-x   0 root         (0) root         (0)        0 2024-02-22 17:41:14.574498 struphy-2.2.0/src/struphy.egg-info/
--rw-r--r--   0 root         (0) root         (0)     3659 2024-02-22 17:41:14.000000 struphy-2.2.0/src/struphy.egg-info/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)    14135 2024-02-22 17:41:14.000000 struphy-2.2.0/src/struphy.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0) root         (0)        1 2024-02-22 17:41:14.000000 struphy-2.2.0/src/struphy.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0) root         (0)       57 2024-02-22 17:41:14.000000 struphy-2.2.0/src/struphy.egg-info/entry_points.txt
--rw-r--r--   0 root         (0) root         (0)      423 2024-02-22 17:41:14.000000 struphy-2.2.0/src/struphy.egg-info/requires.txt
--rw-r--r--   0 root         (0) root         (0)        8 2024-02-22 17:41:14.000000 struphy-2.2.0/src/struphy.egg-info/top_level.txt
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.583135 struphy-2.3.0/
+-rw-rw-rw-   0 root         (0) root         (0)     1115 2024-04-02 11:44:27.000000 struphy-2.3.0/LICENSE
+-rw-r--r--   0 root         (0) root         (0)     3697 2024-04-02 13:29:54.579135 struphy-2.3.0/PKG-INFO
+-rwxrwxrwx   0 root         (0) root         (0)      779 2024-04-02 11:44:27.000000 struphy-2.3.0/README.md
+-rw-rw-rw-   0 root         (0) root         (0)     2453 2024-04-02 13:02:43.000000 struphy-2.3.0/pyproject.toml
+-rw-rw-rw-   0 root         (0) root         (0)      124 2024-04-02 13:29:54.583135 struphy-2.3.0/setup.cfg
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.499135 struphy-2.3.0/src/
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.511135 struphy-2.3.0/src/struphy/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.515135 struphy-2.3.0/src/struphy/bsplines/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/bsplines/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    20756 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/bsplines/bsplines.py
+-rw-rw-rw-   0 root         (0) root         (0)    22248 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/bsplines/bsplines_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)     4855 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/bsplines/evaluation_kernels_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    14460 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/bsplines/evaluation_kernels_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    34494 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/bsplines/evaluation_kernels_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)     6266 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/bsplines/shapefunc_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.515135 struphy-2.3.0/src/struphy/bsplines/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/bsplines/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     7222 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/bsplines/tests/test_bsplines_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    22218 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/bsplines/tests/test_eval_spline_mpi.py
+-rw-rw-rw-   0 root         (0) root         (0)     2210 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/compile_struphy.mk
+-rw-rw-rw-   0 root         (0) root         (0)      434 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/conftest.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.515135 struphy-2.3.0/src/struphy/console/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/console/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     9690 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/console/compile.py
+-rw-rw-rw-   0 root         (0) root         (0)    27928 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/console/main.py
+-rw-rw-rw-   0 root         (0) root         (0)      939 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/console/params.py
+-rw-rw-rw-   0 root         (0) root         (0)     1343 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/console/pproc.py
+-rw-rw-rw-   0 root         (0) root         (0)     7461 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/console/profile.py
+-rw-rw-rw-   0 root         (0) root         (0)     6816 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/console/run.py
+-rw-rw-rw-   0 root         (0) root         (0)    13793 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/console/test.py
+-rw-rw-rw-   0 root         (0) root         (0)     1312 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/console/units.py
+-rw-rw-rw-   0 root         (0) root         (0)     2595 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/dependencies.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.519135 struphy-2.3.0/src/struphy/diagnostics/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/diagnostics/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     6951 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/diagnostics/console_diagn.py
+-rw-rw-rw-   0 root         (0) root         (0)    13985 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/diagnostics/continuous_spectra.py
+-rw-rw-rw-   0 root         (0) root         (0)    12198 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/diagnostics/diagn_tools.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.519135 struphy-2.3.0/src/struphy/diagnostics/paraview/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/diagnostics/paraview/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    13277 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/diagnostics/paraview/mesh_creator.py
+-rw-rw-rw-   0 root         (0) root         (0)     3004 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/diagnostics/paraview/vtk_writer.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.519135 struphy-2.3.0/src/struphy/dispersion_relations/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/dispersion_relations/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    38270 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/dispersion_relations/analytic.py
+-rw-rw-rw-   0 root         (0) root         (0)     3881 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/dispersion_relations/base.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.523135 struphy-2.3.0/src/struphy/eigenvalue_solvers/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     5540 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/derivatives.py
+-rw-rw-rw-   0 root         (0) root         (0)     5136 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/kernels_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)     7722 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/kernels_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    23321 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/kernels_projectors_global.py
+-rw-rw-rw-   0 root         (0) root         (0)    34341 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/kernels_projectors_global_mhd.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.523135 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/
+-rw-rw-rw-   0 root         (0) root         (0)    32191 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/MHD_eigenvalues_cylinder_1D.py
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.527135 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    15856 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)     8521 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kernels_control_variate.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.527135 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     7080 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)    20939 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_kernels_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)    11250 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)     1618 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_cv_kernel_2.py
+-rw-rw-rw-   0 root         (0) root         (0)    21155 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_kernels_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)     9994 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_control_variate.py
+-rw-rw-rw-   0 root         (0) root         (0)     8890 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_cvker.py
+-rw-rw-rw-   0 root         (0) root         (0)    32983 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_kernels_control_variate.py
+-rwxrwxrwx   0 root         (0) root         (0)     9189 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/emw_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)     3606 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/inner_products_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    11738 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/inner_products_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    12358 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/inner_products_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)     3432 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/l2_error_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    17672 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/l2_error_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    17438 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/l2_error_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    16554 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/mass_matrices_3d_pre.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.527135 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    18036 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_arrays.py
+-rw-rw-rw-   0 root         (0) root         (0)    14708 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bb_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)    25336 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bv_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)    46819 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_massless_linear_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    27150 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_vv_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)   138353 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.527135 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.531135 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    10395 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local.py
+-rw-rw-rw-   0 root         (0) root         (0)    22026 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local_mhd.py
+-rw-rw-rw-   0 root         (0) root         (0)   144069 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/mhd_operators_3d_local.py
+-rw-rw-rw-   0 root         (0) root         (0)    72812 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/projectors_local.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.531135 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    94146 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_L2_projector_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)    26256 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_L2.py
+-rw-rw-rw-   0 root         (0) root         (0)    33024 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_local.py
+-rw-rw-rw-   0 root         (0) root         (0)   129599 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_local_projector_kernel.py
+-rw-rw-rw-   0 root         (0) root         (0)     8105 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/mass_matrices_1d.py
+-rw-rw-rw-   0 root         (0) root         (0)    19797 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/mass_matrices_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    21575 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/mass_matrices_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)     9602 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/mhd_axisymmetric_main.py
+-rw-rw-rw-   0 root         (0) root         (0)     2347 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/mhd_axisymmetric_pproc.py
+-rw-rw-rw-   0 root         (0) root         (0)    45855 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/mhd_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    70280 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/mhd_operators_core.py
+-rw-rw-rw-   0 root         (0) root         (0)    85337 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/projectors_global.py
+-rw-rw-rw-   0 root         (0) root         (0)    93566 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/spline_space.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.531135 struphy-2.3.0/src/struphy/eigenvalue_solvers/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    45719 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/eigenvalue_solvers/tests/test_legacy_mhd_projectors.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.531135 struphy-2.3.0/src/struphy/examples/
+-rw-rw-rw-   0 root         (0) root         (0)     2328 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/examples/_draw_parallel.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.535135 struphy-2.3.0/src/struphy/feec/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/feec/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     1873 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/banded_to_stencil_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    20467 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/basis_projection_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    51103 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/basis_projection_ops.py
+-rw-rw-rw-   0 root         (0) root         (0)    21008 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/linear_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    62263 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/mass.py
+-rw-rw-rw-   0 root         (0) root         (0)    25439 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/mass_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    35020 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/preconditioner.py
+-rw-rw-rw-   0 root         (0) root         (0)    24877 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/projectors.py
+-rw-rw-rw-   0 root         (0) root         (0)    79355 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/psydac_derham.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.539135 struphy-2.3.0/src/struphy/feec/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/feec/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    26231 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_basis_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    20660 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_basis_ops.py
+-rw-rw-rw-   0 root         (0) root         (0)     8465 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_derham.py
+-rw-rw-rw-   0 root         (0) root         (0)    10976 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_eval_field.py
+-rw-rw-rw-   0 root         (0) root         (0)    39718 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_field_init.py
+-rw-rw-rw-   0 root         (0) root         (0)     8780 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_l2_projectors.py
+-rw-rw-rw-   0 root         (0) root         (0)     9743 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_lowdim_nel_is_1.py
+-rw-rw-rw-   0 root         (0) root         (0)    40329 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_mass_matrices.py
+-rw-rw-rw-   0 root         (0) root         (0)     3969 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_toarray_struphy.py
+-rw-rw-rw-   0 root         (0) root         (0)     3915 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/test_tosparse_struphy.py
+-rw-rw-rw-   0 root         (0) root         (0)     3506 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/tests/xx_test_preconds.py
+-rw-rw-rw-   0 root         (0) root         (0)    14826 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/utilities.py
+-rw-rw-rw-   0 root         (0) root         (0)     8978 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/utilities_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)     8463 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/feec/variational_utilities.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.539135 struphy-2.3.0/src/struphy/fields_background/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.539135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    28284 2024-04-02 11:44:27.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/base.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.539135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/eqdsk/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/eqdsk/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.547135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/eqdsk/data/
+-rw-rw-rw-   0 root         (0) root         (0)  8579339 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/eqdsk/data/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     9280 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py
+-rw-rw-rw-   0 root         (0) root         (0)    69925 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/equils.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.547135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.503135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.551135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/
+-rw-rw-rw-   0 root         (0) root         (0)    65028 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
+-rw-rw-rw-   0 root         (0) root         (0)     7253 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/parameter.ini
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.551135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/
+-rw-rw-rw-   0 root         (0) root         (0)    89724 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
+-rw-rw-rw-   0 root         (0) root         (0)     7276 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/parameter.ini
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.551135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/
+-rw-rw-rw-   0 root         (0) root         (0)   161316 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat
+-rw-rw-rw-   0 root         (0) root         (0)     7249 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/parameter.ini
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.551135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/output/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/output/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.551135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/output/vtk/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/output/vtk/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.551135 struphy-2.3.0/src/struphy/fields_background/mhd_equil/vmec/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/mhd_equil/vmec/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.551135 struphy-2.3.0/src/struphy/fields_background/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/fields_background/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     7371 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/tests/test_gvec_equil.py
+-rw-rw-rw-   0 root         (0) root         (0)    37618 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/tests/test_mhd_equils.py
+-rw-rw-rw-   0 root         (0) root         (0)     6396 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/fields_background/tests/test_numerical_mhd_equil.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.555135 struphy-2.3.0/src/struphy/geometry/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/geometry/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    69546 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/geometry/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    34179 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/geometry/domains.py
+-rw-rw-rw-   0 root         (0) root         (0)    27141 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/geometry/evaluation_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.555135 struphy-2.3.0/src/struphy/geometry/map_coef/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/geometry/map_coef/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    33000 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/geometry/mappings_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.555135 struphy-2.3.0/src/struphy/geometry/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/geometry/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    40368 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/geometry/tests/test_domain.py
+-rw-rw-rw-   0 root         (0) root         (0)    17783 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/geometry/transform_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    10422 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/geometry/utilities.py
+-rw-rw-rw-   0 root         (0) root         (0)     3359 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/geometry/utilities_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.555135 struphy-2.3.0/src/struphy/initial/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/initial/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     8348 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/initial/eigenfunctions.py
+-rw-rw-rw-   0 root         (0) root         (0)    20990 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/initial/perturbations.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.555135 struphy-2.3.0/src/struphy/initial/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/initial/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    15449 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/initial/tests/test_init_perturbations.py
+-rw-rw-rw-   0 root         (0) root         (0)     2114 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/initial/utilities.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.555135 struphy-2.3.0/src/struphy/io/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/io/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.559135 struphy-2.3.0/src/struphy/io/batch/
+-rw-rw-rw-   0 root         (0) root         (0)     1073 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/batch/batch_cobra.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1302 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/batch/p_016.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1531 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/batch/p_032.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1531 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/batch/p_064.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1534 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/batch/p_128.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1534 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/batch/p_256.sh
+-rw-rw-rw-   0 root         (0) root         (0)     1535 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/batch/p_512.sh
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.559135 struphy-2.3.0/src/struphy/io/inp/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/io/inp/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.559135 struphy-2.3.0/src/struphy/io/inp/longer_examples/
+-rw-rw-rw-   0 root         (0) root         (0)     4747 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/longer_examples/params_TAE_tokamak.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5516 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/longer_examples/params_hybridmhdvlasovcc.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5308 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/longer_examples/params_hybridmhdvlasovpc.yml
+-rw-rw-rw-   0 root         (0) root         (0)     3629 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/longer_examples/params_linearextendedmhd.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5542 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_landau.yml
+-rwxrwxrwx   0 root         (0) root         (0)     5209 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_streaming_weibel.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5451 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_weibel.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5326 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/parameters.yml
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.559135 struphy-2.3.0/src/struphy/io/inp/tutorials/
+-rw-rw-rw-   0 root         (0) root         (0)     5032 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/tutorials/params_02.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5057 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/tutorials/params_03.yml
+-rw-rw-rw-   0 root         (0) root         (0)     2111 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/tutorials/params_04a.yml
+-rw-rw-rw-   0 root         (0) root         (0)     3033 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/tutorials/params_04b.yml
+-rw-rw-rw-   0 root         (0) root         (0)     4895 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/tutorials/params_05a.yml
+-rw-rw-rw-   0 root         (0) root         (0)     5118 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/inp/tutorials/params_05b.yml
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.559135 struphy-2.3.0/src/struphy/io/out/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/io/out/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     4889 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/output_handling.py
+-rw-rw-rw-   0 root         (0) root         (0)    16474 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/io/setup.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.559135 struphy-2.3.0/src/struphy/kinetic_background/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/kinetic_background/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     6091 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/kinetic_background/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    22638 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/kinetic_background/maxwellians.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.563135 struphy-2.3.0/src/struphy/kinetic_background/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/kinetic_background/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    62340 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/kinetic_background/tests/test_maxwellians.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.563135 struphy-2.3.0/src/struphy/linear_algebra/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/linear_algebra/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     7831 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/linear_algebra/linalg_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    11750 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/linear_algebra/linalg_kron.py
+-rw-rw-rw-   0 root         (0) root         (0)     3796 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/linear_algebra/schur_solver.py
+-rw-rw-rw-   0 root         (0) root         (0)     8558 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/linear_algebra/stencil_dot_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    14375 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/linear_algebra/stencil_transpose_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.563135 struphy-2.3.0/src/struphy/linear_algebra/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/linear_algebra/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    11273 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/linear_algebra/tests/test_stencil_dot_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    11179 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/linear_algebra/tests/test_stencil_transpose_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)     8917 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/main.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.563135 struphy-2.3.0/src/struphy/models/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/models/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    65143 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    24579 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/fluid.py
+-rw-rw-rw-   0 root         (0) root         (0)    49262 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/hybrid.py
+-rw-rw-rw-   0 root         (0) root         (0)    60670 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/kinetic.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.567135 struphy-2.3.0/src/struphy/models/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/models/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     2078 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/tests/test_fluid_models.py
+-rw-rw-rw-   0 root         (0) root         (0)     1976 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/tests/test_hybrid_models.py
+-rw-rw-rw-   0 root         (0) root         (0)     1962 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/tests/test_kinetic_models.py
+-rw-rw-rw-   0 root         (0) root         (0)     1585 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/tests/test_toy_models.py
+-rw-rw-rw-   0 root         (0) root         (0)     1993 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/tests/test_xxpproc.py
+-rw-rw-rw-   0 root         (0) root         (0)     6288 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/tests/util.py
+-rw-rw-rw-   0 root         (0) root         (0)    34246 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/models/toy.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.567135 struphy-2.3.0/src/struphy/pic/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/pic/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.567135 struphy-2.3.0/src/struphy/pic/accumulation/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/pic/accumulation/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    75248 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/accumulation/accum_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)   100243 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/accumulation/accum_kernels_gc.py
+-rw-rw-rw-   0 root         (0) root         (0)    19951 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/accumulation/filler_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)   267901 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/accumulation/particle_to_mat_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    19786 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/accumulation/particles_to_grid.py
+-rw-rw-rw-   0 root         (0) root         (0)    42527 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    11016 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/particles.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.571135 struphy-2.3.0/src/struphy/pic/pushing/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/pic/pushing/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    81932 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/pushing/eval_kernels_gc.py
+-rw-rw-rw-   0 root         (0) root         (0)     9602 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/pushing/pusher.py
+-rw-rw-rw-   0 root         (0) root         (0)   115538 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/pushing/pusher_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)   131357 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/pushing/pusher_kernels_gc.py
+-rw-rw-rw-   0 root         (0) root         (0)    21808 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/pushing/pusher_utilities_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)     2055 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/sampling_kernels.py
+-rw-rw-rw-   0 root         (0) root         (0)    14808 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/sobol_seq.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.571135 struphy-2.3.0/src/struphy/pic/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/pic/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     2984 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_accum_vec_H1.py
+-rw-rw-rw-   0 root         (0) root         (0)    18067 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_accumulation.py
+-rw-rw-rw-   0 root         (0) root         (0)    19016 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_binning.py
+-rw-rw-rw-   0 root         (0) root         (0)     3391 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_draw_parallel.py
+-rw-rw-rw-   0 root         (0) root         (0)    15922 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_mat_vec_filler.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.575135 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    19407 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/accumulation.py
+-rw-rw-rw-   0 root         (0) root         (0)    51401 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/accumulation_kernels_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    22384 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/mappings_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    14097 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/mappings_3d_fast.py
+-rw-rw-rw-   0 root         (0) root         (0)    11105 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/pusher.py
+-rw-rw-rw-   0 root         (0) root         (0)    64954 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_pos.py
+-rw-rw-rw-   0 root         (0) root         (0)    17905 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_vel_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    38066 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_vel_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    14177 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/spline_evaluation_2d.py
+-rw-rw-rw-   0 root         (0) root         (0)    33253 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/spline_evaluation_3d.py
+-rw-rw-rw-   0 root         (0) root         (0)    31073 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/tests/test_pushers.py
+-rw-rw-rw-   0 root         (0) root         (0)     5867 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/utilities.py
+-rw-rw-rw-   0 root         (0) root         (0)    36187 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/pic/utilities_kernels.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.575135 struphy-2.3.0/src/struphy/polar/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/polar/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    16535 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/polar/basic.py
+-rw-rw-rw-   0 root         (0) root         (0)    51750 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/polar/extraction_operators.py
+-rw-rw-rw-   0 root         (0) root         (0)    32197 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/polar/linear_operators.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.575135 struphy-2.3.0/src/struphy/polar/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/polar/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     4973 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/polar/tests/test_legacy_polar_splines.py
+-rw-rw-rw-   0 root         (0) root         (0)    13320 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/polar/tests/test_polar.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.575135 struphy-2.3.0/src/struphy/post_processing/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/post_processing/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     6362 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/post_processing/cprofile_analyser.py
+-rw-rw-rw-   0 root         (0) root         (0)    18376 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/post_processing/post_processing_tools.py
+-rw-rw-rw-   0 root         (0) root         (0)     6489 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/post_processing/pproc_struphy.py
+-rw-rw-rw-   0 root         (0) root         (0)     5300 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/post_processing/profile_struphy.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.575135 struphy-2.3.0/src/struphy/post_processing/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/post_processing/tests/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.579135 struphy-2.3.0/src/struphy/propagators/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/propagators/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     5125 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/propagators/base.py
+-rw-rw-rw-   0 root         (0) root         (0)    64977 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/propagators/propagators_coupling.py
+-rw-rw-rw-   0 root         (0) root         (0)   181345 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/propagators/propagators_fields.py
+-rw-rw-rw-   0 root         (0) root         (0)    52995 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/propagators/propagators_markers.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.579135 struphy-2.3.0/src/struphy/propagators/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/propagators/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)    20765 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/propagators/tests/test_gyrokinetic_poisson.py
+-rw-rw-rw-   0 root         (0) root         (0)    15405 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/propagators/tests/test_poisson.py
+-rw-rw-rw-   0 root         (0) root         (0)   622468 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/psydac-0.1.12-py3-none-any.whl
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.579135 struphy-2.3.0/src/struphy/tutorials/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/tutorials/__init__.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.579135 struphy-2.3.0/src/struphy/tutorials/longer_examples/
+-rw-rw-rw-   0 root         (0) root         (0)     8055 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/tutorials/longer_examples/TAE_tokamak.py
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/tutorials/longer_examples/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     6985 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/tutorials/longer_examples/linearextendedmhd.py
+-rw-rw-rw-   0 root         (0) root         (0)     4093 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/tutorials/longer_examples/linearmhdvlasov_cc.py
+-rw-rw-rw-   0 root         (0) root         (0)     4093 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/tutorials/longer_examples/linearmhdvlasov_pc.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.579135 struphy-2.3.0/src/struphy/tutorials/tests/
+-rw-rw-rw-   0 root         (0) root         (0)        0 2024-04-02 13:29:42.000000 struphy-2.3.0/src/struphy/tutorials/tests/__init__.py
+-rw-rw-rw-   0 root         (0) root         (0)     1917 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/tutorials/tests/test_tutorials.py
+-rw-rw-rw-   0 root         (0) root         (0)      442 2024-04-02 11:44:28.000000 struphy-2.3.0/src/struphy/tutorials/utilities.py
+drwxr-xr-x   0 root         (0) root         (0)        0 2024-04-02 13:29:54.579135 struphy-2.3.0/src/struphy.egg-info/
+-rw-r--r--   0 root         (0) root         (0)     3697 2024-04-02 13:29:54.000000 struphy-2.3.0/src/struphy.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)    14200 2024-04-02 13:29:54.000000 struphy-2.3.0/src/struphy.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0) root         (0)        1 2024-04-02 13:29:54.000000 struphy-2.3.0/src/struphy.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0) root         (0)       57 2024-04-02 13:29:54.000000 struphy-2.3.0/src/struphy.egg-info/entry_points.txt
+-rw-r--r--   0 root         (0) root         (0)      446 2024-04-02 13:29:54.000000 struphy-2.3.0/src/struphy.egg-info/requires.txt
+-rw-r--r--   0 root         (0) root         (0)        8 2024-04-02 13:29:54.000000 struphy-2.3.0/src/struphy.egg-info/top_level.txt
```

### Comparing `struphy-2.2.0/LICENSE` & `struphy-2.3.0/LICENSE`

 * *Files 0% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-Copyright (c) 2019-2023, Struphy developers, Max Planck Institute for Plasma Physics
+Copyright (c) 2019-2024, Struphy developers, Max Planck Institute for Plasma Physics
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and 
 associated documentation files (the "Software"), to deal in the Software without restriction, 
 including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
 and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, 
 subject to the following conditions:
```

### Comparing `struphy-2.2.0/PKG-INFO` & `struphy-2.3.0/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 Metadata-Version: 2.1
 Name: struphy
-Version: 2.2.0
+Version: 2.3.0
 Summary: Multi-model plasma physics package
 Author: Max Planck Institute for Plasma Physics
 Author-email: stefan.possanner@ipp.mpg.de, eric.sonnendruecker@ipp.mpg.de
-License: Copyright (c) 2019-2023, Struphy developers, Max Planck Institute for Plasma Physics
+License: Copyright (c) 2019-2024, Struphy developers, Max Planck Institute for Plasma Physics
         
         Permission is hereby granted, free of charge, to any person obtaining a copy of this software and 
         associated documentation files (the "Software"), to deal in the Software without restriction, 
         including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
         and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, 
         subject to the following conditions:
         
@@ -27,38 +27,39 @@
 Project-URL: Bug Tracker, https://gitlab.mpcdf.mpg.de/struphy/struphy/-/issues
 Keywords: plasma physics, fusion, numerical modeling, partial differential equations, energetic particles
 Classifier: Programming Language :: Python :: 3
 Requires-Python: <3.12,>=3.7
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: PyYAML==6.0.1
-Requires-Dist: argcomplete==3.2.1
+Requires-Dist: argcomplete==3.2.3
 Requires-Dist: docutils==0.20.1
-Requires-Dist: gvec-to-python==1.2.0
+Requires-Dist: gvec-to-python==1.2.1
 Requires-Dist: h5py==3.10.0
-Requires-Dist: ipyparallel==8.6.1
+Requires-Dist: ipyparallel==8.7.0
+Requires-Dist: lxml_html_clean==0.1.0
 Requires-Dist: m2r2==0.3.3.post2
-Requires-Dist: matplotlib==3.8.2
+Requires-Dist: matplotlib==3.8.3
 Requires-Dist: mistune==0.8.4
 Requires-Dist: mpi4py==3.1.5
 Requires-Dist: myst-parser==2.0.0
 Requires-Dist: nbsphinx==0.9.3
-Requires-Dist: notebook==7.0.6
+Requires-Dist: notebook==7.1.2
 Requires-Dist: numpy==1.24.4
-Requires-Dist: pyccel==1.11.1
-Requires-Dist: pydata-sphinx-theme==0.15.1
-Requires-Dist: pytest==7.4.4
+Requires-Dist: pyccel==1.11.2
+Requires-Dist: pydata-sphinx-theme==0.15.2
+Requires-Dist: pytest==8.1.1
 Requires-Dist: pytest-monitor==1.6.6
 Requires-Dist: pytest-mpi==0.6
-Requires-Dist: scipy==1.11.4
+Requires-Dist: scipy==1.12.0
 Requires-Dist: Sphinx==7.2.6
 Requires-Dist: sphinxcontrib-napoleon==0.7
-Requires-Dist: tqdm==4.66.1
+Requires-Dist: tqdm==4.66.2
 Requires-Dist: vtk==9.3.0
-Requires-Dist: wheel==0.42.0
+Requires-Dist: wheel==0.43.0
 
 # Struphy - Structure-preserving hybrid codes
 
 A Python package for plasma physics PDEs.
 
 See the [Struphy documentation](https://struphy.pages.mpcdf.de/struphy/index.html) for details.
```

### Comparing `struphy-2.2.0/README.md` & `struphy-2.3.0/README.md`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/pyproject.toml` & `struphy-2.3.0/pyproject.toml`

 * *Files 7% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 [build-system]
 requires = ["setuptools>=61.0"]
 build-backend = "setuptools.build_meta"
 
 [project]
 name = "struphy"
-version = "2.2.0"
+version = "2.3.0"
 readme = "README.md"
 requires-python = ">=3.7, <3.12"
 license = {file = "LICENSE"}
 authors = [
   { name = "Max Planck Institute for Plasma Physics"},
   { email = "stefan.possanner@ipp.mpg.de"},
   { email = "eric.sonnendruecker@ipp.mpg.de"}
@@ -16,38 +16,39 @@
 description = "Multi-model plasma physics package"
 keywords = ["plasma physics, fusion, numerical modeling, partial differential equations, energetic particles"]
 classifiers = [
     "Programming Language :: Python :: 3",
     ]
 dependencies = [
     'PyYAML==6.0.1',
-    'argcomplete==3.2.1',
+    'argcomplete==3.2.3',
     'docutils==0.20.1',
-    'gvec-to-python==1.2.0',
+    'gvec-to-python==1.2.1',
     'h5py==3.10.0',
-    'ipyparallel==8.6.1',
+    'ipyparallel==8.7.0',
+    'lxml_html_clean==0.1.0',
     'm2r2==0.3.3.post2',
-    'matplotlib==3.8.2',
+    'matplotlib==3.8.3',
     'mistune==0.8.4',
     'mpi4py==3.1.5',
     'myst-parser==2.0.0',
     'nbsphinx==0.9.3',
-    'notebook==7.0.6',
+    'notebook==7.1.2',
     'numpy==1.24.4',
-    'pyccel==1.11.1',
-    'pydata-sphinx-theme==0.15.1',
-    'pytest==7.4.4',
+    'pyccel==1.11.2',
+    'pydata-sphinx-theme==0.15.2',
+    'pytest==8.1.1',
     'pytest-monitor==1.6.6',
     'pytest-mpi==0.6',
-    'scipy==1.11.4',
+    'scipy==1.12.0',
     'Sphinx==7.2.6',
     'sphinxcontrib-napoleon==0.7',
-    'tqdm==4.66.1',
+    'tqdm==4.66.2',
     'vtk==9.3.0',
-    'wheel==0.42.0',
+    'wheel==0.43.0',
 ]
 
 [project.urls]
 homepage = "https://struphy.pages.mpcdf.de/struphy/"
 documentation = "https://struphy.pages.mpcdf.de/struphy/"
 repository = "https://gitlab.mpcdf.mpg.de/struphy/struphy"
 changelog = "https://gitlab.mpcdf.mpg.de/struphy/struphy/-/blob/devel/CHANGELOG.md"
@@ -75,9 +76,9 @@
 'struphy.io.inp' = ['parameters.yml',
                     'tests/*.yml',
                     'tutorials/*.yml',
                     'longer_examples/*.yml',
                     ]
                     
 struphy = ['compile_struphy.mk',
-           'psydac-0.1.9-py3-none-any.whl',
+           'psydac-0.1.12-py3-none-any.whl',
            ]
```

### Comparing `struphy-2.2.0/src/struphy/bsplines/bsplines.py` & `struphy-2.3.0/src/struphy/bsplines/bsplines.py`

 * *Files 0% similar despite different names*

```diff
@@ -369,15 +369,15 @@
 
     return mat
 
 
 # ==============================================================================
 def histopolation_matrix(knots, degree, xgrid, periodic):
     """
-    Computes the histopolation matrix $H_ij = int_x_i^x_{i+1} D_j(x) dx$ of the M_splines.
+    Computes the histopolation matrix $H_ij = int_{x_i}^x_{i+1} D_j(x) dx$ of the M_splines.
 
     Parameters
     ----------
     knots : 1D array_like
         Knots sequence.
 
     degree : int
```

### Comparing `struphy-2.2.0/src/struphy/bsplines/bsplines_kernels.py` & `struphy-2.3.0/src/struphy/bsplines/bsplines_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/bsplines/evaluation_kernels_1d.py` & `struphy-2.3.0/src/struphy/bsplines/evaluation_kernels_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/bsplines/evaluation_kernels_2d.py` & `struphy-2.3.0/src/struphy/bsplines/evaluation_kernels_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/bsplines/evaluation_kernels_3d.py` & `struphy-2.3.0/src/struphy/bsplines/evaluation_kernels_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/bsplines/shapefunc_kernels.py` & `struphy-2.3.0/src/struphy/bsplines/shapefunc_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/bsplines/tests/test_bsplines_kernels.py` & `struphy-2.3.0/src/struphy/bsplines/tests/test_bsplines_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/bsplines/tests/test_eval_spline_mpi.py` & `struphy-2.3.0/src/struphy/bsplines/tests/test_eval_spline_mpi.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/compile_struphy.mk` & `struphy-2.3.0/src/struphy/compile_struphy.mk`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/console/compile.py` & `struphy-2.3.0/src/struphy/console/compile.py`

 * *Files 0% similar despite different names*

```diff
@@ -204,15 +204,15 @@
         if _num >= 180:
             flags += ' --conda-warnings=off'
 
         if verbose:
             flags += ' --verbose'
 
         # install psydac from wheel if not there
-        current_ver = '0.1.9'
+        current_ver = '0.1.12'
         psydac_file = 'psydac-' + current_ver + '-py3-none-any.whl'
 
         try:
             import psydac
             import importlib.metadata
 
             your_ver = importlib.metadata.version("psydac")
```

### Comparing `struphy-2.2.0/src/struphy/console/main.py` & `struphy-2.3.0/src/struphy/console/main.py`

 * *Files 1% similar despite different names*

```diff
@@ -36,15 +36,15 @@
     parser = argparse.ArgumentParser(prog='struphy',
                                      formatter_class=CustomFormatter,
                                      description='Struphy: STRUcture-Preserving HYbrid codes for plasma physics.',
                                      epilog=epilog_message)
 
     # version message
     version_message = f'Struphy {__version__}\n'
-    version_message += 'Copyright 2019-2023 (c) Struphy dev team | Max Planck Institute for Plasma Physics\n'
+    version_message += 'Copyright 2019-2024 (c) Struphy dev team | Max Planck Institute for Plasma Physics\n'
     version_message += 'MIT license\n'
 
     # state dictionary
     try:
         with open(os.path.join(libpath, 'state.yml')) as f:
             state = yaml.load(f, Loader=yaml.FullLoader)
     except FileNotFoundError:
@@ -84,15 +84,16 @@
     all_folders = os.listdir(o_path)
     out_folders = []
     for name in all_folders:
         if '.' not in name:
             out_folders += [name]
 
     # check batch scripts in current batch path:
-    batch_files = recursive_get_files(b_path, contains=('.sh'), out=[], prefix=[])
+    batch_files = recursive_get_files(
+        b_path, contains=('.sh'), out=[], prefix=[])
 
     # collect available model, contains=('.yml', '.yaml')s
     list_fluid = []
     fluid_string = ''
     for name, obj in inspect.getmembers(fluid):
         if inspect.isclass(obj):
             if name not in {'StruphyModel', }:
@@ -221,19 +222,19 @@
     parser_compile.add_argument('-s', '--status',
                                 help='print current Struphy compilation status on screen',
                                 action='store_true')
 
     parser_compile.add_argument('-v', '--verbose',
                                 help='call pyccel with --verbose compiler option',
                                 action='store_true')
-    
+
     parser_compile.add_argument('--dependencies',
                                 help='print Struphy kernels to be compiled (.py) and their dependencies (.so) on screen',
                                 action='store_true')
-    
+
     parser_compile.add_argument('-y', '--yes',
                                 help='say yes to prompt when changing the language',
                                 action='store_true')
 
     # 2. "run" sub-command
     parser_run = subparsers.add_parser('run',
                                        formatter_class=lambda prog: argparse.RawTextHelpFormatter(
@@ -302,15 +303,15 @@
                             metavar='N',
                             help='use "mpirun -n N" to launch a parallel Struphy run (default=1)',
                             default=1,)
 
     parser_run.add_argument('--debug',
                             help='launch a Cobra debug run, see https://docs.mpcdf.mpg.de/doc/computing/cobra-user-guide.html#interactive-debug-runs',
                             action='store_true',)
-    
+
     parser_run.add_argument('--cprofile',
                             help='run with Cprofile',
                             action='store_true',)
 
     # 3. "units" sub-command
     parser_units = subparsers.add_parser(
         'units',
@@ -432,52 +433,51 @@
                               default=1)
 
     # 7. "test" sub-command
     parser_test = subparsers.add_parser('test',
                                         formatter_class=lambda prog: argparse.RawTextHelpFormatter(
                                             prog, max_help_position=30),
                                         help='run Struphy tests',
-                                        description='Run available unit tests or test Struphy models, propagators or tutorials.')
+                                        description='Run available unit tests or test Struphy models or tutorials.')
 
     parser_test.add_argument('group',
                              type=str,
                              choices=list_models +
-                             ['models'] + ['unit'] + ['propagators'] +
+                             ['models'] + ['unit'] +
                              ['tutorials'] + ['timings'],
                              metavar='GROUP',
                              help='can be either:\na) a model name (tests on 1 MPI process in "Cuboid", "HollowTorus" and "Tokamak" geometries) \
                                 \nb) "models" for quick testing of all models \
                                 \nc) "unit" for performing unit tests \
-                                \nd) "propagators" for testing all propagators \
-                                \ne) "tutorials" for notebook tutorials, see `https://struphy.pages.mpcdf.de/struphy/sections/tutorials.html`_ \
-                                \nf) "timings" for creating .html and .json files of test metrics (include --verbose to print metrics to screen)',)
+                                \nd) "tutorials" for notebook tutorials, see `https://struphy.pages.mpcdf.de/struphy/sections/tutorials.html`_ \
+                                \ne) "timings" for creating .html and .json files of test metrics (include --verbose to print metrics to screen)',)
 
     parser_test.add_argument('--mpi',
                              type=int,
                              metavar='N',
                              help='set number of MPI processes used in tests (must be >1, default=2), has no effect if GROUP=a)',
                              default=2)
 
     parser_test.add_argument('-f', '--fast',
                              help='test model(s) just in slab geometry (Cuboid)',
                              action='store_true')
 
     parser_test.add_argument('-v', '--verbose',
                              help='print timings to screen',
                              action='store_true')
-    
+
     parser_test.add_argument('--monitor',
                              help='use pytest-monitor in tests',
                              action='store_true')
 
     parser_test.add_argument('-n',
                              type=int,
                              help='specific tutorial simulation to run (int, optional)',
                              default=None)
-    
+
     parser_test.add_argument('-T', '--Tend',
                              type=float,
                              help='if GROUP=a), simulation end time in units of the model (default=0.015 with dt=0.005), data is only saved at TEND if set',
                              default=None)
 
     # parse argument
     argcomplete.autocomplete(parser)
@@ -691,15 +691,15 @@
             else:
                 out += [os.path.join(prefix[-1], name)]
         elif os.path.isdir(os.path.join(path, name)):
             if len(prefix) == 0:
                 prefix = [name]
             else:
                 prefix += [os.path.join(prefix[-1], name)]
-            recursive_get_files(os.path.join(path, name), 
-                                contains=contains, 
-                                out=out, 
+            recursive_get_files(os.path.join(path, name),
+                                contains=contains,
+                                out=out,
                                 prefix=prefix)
     if n_folders == 0 and len(prefix) != 0:
         prefix.pop()
 
-    return out
+    return out
```

### Comparing `struphy-2.2.0/src/struphy/console/params.py` & `struphy-2.3.0/src/struphy/console/params.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/console/pproc.py` & `struphy-2.3.0/src/struphy/console/pproc.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/console/profile.py` & `struphy-2.3.0/src/struphy/console/profile.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/console/run.py` & `struphy-2.3.0/src/struphy/console/run.py`

 * *Files 2% similar despite different names*

```diff
@@ -145,19 +145,20 @@
                        str(mpi)] + cmd_python + cprofile*cmd_cprofile + cmd_main
 
         # add restart flag
         if restart:
             command += ['-r']
             
         if cprofile:
-            print('Cprofile turned on.')
+            print('\nCprofile turned on.')
         else:
-            print('Cprofile turned off.')
+            print('\nCprofile turned off.')
 
         # run command as subprocess
+        print(f"\nRunning the following command:\n{' '.join(command)}")
         subprocess.run(command, check=True, cwd=libpath)
 
     # run in batch mode
     else:
 
         # create output folder if it does not exit
         if not os.path.exists(output_abs):
```

### Comparing `struphy-2.2.0/src/struphy/console/test.py` & `struphy-2.3.0/src/struphy/console/test.py`

 * *Files 2% similar despite different names*

```diff
@@ -49,15 +49,15 @@
 
         subprocess.run(['mpirun',
                         '-n',
                         str(mpi),
                         'pytest',
                         '--no-monitor'*(not monitor),
                         '-k',
-                        'not _models and not _propagators and not _tutorial and not pproc',
+                        'not _models and not _tutorial and not pproc',
                         '--with-mpi',
                         '--restrict-scope-to',
                         'module',
                         '--db',
                         '_pymon/.pymon_unit',
                         '--description',
                         f'language={state["last_used_language"]}, compiler={state["last_used_compiler"]}, omp_pic={state["last_used_omp_pic"]}, omp_feec={state["last_used_omp_feec"]}',
@@ -123,39 +123,14 @@
         subprocess.run(['pytest',
                         '-k',
                         'pproc',
                         '-s',
                         '--no-monitor',],
                        check=True, cwd=libpath)
 
-    elif 'propagators' in group:
-        pymon_file = os.path.join(pymon_abs, '.pymon_propagators')
-        if os.path.isfile(pymon_file):
-            os.remove(pymon_file)
-
-        subprocess.run(['mpirun',
-                        '-n',
-                        str(mpi),
-                        'pytest',
-                        '--no-monitor'*(not monitor),
-                        '-k',
-                        '_propagators',
-                        '--with-mpi',
-                        '--restrict-scope-to',
-                        'module',
-                        '--db',
-                        '_pymon/.pymon_propagators',
-                        '--description',
-                        f'language={state["last_used_language"]}, compiler={state["last_used_compiler"]}, omp_pic={state["last_used_omp_pic"]}, omp_feec={state["last_used_omp_feec"]}',
-                        '--tag',
-                        f'struphy={importlib.metadata.version("struphy")}',
-                        '--tag',
-                        f'pyccel={pyccel.__version__}',],
-                       check=True, cwd=libpath)
-
     elif 'tutorials' in group:
         pymon_file = os.path.join(pymon_abs, '.pymon_tutorials')
         if os.path.isfile(pymon_file):
             os.remove(pymon_file)
 
         import pytest
 
@@ -200,15 +175,15 @@
         #                        f'struphy={importlib.metadata.version("struphy")}',
         #                        '--tag',
         #                        f'pyccel={pyccel.__version__}',
         #                        os.path.join(libpath, 'tutorials')])
 
     elif 'timings' in group:
 
-        for gr in ['unit', 'models', 'propagators', 'tutorials']:
+        for gr in ['unit', 'models', 'tutorials']:
             _file = os.path.join(pymon_abs, '.pymon_' + gr)
             if os.path.isfile(_file):
                 pymon_html_json(gr, verbose=verbose)
 
     else:
         from struphy.models.tests import test_toy_models, test_fluid_models, test_kinetic_models, test_hybrid_models
         from struphy.models.tests.test_xxpproc import test_pproc_codes
@@ -234,15 +209,15 @@
     '''Use sqlite3 to create Struphy timings in .html and .json format from .pymon files.
 
     Output is written to _pymon/ in the struphy root directory.
 
     Parameters
     ----------
     group : str
-        One of "unit", "models", "propagators", "tutorials" or "pproc".
+        One of "unit", "models", "tutorials" or "pproc".
     '''
 
     libpath = struphy.__path__[0]
 
     pymon_abs = os.path.join(libpath, '_pymon/')
     if not os.path.exists(pymon_abs):
         os.mkdir(pymon_abs)
```

### Comparing `struphy-2.2.0/src/struphy/console/units.py` & `struphy-2.3.0/src/struphy/console/units.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/dependencies.py` & `struphy-2.3.0/src/struphy/dependencies.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/diagnostics/console_diagn.py` & `struphy-2.3.0/src/struphy/diagnostics/console_diagn.py`

 * *Files 26% similar despite different names*

```diff
@@ -67,31 +67,62 @@
     saved_scalars = file['scalar']
     saved_time = file['time']['value'][:]
 
     # read in parameters
     with open(path + '/parameters.yml') as file:
         params = yaml.load(file, Loader=yaml.FullLoader)
 
+    # Get model name
+    with open(path + '/meta.txt', 'r') as file:
+        for line in file.readlines():
+            if line[0:10] == 'model_name':
+                model_name = line.split(':')[1].strip()
+
     if 'plot_scalars' in actions:
         plot_scalars(saved_time,
                      saved_scalars,
                      scalars_plot=scalars_plot,
                      do_log=do_log,
                      save_plot=True,
                      savedir=path)
 
     if 'plot_distr' in actions:
         for species in params['kinetic'].keys():
+            # Get model class
+            from struphy.models import fluid, kinetic, hybrid, toy
+            objs = [fluid, kinetic, hybrid, toy]
+            for obj in objs:
+                try:
+                    model_class = getattr(obj, model_name)
+                except AttributeError:
+                    pass
+
+            # get particles class name
+            species_dict = model_class.species()
+            particles_class_name = species_dict['kinetic'][species]
+
+            # Get default background of particles class
+            from struphy.pic import particles
+            default_bckgr_type = getattr(particles, particles_class_name).default_bckgr_params()['type']
+
+            # Get default background parameters
+            from struphy.kinetic_background import maxwellians
+            default_bckgr_params = getattr(maxwellians, default_bckgr_type).default_bckgr_params()
+
             # Set velocity point of evaluation to v_shift of background params if not given by input
             if params['kinetic'][species]['markers']['type'] == 'full_f':
                 for k in range(1, 4):
                     if grid_slices['v' + str(k)] is None:
-                        bckgr_type = params['kinetic'][species]['init']['type']
-                        bckgr_param = params['kinetic'][species]['init'][bckgr_type]['u' + str(
-                            k)]
+                        key = 'u' + str(k)
+                        bckgr_type = params['kinetic'][species]['background']['type']
+
+                        if key not in params['kinetic'][species]['background'][bckgr_type].keys():
+                            bckgr_param = default_bckgr_params[key]
+                        else:
+                            bckgr_param = params['kinetic'][species]['background'][bckgr_type][key]
                         if isinstance(bckgr_param, dict):
                             grid_slices['v' + str(k)] = \
                                 bckgr_param['u0' + str(k)]
                         else:
                             grid_slices['v' + str(k)] = bckgr_param
             elif params['kinetic'][species]['markers']['type'] == 'delta_f' \
                     or params['kinetic'][species]['markers']['type'] == 'control_variate':
@@ -105,17 +136,21 @@
                                 bckgr_param['u0' + str(k)]
                         else:
                             grid_slices['v' + str(k)] = bckgr_param
 
             # Get index of where to plot in time
             time_idx = np.argmin(np.abs(time - saved_time))
 
-            plot_distr_fun(path=os.path.join(path, 'post_processing', 'kinetic_data', species),
-                           time_idx=time_idx,
-                           grid_slices=grid_slices,
-                           save_plot=True, savepath=path)
+            plot_distr_fun(
+                path=os.path.join(
+                    path, 'post_processing', 'kinetic_data', species
+                ),
+                time_idx=time_idx,
+                grid_slices=grid_slices,
+                save_plot=True, savepath=path,
+            )
 
     file.close()
 
 
 if __name__ == '__main__':
     main()
```

### Comparing `struphy-2.2.0/src/struphy/diagnostics/continuous_spectra.py` & `struphy-2.3.0/src/struphy/diagnostics/continuous_spectra.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/diagnostics/diagn_tools.py` & `struphy-2.3.0/src/struphy/diagnostics/diagn_tools.py`

 * *Files 1% similar despite different names*

```diff
@@ -8,16 +8,15 @@
 from struphy.dispersion_relations import analytic
 
 
 def power_spectrum_2d(values, name, code, grids,
                grids_mapped=None, component=0, slice_at=[None, 0, 0],
                do_plot=False, disp_name=None, disp_params={},
                save_plot=False, save_name=None, file_format='png'):
-    """
-    Perform fft in space-time, (t, x) -> (omega, k), where x can be a logical or physical coordinate.
+    """ Perform fft in space-time, (t, x) -> (omega, k), where x can be a logical or physical coordinate.
     Returns values if plot=False.
 
     Parameters
     ----------
         values : dict
             Dictionary holding values of a B-spline FemField on the grid as 3d np.arrays:
             values[n] contains the values at time step n, where n = 0:Nt-1:step with 0<step.
@@ -172,16 +171,15 @@
             plt.show()
 
     else:
         return kvec, omega, dispersion
 
 
 def plot_scalars(time, scalar_quantities, scalars_plot=[], do_log=False, save_plot=False, savedir=None, file_format='png'):
-    """
-    Plot the scalar quantities and the relative error in the total energy for a simulation.
+    """ Plot the scalar quantities and the relative error in the total energy for a simulation.
 
     Parameters
     ----------
     scalar_quantities : dict
         HDF5 dictionary dataset containing the scalar quantities that were saved during the simulation
 
     scalars_plot : list
@@ -247,16 +245,15 @@
         assert savedir is not None, 'When wanting to save the plot a path has to be given!'
         plt.savefig(os.path.join(savedir, 'scalars' + '.' + file_format))
     else:
         plt.show()
 
 
 def plot_distr_fun(path, time_idx, grid_slices, save_plot=False, savepath=None, file_format='png'):
-    """
-    Plot the binned distribution function at given slices of the phase space.
+    """ Plot the binned distribution function at given slices of the phase space.
 
     Parameters
     ----------
     path : str
         Path to the kinetic data of the species.
 
     time : float
```

### Comparing `struphy-2.2.0/src/struphy/diagnostics/paraview/mesh_creator.py` & `struphy-2.3.0/src/struphy/diagnostics/paraview/mesh_creator.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/diagnostics/paraview/vtk_writer.py` & `struphy-2.3.0/src/struphy/diagnostics/paraview/vtk_writer.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/dispersion_relations/analytic.py` & `struphy-2.3.0/src/struphy/dispersion_relations/analytic.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/dispersion_relations/base.py` & `struphy-2.3.0/src/struphy/dispersion_relations/base.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/derivatives.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/derivatives.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/kernels_2d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/kernels_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/kernels_3d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/kernels_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/kernels_projectors_global.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/kernels_projectors_global.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/kernels_projectors_global_mhd.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/kernels_projectors_global_mhd.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/MHD_eigenvalues_cylinder_1D.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/MHD_eigenvalues_cylinder_1D.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/control_variate.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kernels_control_variate.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kernels_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_control_variate.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_kernels_control_variate.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fB_massless_kernels_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_control_variate.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_cv_kernel_2.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_cv_kernel_2.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_kernels_control_variate.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/fnB_massless_kernels_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_control_variate.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_cvker.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_cvker.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_kernels_control_variate.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/control_variates/kinetic_extended/massless_kernels_control_variate.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/emw_operators.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/emw_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/inner_products_1d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/inner_products_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/inner_products_2d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/inner_products_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/inner_products_3d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/inner_products_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/l2_error_1d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/l2_error_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/l2_error_2d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/l2_error_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/l2_error_3d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/l2_error_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/mass_matrices_3d_pre.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/mass_matrices_3d_pre.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_arrays.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_arrays.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bb_kernel.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bb_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bv_kernel.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_bv_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_massless_linear_operators.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_massless_linear_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_vv_kernel.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/massless_operators/fB_vv_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/mhd_operators_MF.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local_mhd.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/kernels_projectors_local_mhd.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/mhd_operators_3d_local.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/mhd_operators_3d_local.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/projectors_local.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/pro_local/projectors_local.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_L2_projector_kernel.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_L2_projector_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_L2.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_L2.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_local.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_function_projectors_local.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_local_projector_kernel.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/legacy/projectors_local/shape_pro_local/shape_local_projector_kernel.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/mass_matrices_1d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/mass_matrices_1d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/mass_matrices_2d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/mass_matrices_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/mass_matrices_3d.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/mass_matrices_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/mhd_axisymmetric_main.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/mhd_axisymmetric_main.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/mhd_axisymmetric_pproc.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/mhd_axisymmetric_pproc.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/mhd_operators.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/mhd_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/mhd_operators_core.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/mhd_operators_core.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/projectors_global.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/projectors_global.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/spline_space.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/spline_space.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/eigenvalue_solvers/tests/test_legacy_mhd_projectors.py` & `struphy-2.3.0/src/struphy/eigenvalue_solvers/tests/test_legacy_mhd_projectors.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/examples/_draw_parallel.py` & `struphy-2.3.0/src/struphy/examples/_draw_parallel.py`

 * *Files 12% similar despite different names*

```diff
@@ -36,15 +36,15 @@
     if rank == 0:
         print()
         print('Domain decomposition according to : ')
         print(derham.domain_array)
 
     # create particles
     particles = Particles6D(
-        'energetic_ions', **marker_params, derham=derham)
+        'energetic_ions', **marker_params, derham=derham, bckgr_params=None)
 
     comm.Barrier()
     print('Number of particles w/wo holes on each process before sorting : ')
     print('Rank', rank, ':', particles.n_mks_loc, particles.markers.shape[0])
 
     domain.show(grid_info=derham.domain_array,
                 markers=particles.markers_wo_holes)
```

### Comparing `struphy-2.2.0/src/struphy/feec/banded_to_stencil_kernels.py` & `struphy-2.3.0/src/struphy/feec/banded_to_stencil_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/basis_projection_kernels.py` & `struphy-2.3.0/src/struphy/feec/basis_projection_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/basis_projection_ops.py` & `struphy-2.3.0/src/struphy/feec/basis_projection_ops.py`

 * *Files 2% similar despite different names*

```diff
@@ -37,15 +37,15 @@
     """
 
     def __init__(self, derham, domain, **weights):
 
         if np.any([p == 1 and Nel > 1 for p, Nel in zip(derham.p, derham.Nel)]):
             if derham.comm.Get_rank() == 0:
                 print(
-                    f'\nWARNING: Class "BasisProjectionOperators" called with p={derham.p} (interpolation of piece-wise constants should be avoided).\n')
+                    f'\nWARNING: Class "BasisProjectionOperators" called with p={derham.p} (interpolation of piece-wise constants should be avoided).')
 
         self._derham = derham
         self._domain = domain
         self._weights = weights
 
     @property
     def derham(self):
@@ -1281,43 +1281,47 @@
             span[n, nq] = span_tmp  # % space.nbasis
 
     return span, basis
 
 
 class CoordinateProjector(LinearOperator):
     r"""
-    Class of projectors on one component of a ProductFemSpace. Represent the projection on the i-th component :
+    Class of projectors on one component of a ProductFemSpace. 
+    Represent the projection on the :math:`\mu`-th component :
 
     .. math::
-        P_i : X = V_1 \times V_2 \times ... \times V_n \longrightarrow V_i \\
-        \mathbf{x} = (x_1,...,x_n) \mapsto x_i
-
+    
+        \begin{align}
+        P_\mu : \ & V_1 \times \ldots \times V_\mu \times \ldots \times V_n \longrightarrow V_\mu \,,
+        \\[2mm]    
+        &\vec{x} = (x_1,\ldots,x_\mu,\ldots ,x_n) \mapsto x_\mu \,.
+        \end{align}
 
     Parameters
     ----------
-    i : int
-        The component on which to project
+    mu : int
+        The component on which to project.
 
     V : psydac.fem.basic.(Product)FemSpace
         Finite element spline space (domain, input space).
 
-    Vi : psydac.fem.basic.FemSpace
-        Finite element spline space (codomain, out space), must be V i-th space
+    Vmu : psydac.fem.basic.FemSpace
+        Finite element spline space (codomain, out space), must be :math:`\mu`-th space of V.
     """
 
-    def __init__(self, i, V, Vi):
+    def __init__(self, mu, V, Vmu):
         assert isinstance(V, FemSpace)
-        assert isinstance(i, int)
-        assert V.spaces[i] == Vi
+        assert isinstance(mu, int)
+        assert V.spaces[mu] == Vmu
 
         self.full_space = V
-        self.sub_space = Vi
-        self.dir = i
+        self.sub_space = Vmu
+        self.dir = mu
         self._domain = V.vector_space
-        self._codomain = Vi.vector_space
+        self._codomain = Vmu.vector_space
         self._dtype = V.vector_space.dtype
 
     @property
     def domain(self):
         """ Domain vector space (input) of the operator.
         """
         return self._domain
@@ -1360,42 +1364,47 @@
         assert (v.space == self._domain)
         assert (out.space == self._codomain)
         out += v.blocks[self.dir]
 
 
 class CoordinateInclusion(LinearOperator):
     r"""
-    Class of inclusion operator from one component of a ProductFemSpace. Represent the canonical inclusion on the i-th component :
+    Class of inclusion operator from one component of a ProductFemSpace. 
+    Represent the canonical inclusion on the :math:`\mu`-th component :
 
     .. math::
-        I_i : V_i \longrightarrow X = V_1 \times V_2 \times ... \times V_n \\
-        x_i \mapsto \mathbf{x} = (0,...,x_i,...,0)
+
+        \begin{align}
+        I_\mu : \ &V_\mu \longrightarrow V_1 \times \ldots \times V_\mu \times \ldots \times V_n \,,
+        \\[2mm]
+        &x_\mu \mapsto \vec{x} = (0,\ldots,x_\mu,\ldots , 0) \,.
+        \end{align}
 
 
     Parameters
     ----------
-    i : int
-        The component on which to project
+    mu : int
+        The component on which to project.
 
     V : psydac.fem.basic.(Product)FemSpace
         Finite element spline space (codomain, out space).
 
-    Vi : psydac.fem.basic.FemSpace
-        Finite element spline space (domain, in space), must be V i-th space
+    Vmu : psydac.fem.basic.FemSpace
+        Finite element spline space (domain, in space), must be :math:`\mu`-th space of V.
     """
 
-    def __init__(self, i, V, Vi):
+    def __init__(self, mu, V, Vmu):
         assert isinstance(V, FemSpace)
-        assert isinstance(i, int)
-        assert V.spaces[i] == Vi
+        assert isinstance(mu, int)
+        assert V.spaces[mu] == Vmu
 
         self.full_space = V
-        self.sub_space = Vi
-        self.dir = i
-        self._domain = Vi.vector_space
+        self.sub_space = Vmu
+        self.dir = mu
+        self._domain = Vmu.vector_space
         self._codomain = V.vector_space
         self._dtype = V.vector_space.dtype
 
     @property
     def domain(self):
         """ Domain vector space (input) of the operator.
         """
@@ -1426,15 +1435,14 @@
 
     def dot(self, v, out=None):
         assert (v.space == self._domain)
         if out is not None:
             assert out.space == self._codomain
             out *= 0.
             out._blocks[self.dir] += v
-
         else:
             blocks = [sspace.zeros() for sspace in self.codomain.spaces]
             blocks[self.dir] = v.copy()
             out = BlockVector(self._codomain, blocks)
 
         out.update_ghost_regions()
         return out
```

### Comparing `struphy-2.2.0/src/struphy/feec/linear_operators.py` & `struphy-2.3.0/src/struphy/feec/linear_operators.py`

 * *Files 0% similar despite different names*

```diff
@@ -505,7 +505,8 @@
         return out
 
     def transpose(self, conjugate=False):
         """
         Returns the transposed operator.
         """
         return BoundaryOperator(self._domain, self._space_id, self.bc)
+
```

### Comparing `struphy-2.2.0/src/struphy/feec/mass.py` & `struphy-2.3.0/src/struphy/feec/mass.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 import numpy as np
 from mpi4py import MPI
 
-from psydac.linalg.stencil import StencilVector, StencilMatrix
+from psydac.linalg.stencil import StencilVector, StencilMatrix, StencilDiagonalMatrix
 from psydac.linalg.block import BlockVector, BlockLinearOperator
 from psydac.linalg.basic import Vector, IdentityOperator
 
 from psydac.fem.tensor import TensorFemSpace
 from psydac.fem.vector import VectorFemSpace
 
 from psydac.api.settings import PSYDAC_BACKEND_GPYCCEL
@@ -26,26 +26,30 @@
 
     domain : :ref:`avail_mappings`
         Mapping from logical unit cube to physical domain and corresponding metric coefficients.
 
     **weights : dict
         Objects to access callables that can serve as weight functions.
 
+    matrix_free : bool
+        If set to true will not compute the matrix associated with the operator but directly compute the product when called
+
     Notes
     -----
     Possible choices for key-value pairs in ****weights** are, at the moment:
 
     - eq_mhd: :class:`struphy.fields_background.mhd_equil.base.MHDequilibrium`
     """
 
-    def __init__(self, derham, domain, **weights):
+    def __init__(self, derham, domain, matrix_free=False, **weights):
 
         self._derham = derham
         self._domain = domain
         self._weights = weights
+        self._matrix_free = matrix_free
 
         # only for M1 Mac users
         PSYDAC_BACKEND_GPYCCEL['flags'] = '-O3 -march=native -mtune=native -ffast-math -ffree-line-length-none'
 
     @property
     def derham(self):
         """ Discrete de Rham sequence on the logical unit cube. 
@@ -74,15 +78,15 @@
 
     def sqrt_g(self, e1, e2, e3):
         '''Jacobian determinant callable.'''
         return abs(self.domain.jacobian_det(e1, e2, e3))
 
     def DFinv(self, e1, e2, e3):
         '''Inverse Jacobian callable.'''
-        return self.domain.jacobian_inv(e1, e2, e3, change_out_order=True, squeeze_out=False)
+        return self.domain.jacobian_inv(e1, e2, e3, change_out_order=True)
 
     #######################################################################
     # Mass matrices related to L2-scalar products in all 3d derham spaces #
     #######################################################################
     @property
     def M0(self):
         r"""
@@ -102,15 +106,15 @@
     @property
     def M1(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^1_{(\mu,ijk), (\nu,mno)} = \int \Lambda^1_{\mu,ijk}\, G^{-1}_{\mu,\nu}\, \Lambda^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^1_{(\mu,ijk), (\nu,mno)} = \int \vec{\Lambda}^1_{\mu,ijk}\, G^{-1}\, \vec{\Lambda}^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
         """
 
         if not hasattr(self, '_M1'):
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
@@ -125,15 +129,15 @@
     @property
     def M2(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^2_{(\mu,ijk), (\nu,mno)} = \int \Lambda^2_{\mu,ijk}\, G_{\mu,\nu}\, \Lambda^2_{\nu, mno} \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^2_{(\mu,ijk), (\nu,mno)} = \int \vec{\Lambda}^2_{\mu,ijk}\, G\, \vec{\Lambda}^2_{\nu, mno} \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
         """
 
         if not hasattr(self, '_M2'):
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
@@ -164,15 +168,15 @@
     @property
     def Mv(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^2_{(\mu,ijk), (\nu,mno)} = \int \Lambda^2_{\mu,ijk}\, G_{\mu,\nu}\, \Lambda^2_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^v_{(\mu,ijk), (\nu,mno)} = \int \vec{\Lambda}^v_{\mu,ijk}\, G\, \vec{\Lambda}^v_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
         """
 
         if not hasattr(self, '_Mv'):
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
@@ -190,119 +194,119 @@
     @property
     def M1n(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{1,n}_{(\mu,ijk), (\nu,mno)} = \int n^0_{\textnormal{eq}}(\boldsymbol \eta) \Lambda^1_{\mu,ijk}\, G^{-1}_{\mu,\nu}\, \Lambda^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{1,n}_{(\mu,ijk), (\nu,mno)} = \int n^0_{\textnormal{eq}}(\boldsymbol \eta) \vec{\Lambda}^1_{\mu,ijk}\, G^{-1}\, \vec{\Lambda}^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
 
         where :math:`n^0_{\textnormal{eq}}(\boldsymbol \eta)` is an MHD equilibrium density (0-form).
         """
 
         if not hasattr(self, '_M1n'):
             assert 'eq_mhd' in self.weights
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
                     fun[-1] += [lambda e1, e2, e3, m=m, n=n: self.Ginv(e1, e2, e3)[:, :, :, m, n] * self.sqrt_g(
-                        e1, e2, e3) * self.weights['eq_mhd'].n0(e1, e2, e3, squeeze_out=False)]
+                        e1, e2, e3) * self.weights['eq_mhd'].n0(e1, e2, e3)]
 
             self._M1n = self.assemble_weighted_mass(
                 fun, 'Hcurl', 'Hcurl', name='M1n')
 
         return self._M1n
 
     @property
     def M2n(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{2,n}_{(\mu,ijk), (\nu,mno)} = \int n^0_{\textnormal{eq}}(\boldsymbol \eta) \Lambda^2_{\mu,ijk}\, G_{\mu,\nu}\, \Lambda^2_{\nu, mno} \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{2,n}_{(\mu,ijk), (\nu,mno)} = \int n^0_{\textnormal{eq}}(\boldsymbol \eta) \vec{\Lambda}^2_{\mu,ijk}\, G\, \vec{\Lambda}^2_{\nu, mno} \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
 
         where :math:`n^0_{\textnormal{eq}}(\boldsymbol \eta)` is an MHD equilibrium density (0-form).
         """
 
         if not hasattr(self, '_M2n'):
             assert 'eq_mhd' in self.weights
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
                     fun[-1] += [lambda e1, e2, e3, m=m, n=n: self.G(e1, e2, e3)[:, :, :, m, n] / self.sqrt_g(
-                        e1, e2, e3) * self.weights['eq_mhd'].n0(e1, e2, e3, squeeze_out=False)]
+                        e1, e2, e3) * self.weights['eq_mhd'].n0(e1, e2, e3)]
 
             self._M2n = self.assemble_weighted_mass(
                 fun, 'Hdiv', 'Hdiv', name='M2n')
 
         return self._M2n
 
     @property
     def Mvn(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{v,n}_{(\mu,ijk), (\nu,mno)} = \int n^0_{\textnormal{eq}}(\boldsymbol \eta) \Lambda^v_{\mu,ijk}\, G_{\mu,\nu}\, \Lambda^v_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{v,n}_{(\mu,ijk), (\nu,mno)} = \int n^0_{\textnormal{eq}}(\boldsymbol \eta) \vec{\Lambda}^v_{\mu,ijk}\, G\, \vec{\Lambda}^v_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
 
         where :math:`n^0_{\textnormal{eq}}(\boldsymbol \eta)` is an MHD equilibrium density (0-form).
         """
 
         if not hasattr(self, '_Mvn'):
             assert 'eq_mhd' in self.weights
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
                     fun[-1] += [lambda e1, e2, e3, m=m, n=n: self.G(e1, e2, e3)[:, :, :, m, n] * self.sqrt_g(
-                        e1, e2, e3) * self.weights['eq_mhd'].n0(e1, e2, e3, squeeze_out=False)]
+                        e1, e2, e3) * self.weights['eq_mhd'].n0(e1, e2, e3)]
 
             self._Mvn = self.assemble_weighted_mass(
                 fun, 'H1vec', 'H1vec', name='Mvn')
 
         return self._Mvn
 
     @property
     def M1ninv(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{1,\frac{1}{n}}_{(\mu,ijk), (\nu,mno)} = \int \frac{1}{n^0_{\textnormal{eq}}(\boldsymbol \eta)} \Lambda^1_{\mu,ijk}\, G^{-1}_{\mu,\nu}\, \Lambda^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{1,\frac{1}{n}}_{(\mu,ijk), (\nu,mno)} = \int \frac{1}{n^0_{\textnormal{eq}}(\boldsymbol \eta)} \vec{\Lambda}^1_{\mu,ijk}\, G^{-1}\, \vec{\Lambda}^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
 
         where :math:`n^0_{\textnormal{eq}}(\boldsymbol \eta)` is an MHD equilibrium density (0-form).
         """
 
         if not hasattr(self, '_M1ninv'):
             assert 'eq_mhd' in self.weights
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
                     fun[-1] += [lambda e1, e2, e3, m=m, n=n: self.Ginv(e1, e2, e3)[:, :, :, m, n] * self.sqrt_g(
-                        e1, e2, e3) / self.weights['eq_mhd'].n0(e1, e2, e3, squeeze_out=False)]
+                        e1, e2, e3) / self.weights['eq_mhd'].n0(e1, e2, e3)]
 
             self._M1ninv = self.assemble_weighted_mass(
                 fun, 'Hcurl', 'Hcurl', name='M1ninv')
 
         return self._M1ninv
 
     @property
     def M1J(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{1,J}_{(\mu,ijk), (\nu,mno)} = \int \Lambda^1_{\mu,ijk}\, G^{-1}_{\mu,\alpha}\, \mathcal R^J_{\alpha, \nu}\, \Lambda^2_{\nu, mno} \,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{1,J}_{(\mu,ijk), (\nu,mno)} = \int \vec{\Lambda}^1_{\mu,ijk}\, G^{-1}\, \mathcal R^J\, \vec{\Lambda}^2_{\nu, mno} \,  \textnormal d \boldsymbol\eta. 
 
         with the rotation matrix
 
         .. math::
 
             \mathcal R^J_{\alpha, \nu} := \epsilon_{\alpha \beta \nu}\, J^2_{\textnormal{eq}, \beta}\,,\qquad s.t. \qquad \mathcal R^J \vec v = \vec J^2_{\textnormal{eq}} \times \vec v\,,
 
@@ -329,15 +333,15 @@
     @property
     def M2J(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{2,J}_{(\mu,ijk), (\nu,mno)} = \int \Lambda^2_{\mu,ijk}\, \mathcal R^J_{\alpha, \nu}\, \Lambda^2_{\nu, mno} \, \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{2,J}_{(\mu,ijk), (\nu,mno)} = \int \vec{\Lambda}^2_{\mu,ijk}\, \mathcal R^J\, \vec{\Lambda}^2_{\nu, mno} \, \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
 
         with the rotation matrix
 
         .. math::
 
             \mathcal R^J_{\alpha, \nu} := \epsilon_{\alpha \beta \nu}\, J^2_{\textnormal{eq}, \beta}\,,\qquad s.t. \qquad \mathcal R^J \vec v = \vec J^2_{\textnormal{eq}} \times \vec v\,,
 
@@ -364,15 +368,15 @@
     @property
     def MvJ(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{v,J}_{(\mu,ijk), (\nu,mno)} = \int \Lambda^v_{\mu,ijk}\, \mathcal R^J_{\alpha, \nu}\, \Lambda^2_{\nu, mno} \,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{v,J}_{(\mu,ijk), (\nu,mno)} = \int \vec{\Lambda}^v_{\mu,ijk}\, \mathcal R^J\, \vec{\Lambda}^v_{\nu, mno} \,  \textnormal d \boldsymbol\eta. 
 
         with the rotation matrix
 
         .. math::
 
             \mathcal R^J_{\alpha, \nu} := \epsilon_{\alpha \beta \nu}\, J^2_{\textnormal{eq}, \beta}\,,\qquad s.t. \qquad \mathcal R^J \vec v = \vec J^2_{\textnormal{eq}} \times \vec v\,,
 
@@ -399,15 +403,15 @@
     @property
     def M2B(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{2,B}_{(\mu,ijk), (\nu,mno)} = \int \Lambda^2_{\mu,ijk}\, \mathcal R^J_{\alpha, \nu}\, \Lambda^2_{\nu, mno} \, \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{2,B}_{(\mu,ijk), (\nu,mno)} = \int \vec{\Lambda}^2_{\mu,ijk}\, \mathcal R^J\, \vec{\Lambda}^2_{\nu, mno} \, \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
 
         with the rotation matrix
 
         .. math::
 
             \mathcal R^J_{\alpha, \nu} := \epsilon_{\alpha \beta \nu}\, B^2_{\textnormal{eq}, \beta}\,,\qquad s.t. \qquad \mathcal R^J \vec v = \vec B^2_{\textnormal{eq}} \times \vec v\,,
 
@@ -451,15 +455,15 @@
     @property
     def M2Bn(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{2,BN}_{(\mu,ijk), (\nu,mno)} = \int \Lambda^2_{\mu,ijk}\, \mathcal R^J_{\alpha, \nu}\, \Lambda^2_{\nu, mno} \, \frac{1}{n^0_{\textnormal{eq}}(\boldsymbol \eta)}\, \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{2,BN}_{(\mu,ijk), (\nu,mno)} = \int \vec{\Lambda}^2_{\mu,ijk}\, \mathcal R^J\, \vec{\Lambda}^2_{\nu, mno} \, \frac{1}{n^0_{\textnormal{eq}}(\boldsymbol \eta)}\, \frac{1}{\sqrt g}\,  \textnormal d \boldsymbol\eta. 
 
         with the rotation matrix
 
         .. math::
 
             \mathcal R^J_{\alpha, \nu} := \epsilon_{\alpha \beta \nu}\, B^2_{\textnormal{eq}, \beta}\,,\qquad s.t. \qquad \mathcal R^J \vec v = \vec B^2_{\textnormal{eq}} \times \vec v\,,
 
@@ -489,29 +493,29 @@
             rot_B = RotationMatrix(
                 b02funx, b02funy, b02funz)
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
                     fun[-1] += [lambda e1, e2, e3, m=m,
-                                n=n: rot_B(e1, e2, e3)[:, :, :, m, n] / (self.sqrt_g(e1, e2, e3) * self.weights['eq_mhd'].n0(e1, e2, e3, squeeze_out=False))]
+                                n=n: rot_B(e1, e2, e3)[:, :, :, m, n] / (self.sqrt_g(e1, e2, e3) * self.weights['eq_mhd'].n0(e1, e2, e3))]
 
             self._M2BN = self.assemble_weighted_mass(
                 fun, 'Hdiv', 'Hdiv', name='M2Bn')
 
         return self._M2BN
 
     @property
     def M1Bninv(self):
         r"""
         Mass matrix 
 
         .. math::
 
-            \mathbb M^{1,B\frac{1}{n}}_{(\mu,ijk), (\nu,mno)} = \int \frac{1}{n^0_{\textnormal{eq}}(\boldsymbol \eta)}\, \Lambda^1_{\mu,ijk}\, G^{-1}_{\mu,\alpha}\, \mathcal R^J_{\alpha, \gamma}\, G^{-1}_{\gamma,\nu}\, \Lambda^1_{\nu, mno} \, \sqrt g\,  \textnormal d \boldsymbol\eta. 
+            \mathbb M^{1,B\frac{1}{n}}_{(\mu,ijk), (\nu,mno)} = \int \frac{1}{n^0_{\textnormal{eq}}(\boldsymbol \eta)}\, \vec{\Lambda}^1_{\mu,ijk}\, G^{-1}\, \mathcal R^J_{\alpha, \gamma}\, G^{-1}_{\gamma,\nu}\, \vec{\Lambda}^1_{\nu, mno} \, \sqrt g\,  \textnormal d \boldsymbol\eta. 
 
         with the rotation matrix
 
         .. math::
 
             \mathcal R^J_{\alpha, \nu} := \epsilon_{\alpha \beta \nu}\, B^2_{\textnormal{eq}, \beta}\,,\qquad s.t. \qquad \mathcal R^J \vec v = \vec B^2_{\textnormal{eq}} \times \vec v\,,
 
@@ -524,35 +528,29 @@
                 self.weights['eq_mhd'].b2_1, self.weights['eq_mhd'].b2_2, self.weights['eq_mhd'].b2_3)
 
             fun = []
             for m in range(3):
                 fun += [[]]
                 for n in range(3):
                     fun[-1] += [lambda e1, e2, e3, m=m,
-                                n=n: (self.Ginv(e1, e2, e3) @ rot_B(e1, e2, e3) @ self.Ginv(e1, e2, e3))[:, :, :, m, n] * (self.sqrt_g(e1, e2, e3) / self.weights['eq_mhd'].n0(e1, e2, e3, squeeze_out=False))]
+                                n=n: (self.Ginv(e1, e2, e3) @ rot_B(e1, e2, e3) @ self.Ginv(e1, e2, e3))[:, :, :, m, n] * (self.sqrt_g(e1, e2, e3) / self.weights['eq_mhd'].n0(e1, e2, e3))]
 
             self._M1Bninv = self.assemble_weighted_mass(
                 fun, 'Hcurl', 'Hcurl', name='M1Bninv')
 
         return self._M1Bninv
 
     @property
     def M1perp(self):
         r"""
         Mass matrix 
 
         .. math::
 
-           \mathbb M^1_{\perp, (\mu,ijk), (\nu,mno)} = \int \Lambda^1_{\mu,ijk} DF^{-1}_{\mu,\alpha}(\delta_{\alpha,\beta} - \delta_{\alpha,3}) DF^{-\top}_{\beta,\nu}\Lambda^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta.
-
-        where :math:`\delta_{\mu,\nu}` denotes the Kronecker delta. In vector-valued form:
-
-        .. math::
-
-            \mathbb M^1_{\perp, (ijk), (mno)} = \int \vec \Lambda^1_{ijk} DF^{-1} \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{pmatrix} DF^{-\top}\vec \Lambda^1_{mno} \sqrt g\,  \textnormal d \boldsymbol\eta.
+            \mathbb M^{1, \perp}_{(\mu, ijk), (\nu, mno)} = \int \vec{\Lambda}^1_{\mu, ijk}\, DF^{-1} \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{pmatrix} DF^{-\top} \vec{\Lambda}^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta.
 
         """
 
         if not hasattr(self, '_M1perp'):
             self.D = [[1, 0, 0], [0, 1, 0], [0, 0, 0]]
             fun = []
             for m in range(3):
@@ -562,14 +560,60 @@
                         e1, e2, e3)]
 
             self._M1perp = self.assemble_weighted_mass(
                 fun, 'Hcurl', 'Hcurl', name='M1perp')
 
         return self._M1perp
 
+    @property
+    def M0ad(self):
+        r"""
+        Mass matrix 
+
+        .. math::
+
+            \mathbb M^0_{ijk, mno} = \int \Lambda^0_{ijk}\,  \Lambda^0_{mno} \sqrt g\,  \textnormal d \boldsymbol\eta.
+        """
+
+        if not hasattr(self, '_M0ad'):
+            assert 'eq_mhd' in self.weights
+            fun = [[lambda e1, e2, e3: self.weights['eq_mhd'].n0(
+                e1, e2, e3)**2 / self.weights['eq_mhd'].p0(e1, e2, e3) * self.sqrt_g(e1, e2, e3)]]
+            self._M0ad = self.assemble_weighted_mass(
+                fun, 'H1', 'H1', name='M0ad')
+
+        return self._M0ad
+
+    @property
+    def M1gyro(self):
+        r"""
+        Mass matrix 
+
+        .. math::
+
+            \mathbb M^{1,n}_{(\mu,ijk), (\nu,mno)} = \int n^0_{\textnormal{eq}}(\boldsymbol \eta) \Lambda^1_{\mu,ijk}\, G^{-1}_{\mu,\nu}\, \Lambda^1_{\nu, mno} \sqrt g\,  \textnormal d \boldsymbol\eta. 
+
+        where :math:`n^0_{\textnormal{eq}}(\boldsymbol \eta)` is an MHD equilibrium density (0-form).
+        """
+
+        if not hasattr(self, '_M1gyro'):
+            assert 'eq_mhd' in self.weights
+            self.D = [[1, 0, 0], [0, 1, 0], [0, 0, 0]]
+            fun = []
+            for m in range(3):
+                fun += [[]]
+                for n in range(3):
+                    fun[-1] += [lambda e1, e2, e3, m=m, n=n: self.weights['eq_mhd'].n0(e1, e2, e3) / self.weights['eq_mhd'].absB0(e1, e2, e3) * self.D[m][n] * self.Ginv(e1, e2, e3)[:, :, :, m, n] * self.D[m][n] * self.sqrt_g(
+                        e1, e2, e3)]
+
+            self._M1gyro = self.assemble_weighted_mass(
+                fun, 'Hcurl', 'Hcurl', name='M1gyro')
+
+        return self._M1gyro
+
     #######################################
     # Wrapper around WeightedMassOperator #
     #######################################
     def assemble_weighted_mass(self, fun: list, V_id: str, W_id: str, name=None):
         r""" Weighted mass matrix :math:`V^\alpha_h \to V^\beta_h` with given (matrix-valued) weight function :math:`W(\boldsymbol \eta)`:
 
         .. math::
@@ -619,15 +663,16 @@
         out = WeightedMassOperator(self.derham.Vh_fem[V_id],
                                    self.derham.Vh_fem[W_id],
                                    V_extraction_op=self.derham.extraction_ops[V_id],
                                    W_extraction_op=self.derham.extraction_ops[W_id],
                                    V_boundary_op=self.derham.boundary_ops[V_id],
                                    W_boundary_op=self.derham.boundary_ops[W_id],
                                    weights_info=fun,
-                                   transposed=False)
+                                   transposed=False,
+                                   matrix_free=self._matrix_free)
 
         out.assemble(name=name)
 
         return out
 
 
 class WeightedMassOperator(LinOpWithTransp):
@@ -715,15 +760,15 @@
         if W_boundary_op is not None:
             self._W_boundary_op = W_boundary_op
         else:
             self._W_boundary_op = IdentityOperator(
                 self._W_extraction_op.codomain)
 
         self._transposed = transposed
-        self._matrixless = matrix_free
+        self._matrix_free = matrix_free
 
         self._dtype = V.vector_space.dtype
 
         # set domain and codomain symbolic names
         if hasattr(V.symbolic_space, 'name'):
             V_name = V.symbolic_space.name
         else:
@@ -760,21 +805,20 @@
             self._codomain_symbolic_name = W_name
 
         # Are both space scalar spaces : useful to know if _dof_mat will be Stencil or Block Matrix
         self._is_scalar = True
         if not isinstance(V, TensorFemSpace):
             self._is_scalar = False
             self._mpi_comm = V.vector_space.spaces[0].cart.comm
-        else :
+        else:
             self._mpi_comm = V.vector_space.cart.comm
 
         if not isinstance(W, TensorFemSpace):
             self._is_scalar = False
 
-        
         # ====== initialize Stencil-/BlockLinearOperator ====
 
         # collect TensorFemSpaces for each component in tuple
         if isinstance(V, TensorFemSpace):
             Vspaces = (V,)
         else:
             Vspaces = V.spaces
@@ -782,46 +826,46 @@
         if isinstance(W, TensorFemSpace):
             Wspaces = (W,)
         else:
             Wspaces = W.spaces
 
         # initialize blocks according to given symmetry and set zero default weights
         if isinstance(weights_info, str):
-            
+
             self._symmetry = weights_info
 
             assert V_name == W_name, 'only square matrices (V=W) allowed!'
             assert len(
                 V_name) > 2, 'only block matrices with domain/codomain spaces Hcurl, Hdiv and H1vec are allowed!'
-            
-            if self._matrixless:
+
+            if self._matrix_free:
                 if weights_info == 'symm':
                     blocks = [[StencilMatrixFreeMassOperator(Vs, Ws)
-                            for Vs in V.spaces] for Ws in W.spaces]
+                               for Vs in V.spaces] for Ws in W.spaces]
                 elif weights_info == 'asym':
                     blocks = [[StencilMatrixFreeMassOperator(Vs, Ws)
-                            if i != j else None for j, Vs in enumerate(V.spaces)] for i, Ws in enumerate(W.spaces)]
+                               if i != j else None for j, Vs in enumerate(V.spaces)] for i, Ws in enumerate(W.spaces)]
                 elif weights_info == 'diag':
                     blocks = [[StencilMatrixFreeMassOperator(Vs, Ws)
-                            if i == j else None for j, Vs in enumerate(V.spaces)] for i, Ws in enumerate(W.spaces)]
+                               if i == j else None for j, Vs in enumerate(V.spaces)] for i, Ws in enumerate(W.spaces)]
                 else:
                     raise NotImplementedError(
                         f'given symmetry {weights_info} is not implemented!')
 
-            else :
+            else:
 
                 if weights_info == 'symm':
                     blocks = [[StencilMatrix(Vs.vector_space, Ws.vector_space, backend=PSYDAC_BACKEND_GPYCCEL, precompiled=True)
-                            for Vs in V.spaces] for Ws in W.spaces]
+                               for Vs in V.spaces] for Ws in W.spaces]
                 elif weights_info == 'asym':
                     blocks = [[StencilMatrix(Vs.vector_space, Ws.vector_space, backend=PSYDAC_BACKEND_GPYCCEL, precompiled=True)
-                            if i != j else None for j, Vs in enumerate(V.spaces)] for i, Ws in enumerate(W.spaces)]
+                               if i != j else None for j, Vs in enumerate(V.spaces)] for i, Ws in enumerate(W.spaces)]
                 elif weights_info == 'diag':
                     blocks = [[StencilMatrix(Vs.vector_space, Ws.vector_space, backend=PSYDAC_BACKEND_GPYCCEL, precompiled=True)
-                            if i == j else None for j, Vs in enumerate(V.spaces)] for i, Ws in enumerate(W.spaces)]
+                               if i == j else None for j, Vs in enumerate(V.spaces)] for i, Ws in enumerate(W.spaces)]
                 else:
                     raise NotImplementedError(
                         f'given symmetry {weights_info} is not implemented!')
 
             self._mat = BlockLinearOperator(
                 V.vector_space, W.vector_space, blocks=blocks)
 
@@ -849,16 +893,17 @@
                 self._weights += [[]]
 
                 # loop over domain spaces (columns)
                 for b, vspace in enumerate(Vspaces):
 
                     # set zero default weights if weights is None
                     if weights_info is None:
-                        if self._matrixless:
-                            blocks[-1] += [StencilMatrixFreeMassOperator(vspace, wspace)]
+                        if self._matrix_free:
+                            blocks[-1] += [
+                                StencilMatrixFreeMassOperator(vspace, wspace)]
                         else:
                             blocks[-1] += [StencilMatrix(
                                 vspace.vector_space, wspace.vector_space, backend=PSYDAC_BACKEND_GPYCCEL, precompiled=True)]
                         self._weights[-1] += [lambda *etas: 0*etas[0]]
 
                     else:
 
@@ -866,45 +911,46 @@
                             blocks[-1] += [None]
                             self._weights[-1] += [None]
 
                         else:
 
                             # test weight function at quadrature points to identify zero blocks
                             pts = [quad_grid[nquad].points.flatten()
-                                    for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
+                                   for quad_grid, nquad in zip(wspace._quad_grids, wspace.nquads)]
 
                             if callable(weights_info[a][b]):
                                 PTS = np.meshgrid(*pts, indexing='ij')
                                 mat_w = weights_info[a][b](*PTS).copy()
                             elif isinstance(weights_info[a][b], np.ndarray):
                                 mat_w = weights_info[a][b]
 
                             assert mat_w.shape == tuple(
                                 [pt.size for pt in pts])
 
                             if np.any(np.abs(mat_w) > 1e-14):
-                                if self._matrixless:
-                                    blocks[-1] += [StencilMatrixFreeMassOperator(vspace, wspace)]
+                                if self._matrix_free:
+                                    blocks[-1] += [StencilMatrixFreeMassOperator(
+                                        vspace, wspace, weights=weights_info[a][b])]
                                 else:
                                     blocks[-1] += [StencilMatrix(
                                         vspace.vector_space, wspace.vector_space, backend=PSYDAC_BACKEND_GPYCCEL, precompiled=True)]
                                 self._weights[-1] += [weights_info[a][b]]
                             else:
                                 blocks[-1] += [None]
                                 self._weights[-1] += [None]
 
-
             if len(blocks) == len(blocks[0]) == 1:
                 if blocks[0][0] is None:
-                    if self._matrixless:
-                    
-                        self._mat = StencilMatrixFreeMassOperator(vspace, wspace)
+                    if self._matrix_free:
+
+                        self._mat = StencilMatrixFreeMassOperator(
+                            vspace, wspace)
                     else:
                         self._mat = StencilMatrix(
-                                        vspace.vector_space, wspace.vector_space, backend=PSYDAC_BACKEND_GPYCCEL, precompiled=True)
+                            vspace.vector_space, wspace.vector_space, backend=PSYDAC_BACKEND_GPYCCEL, precompiled=True)
                 else:
                     self._mat = blocks[0][0]
             else:
                 self._mat = BlockLinearOperator(
                     V.vector_space, W.vector_space, blocks=blocks)
 
         # transpose of matrix and weights
@@ -938,21 +984,21 @@
         # build composite linear operators BW * EW * M * EV^T * BV^T, resp. IDV * EV * M^T * EW^T * IDW^T
         if transposed:
             self._M = EV @ self._mat @ EW.T
             self._M0 = BV @ self._M @ BW.T
         else:
             self._M = EW @ self._mat @ EV.T
             self._M0 = BW @ self._M @ BV.T
-            
+
         # set domain and codomain
         self._domain = self._M.domain
         self._codomain = self._M.codomain
 
         # load assembly kernel
-        if not self._matrixless:
+        if not self._matrix_free:
             self._assembly_kernel = getattr(
                 mass_kernels, 'kernel_' + str(self._V.ldim) + 'd_mat')
 
     @property
     def domain(self):
         return self._domain
 
@@ -1067,24 +1113,24 @@
             weights = self._weights
 
         if self._symmetry is None:
 
             M = WeightedMassOperator(self._V, self._W,
                                      self._V_extraction_op, self._W_extraction_op,
                                      self._V_boundary_op, self._W_boundary_op,
-                                     weights, not self._transposed, self._matrixless)
+                                     weights, not self._transposed, self._matrix_free)
 
             M.assemble(verbose=False)
 
         else:
 
             M = WeightedMassOperator(self._V, self._W,
                                      self._V_extraction_op, self._W_extraction_op,
                                      self._V_boundary_op, self._W_boundary_op,
-                                     self._symmetry, not self._transposed, self._matrixless)
+                                     self._symmetry, not self._transposed, self._matrix_free)
 
             M.assemble(weights=weights, verbose=False)
 
         return M
 
     def assemble(self, weights=None, clear=True, verbose=True, name=None):
         """
@@ -1107,29 +1153,29 @@
         verbose : bool
             Whether to do some printing.
 
         name : str
             Name of the operator.
         """
 
+        if self._matrix_free:
+            if weights is not None:
+                if self._is_scalar:
+                    self._mat.weights = weights[0][0]
+                else:
+                    for a, weights_row in enumerate(weights):
+                        for b, weight in enumerate(weights_row):
+                            if weight is not None:
+                                assert callable(weight) or isinstance(
+                                    weight, np.ndarray)
+                            self._mat[a, b].weights = weight
 
-        if self._matrixless :
-            if self._is_scalar :
-                self._mat.weights = weights[0][0]
-            else:
-                for a, weights_row in enumerate(weights):
-                    for b, weight in enumerate(weights_row):
-                        if weight is not None:
-                            assert callable(weight) or isinstance(
-                                weight, np.ndarray)
-                        self._mat[a,b].weights = weight
-                               
-            self._weights = weights
+                self._weights = weights
 
-        else : 
+        else:
 
             # clear data
             if clear:
                 if isinstance(self._mat, StencilMatrix):
                     self._mat._data[:] = 0.
                 else:
                     for block_row in self._mat.blocks:
@@ -1147,15 +1193,15 @@
                 if self._V.vector_space[0].cart.comm is not None:
                     rank = self._V.vector_space[0].cart.comm.Get_rank()
                 else:
                     rank = 0
 
             if rank == 0 and verbose:
                 print(
-                    f'Assembling matrix of WeightedMassOperator "{name}" with V={self._domain_symbolic_name}, W={self._codomain_symbolic_name}.')
+                    f'\nAssembling matrix of WeightedMassOperator "{name}" with V={self._domain_symbolic_name}, W={self._codomain_symbolic_name}.')
 
             # collect domain/codomain TensorFemSpaces for each component in tuple
             if self._transposed:
                 if isinstance(self._W, TensorFemSpace):
                     domain_spaces = (self._W,)
                 else:
                     domain_spaces = self._W.spaces
@@ -1185,22 +1231,22 @@
 
                 # knot span indices of elements of local domain
                 codomain_spans = [
                     quad_grid[nquad].spans for quad_grid, nquad in zip(codomain_space._quad_grids, codomain_space.nquads)]
 
                 # global start spline index on process
                 codomain_starts = [int(start)
-                                for start in codomain_space.vector_space.starts]
+                                   for start in codomain_space.vector_space.starts]
 
                 # pads (ghost regions)
                 codomain_pads = codomain_space.vector_space.pads
 
                 # global quadrature points (flattened) and weights in format (local element, local weight)
                 pts = [quad_grid[nquad].points.flatten()
-                    for quad_grid, nquad in zip(codomain_space._quad_grids, codomain_space.nquads)]
+                       for quad_grid, nquad in zip(codomain_space._quad_grids, codomain_space.nquads)]
                 wts = [quad_grid[nquad].weights for quad_grid, nquad in zip(
                     codomain_space._quad_grids, codomain_space.nquads)]
 
                 # evaluated basis functions at quadrature points of codomain space
                 codomain_basis = [
                     quad_grid[nquad].basis for quad_grid, nquad in zip(codomain_space._quad_grids, codomain_space.nquads)]
 
@@ -1219,52 +1265,56 @@
                     # evaluate weight at quadrature points
                     if callable(loc_weight):
                         PTS = np.meshgrid(*pts, indexing='ij')
                         mat_w = loc_weight(*PTS).copy()
                     elif isinstance(loc_weight, np.ndarray):
                         mat_w = loc_weight
                     elif loc_weight is not None:
-                        raise TypeError("weights must be callable or np.ndarray or None but is {}".format(type(self._weights[a][b])))
+                        raise TypeError("weights must be callable or np.ndarray or None but is {}".format(
+                            type(self._weights[a][b])))
 
                     if loc_weight is not None:
                         assert mat_w.shape == tuple([pt.size for pt in pts])
 
-                    not_weight_zero = np.array(int(loc_weight is not None and np.any(np.abs(mat_w) > 1e-14)))
+                    not_weight_zero = np.array(
+                        int(loc_weight is not None and np.any(np.abs(mat_w) > 1e-14)))
                     if self._mpi_comm is not None:
-                        self._mpi_comm.Allreduce(MPI.IN_PLACE, not_weight_zero, op=MPI.LOR)
+                        self._mpi_comm.Allreduce(
+                            MPI.IN_PLACE, not_weight_zero, op=MPI.LOR)
 
                     # evaluated basis functions at quadrature points of domain space
                     domain_basis = [
                         quad_grid[nquad].basis for quad_grid, nquad in zip(domain_space._quad_grids, domain_space.nquads)]
 
                     # assemble matrix (if mat_w is not zero) by calling the appropriate kernel (1d, 2d or 3d)
                     if not_weight_zero or self._is_scalar:
 
                         # get cell of block matrix (don't instantiate if all zeros)
                         if self._is_scalar:
                             mat = self._mat
                             if loc_weight is None:
                                 # in case it's none we still need to have zeros weights to call the kernel
-                                mat_w = np.zeros(tuple([pt.size for pt in pts]))
+                                mat_w = np.zeros(
+                                    tuple([pt.size for pt in pts]))
                         else:
                             mat = self._mat[a, b]
 
                         if mat is None:
                             # Maybe in a previous iteration we had more zeros
                             # Can only happen in the Block case
                             self._mat[a, b] = StencilMatrix(
                                 domain_space.vector_space, codomain_space.vector_space, backend=PSYDAC_BACKEND_GPYCCEL, precompiled=True)
                             mat = self._mat[a, b]
-                        
+
                         self._assembly_kernel(*codomain_spans, *codomain_space.degree, *domain_space.degree, *codomain_starts,
-                                            *codomain_pads, *wts, *codomain_basis, *domain_basis, mat_w, mat._data)
+                                              *codomain_pads, *wts, *codomain_basis, *domain_basis, mat_w, mat._data)
 
                     else:
                         self._mat[a, b] = None
-            
+
             # exchange assembly data (accumulate ghost regions)
             self._mat.exchange_assembly_data()
 
             # copy data for symmetric/anti-symmetric block matrices
             if self.symmetry == 'symm':
 
                 self._mat.update_ghost_regions()
@@ -1381,103 +1431,111 @@
     .. math::
 
         w^\mu_{ijk} = \int \Lambda_{\mu,ijk}\, S_h\, w(\boldsymbol\eta)\,\textrm d \boldsymbol \eta \,,
 
     where :math:`w(\boldsymbol\eta)` is a weight function (including the geometric weights).
 
     Should only be instanciated via `WeightedMassOperator`, where it's used to replace `StencilMatrix` when one does not want to assemble the matrix for cost reasons
-    
+
     Parameters
     ----------
     V : TensorFemSpace
         Domain of the mass operator
 
     W : TensorFemSpace
         Codomain of the mass operator
 
     weights : callable | numpy.ndarry | None
         The weights of the mass operator
     """
+
     def __init__(self, V, W, weights=None):
         self._V = V
         self._W = W
         self._domain = V.vector_space
         self._codomain = W.vector_space
         self._weights = weights
         self._dtype = V.vector_space.dtype
         self._dot_kernel = getattr(
-            mass_kernels, 'kernel_' + str(self._V.ldim) + 'd_matrixless')
-        
+            mass_kernels, 'kernel_' + str(self._V.ldim) + 'd_matrixfree')
+
+        self._diag_kernel = getattr(
+            mass_kernels, 'kernel_' + str(self._V.ldim) + 'd_diag')
+
+        shape = tuple(e - s + 1 for s,
+                      e in zip(V.vector_space.starts, V.vector_space.ends))
+        self._diag_tmp = np.zeros((shape))
+
         # knot span indices of elements of local domain
         self._codomain_spans = [
             quad_grid[nquad].spans for quad_grid, nquad in zip(self._W._quad_grids, self._W.nquads)]
 
         # global start spline index on process
         self._codomain_starts = [int(start)
-                            for start in self._W.vector_space.starts]
+                                 for start in self._W.vector_space.starts]
         # pads (ghost regions)
         self._codomain_pads = self._W.vector_space.pads
 
         # evaluated basis functions at quadrature points of codomain space
         self._codomain_basis = [
             quad_grid[nquad].basis for quad_grid, nquad in zip(self._W._quad_grids, self._W.nquads)]
 
         # knot span indices of elements of local domain
         self._domain_spans = [
             quad_grid[nquad].spans for quad_grid, nquad in zip(self._V._quad_grids, self._V.nquads)]
 
-                # global start spline index on process
+        # global start spline index on process
         self._domain_starts = [int(start)
-                        for start in self._V.vector_space.starts]
-                
+                               for start in self._V.vector_space.starts]
+
         # pads (ghost regions)
         self._domain_pads = self._V.vector_space.pads
 
         # evaluated basis functions at quadrature points of domain space
         self._domain_basis = [
             quad_grid[nquad].basis for quad_grid, nquad in zip(self._V._quad_grids, self._V.nquads)]
 
         # global quadrature points (flattened) and weights in format (local element, local weight)
         self._pts = [quad_grid[nquad].points.flatten()
-            for quad_grid, nquad in zip(self._W._quad_grids, self._W.nquads)]
+                     for quad_grid, nquad in zip(self._W._quad_grids, self._W.nquads)]
         self._wts = [quad_grid[nquad].weights for quad_grid, nquad in zip(
             self._W._quad_grids, self._W.nquads)]
 
     @property
     def domain(self):
         return self._domain
-    
+
     @property
     def codomain(self):
-        return self._domain
-    
+        return self._codomain
+
     @property
     def dtype(self):
         return self._dtype
-    
+
     @property
     def tosparse(self):
         raise NotImplementedError()
 
     @property
     def toarray(self):
         raise NotImplementedError()
 
     def transpose(self):
         return StencilMatrixFreeMassOperator(self._codomain, self._domain, self._weights)
-    
+
     @property
     def weights(self):
         return self._weights
-    
+
     @weights.setter
     def weights(self, new):
         self._weights = new
-    
-    def dot(self, v, out):
+
+    def dot(self, v, out=None):
         """
         Dot product of the operator with a vector. Direct computation (not using a StencilMatrix).
 
         Parameters
         ----------
         v : psydac.linalg.basic.Vector
             The input (domain) vector.
@@ -1490,34 +1548,105 @@
 
         Returns
         -------
         out : psydac.linalg.basic.Vector
             The output (codomain) vector.
         """
 
-        if out is None :
+        if out is None:
             out = self.codomain.zeros()
-        else :
+        else:
             assert isinstance(out, Vector)
             assert out.space == self.codomain
             out._data[:] = 0.
 
         v.update_ghost_regions()
 
         # evaluate weight at quadrature points
         if callable(self._weights):
             PTS = np.meshgrid(*self._pts, indexing='ij')
             mat_w = self._weights(*PTS).copy()
         elif isinstance(self._weights, np.ndarray):
             mat_w = self._weights
 
-        assert mat_w.shape == tuple([pt.size for pt in self._pts])
+        if self._weights is not None:
+
+            assert mat_w.shape == tuple([pt.size for pt in self._pts])
+
+            # call kernel (if mat_w is not zero) by calling the appropriate kernel (1d, 2d or 3d)
+            if np.any(np.abs(mat_w) > 1e-14):
+                self._dot_kernel(*self._codomain_spans, *self._domain_spans, *self._W.degree, *self._V.degree,
+                                 *self._codomain_starts, *self._domain_starts, *
+                                 self._codomain_pads, *self._domain_pads, *self._wts,
+                                 *self._codomain_basis, *self._domain_basis, mat_w,
+                                 out._data, v._data)
+
+            out.exchange_assembly_data()
+        return out
+
+    def diagonal(self, inverse=False, sqrt=False, out=None):
+        """
+        Get the coefficients on the main diagonal as a StencilDiagonalMatrix object.
+
+        Parameters
+        ----------
+        inverse : bool
+            If True, get the inverse of the diagonal. (Default: False).
+
+        sqrt : bool
+            If True, get the square root of the diagonal. (Default: False).
+            Can be combined with inverse to get the inverse square root
+
+        out : StencilDiagonalMatrix
+            If provided, write the diagonal entries into this matrix. (Default: None).
+
+        Returns
+        -------
+        StencilDiagonalMatrix
+            The matrix which contains the main diagonal of self (or its inverse).
+
+        """
+        # Check `inverse` argument
+        assert isinstance(inverse, bool)
+
+        # Only if domain == codomain
+        assert self.domain == self.codomain
+
+        # Determine domain and codomain of the StencilDiagonalMatrix
+        V, W = self.domain, self.codomain
+
+        # Check `out` argument
+        if out is not None:
+            assert isinstance(out, StencilDiagonalMatrix)
+            assert out.domain is V
+            assert out.codomain is W
+
+        # evaluate weight at quadrature points
+        if callable(self._weights):
+            PTS = np.meshgrid(*self._pts, indexing='ij')
+            mat_w = self._weights(*PTS).copy()
+        elif isinstance(self._weights, np.ndarray):
+            mat_w = self._weights
+
+        diag = self._diag_tmp
+        diag[:] = 0.
+        self._diag_kernel(*self._codomain_spans, *self._W.degree, *self._codomain_starts,
+                          *self._codomain_pads, *self._wts, *self._codomain_basis, mat_w, diag)
+
+        data = out._data if out else None
+
+        # Calculate entries of StencilDiagonalMatrix
+        if sqrt:
+            diag = np.sqrt(diag)
+
+        if inverse:
+            data = np.divide(1, diag, out=data)
+        elif out:
+            np.copyto(data, diag)
+        else:
+            data = diag.copy()
+
+        # If needed create a new StencilDiagonalMatrix object
+        if out is None:
+            out = StencilDiagonalMatrix(V, W, data)
 
-        # call kernel (if mat_w is not zero) by calling the appropriate kernel (1d, 2d or 3d)
-        if np.any(np.abs(mat_w) > 1e-14):
-            self._dot_kernel(*self._codomain_spans, *self._domain_spans, *self._W.degree, *self._V.degree, 
-                            *self._codomain_starts, *self._domain_starts, *self._codomain_pads, *self._domain_pads, *self._wts, 
-                            *self._codomain_basis, *self._domain_basis, mat_w, 
-                            out._data, v._data)
-                
-        out.exchange_assembly_data()
-        return out
+        return out
```

### Comparing `struphy-2.2.0/src/struphy/feec/mass_kernels.py` & `struphy-2.3.0/src/struphy/feec/mass_kernels.py`

 * *Files 2% similar despite different names*

```diff
@@ -412,15 +412,15 @@
                                 for q2 in range(nq2):
                                     for q3 in range(nq3):
                                         values[iel1*nq1 + q1, iel2*nq2 + q2, iel3*nq3 + q3] += \
                                             coeffs_data[pads1 + i_local1, pads2 + i_local2, pads3 + i_local3] \
                                             * bi1[iel1, il1, 0, q1] * bi2[iel2, il2, 0, q2] * bi3[iel3, il3, 0, q3]
 
 
-def kernel_3d_matrixless(spansi1: 'int[:]', spansi2: 'int[:]', spansi3: 'int[:]', spansj1: 'int[:]', spansj2: 'int[:]', spansj3: 'int[:]', pi1: int, pi2: int, pi3: int, pj1: int, pj2: int, pj3: int, startsi1: int, startsi2: int, startsi3: int, startsj1: int, startsj2: int, startsj3: int, padsi1: int, padsi2: int, padsi3: int, padsj1: int, padsj2: int, padsj3: int, w1: 'float[:,:]', w2: 'float[:,:]', w3: 'float[:,:]', bi1: 'float[:,:,:,:]', bi2: 'float[:,:,:,:]', bi3: 'float[:,:,:,:]', bj1: 'float[:,:,:,:]', bj2: 'float[:,:,:,:]', bj3: 'float[:,:,:,:]', mat_fun: 'float[:,:,:]', data_out: 'float[:,:,:]', data_in: 'float[:,:,:]'):
+def kernel_3d_matrixfree(spansi1: 'int[:]', spansi2: 'int[:]', spansi3: 'int[:]', spansj1: 'int[:]', spansj2: 'int[:]', spansj3: 'int[:]', pi1: int, pi2: int, pi3: int, pj1: int, pj2: int, pj3: int, startsi1: int, startsi2: int, startsi3: int, startsj1: int, startsj2: int, startsj3: int, padsi1: int, padsi2: int, padsi3: int, padsj1: int, padsj2: int, padsj3: int, w1: 'float[:,:]', w2: 'float[:,:]', w3: 'float[:,:]', bi1: 'float[:,:,:,:]', bi2: 'float[:,:,:,:]', bi3: 'float[:,:,:,:]', bj1: 'float[:,:,:,:]', bj2: 'float[:,:,:,:]', bj3: 'float[:,:,:,:]', mat_fun: 'float[:,:,:]', data_out: 'float[:,:,:]', data_in: 'float[:,:,:]'):
     """
     Performs the integration of Lambda_ijk * mat_fun(eta1, eta2, eta3) * f(eta1, eta2, eta3) for the basis functions (ijk) available on the calling process,
     where f is the spline function represented by the coefficients in data_in. 
 
     The results are written into data (attention: data is NOT set to zero first, but the results are added to data).
     """
 
@@ -515,7 +515,98 @@
                                             tmp_bi2[il2] * \
                                             tmp_bi3[il3]
 
                                         value = wvol * bi * bj
 
                                         data_out[i_local1, i_local2,
                                                  i_local3] += value
+                                        
+
+def kernel_3d_diag(spans1: 'int[:]', spans2: 'int[:]', spans3: 'int[:]', pi1: int, pi2: int, pi3: int, starts1: int, starts2: int, starts3: int, pads1: int, pads2: int, pads3: int, w1: 'float[:,:]', w2: 'float[:,:]', w3: 'float[:,:]', bi1: 'float[:,:,:,:]', bi2: 'float[:,:,:,:]', bi3: 'float[:,:,:,:]', mat_fun: 'float[:,:,:]', data: 'float[:,:,:]'):
+    """
+    Computes the diagonal of a mass matrix, assuming that the domain and the codomain are the same.
+
+    The results are written into data (attention: data is NOT set to zero first, but the results are added to data).
+    """
+
+    import numpy as np
+
+    ne1 = spans1.size
+    ne2 = spans2.size
+    ne3 = spans3.size
+
+    nq1 = shape(w1)[1]
+    nq2 = shape(w2)[1]
+    nq3 = shape(w3)[1]
+
+    nb1, nb2, nb3 = data.shape
+
+    tmp_bi1 = np.zeros(nq1)
+    tmp_bi2 = np.zeros(nq2)
+    tmp_bi3 = np.zeros(nq3)
+
+    tmp_w1 = np.zeros(nq1)
+    tmp_w2 = np.zeros(nq2)
+    tmp_w3 = np.zeros(nq3)
+
+    tmp_mat_fun = np.zeros((nq1, nq2, nq3))
+
+    for iel1 in range(ne1):
+        for iel2 in range(ne2):
+            for iel3 in range(ne3):
+
+                tmp_mat_fun[:, :, :] = mat_fun[iel1 * nq1: (iel1+1) * nq1,
+                                               iel2 * nq2: (iel2+1) * nq2,
+                                               iel3 * nq3: (iel3+1) * nq3]
+
+                tmp_w1[:] = w1[iel1, :]
+                tmp_w2[:] = w2[iel2, :]
+                tmp_w3[:] = w3[iel3, :]
+
+                for il1 in range(pi1 + 1):
+                    for il2 in range(pi2 + 1):
+                        for il3 in range(pi3 + 1):
+
+                            tmp_bi1[:] = bi1[iel1, il1, 0, :]
+                            tmp_bi2[:] = bi2[iel2, il2, 0, :]
+                            tmp_bi3[:] = bi3[iel3, il3, 0, :]
+
+                            # global spline indices
+                            i_global1 = spans1[iel1] - pi1 + il1
+                            i_global2 = spans2[iel2] - pi2 + il2
+                            i_global3 = spans3[iel3] - pi3 + il3
+
+                            # local spline indices (- starts --> can be negative, will therefore be written to ghost regions)
+                            i_local1 = i_global1 - starts1
+                            i_local2 = i_global2 - starts2
+                            i_local3 = i_global3 - starts3
+                            
+                            # Periodic case : last basis function are the first ones (no ghost regions on DiagonalStencilMatrix)
+                            if i_local1>=nb1:
+                                i_local1 -= nb1
+                                
+                            if i_local2>=nb2:
+                                i_local2 -= nb2
+
+                            if i_local3>=nb3:
+                                i_local3 -= nb3
+
+                            value = 0.
+
+                            for q1 in range(nq1):
+                                for q2 in range(nq2):
+                                    for q3 in range(nq3):
+
+                                        wvol = tmp_w1[q1] * tmp_w2[q2] * tmp_w3[q3] * \
+                                            tmp_mat_fun[q1, q2, q3]
+
+                                        bi = tmp_bi1[q1] * \
+                                            tmp_bi2[q2] * \
+                                            tmp_bi3[q3]
+                                        
+                                        
+                                        value += wvol * bi * bi
+
+                            # No padding on StencilDiagonalMatrix
+                            data[i_local1, i_local2, i_local3] += value
+
+
```

### Comparing `struphy-2.2.0/src/struphy/feec/preconditioner.py` & `struphy-2.3.0/src/struphy/feec/projectors.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,607 +1,662 @@
-from psydac.linalg.basic import Vector, LinearSolver, LinearOperator, ComposedLinearOperator
-from psydac.linalg.direct_solvers import DirectSolver, SparseSolver
-from psydac.linalg.stencil import StencilMatrix, StencilVectorSpace
-from psydac.linalg.block import BlockLinearOperator, BlockDiagonalSolver
-from psydac.linalg.kron import KroneckerLinearSolver, KroneckerStencilMatrix
-
+from psydac.linalg.stencil import StencilVector
+from psydac.linalg.block import BlockVector, BlockLinearOperator
+from psydac.linalg.kron import KroneckerStencilMatrix
+from psydac.linalg.basic import Vector, IdentityOperator
+from psydac.linalg.solvers import inverse
 from psydac.fem.tensor import TensorFemSpace
+from psydac.feec.global_projectors import GlobalProjector
+from psydac.api.settings import PSYDAC_BACKEND_GPYCCEL
 
-from psydac.ddm.cart import DomainDecomposition, CartDecomposition
-from psydac.api.essential_bc import apply_essential_bc_stencil
-
-from struphy.feec.linear_operators import BoundaryOperator
-from struphy.feec.mass import WeightedMassOperator
+from struphy.polar.linear_operators import PolarExtractionOperator
+from struphy.feec.mass import WeightedMassOperators
+from struphy.feec import preconditioner
+from struphy.feec.preconditioner import ProjectorPreconditioner
+from struphy.feec import mass_kernels
+from struphy.fields_background.mhd_equil.equils import set_defaults
 
-from scipy.linalg import solve_circulant
 import numpy as np
-from scipy import sparse
 
-class MassMatrixPreconditioner(LinearOperator):
+
+class CommutingProjector:
     """
-    Preconditioner for inverting 3d weighted mass matrices. 
+    A commuting projector in a 3d de Rham diagram (can be polar). 
+
+    The general structure of the inter-/histopolation problem reads
+
+         (B * P * Imat * E^T * B^T) * coeffs = B * P * dofs,
 
-    The mass matrix is approximated by a Kronecker product of 1d mass matrices 
-    in each direction with correct boundary conditions (block diagonal in case of vector-valued spaces). 
-    In this process, the 3d weight function is appoximated by a 1d counterpart in the FIRST (eta_1) direction
-    at the fixed point (eta_2=0.5, eta_3=0.5). The inversion is then performed with a Kronecker solver.
+    with the following linear operators:
+
+        * B    : boundary operator,
+        * P    : polar degrees of freedom extraction operator,
+        * Imat : tensor product inter-/histopolation matrix,
+        * E    : polar basis extraction operator.
+
+    P and E (and B in case of no boundary conditions) can be identity operators, 
+    which gives the pure tensor-product Psydac projector.
 
     Parameters
     ----------
-    mass_operator : struphy.feec.mass.WeightedMassOperator
-        The weighted mass operator for which the approximate inverse is needed.
+    projector_tensor : psydac.feec.global_projectors.GlobalProjector
+        The pure tensor product projector.
+
+    dofs_extraction_op : struphy.polar.linear_operators.PolarExtractionOperator, optional
+        The degrees of freedom extraction operator mapping tensor product DOFs to polar DOFs. If not given, is set to identity.
 
-    apply_bc : bool
-        Whether to include boundary operators.
+    base_extraction_op : struphy.polar.linear_operators.PolarExtractionOperator, optional
+        The basis extraction operator mapping tensor product basis functions to polar basis functions. If not given, is set to identity.
 
-    dim_reduce : int
-        Along which axis to take the approximate value of the weight
+    boundary_op : struphy.feec.linear_operators.BoundaryOperator.
+        The boundary operator applying essential boundary conditions to a vector. If not given, is set to identity.
     """
 
-    def __init__(self, mass_operator, apply_bc=True, dim_reduce=0):
+    def __init__(self, projector_tensor: GlobalProjector, dofs_extraction_op=None, base_extraction_op=None, boundary_op=None):
 
-        assert isinstance(mass_operator, WeightedMassOperator)
-        assert mass_operator.domain == mass_operator.codomain, 'Only square mass matrices can be inverted!'
+        self._projector_tensor = projector_tensor
 
-        self._mass_operator = mass_operator
-        self._femspace = mass_operator.domain_femspace
-        self._space = mass_operator.domain
-        self._dtype = mass_operator.dtype
-        self._codomain = mass_operator.codomain
-        self._apply_bc = apply_bc
-        
-        # 3d Kronecker stencil matrices and solvers
-        solverblocks = []
-        matrixblocks = []
-
-        # collect TensorFemSpaces in a tuple
-        if isinstance(self._femspace, TensorFemSpace):
-            femspaces = (self._femspace,)
-        else:
-            femspaces = self._femspace.spaces
-
-        n_comps = len(femspaces)
-        n_dims = self._femspace.ldim
-
-        assert n_dims == 3  # other dims not yet implemented
-        assert dim_reduce<n_dims
-
-        # get boundary conditions list from BoundaryOperator in ComposedLinearOperator M0 of mass operator
-        if apply_bc and isinstance(mass_operator.M0, ComposedLinearOperator):            
-            if isinstance(mass_operator.M0.multiplicants[-1], BoundaryOperator):
-                bc = mass_operator.M0.multiplicants[-1].bc
-            else:
-                apply_bc = False
-                bc = None
+        if dofs_extraction_op is not None:
+            self._dofs_extraction_op = dofs_extraction_op
         else:
-            apply_bc = False
-            bc = None
+            self._dofs_extraction_op = IdentityOperator(
+                self.space.vector_space)
 
-        # loop over components
-        for c in range(n_comps):
+        if base_extraction_op is not None:
+            self._base_extraction_op = base_extraction_op
+        else:
+            self._base_extraction_op = IdentityOperator(
+                self.space.vector_space)
 
-            # 1d mass matrices and solvers
-            solvercells = []
-            matrixcells = []
-
-            # loop over spatial directions
-            for d in range(n_dims):
-
-                # weight function only along in first direction
-                if d == dim_reduce:
-                    #pts = [0.5] * (n_dims - 1)
-                    loc_weights = mass_operator.weights[c][c]
-                    if callable(loc_weights):
-                        def fun(e):
-                            # make input in meshgrid format to be able to use it with general functions
-                            s = e.shape[0]
-                            newshape = tuple([1 if i!=d else s for i in range(n_dims)])
-                            f = e.reshape(newshape)
-                            return loc_weights(*[np.array(np.full_like(f, .5)) if i!=d else np.array(f) for i in range(n_dims)]).squeeze()
-                    elif isinstance(loc_weights, np.ndarray):
-                        s = loc_weights.shape
-                        if d == 0:
-                            fun = loc_weights[:,s[1]//2,s[2]//2]
-                        elif d==1:
-                            fun = loc_weights[s[0]//2,:,s[2]//2]
-                        elif d==2:
-                            fun = loc_weights[s[0]//2,s[1]//2,:]
-                    elif loc_weights is None:
-                        fun = lambda e: np.ones(e.size, dtype=float)
-                    else : 
-                        raise TypeError("weights needs to be callable, np.ndarray or None but is{}".format(type(loc_weights)))
-                    fun = [[fun]]
-                else:
-                    fun = [[lambda e: np.ones(e.size, dtype=float)]]
+        if boundary_op is not None:
+            self._boundary_op = boundary_op
+        else:
+            self._boundary_op = IdentityOperator(self.space.vector_space)
 
-                # get 1D FEM space (serial, not distributed) and quadrature order
-                femspace_1d = femspaces[c].spaces[d]
-                qu_order_1d = femspaces[c].nquads[d]
-
-                # assemble 1d weighted mass matrix
-                domain_decompos_1d = DomainDecomposition(
-                    [femspace_1d.ncells], [femspace_1d.periodic])
-                femspace_1d_tensor = TensorFemSpace(
-                    domain_decompos_1d, femspace_1d, nquads=[qu_order_1d])
-
-                M = WeightedMassOperator(
-                    femspace_1d_tensor, femspace_1d_tensor, weights_info=fun)
-                M.assemble(verbose=False)
-                M = M.matrix
+        # convert Kronecker inter-/histopolation matrix to Stencil-/BlockLinearOperator (only needed in polar case)
+        if isinstance(self.dofs_extraction_op, PolarExtractionOperator):
 
-                # apply boundary conditions
-                if apply_bc:
-                    if mass_operator._domain_symbolic_name != 'H1vec':
-                        if femspace_1d.basis == 'B':
-                            if bc[d][0]:
-                                apply_essential_bc_stencil(
-                                    M, axis=0, ext=-1, order=0, identity=True)
-                            if bc[d][1]:
-                                apply_essential_bc_stencil(
-                                    M, axis=0, ext=+1, order=0, identity=True)
-                    else:
-                        if c == d:
-                            if bc[d][0]:
-                                apply_essential_bc_stencil(
-                                    M, axis=0, ext=-1, order=0, identity=True)
-                            if bc[d][1]:
-                                apply_essential_bc_stencil(
-                                    M, axis=0, ext=+1, order=0, identity=True)
-
-                M_arr = M.toarray()
-
-                # create 1d solver for mass matrix
-                if is_circulant(M_arr):
-                    solvercells += [FFTSolver(M_arr)]
-                else:
-                    solvercells += [SparseSolver(M.tosparse())]
+            self._is_polar = True
 
-                # === NOTE: for KroneckerStencilMatrix being built correctly, 1d matrices must be local to process! ===
-                periodic = femspaces[c].vector_space.periods[d]
+            if isinstance(projector_tensor.imat_kronecker, KroneckerStencilMatrix):
+                self._imat = projector_tensor.imat_kronecker.tostencil()
+                self._imat.set_backend(
+                    PSYDAC_BACKEND_GPYCCEL, precompiled=True)
+            else:
 
-                n = femspaces[c].vector_space.npts[d]
-                p = femspaces[c].vector_space.pads[d]
-                s = femspaces[c].vector_space.starts[d]
-                e = femspaces[c].vector_space.ends[d]
+                b11 = projector_tensor.imat_kronecker.blocks[0][0].tostencil()
+                b11.set_backend(PSYDAC_BACKEND_GPYCCEL, precompiled=True)
+                b22 = projector_tensor.imat_kronecker.blocks[1][1].tostencil()
+                b22.set_backend(PSYDAC_BACKEND_GPYCCEL, precompiled=True)
+                b33 = projector_tensor.imat_kronecker.blocks[2][2].tostencil()
+                b33.set_backend(PSYDAC_BACKEND_GPYCCEL, precompiled=True)
 
-                cart_decomp_1d = CartDecomposition(
-                    domain_decompos_1d, [n], [[s]], [[e]], [p], [1])
+                blocks = [[b11, None, None],
+                          [None, b22, None],
+                          [None, None, b33]]
 
-                V_local = StencilVectorSpace(cart_decomp_1d)
+                self._imat = BlockLinearOperator(
+                    self.space.vector_space, self.space.vector_space, blocks)
 
-                M_local = StencilMatrix(V_local, V_local)
+        else:
 
-                row_indices, col_indices = np.nonzero(M_arr)
+            self._is_polar = False
 
-                for row_i, col_i in zip(row_indices, col_indices):
+            self._imat = projector_tensor.imat_kronecker
 
-                    # only consider row indices on process
-                    if row_i in range(V_local.starts[0], V_local.ends[0] + 1):
-                        row_i_loc = row_i - s
+        # transposed
+        self._imatT = self._imat.T
 
-                        M_local._data[row_i_loc + p, (col_i + p - row_i) %
-                                      M_arr.shape[1]] = M_arr[row_i, col_i]
+        # some shortcuts
+        P = self._dofs_extraction_op
+        E = self._base_extraction_op
 
-                # check if stencil matrix was built correctly
-                assert np.allclose(M_local.toarray()[s:e + 1], M_arr[s:e + 1])
+        B = self._boundary_op
 
-                matrixcells += [M_local.copy()]
-                # =======================================================================================================
+        # build inter-/histopolation matrix I = ID * P * I * E^T * ID^T and I0 = B * P * I * E^T * B^T as ComposedLinearOperator
+        self._I = P @ self._imat @ E.T
+        self._I0 = B @ self._I @ B.T
 
-            if isinstance(self._femspace, TensorFemSpace):
-                matrixblocks += [KroneckerStencilMatrix(
-                    self._femspace.vector_space, self._femspace.vector_space, *matrixcells)]
-                solverblocks += [KroneckerLinearSolver(
-                    self._femspace.vector_space, solvercells)]
-            else:
-                matrixblocks += [KroneckerStencilMatrix(
-                    self._femspace.vector_space[c], self._femspace.vector_space[c], *matrixcells)]
-                solverblocks += [KroneckerLinearSolver(
-                    self._femspace.vector_space[c], solvercells)]
-
-        # build final matrix and solver
-        if isinstance(self._femspace, TensorFemSpace):
-            self._matrix = matrixblocks[0]
-            self._solver = solverblocks[0]
-        else:
-
-            blocks = [[matrixblocks[0], None, None],
-                      [None, matrixblocks[1], None],
-                      [None, None, matrixblocks[2]]]
-
-            self._matrix = BlockLinearOperator(
-                self._femspace.vector_space, self._femspace.vector_space, blocks=blocks)
-            self._solver = BlockDiagonalSolver(
-                self._femspace.vector_space, solverblocks)
+        # transposed
+        self._IT = E @ self._imatT @ P.T
+        self._I0T = B @ self._IT @ B.T
 
-        # save mass operator to be inverted (needed in solve method)
-        if apply_bc:
-            self._M = mass_operator.M0
-        else:
-            self._M = mass_operator.M
-            
-        self._is_composed = isinstance(self._M, ComposedLinearOperator)
-        
-        # temporary vectors for dot product
-        if self._is_composed:
-            tmp_vectors = []
-            for op in self._M.multiplicants[1:]:
-                tmp_vectors.append(op.codomain.zeros())
+        # preconditioner ID * P * I^(-1) * E^T * ID^T and B * P * I^(-1) * E^T * B^T for iterative polar projections
+        self._pc = ProjectorPreconditioner(
+            self, transposed=False, apply_bc=False)
+        self._pc0 = ProjectorPreconditioner(
+            self, transposed=False, apply_bc=True)
 
-            self._tmp_vectors = tuple(tmp_vectors)
+        # transposed
+        self._pcT = ProjectorPreconditioner(
+            self, transposed=True, apply_bc=False)
+        self._pc0T = ProjectorPreconditioner(
+            self, transposed=True, apply_bc=True)
+
+        # linear solver used for polar projections
+        if self._is_polar:
+            self._polar_solver = inverse(
+                self._I, 'pbicgstab', pc=self._pc, tol=1e-14, maxiter=1000, verbose=False)
+            self._polar_solver0 = inverse(
+                self._I0, 'pbicgstab', pc=self._pc0, tol=1e-14, maxiter=1000, verbose=False)
+            self._polar_solverT = inverse(
+                self._IT, 'pbicgstab', pc=self._pcT, tol=1e-14, maxiter=1000, verbose=False)
+            self._polar_solver0T = inverse(
+                self._I0T, 'pbicgstab', pc=self._pc0T, tol=1e-14, maxiter=1000, verbose=False)
         else:
-            self._tmp_vector = self._M.codomain.zeros() 
+            self._polar_solver = None
+
+        self._polar_info = None
+
+    @property
+    def projector_tensor(self):
+        """ Tensor product projector.
+        """
+        return self._projector_tensor
 
     @property
     def space(self):
-        """ Stencil-/BlockVectorSpace or PolarDerhamSpace.
+        """ Tensor product FEM space corresponding to projector.
         """
-        return self._space
+        return self._projector_tensor.space
 
     @property
-    def matrix(self):
-        """ Approximation of the input mass matrix as KroneckerStencilMatrix.
+    def dofs_extraction_op(self):
+        """ Degrees of freedom extraction operator (tensor product DOFs --> polar DOFs).
         """
-        return self._matrix
+        return self._dofs_extraction_op
 
     @property
-    def solver(self):
-        """ KroneckerLinearSolver or BlockDiagonalSolver for exactly inverting the approximate mass matrix self.matrix.
+    def base_extraction_op(self):
+        """ Basis functions extraction operator (tensor product basis functions --> polar basis functions).
         """
-        return self._solver
-    
+        return self._base_extraction_op
+
     @property
-    def domain(self):
-        """ The domain of the linear operator - an element of Vectorspace """
-        return self._space
+    def boundary_op(self):
+        """ Boundary operator setting essential boundary conditions to Stencil-/BlockVector.
+        """
+        return self._boundary_op
 
     @property
-    def codomain(self):
-        """ The codomain of the linear operator - an element of Vectorspace """
-        return self._codomain
+    def is_polar(self):
+        """ Whether the projector maps to polar splines (True) or pure tensor product splines.
+        """
+        return self._is_polar
 
     @property
-    def dtype(self):
-        return self._dtype
+    def I(self):
+        """ Inter-/histopolation matrix ID * P * I * E^T * ID^T as ComposedLinearOperator (ID = IdentityOperator).
+        """
+        return self._I
 
-    def tosparse(self):
-        raise NotImplementedError()
+    @property
+    def I0(self):
+        """ Inter-/histopolation matrix B * P * I * E^T * B^T as ComposedLinearOperator.
+        """
+        return self._I0
 
-    def toarray(self):
-        raise NotImplementedError()
+    @property
+    def IT(self):
+        """ Transposed inter-/histopolation matrix ID * E * I^T * P^T * ID^T as ComposedLinearOperator (ID = IdentityOperator).
+        """
+        return self._IT
 
-    def transpose(self, conjugate=False):
+    @property
+    def I0T(self):
+        """ Transposed inter-/histopolation matrix B * E * I^T * P^T * B^T as ComposedLinearOperator.
         """
-        Returns the transposed operator.
+        return self._I0T
+
+    @property
+    def pc(self):
+        """ Preconditioner P * I^(-1) * E^T for iterative polar projections.
         """
-        return MassMatrixPreconditioner(self._mass_operator.transpose(), self._apply_bc)
+        return self._pc
 
+    @property
+    def pc0(self):
+        """ Preconditioner B * P * I^(-1) * E^T * B^T for iterative polar projections.
+        """
+        return self._pc0
+
+    @property
+    def pcT(self):
+        """ Transposed preconditioner P * I^(-T) * E^T for iterative polar projections.
+        """
+        return self._pcT
 
+    @property
+    def pc0T(self):
+        """ Transposed preconditioner B * P * I^(-T) * E^T * B^T for iterative polar projections.
+        """
+        return self._pc0T
 
-    def solve(self, rhs, out=None):
+    def solve(self, rhs, transposed=False, apply_bc=False, out=None):
         """
-        Computes (B * E * M^(-1) * E^T * B^T) * rhs as an approximation for an inverse mass matrix.
+        Solves the linear system I * x = rhs, resp. I^T * x = rhs for x, where I is the composite inter-/histopolation matrix.
 
         Parameters
         ----------
-        rhs : psydac.linalg.basic.Vector
-            The right-hand side vector.
+        rhs : psydac.linalg.basic.vector
+            The right-hand side of the linear system.
+
+        transposed : bool, optional
+            Whether to invert the transposed inter-/histopolation matrix.
 
-        out : psydac.linalg.basic.Vector, optional
-            If given, the output vector will be written into this vector in-place.
+        apply_bc : bool, optional
+            Whether to apply essential boundary conditions to degrees of freedom and coefficients.
+
+        out : psydac.linalg.basic.vector, optional
+            If given, the result will be written into this vector in-place.
 
         Returns
         -------
-        out : psydac.linalg.basic.Vector
-            The result of (B * E * M^(-1) * E^T * B^T) * rhs.
+        x : psydac.linalg.basic.vector
+            Output vector (result of linear system).
         """
 
         assert isinstance(rhs, Vector)
-        assert rhs.space == self._space
+        assert rhs.space == self._I.domain
 
-        # successive dot products with all but last operator
-        if self._is_composed:
-            x = rhs
-            for i in range(len(self._tmp_vectors)):
-                y = self._tmp_vectors[-1 - i]
-                A = self._M.multiplicants[-1 - i]
-                if isinstance(A, (StencilMatrix, BlockLinearOperator)):
-                    self.solver.solve(x, out=y)
+        if transposed:
+            # polar case (iterative solve with PBiConjugateGradientStab)
+            if self.is_polar:
+                if apply_bc:
+                    x = self._polar_solver0T.solve(
+                        self._boundary_op.T.dot(rhs), out=out)
                 else:
-                    A.dot(x, out=y)
-                x = y
-
-            # last operator
-            A = self._M.multiplicants[0]
-            if out is None:
-                out = A.dot(x)
+                    x = self._polar_solverT.solve(
+                        self._boundary_op.T.dot(rhs), out=out)
+            # standard (tensor product) case (Kronecker solver)
             else:
-                assert isinstance(out, Vector)
-                assert out.space == self._space
-                A.dot(x, out=out)
-                
+                if apply_bc:
+                    x = self.pc0T.solve(rhs, out=out)
+                else:
+                    x = self.pcT.solve(rhs, out=out)
         else:
-            if out is None:
-                out = self._tmp_vector
-            self.solver.solve(rhs, out=out)
+            # polar case (iterative solve with PBiConjugateGradientStab)
+            if self.is_polar:
+                if apply_bc:
+                    x = self._polar_solver0.solve(
+                        self._boundary_op.T.dot(rhs), out=out)
+                else:
+                    x = self._polar_solver.solve(
+                        self._boundary_op.T.dot(rhs), out=out)
+            # standard (tensor product) case (Kronecker solver)
+            else:
+                if apply_bc:
+                    x = self.pc0.solve(rhs, out=out)
+                else:
+                    x = self.pc.solve(rhs, out=out)
 
-        return out
-    
-    def dot(self, v, out=None):
-        """ Apply linear operator to Vector v. Result is written to Vector out, if provided."""
-        
-        assert isinstance(v, Vector)
-        assert v.space == self.domain
+        return x
 
-        # newly created output vector
-        if out is None:
-            out = self.solve(v)
+    def get_dofs(self, fun, dofs=None, apply_bc=False):
+        """
+        Computes the geometric degrees of freedom associated to given callable(s).
+
+        Parameters
+        ----------
+        fun : callable | list
+            The function for which the geometric degrees of freedom shall be computed. List of callables for vector-valued functions.
+
+        dofs : psydac.linalg.basic.vector, optional
+            If given, the dofs will be written into this vector in-place.
 
-        # in-place dot-product (result is written to out)
+        apply_bc : bool, optional
+            Whether to apply essential boundary conditions to degrees of freedom.
+
+        Returns
+        -------
+        dofs : psydac.linalg.basic.vector
+            The geometric degrees of freedom associated to given callable(s) "fun".
+        """
+        # get dofs on tensor-product grid + apply polar DOF extraction operator
+        if dofs is None:
+            dofs = self.dofs_extraction_op.dot(
+                self.projector_tensor(fun, dofs_only=True))
         else:
+            self.dofs_extraction_op.dot(
+                self.projector_tensor(fun, dofs_only=True), out=dofs)
 
-            assert isinstance(out, Vector)
-            assert out.space == self.codomain
-            self.solve(v, out= out)
-            
+        # apply boundary operator
+        if apply_bc:
+            dofs = self.boundary_op.dot(dofs)
 
-        return out
+        return dofs
 
+    def __call__(self, fun, out=None, dofs=None, apply_bc=False):
+        """
+        Applies projector to given callable(s).
 
-class ProjectorPreconditioner(LinearOperator):
-    """
-    Preconditioner for approximately inverting a (polar) 3d inter-/histopolation matrix via
+        Parameters
+        ----------
+        fun : callable | list
+            The function to be projected. List of three callables for vector-valued functions.
 
-        (B * P * I * E^T * B^T)^(-1) approx. B * P * I^(-1) * E^T * B^T.
+        out : psydac.linalg.basic.vector, optional
+            If given, the result will be written into this vector in-place.
 
-    In case that P and E are identity operators, the solution is exact (pure tensor product case).
+        dofs : psydac.linalg.basic.vector, optional
+            If given, the dofs will be written into this vector in-place.
 
-    Parameters
-    ----------
-    projector : struphy.feec.projectors.CommutingProjector
-        The global commuting projector for which the inter-/histopolation matrix shall be inverted. 
+        apply_bc : bool, optional
+            Whether to apply essential boundary conditions to degrees of freedom and coefficients.
 
-    transposed : bool, optional
-        Whether to invert the transposed inter-/histopolation matrix.
+        Returns
+        -------
+        coeffs : psydac.linalg.basic.vector
+            The FEM spline coefficients after projection.
+        """
+        return self.solve(self.get_dofs(fun, dofs=dofs, apply_bc=apply_bc), transposed=False,
+                          apply_bc=apply_bc, out=out)
 
-    apply_bc : bool, optional
-        Whether to include the boundary operators.
-    """
 
-    def __init__(self, projector, transposed=False, apply_bc=False):
+class L2Projector:
+    r"""
+    A projector into the discrete Derham spaces based on the L2-scalar product in logical coordinates.
 
-        # vector space in tensor product case/polar case
-        self._space = projector.I.domain
-        
-        self._codomain = projector.I.codomain
-        
-        self._dtype = projector.I.dtype
-        
-        self._projector = projector
-        
-        self._apply_bc = apply_bc
-        
-        # save Kronecker solver (needed in solve method)
-        self._solver = projector.projector_tensor.solver
+    It solves the following system for the FE-coefficients
 
-        self._transposed = transposed
+    .. math::
 
-        # save inter-/histopolation matrix to be inverted
-        if transposed:
-            self._I = projector.IT
-        else:
-            self._I = projector.I
-          
-        self._is_composed = isinstance(self._I, ComposedLinearOperator)
-        
-        # temporary vectors for dot product
-        if self._is_composed:
-            tmp_vectors = []
-            for op in self._I.multiplicants[1:]:
-                tmp_vectors.append(op.codomain.zeros())
+        \mathbb M^p_{ijk, lmn} f_{lmn} = (f^p(\boldsymbol \eta), \Lambda^p_{ijk})_{L^2}\,,
 
-            self._tmp_vectors = tuple(tmp_vectors)
-        else:
-            self._tmp_vector = self._I.codomain.zeros() 
+    where :math:`M^p` denotes the mass matrix of space :math:`p` and :math:`f^p` is a :math:`p`-form proxy function. 
+
+    Parameters:
+    -----------
+    space_id : str
+        One of "H1", "Hcurl", "Hdiv", "L2" or "H1vec".
+
+    mass_ops : struphy.mass.WeighteMassOperators
+        Mass operators object, see :ref:`mass_ops`.
+
+    params : dict
+        Keyword arguments for the solver parameters.
+    """
+
+    def __init__(self, space_id, mass_ops, **params):
+
+
+        assert space_id in ('H1', 'Hcurl', 'Hdiv', 'L2', 'H1vec')
+
+        params_default = {'type': ('pcg', 'MassMatrixPreconditioner'),
+                          'tol': 1.e-14,
+                          'maxiter': 500,
+                          'info': False,
+                          'verbose': False, }
+
+        set_defaults(params, params_default)
+
+        self._space_id = space_id
+        self._mass_ops = mass_ops
+        self._params = params
+        self._space_key = mass_ops.derham.space_to_form[self.space_id]
+        self._space = mass_ops.derham.Vh_fem[self.space_key]
+
+        # mass matrix
+        self._Mmat = getattr(self.mass_ops, 'M' + self.space_key)
+
+        # quadrature grid
+        self._quad_grid_pts = self.mass_ops.derham.quad_grid_pts[self.space_key]
+
+        if space_id in ('H1', 'L2'):
+            self._quad_grid_mesh = np.meshgrid(
+                *[pt.flatten() for pt in self.quad_grid_pts], indexing='ij')
+            self._geom_weights = self.Mmat.weights[0][0](*self.quad_grid_mesh)
+        else:
+            self._quad_grid_mesh = []
+            self._tmp = []  # tmp for matrix-vector product of geom_weights with fun
+            for pts in self.quad_grid_pts:
+                self._quad_grid_mesh += [np.meshgrid(*[pt.flatten() for pt in pts], indexing='ij')]
+                self._tmp += [np.zeros_like(self.quad_grid_mesh[-1][0])]
+            # geometric weights evaluated at quadrature grid
+            self._geom_weights = []
+            # loop over rows (different meshes)
+            for mesh, row_weights in zip(self.quad_grid_mesh, self.Mmat.weights):
+                self._geom_weights += [[]]
+                # loop over columns (differnt geometric coeffs)
+                for weight in row_weights:
+                    if weight is not None:
+                        self._geom_weights[-1] += [weight(*mesh)]
+                    else: 
+                        self._geom_weights[-1] += [np.zeros_like(mesh[0])]
+
+        # other quad grid info
+        if isinstance(self.space, TensorFemSpace):
+            self._tensor_fem_spaces = [self.space]
+            self._wts_l = [self.mass_ops.derham.quad_grid_wts[self.space_key]]
+            self._spans_l = [
+                self.mass_ops.derham.quad_grid_spans[self.space_key]]
+            self._bases_l = [
+                self.mass_ops.derham.quad_grid_bases[self.space_key]]
+        else:
+            self._tensor_fem_spaces = self.space.spaces
+            self._wts_l = self.mass_ops.derham.quad_grid_wts[self.space_key]
+            self._spans_l = self.mass_ops.derham.quad_grid_spans[self.space_key]
+            self._bases_l = self.mass_ops.derham.quad_grid_bases[self.space_key]
+
+        # Preconditioner
+        if self.params['type'][1] is None:
+            pc = None
+        else:
+            pc_class = getattr(preconditioner, self.params['type'][1])
+            pc = pc_class(self.Mmat)
+
+        # solver
+        self._solver = inverse(self.Mmat,
+                               self.params['type'][0],
+                               pc=pc,
+                               tol=self.params['tol'],
+                               maxiter=self.params['maxiter'],
+                               verbose=self.params['verbose'])
+
+    @property
+    def mass_ops(self):
+        '''Struphy mass operators object, see :ref:`mass_ops`..'''
+        return self._mass_ops
+
+    @property
+    def space_id(self):
+        """ The ID of the space (H1, Hcurl, Hdiv, L2 or H1vec)."""
+        return self._space_id
+
+    @property
+    def space_key(self):
+        """ The key of the space (0, 1, 2, 3 or v)."""
+        return self._space_key
 
     @property
     def space(self):
-        """ Stencil-/BlockVectorSpace or PolarDerhamSpace.
-        """
+        '''The Derham finite element space (from Derham.Vh_fem).'''
         return self._space
 
     @property
-    def solver(self):
-        """ KroneckerLinearSolver for exactly inverting tensor product inter-histopolation matrix.
-        """
-        return self._solver
+    def params(self):
+        '''Parameters for the iterative solver.'''
+        return self._params
 
     @property
-    def transposed(self):
-        """ Whether to invert the transposed inter-/histopolation matrix.
-        """
-        return self._transposed
+    def Mmat(self):
+        '''The mass matrix of space.'''
+        return self._Mmat
 
     @property
-    def domain(self):
-        """ The domain of the linear operator - an element of Vectorspace """
-        return self._space
+    def quad_grid_pts(self):
+        '''List of quadrature points in each direction for integration over grid cells in format (ni, nq) = (cell, quadrature point).'''
+        return self._quad_grid_pts
 
     @property
-    def codomain(self):
-        """ The codomain of the linear operator - an element of Vectorspace """
-        return self._codomain
+    def quad_grid_mesh(self):
+        '''Mesh grids of quad_grid_pts.'''
+        return self._quad_grid_mesh
 
     @property
-    def dtype(self):
-        return self._dtype
-
-    def tosparse(self):
-        raise NotImplementedError()
+    def geom_weights(self):
+        '''Geometric coefficients (e.g. Jacobians) evaluated at quad_grid_mesh, stored as list[list] either 1x1 or 3x3.'''
+        return self._geom_weights
 
-    def toarray(self):
-        raise NotImplementedError()
-
-    def transpose(self, conjugate=False):
-        """
-        Returns the transposed operator.
-        """
-        return ProjectorPreconditioner(self._projector, True, self._apply_bc)
-    
     def solve(self, rhs, out=None):
         """
-        Computes (B * P * I^(-1) * E^T * B^T) * rhs, resp. (B * P * I^(-T) * E^T * B^T) * rhs (transposed=True) as an approximation for an inverse inter-/histopolation matrix.
+        Solves the linear system M * x = rhs, where M is the mass matrix.
 
         Parameters
         ----------
-        rhs : psydac.linalg.basic.Vector
-            The right-hand side vector.
+        rhs : psydac.linalg.basic.vector
+            The right-hand side of the linear system.
 
-        out : psydac.linalg.basic.Vector, optional
-            If given, the output vector will be written into this vector in-place.
+        out : psydac.linalg.basic.vector, optional
+            If given, the result will be written into this vector in-place.
 
         Returns
         -------
-        out : psydac.linalg.basic.Vector
-            The result of (B * E * M^(-1) * E^T * B^T) * rhs, resp. (B * P * I^(-T) * E^T * B^T) * rhs (transposed=True).
+        out : psydac.linalg.basic.vector
+            Output vector (result of linear system).
         """
 
         assert isinstance(rhs, Vector)
-        assert rhs.space == self._space
-
-        # successive dot products with all but last operator    
-        if self._is_composed:
-            x = rhs
-            for i in range(len(self._tmp_vectors)):
-                y = self._tmp_vectors[-1 - i]
-                A = self._I.multiplicants[-1 - i]
-                if isinstance(A, (StencilMatrix, KroneckerStencilMatrix, BlockLinearOperator)):
-                    self.solver.solve(x, out=y, transposed=self._transposed)
-                else:
-                    A.dot(x, out=y)
-                x = y
 
-            # last operator
-            A = self._I.multiplicants[0]
-            if out is None:
-                out = A.dot(x)
-            else:
-                assert isinstance(out, Vector)
-                assert out.space == self._space
-                A.dot(x, out=out)
-                
+        if out is None:
+            out = self._solver.dot(rhs)
         else:
-            if out is None:
-                out = self.solver.solve(rhs, transposed=self._transposed)
-            self.solver.solve(rhs, out=out, transposed=self._transposed)
+            self._solver.dot(rhs, out=out)
 
         return out
-    
-    def dot(self, v, out=None):
-        """ Apply linear operator to Vector v. Result is written to Vector out, if provided."""
+
+    def get_dofs(self, fun, dofs=None, apply_bc=False, clear=True):
+        r"""
+        Assembles (in 3d) the Stencil-/BlockVector
         
-        assert isinstance(v, Vector)
-        assert v.space == self.domain
+        .. math::
+        
+            V_{ijk} = \int f * w_\textrm{geom} * \Lambda^\alpha_{ijk}\,\textrm d \boldsymbol \eta = \left( f\,, \Lambda^\alpha_{ijk}\right)_{L^2}\,, 
+            
+        where :math:`\Lambda^\alpha_{ijk}` are the basis functions of :math:`V_h^\alpha`,
+        :math:`f` is an :math:`\alpha`-form proxy function and :math:`w_\textrm{geom}` stand for metric coefficients.
 
-        # newly created output vector
-        if out is None:
-            out = self.solve(v)
+        Note that any geometric terms (e.g. Jacobians) in the L2 scalar product are automatically assembled 
+        into :math:`w_\textrm{geom}`, depending on the space of :math:`\alpha`-forms.
 
-        # in-place dot-product (result is written to out)
-        else:
+        The integration is performed with Gauss-Legendre quadrature over the whole logical domain.
 
-            assert isinstance(out, Vector)
-            assert out.space == self.codomain
-            self.solve(v, out= out)
-            
+        Parameters
+        ----------
+        fun : callable | list
+            Weight function(s) (callables or np.ndarrays) in a 1d list of shape corresponding to number of components.
 
-        return out
+        dofs : StencilVector | BlockVector, optional
+            The vector for the output.
 
+        apply_bc : bool, optional
+            Whether to apply essential boundary conditions to degrees of freedom.
 
-class FFTSolver(DirectSolver):
-    """
-    Solve the equation Ax = b for x, assuming A is a circulant matrix.
-    b can contain multiple right-hand sides (RHS) and is of shape (#RHS, N).
+        clear : bool
+            Whether to first set all data to zero before assembly. If False, the new contributions are added to existing ones in vec.
+        """
+
+        # evaluate fun at quad_grid or check array size
+        if callable(fun):
+            fun_weights = fun(*self._quad_grid_mesh)
+        elif isinstance(fun, np.ndarray):
+            assert fun.shape == self._quad_grid_mesh[
+                0].shape, f'Expected shape {self._quad_grid_mesh[0].shape}, got {fun.shape = } instead.'
+            fun_weights = fun
+        else:
+            assert len(
+                fun) == 3, f'List input only for vector-valued spaces of size 3, but {len(fun) = }.'
+            fun_weights = []
+            # loop over rows (different meshes)
+            for mesh in self._quad_grid_mesh:
+                fun_weights += [[]]
+                # loop over columns (different functions)
+                for f in fun:
+                    if callable(f):
+                        fun_weights[-1] += [f(*mesh)]
+                    elif isinstance(f, np.ndarray):
+                        assert f.shape == mesh[
+                            0].shape, f'Expected shape {mesh[0].shape}, got {f.shape = } instead.'
+                        fun_weights[-1] += [f]
+                    else:
+                        raise ValueError(
+                            f'Expected callable or numpy array, got {type(f) = } instead.')
 
-    Parameters
-    ----------
-    circmat : np.ndarray
-        Generic circulant matrix.
-    """
+        # check output vector
+        if dofs is None:
+            dofs = self.space.vector_space.zeros()
+        else:
+            assert isinstance(dofs, (StencilVector, BlockVector))
+            assert dofs.space == self.Mmat.codomain
+
+        # compute matrix data for kernel, i.e. fun * geom_weight
+        tot_weights = []
+        if isinstance(fun_weights, np.ndarray):
+            tot_weights += [fun_weights * self.geom_weights]
+        else:
+            # loop over rows (differnt meshes)
+            for row_fun, row_geom, tmp in zip(fun_weights, self.geom_weights, self._tmp):
+                tmp *= 0.
+                # loop over columns (different functions)
+                for fun_weight, geom_weight in zip(row_fun, row_geom):
+                    # matrix-vector product
+                    tmp += fun_weight * geom_weight
+                tot_weights += [tmp]
+                
+        # clear data
+        if clear:
+            if isinstance(dofs, StencilVector):
+                dofs._data[:] = 0.
+            else:
+                for block in dofs.blocks:
+                    block._data[:] = 0.
 
-    def __init__(self, circmat):
+        # loop over components (just one for scalar spaces)
+        for a, (fem_space, spans, wts, basis, mat_w) in enumerate(zip(self._tensor_fem_spaces,
+                                                                      self._spans_l,
+                                                                      self._wts_l,
+                                                                      self._bases_l,
+                                                                      tot_weights)):
+            # indices
+            starts = [int(start) for start in fem_space.vector_space.starts]
+            pads = fem_space.vector_space.pads
+
+            if isinstance(dofs, StencilVector):
+                mass_kernels.kernel_3d_vec(*spans, *fem_space.degree, *starts, *pads,
+                                           *wts, *basis, mat_w, dofs._data)
+            else:
+                mass_kernels.kernel_3d_vec(*spans, *fem_space.degree, *starts, *pads,
+                                           *wts, *basis, mat_w, dofs[a]._data)
 
-        assert isinstance(circmat, np.ndarray)
-        assert is_circulant(circmat)
+        # exchange assembly data (accumulate ghost regions) and update ghost regions
+        dofs.exchange_assembly_data()
+        dofs.update_ghost_regions()
 
-        self._space = np.ndarray
-        self._column = circmat[:, 0]
+        # apply boundary operator
+        if apply_bc:
+            dofs = self.mass_ops.derham.boundary_ops[self.space_key].dot(dofs)
 
-    # --------------------------------------
-    # Abstract interface
-    # --------------------------------------
-    @property
-    def space(self):
-        return self._space
+        return dofs
 
-    # ...
-    def solve(self, rhs, out=None, transposed=False):
+    def __call__(self, fun, out=None, dofs=None, apply_bc=False):
         """
-        Solves for the given right-hand side.
+        Applies projector to given callable(s).
 
         Parameters
         ----------
-        rhs : np.ndarray
-            The right-hand sides to solve for. The vectors are assumed to be given in C-contiguous order, 
-            i.e. if multiple right-hand sides are given, then rhs is a two-dimensional array with the 0-th 
-            index denoting the number of the right-hand side, and the 1-st index denoting the element inside 
-            a right-hand side.
+        fun : callable | list
+            The function to be projected. List of three callables for vector-valued functions.
 
-        out : np.ndarray, optional
-            Output vector. If given, it has to have the same shape and datatype as rhs.
-
-        transposed : bool
-            If and only if set to true, we solve against the transposed matrix. (supported by the underlying solver)
-        """
-
-        assert rhs.T.shape[0] == self._column.size
-
-        if out is None:
-            out = solve_circulant(self._column, rhs.T).T
-
-        else:
-            assert out.shape == rhs.shape
-            assert out.dtype == rhs.dtype
-
-            out[:] = solve_circulant(self._column, rhs.T).T
-
-        return out
+        out : psydac.linalg.basic.vector, optional
+            If given, the result will be written into this vector in-place.
 
+        dofs : psydac.linalg.basic.vector, optional
+            If given, the dofs will be written into this vector in-place.
 
-def is_circulant(mat):
-    """ 
-    Returns true if a matrix is circulant.
+        apply_bc : bool, optional
+            Whether to apply essential boundary conditions to degrees of freedom and coefficients.
 
-    Parameters
-    ----------
-    mat : array[float]
-        The matrix that is checked to be circulant.
-
-    Returns
-    -------
-    circulant : bool
-        Whether the matrix is circulant (=True) or not (=False).
-    """
-
-    assert isinstance(mat, np.ndarray)
-    assert len(mat.shape) == 2
-    assert mat.shape[0] == mat.shape[1]
-    
-    if mat.shape[0] > 1:
-        for i in range(mat.shape[0] - 1):
-            circulant = np.allclose(mat[i, :], np.roll(mat[i + 1, :], -1))
-            if not circulant:
-                return circulant
-    else:
-        circulant = True
-
-    return circulant
+        Returns
+        -------
+        coeffs : psydac.linalg.basic.vector
+            The FEM spline coefficients after projection.
+        """
+        return self.solve(self.get_dofs(fun, dofs=dofs, apply_bc=apply_bc), out=out)
```

### Comparing `struphy-2.2.0/src/struphy/feec/psydac_derham.py` & `struphy-2.3.0/src/struphy/feec/psydac_derham.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 #!/usr/bin/env python3
 
 from sympde.topology import Cube
 from sympde.topology import Derham as Derham_psy
 
 from psydac.api.discretization import discretize
 from psydac.fem.vector import VectorFemSpace
-from psydac.fem.tensor import TensorFemSpace
 from psydac.feec.global_projectors import Projector_H1vec
 from psydac.linalg.stencil import StencilVector
 from psydac.linalg.block import BlockVector
 from psydac.linalg.basic import IdentityOperator
 
 from struphy.feec.linear_operators import BoundaryOperator
 from struphy.feec.projectors import CommutingProjector
@@ -20,15 +19,15 @@
 from struphy.polar.basic import PolarVector
 from struphy.initial import perturbations
 from struphy.initial import eigenfunctions
 from struphy.initial import utilities
 from struphy.geometry.base import Domain
 from struphy.bsplines import evaluation_kernels_3d as eval_3d
 from struphy.bsplines.evaluation_kernels_3d import eval_spline_mpi_tensor_product_fixed
-from struphy.fields_background.mhd_equil.equils import set_defaults
+from struphy.fields_background.mhd_equil.base import MHDequilibrium
 
 import numpy as np
 from mpi4py import MPI
 
 
 class Derham:
     """
@@ -652,26 +651,32 @@
         """
         return self._div
 
     # --------------------------
     #      methods:
     # --------------------------
 
-    def create_field(self, name, space_id):
+    def create_field(self, name, space_id, bckgr_params=None, pert_params=None):
         '''Creat a callable spline field.
 
         Parameters
         ----------
         name : str
             Field's key to be used for instance when saving to hdf5 file.
 
         space_id : str
             Space identifier for the field ("H1", "Hcurl", "Hdiv", "L2" or "H1vec").
+
+        bckgr_params : dict
+            Field's background parameters.
+
+        pert_params : dict
+            Field's perturbation parameters for initial condition.
         '''
-        return self.Field(name, space_id, self)
+        return self.Field(name, space_id, self, bckgr_params=bckgr_params, pert_params=pert_params)
 
     def prepare_eval_tp_fixed(self, grids_1d):
         '''Obtain knot span indices and spline basis functions evaluated at tensor product grid.
 
         Parameters
         ----------
         grids_1d : 3-list of 1d arrays
@@ -993,21 +998,29 @@
             Field's key to be used for instance when saving to hdf5 file.
 
         space_id : str
             Space identifier for the field ("H1", "Hcurl", "Hdiv", "L2" or "H1vec").
 
         derham : struphy.feec.psydac_derham.Derham
             Discrete Derham complex.
+
+        bckgr_params : dict
+            Field's background parameters.
+
+        pert_params : dict
+            Field's perturbation parameters for initial condition.
         """
 
-        def __init__(self, name, space_id, derham):
+        def __init__(self, name, space_id, derham, bckgr_params=None, pert_params=None):
 
             self._name = name
             self._space_id = space_id
             self._derham = derham
+            self._bckgr_params = bckgr_params
+            self._pert_params = pert_params
 
             # initialize field in memory (FEM space, vector and tensor product (stencil) vector)
             self._space_key = derham.space_to_form[space_id]
             self._space = derham.Vh_fem[self._space_key]
 
             self._vector = derham.Vh_pol[self._space_key].zeros()
 
@@ -1176,14 +1189,26 @@
 
                 OR 
 
                 the extracted coefficients in case of PolarVector. Call self.extract_coeffs() beforehand.
             """
             return self._vector_stencil
 
+        @property
+        def bckgr_params(self):
+            """ Field's background parameters.
+            """
+            return self._bckgr_params
+
+        @property
+        def pert_params(self):
+            """ Field's perturbation parameters for initial condition.
+            """
+            return self._pert_params
+
         ###############
         ### Methods ###
         ###############
         def extract_coeffs(self, update_ghost_regions=True):
             """
             Maps polar coeffs to polar tensor product rings in case of PolarVector (written in-place to self.vector_stencil) and updates ghost regions.
 
@@ -1193,215 +1218,267 @@
                     If the ghost regions shall be updated (needed in case of non-local acccess, e.g. in field evaluation).
             """
             self._ET.dot(self._vector, out=self._vector_stencil)
 
             if update_ghost_regions:
                 self._vector_stencil.update_ghost_regions()
 
-        def initialize_coeffs(self, init_params, domain=None, species=None):
+        def initialize_coeffs(self, domain=None, mhd_equil=None, species=None):
             """
             Sets the initial conditions for self.vector.
 
             Parameters
             ----------
-            init_params : dict
-                Parameters of initial condition, see from :ref:`params_yml`.
+            domain : struphy.geometry.domains 
+                Domain object for metric coefficients, only needed for transform of analytical perturbations.
 
-            domain : struphy.geometry.domains (optional)
-                Domain object for metric coefficients.
+            mhd_equil: MHDequilibrium
+                MHD equilibrium object, one of :mod:`struphy.fields_background.mhd_equil.equils`.
 
             species : string
-                Species of the filed (e.g. MHD) which will be initialized.
+                Species name (e.g. "mhd") the field belongs to.
             """
 
-            init_types = []
-            fun_params = []
-
-            # identifying initial conditions of self.vector
-            if init_params['type'] is None:
+            # case of zero initial condition
+            if self.bckgr_params is None and self.pert_params is None:
                 # apply boundary operator (in-place)
                 self.derham.boundary_ops[self.space_key].dot(
                     self._vector.copy(), out=self._vector)
-                # update ghost regions
+
                 self._vector.update_ghost_regions()
                 return
-            elif type(init_params['type']) == str:
-                init_params['type'] = [init_params['type']]
-            else:
-                assert isinstance(init_params['type'], list), f'The type of initial condition must be null or str or list.'
-            
-            # extract the components to be initialized       
-            for _type in init_params['type']:
-
-                if self.name not in init_params[_type]['comps']:
-                    pass
 
+            # check if backgrounds are to be initialized
+            bckgr_types = []
+            bckgr_type_params = []
+
+            if self.bckgr_params is not None:
+                if type(self.bckgr_params['type']) == str:
+                    self.bckgr_params['type'] = [self.bckgr_params['type']]
                 else:
+                    assert isinstance(
+                        self.bckgr_params['type'], list), f'The type of initial condition must be null or str or list.'
 
-                    if self.space_id in {'H1', 'L2'}:
-                        comps_list = [init_params[_type]
-                                        ['comps'][self.name]]
+                # extract the components that have a background
+                for _type in self.bckgr_params['type']:
 
+                    if self.name not in self.bckgr_params[_type]['comps']:
+                        pass
                     else:
-                        comps_list = init_params[_type]['comps'][self.name]
+                        if self.space_id in {'H1', 'L2'}:
+                            tmp_list = [self.bckgr_params[_type]
+                                        ['comps'][self.name]]
+                        else:
+                            tmp_list = self.bckgr_params[_type]['comps'][self.name]
 
-                    if any(_comp for _comp in comps_list):
-                        init_types += [_type]
-                        fun_params += [init_params[_type].copy()]
+                        if any(_comp for _comp in tmp_list):
+                            bckgr_types += [_type]
+                            bckgr_type_params += [self.bckgr_params[_type].copy()]
 
-            ntypes = len(init_types)
+            # add backgrounds to coefficient vector
+            for _type, _params in zip(bckgr_types, bckgr_type_params):
 
-            if ntypes != 0:
+                # constant value (update halos below)
+                if 'LogicalConst' in _type:
 
-                # white noise in logical space for different components
-                if any(_type == 'noise' for _type in init_types):
+                    _val = _params['comps'][self.name]
+
+                    if self.space_id in {'H1', 'L2'}:
+                        assert isinstance(_val, float) or isinstance(_val, int)
+                        def f_tmp(e1, e2, e3):
+                            return _val + 0.*e1
+                        fun = f_tmp
+                    else:
+                        assert isinstance(_val, list)
+                        assert len(_val) == 3
+                        fun = []
+                        for i, _v in enumerate(_val):
+                            assert isinstance(_v, float) or isinstance(
+                                _v, int) or _v is None
+                            
+                        if _val[0] is not None:
+                            fun += [lambda e1, e2, e3: _val[0] + 0.*e1]
+                        else:
+                            fun += [lambda e1, e2, e3: 0.*e1]
+                            
+                        if _val[1] is not None:
+                            fun += [lambda e1, e2, e3: _val[1] + 0.*e1]
+                        else:
+                            fun += [lambda e1, e2, e3: 0.*e1]
+                            
+                        if _val[2] is not None:
+                            fun += [lambda e1, e2, e3: _val[2] + 0.*e1]
+                        else:
+                            fun += [lambda e1, e2, e3: 0.*e1]
+
+                # geometric projection of mhd background
+                if 'MHD' in _type:
+
+                    assert mhd_equil is not None
+                    mhd_var = _params['comps'][self.name]
+                    assert mhd_var in dir(
+                        MHDequilibrium), f'{mhd_var = } is not an attribute of MHDequilibrium.'
+
+                    if self.space_id in {'H1', 'L2'}:
+                        fun = getattr(mhd_equil, mhd_var)
+                    else:
+                        assert (mhd_var + '_1') in dir(
+                            MHDequilibrium), f'{(mhd_var + "_1") = } is not an attribute of MHDequilibrium.'
+                        fun = [getattr(mhd_equil, mhd_var + '_1'),
+                               getattr(mhd_equil, mhd_var + '_2'),
+                               getattr(mhd_equil, mhd_var + '_3')]
+
+                # peform projection
+                self.vector += self.derham.P[self.space_key](fun)
+
+            # check if perturbations are to be initialized
+            pert_types = []
+            pert_type_params = []
+
+            if self.pert_params is not None:
+                if type(self.pert_params['type']) == str:
+                    self.pert_params['type'] = [self.pert_params['type']]
+                else:
+                    assert isinstance(
+                        self.pert_params['type'], list), f'The type of initial condition must be null or str or list.'
+
+                # extract the components to be perturbed
+                for _type in self.pert_params['type']:
+
+                    if self.name not in self.pert_params[_type]['comps']:
+                        pass
+                    else:
+                        if self.space_id in {'H1', 'L2'}:
+                            pert_comps_list = [self.pert_params[_type]
+                                               ['comps'][self.name]]
+                        else:
+                            pert_comps_list = self.pert_params[_type]['comps'][self.name]
+
+                        if any(_comp for _comp in pert_comps_list):
+                            pert_types += [_type]
+                            pert_type_params += [self.pert_params[_type].copy()]
 
-                    assert ntypes == 1, \
-                        AssertionError(
-                            "The init type 'noise' cannot be applied with other init types")
-
-                    params_default = {'comps': {'b2': [True, False, False]},
-                                      'variation_in': 'e3',
-                                      'amp': 0.0001,
-                                      'seed': 1234
-                                      }
+            # add perturbations to coefficient vector
+            for _type, _params in zip(pert_types, pert_type_params):
 
-                    self._params = set_defaults(fun_params[0], params_default)
+                # white noise in logical space for different components
+                if 'noise' in _type:
 
                     # component(s) to perturb
-                    if isinstance(fun_params[0]['comps'][self.name], bool):
-                        comps = [fun_params[0]['comps'][self.name]]
+                    if isinstance(_params['comps'][self.name], bool):
+                        comps = [_params['comps'][self.name]]
                     else:
-                        comps = fun_params[0]['comps'][self.name]
+                        comps = _params['comps'][self.name]
 
                     # set white noise FE coefficients
+                    _params.pop('comps')
+                    
                     if self.space_id in {'H1', 'L2'}:
                         if comps[0]:
-                            self._add_noise(fun_params[0])
+                            self._add_noise(**_params)
 
                     elif self.space_id in {'Hcurl', 'Hdiv', 'H1vec'}:
                         for n, comp in enumerate(comps):
                             if comp:
-                                self._add_noise(fun_params[0], n=n)
-
-                # loading of eigenfunction
-                elif any(_type[-6:] == 'EigFun' for _type in init_types):
-
-                    assert ntypes == 1, \
-                        AssertionError(
-                            "The init type 'EigFun' cannot be applied with other init types")
+                                self._add_noise(**_params, n=n)
 
-                    # select class
-                    funs = getattr(eigenfunctions, init_types[0])(
-                        self.derham, **fun_params[0])
-
-                    # select eigenvector and set coefficients
-                    if hasattr(funs, self.name):
-
-                        eig_vec = getattr(funs, self.name)
-
-                        self.vector = eig_vec
-
-                # Fourier modes or shear layer
-                elif any(_type in ['ModesSin', 'ModesCos', 'TorusModesSin', 'TorusModesCos', 'Shear_x', 'Shear_y', 'Shear_z'] for _type in init_types):
+                # initialize from analytical function via geometric projection
+                if _type in dir(perturbations):
 
                     if self.space_id in {'H1', 'L2'}:
 
-                        assert ntypes == 1, \
-                            AssertionError(
-                                f'Only one init type can be applied to the variables in space {self.space_id}.')
-
-                        fun_params_comp = {}
+                        pert_type_params_comp = {}
 
                         # which transform is to be used: physical, '0' or '3'
-                        fun_form = fun_params[0]['comps'][self.name]
+                        fun_basis = _params['comps'][self.name]
 
-                        for keys, vals in fun_params[0].items():
+                        for keys, vals in _params.items():
 
                             if keys == 'comps':
                                 continue
 
                             elif isinstance(vals, dict):
-                                fun_params_comp[keys] = fun_params[0][keys][self.name]
+                                pert_type_params_comp[keys] = vals[self.name]
 
                             else:
-                                fun_params_comp[keys] = fun_params[0][keys]
+                                pert_type_params_comp[keys] = vals
 
                         # get callable(s) for specified init type
-                        fun_class = getattr(perturbations, init_types[0])
-                        fun_tmp = [fun_class(**fun_params_comp)]
+                        fun_class = getattr(perturbations, _type)
+                        fun_tmp = [fun_class(**pert_type_params_comp)]
 
                         # pullback callable
                         fun = TransformedPformComponent(
-                            fun_tmp, fun_form, self.space_key, domain=domain)
+                            fun_tmp, fun_basis, self.space_key, domain=domain)
 
                     elif self.space_id in {'Hcurl', 'Hdiv', 'H1vec'}:
 
-                        assert ntypes < 4, \
-                            AssertionError(
-                                f'Maximum 3 init types can be applied to the variables in space {self.space_id}.')
-
-                        fun_params_comp = [{}, {}, {}]
+                        pert_type_params_comp = [{}, {}, {}]
                         fun_tmp = [None, None, None]
-                        fun_form = ['v']*3
+                        fun_basis = ['v']*3
 
-                        for n, _type in enumerate(init_types):
+                        fun_class = getattr(perturbations, _type)
 
-                            fun_class = getattr(perturbations, _type)
+                        for axis, comp in enumerate(_params['comps'][self.name]):
 
-                            for axis, comp in enumerate(fun_params[n]['comps'][self.name]):
+                            if comp is not None:
 
-                                if comp is not None:
+                                # which transform is to be used: physical, '1', '2' or 'v'
+                                fun_basis[axis] = comp
 
-                                    # which transform is to be used: physical, '1', '2' or 'v'
-                                    fun_form[axis] = comp
+                                for keys, vals in _params.items():
 
-                                    for keys, vals in fun_params[n].items():
+                                    if keys == 'comps':
+                                        continue
 
-                                        if keys == 'comps':
-                                            continue
+                                    elif isinstance(vals, dict):
+                                        pert_type_params_comp[axis][keys] = vals[self.name][axis]
 
-                                        elif isinstance(vals, dict):
-                                            fun_params_comp[axis][keys] = fun_params[n][keys][self.name][axis]
+                                    else:
+                                        pert_type_params_comp[axis][keys] = vals
 
-                                        else:
-                                            fun_params_comp[axis][keys] = fun_params[n][keys]
-
-                                    fun_tmp[axis] = fun_class(
-                                        **fun_params_comp[axis])
+                                fun_tmp[axis] = fun_class(
+                                    **pert_type_params_comp[axis])
 
                         # pullback callable
                         fun = []
-                        for n, fform in enumerate(fun_form):
+                        for n, fform in enumerate(fun_basis):
                             fun += [TransformedPformComponent(
                                 fun_tmp, fform, self.space_key, comp=n, domain=domain)]
 
                     # peform projection
-                    self.vector = self.derham.P[self.space_key](fun)
+                    self.vector += self.derham.P[self.space_key](fun)
+
+                # loading of MHD eigenfunction (legacy code, might not be up to date)
+                if 'EigFun' in _type:
+
+                    # select class
+                    funs = getattr(eigenfunctions, pert_types[0])(
+                        self.derham, **_params)
+
+                    # select eigenvector and set coefficients
+                    if hasattr(funs, self.name):
+
+                        eig_vec = getattr(funs, self.name)
 
-                elif any(_type == 'InitFromOutput' for _type in init_types):
+                        self.vector += eig_vec
 
-                    assert ntypes == 1, \
-                        AssertionError(
-                            "The init type 'InitFromOutput' cannot be applied with other init types")
+                # initialize from existing output file
+                if 'InitFromOutput' in _type:
 
                     # select class
-                    o_data = getattr(utilities, init_types[0])(
-                        self.derham, self.name, species, **fun_params[0])
+                    o_data = getattr(utilities, pert_types[0])(
+                        self.derham, self.name, species, **_params)
 
                     if isinstance(self.vector, StencilVector):
-                        self.vector._data[:] = o_data.vector
+                        self.vector._data[:] += o_data.vector
 
                     else:
                         for n in range(3):
-                            self.vector[n]._data[:] = o_data.vector[n]
-
-                else:
-                    raise NotImplemented(
-                        f'Initial condition {init_types} not available.')
+                            self.vector[n]._data[:] += o_data.vector[n]
 
             # apply boundary operator (in-place)
             self.derham.boundary_ops[self.space_key].dot(
                 self._vector.copy(), out=self._vector)
 
             # update ghost regions
             self._vector.update_ghost_regions()
@@ -1642,30 +1719,32 @@
                         out[-1] = out[-1].item()
 
             return out
 
         #######################
         ### Private methods ###
         #######################
-        def _add_noise(self, fun_params, n=None):
+        def _add_noise(self, direction='e3', amp=0.0001, seed=None, n=None):
             """ Add noise to a vector component where init_comps==True, otherwise leave at zero.
 
             Parameters
             ----------
-            fun_params : dict
-                From parameter file under init/noise.
+            direction: str
+                The direction(s) of variation of the noise: 'e1', 'e2', 'e3', 'e1e2', etc.
+
+            amp: float
+                Noise amplitude.
+
+            seed: int
+                Seed for the random number generator.
 
             n : int
                 Vector component (0, 1 or 2) to be initialized.
             """
 
-            _direction = fun_params['variation_in']
-            _ampsize = fun_params['amp']
-            _seed = fun_params['seed']
-
             # index slices from global start to end in all directions
             sli = []
             gl_s = []
             for d in range(3):
                 if n == None:
                     sli += [slice(self._gl_s[d], self._gl_e[d] + 1)]
                     gl_s += [self._gl_s[d]]
@@ -1679,74 +1758,74 @@
             if n == None:
                 _shape = (self._gl_e[0] + 1 - self._gl_s[0], self._gl_e
                           [1] + 1 - self._gl_s[1], self._gl_e[2] + 1 - self._gl_s[2])
             else:
                 _shape = (self._gl_e[n][0] + 1 - self._gl_s[n][0], self._gl_e[n]
                           [1] + 1 - self._gl_s[n][1], self._gl_e[n][2] + 1 - self._gl_s[n][2])
 
-            if _direction == 'e1':
+            if direction == 'e1':
                 _amps = self._tmp_noise_for_mpi(
-                    _shape[0], direction=_direction, amp_size=_ampsize, seed=_seed)
+                    _shape[0], direction=direction, amp=amp, seed=seed)
                 for j in range(_shape[1]):
                     for k in range(_shape[2]):
-                        vec[sli[0], gl_s[1] + j, gl_s[2] + k] = _amps
+                        vec[sli[0], gl_s[1] + j, gl_s[2] + k] += _amps
                 del _amps
 
-            elif _direction == 'e2':
+            elif direction == 'e2':
                 _amps = self._tmp_noise_for_mpi(
-                    _shape[1], direction=_direction, amp_size=_ampsize, seed=_seed)
+                    _shape[1], direction=direction, amp=amp, seed=seed)
                 for j in range(_shape[0]):
                     for k in range(_shape[2]):
-                        vec[gl_s[0] + j, sli[1], gl_s[2] + k] = _amps
+                        vec[gl_s[0] + j, sli[1], gl_s[2] + k] += _amps
 
-            elif _direction == 'e3':
+            elif direction == 'e3':
                 _amps = self._tmp_noise_for_mpi(
-                    _shape[2], direction=_direction, amp_size=_ampsize, seed=_seed)
+                    _shape[2], direction=direction, amp=amp, seed=seed)
                 for j in range(_shape[0]):
                     for k in range(_shape[1]):
-                        vec[gl_s[0] + j, gl_s[1] + k, sli[2]] = _amps
+                        vec[gl_s[0] + j, gl_s[1] + k, sli[2]] += _amps
 
-            elif _direction == 'e1e2':
+            elif direction == 'e1e2':
                 _amps = self._tmp_noise_for_mpi(
-                    _shape[0], _shape[1], direction=_direction, amp_size=_ampsize, seed=_seed)
+                    _shape[0], _shape[1], direction=direction, amp=amp, seed=seed)
                 for j in range(_shape[2]):
-                    vec[sli[0], sli[1], gl_s[2] + j] = _amps
+                    vec[sli[0], sli[1], gl_s[2] + j] += _amps
 
-            elif _direction == 'e1e3':
+            elif direction == 'e1e3':
                 _amps = self._tmp_noise_for_mpi(
-                    _shape[0], _shape[2], direction=_direction, amp_size=_ampsize, seed=_seed)
+                    _shape[0], _shape[2], direction=direction, amp=amp, seed=seed)
                 for j in range(_shape[1]):
-                    vec[sli[0], gl_s[1] + j, sli[2]] = _amps
+                    vec[sli[0], gl_s[1] + j, sli[2]] += _amps
 
-            elif _direction == 'e2e3':
+            elif direction == 'e2e3':
                 _amps = self._tmp_noise_for_mpi(
-                    _shape[1], _shape[2], direction=_direction, amp_size=_ampsize, seed=_seed)
+                    _shape[1], _shape[2], direction=direction, amp=amp, seed=seed)
                 for j in range(_shape[0]):
-                    vec[gl_s[0] + j, sli[1], sli[2]] = _amps
+                    vec[gl_s[0] + j, sli[1], sli[2]] += _amps
 
-            elif _direction == 'e1e2e3':
+            elif direction == 'e1e2e3':
                 _amps = self._tmp_noise_for_mpi(
-                    _shape[0], _shape[1], _shape[2], direction=_direction, amp_size=_ampsize, seed=_seed)
-                vec[sli[0], sli[1], sli[2]] = _amps
+                    _shape[0], _shape[1], _shape[2], direction=direction, amp=amp, seed=seed)
+                vec[sli[0], sli[1], sli[2]] += _amps
 
             else:
                 raise ValueError('Invalid direction for noise.')
 
-        def _tmp_noise_for_mpi(self, *shapes, direction='e3', amp_size=0.0001, seed=None):
+        def _tmp_noise_for_mpi(self, *shapes, direction='e3', amp=0.0001, seed=None):
             '''Initialize same FEEC noise regardless of number of MPI processes.
 
             Parameters
             ----------
             shapes : int
                 Length of local array size in each direction where noise is to be initialized.
 
             direction : str
                 Noise direction ('e1', 'e2' or 'e3'). Multi-dim. not yet correct.
 
-            amp_size : float
+            amp : float
                 Noise amplitude
 
             seed : int
                 Seed for random number generator.
 
             Returns
             -------
@@ -1832,46 +1911,46 @@
                         _amps[:] = tmp_arrays[inds[0]][inds[1]]
                     elif direction == 'e1e3':
                         _amps[:] = tmp_arrays[inds[0]][inds[2]]
                     elif direction == 'e2e3':
                         _amps[:] = tmp_arrays[inds[1]][inds[2]]
                     elif direction == 'e1e2e3':
                         _amps[:] = (np.random.rand(
-                            *shapes) - .5) * 2. * amp_size
+                            *shapes) - .5) * 2. * amp
 
                 else:
 
                     if direction == 'e1':
                         tmp_arrays[inds[0]] = (np.random.rand(
-                            *shapes) - .5) * 2. * amp_size
+                            *shapes) - .5) * 2. * amp
                         already_drawn[inds[0], :, :] = True
                         _amps[:] = tmp_arrays[inds[0]]
                     elif direction == 'e2':
                         tmp_arrays[inds[1]] = (np.random.rand(
-                            *shapes) - .5) * 2. * amp_size
+                            *shapes) - .5) * 2. * amp
                         already_drawn[:, inds[1], :] = True
                         _amps[:] = tmp_arrays[inds[1]]
                     elif direction == 'e3':
                         tmp_arrays[inds[2]] = (np.random.rand(
-                            *shapes) - .5) * 2. * amp_size
+                            *shapes) - .5) * 2. * amp
                         already_drawn[:, :, inds[2]] = True
                         _amps[:] = tmp_arrays[inds[2]]
                     elif direction == 'e1e2':
                         tmp_arrays[inds[0]][inds[1]] = (
-                            np.random.rand(*shapes) - .5) * 2. * amp_size
+                            np.random.rand(*shapes) - .5) * 2. * amp
                         already_drawn[inds[0], inds[1], :] = True
                         _amps[:] = tmp_arrays[inds[0]][inds[1]]
                     elif direction == 'e1e3':
                         tmp_arrays[inds[0]][inds[2]] = (
-                            np.random.rand(*shapes) - .5) * 2. * amp_size
+                            np.random.rand(*shapes) - .5) * 2. * amp
                         already_drawn[inds[0], :, inds[2]] = True
                         _amps[:] = tmp_arrays[inds[0]][inds[2]]
                     elif direction == 'e2e3':
                         tmp_arrays[inds[1]][inds[2]] = (
-                            np.random.rand(*shapes) - .5) * 2. * amp_size
+                            np.random.rand(*shapes) - .5) * 2. * amp
                         already_drawn[:, inds[1], inds[2]] = True
                         _amps[:] = tmp_arrays[inds[1]][inds[2]]
 
                 if np.all(np.array([ind_c == ind for ind_c, ind in zip(inds_current, inds)])):
                     return _amps
 
 
@@ -1880,16 +1959,16 @@
     Construct callable component of p-form on logical domain (unit cube).
 
     Parameters
     ----------
     fun : list
         Callable function components. Has to be length three for 1-, 2-forms and vector fields, length one otherwise.
 
-    fun_form : str
-        The representation of the input fun: either a p-form, then '0' or '3' for scalar and 'v', '1' or '2' for vector-valued,
+    fun_basis : str
+        In which basis fun is represented: either a p-form, then '0' or '3' for scalar and 'v', '1' or '2' for vector-valued,
         'physical' when defined on the physical (mapped) domain, and 'norm' when given in the normalized
         contra-variant basis (:math:`\delta_i / |\delta_i|`).
 
     out_form : str
         The p-form representation of the output: '0', '1', '2' '3' or 'v'.
 
     comp : int
@@ -1897,31 +1976,31 @@
 
     domain: struphy.geometry.domains
         All things mapping. If None, the input fun is just evaluated and not transformed at __call__.
 
     Returns
     -------
     out : array[float]
-        The values of the component comp of fun transformed from fun_form to out_form.
+        The values of the component comp of fun transformed from fun_basis to out_form.
     """
 
-    def __init__(self, fun: list, fun_form: str, out_form: str, comp=0, domain=None):
+    def __init__(self, fun: list, fun_basis: str, out_form: str, comp=0, domain=None):
 
         assert len(fun) == 1 or len(fun) == 3
 
         self._fun = []
         for f in fun:
             if f is None:
                 def f_zero(x, y, z): return 0*x
                 self._fun += [f_zero]
             else:
                 assert callable(f)
                 self._fun += [f]
 
-        self._fun_form = fun_form
+        self._fun_basis = fun_basis
         self._out_form = out_form
         self._comp = comp
         self._domain = domain
 
         self._is_scalar = len(fun) == 1
 
         # define which component of the field is evaluated (=0 for scalar fields)
@@ -1936,42 +2015,42 @@
         """
         Evaluate the component of the transformed p-form specified in self._comp.
 
         Depending on the dimension of eta1 either point-wise, tensor-product, 
         slice plane or general (see :ref:`struphy.geometry.base.prepare_arg`).
         """
 
-        if self._fun_form == self._out_form or self._domain is None:
+        if self._fun_basis == self._out_form or self._domain is None:
 
             if self._is_scalar:
                 out = self._fun(eta1, eta2, eta3)
             else:
                 out = self._fun[self._comp](eta1, eta2, eta3)
 
-        elif self._fun_form == 'physical':
+        elif self._fun_basis == 'physical':
 
             if self._is_scalar:
                 out = self._domain.pull(
                     self._fun, eta1, eta2, eta3, kind=self._out_form)
             else:
                 out = self._domain.pull(
                     self._fun, eta1, eta2, eta3, kind=self._out_form)[self._comp]
-                
-        elif self._fun_form == 'physical_at_eta':
+
+        elif self._fun_basis == 'physical_at_eta':
 
             if self._is_scalar:
                 out = self._domain.pull(
                     self._fun, eta1, eta2, eta3, kind=self._out_form, coordinates='logical')
             else:
                 out = self._domain.pull(
                     self._fun, eta1, eta2, eta3, kind=self._out_form, coordinates='logical')[self._comp]
 
         else:
 
-            dict_tran = self._fun_form + '_to_' + self._out_form
+            dict_tran = self._fun_basis + '_to_' + self._out_form
 
             if self._is_scalar:
                 out = self._domain.transform(
                     self._fun, eta1, eta2, eta3, kind=dict_tran)
             else:
                 out = self._domain.transform(
                     self._fun, eta1, eta2, eta3, kind=dict_tran)[self._comp]
```

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_basis_operators.py` & `struphy-2.3.0/src/struphy/feec/tests/test_basis_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_basis_ops.py` & `struphy-2.3.0/src/struphy/feec/tests/test_basis_ops.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_derham.py` & `struphy-2.3.0/src/struphy/feec/tests/test_derham.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_eval_field.py` & `struphy-2.3.0/src/struphy/feec/tests/test_eval_field.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_l2_projectors.py` & `struphy-2.3.0/src/struphy/feec/tests/test_l2_projectors.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_lowdim_nel_is_1.py` & `struphy-2.3.0/src/struphy/feec/tests/test_lowdim_nel_is_1.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 import pytest
 
 
 @pytest.mark.mpi(min_size=2)
-@pytest.mark.parametrize('Nel', [[64, 1, 1], [1, 64, 1], [1, 1, 64], [63, 64, 1], [64, 1, 63], [1, 63, 64]])
+@pytest.mark.parametrize('Nel', [[32, 1, 1], [1, 32, 1], [1, 1, 32], [31, 32, 1], [32, 1, 31], [1, 31, 32]])
 @pytest.mark.parametrize('p', [[1, 1, 1]])
 @pytest.mark.parametrize('spl_kind', [[True, True, True]])
 def test_lowdim_derham(Nel, p, spl_kind, do_plot=False):
     '''Test Nel=1 in various directions.'''
 
     from mpi4py import MPI
     import numpy as np
@@ -147,15 +147,15 @@
     # c) derivative error
     field_df0 = derham.create_field('df0', 'Hcurl')
     field_df0.vector = df0_h
     field_df0_vals = field_df0(e1, e2, e3, squeeze_output=True)
 
     err_df0 = [np.max(np.abs(exact(e1, e2, e3) - field_v)) for exact, field_v in zip(grad_f, field_df0_vals)]
     print(f'{err_df0 = }')
-    assert np.max(err_df0) < .4
+    assert np.max(err_df0) < .64
 
     # d) plotting
     plt.figure(figsize=(8, 12))
     plt.subplot(2, 1, 1)
     plt.plot(e, f(e1, e2, e3), 'o')
     plt.plot(e, field_f0_vals)
     plt.title('fun')
@@ -176,28 +176,28 @@
     field_f1 = derham.create_field('f1', 'Hcurl')
     field_f1.vector = f1_h
     field_f1_vals = field_f1(e1, e2, e3, squeeze_output=True)
 
     # a) projection error
     err_f1 = [np.max(np.abs(exact(e1, e2, e3) - field_v)) for exact, field_v in zip([f, f, f], field_f1_vals)]
     print(f'{err_f1 = }')
-    assert np.max(err_f1) < .05
+    assert np.max(err_f1) < .09
 
     # b) commuting property
     df1_h = derham.curl.dot(f1_h)
     assert np.allclose(df1_h.toarray(), proj_of_curl_fff.toarray())
 
     # c) derivative error
     field_df1 = derham.create_field('df1', 'Hdiv')
     field_df1.vector = df1_h
     field_df1_vals = field_df1(e1, e2, e3, squeeze_output=True)
 
     err_df1 = [np.max(np.abs(exact(e1, e2, e3) - field_v)) for exact, field_v in zip(curl_f, field_df1_vals)]
     print(f'{err_df1 = }')
-    assert np.max(err_df1) < .4
+    assert np.max(err_df1) < .64
 
     # d) plotting
     plt.figure(figsize=(8, 12))
     plt.subplot(3, 1, 1)
     plt.plot(e, f(e1, e2, e3), 'o')
     plt.plot(e, field_f1_vals[c])
     plt.title('all components fun')
@@ -223,28 +223,28 @@
     field_f2 = derham.create_field('f2', 'Hdiv')
     field_f2.vector = f2_h
     field_f2_vals = field_f2(e1, e2, e3, squeeze_output=True)
 
     # a) projection error
     err_f2 = [np.max(np.abs(exact(e1, e2, e3) - field_v)) for exact, field_v in zip([f, f, f], field_f2_vals)]
     print(f'{err_f2 = }')
-    assert np.max(err_f2) < .05
+    assert np.max(err_f2) < .09
 
     # b) commuting property
     df2_h = derham.div.dot(f2_h)
     assert np.allclose(df2_h.toarray(), proj_of_div_fff.toarray())
 
     # c) derivative error
     field_df2 = derham.create_field('df2', 'L2')
     field_df2.vector = df2_h
     field_df2_vals = field_df2(e1, e2, e3, squeeze_output=True)
 
     err_df2 = np.max(np.abs(div_f(e1, e2, e3) - field_df2_vals)) 
     print(f'{err_df2 = }')
-    assert np.max(err_df2) < .4
+    assert np.max(err_df2) < .64
 
     # d) plotting
     plt.figure(figsize=(8, 12))
     plt.subplot(2, 1, 1)
     plt.plot(e, f(e1, e2, e3), 'o')
     plt.plot(e, field_f2_vals[c])
     plt.title('all components fun')
@@ -265,15 +265,15 @@
     field_f3 = derham.create_field('f3', 'L2')
     field_f3.vector = f3_h
     field_f3_vals = field_f3(e1, e2, e3, squeeze_output=True)
 
     # a) projection error
     err_f3 = np.max(np.abs(f(e1, e2, e3) - field_f3_vals))
     print(f'{err_f3 = }')
-    assert err_f3 < 0.05
+    assert err_f3 < 0.09
 
     # d) plotting
     plt.figure(figsize=(8, 12))
     plt.subplot(2, 1, 1)
     plt.plot(e, f(e1, e2, e3), 'o')
     plt.plot(e, field_f3_vals)
     plt.title('fun')
@@ -281,10 +281,10 @@
     
     plt.subplots_adjust(wspace=1.0, hspace=0.4)
 
     if do_plot:
         plt.show()
 
 if __name__ == '__main__':
-    test_lowdim_derham([64, 1, 1], [1, 1, 1], [True, True, True], do_plot=False)
-    test_lowdim_derham([1, 64, 1], [1, 1, 1], [True, True, True], do_plot=False)
-    test_lowdim_derham([1, 1, 64], [1, 1, 1], [True, True, True], do_plot=False)
+    test_lowdim_derham([32, 1, 1], [1, 1, 1], [True, True, True], do_plot=False)
+    test_lowdim_derham([1, 32, 1], [1, 1, 1], [True, True, True], do_plot=False)
+    test_lowdim_derham([1, 1, 32], [1, 1, 1], [True, True, True], do_plot=False)
```

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_mass_matrices.py` & `struphy-2.3.0/src/struphy/feec/tests/test_mass_matrices.py`

 * *Files 9% similar despite different names*

```diff
@@ -108,14 +108,20 @@
                   derham.Vh_fem['1'],
                   derham.Vh_fem['2'],
                   derham.Vh_fem['3'],
                   derham.Vh_fem['v']]
 
     # mass matrices object
     mass_mats = WeightedMassOperators(derham, domain, eq_mhd=eq_mhd)
+    mass_mats_free = WeightedMassOperators(derham, domain, eq_mhd=eq_mhd, matrix_free = True)
+
+    # test calling the diagonal method
+    aaa = mass_mats.M0.matrix.diagonal()
+    bbb = mass_mats.M1.matrix.diagonal()
+    print(f'{aaa = }, {bbb[0, 0] = }, {bbb[0, 1] = }')
 
     # compare to old STRUPHY
     bc_old = [[None, None], [None, None], [None, None]]
     for i in range(3):
         for j in range(2):
             if dirichlet_bc[i][j]:
                 bc_old[i][j] = 'd'
@@ -180,44 +186,75 @@
     r2_psy = mass_mats.M2.dot(x2_psy, apply_bc=True)
     r3_psy = mass_mats.M3.dot(x3_psy, apply_bc=True)
     rv_psy = mass_mats.Mv.dot(xv_psy, apply_bc=True)
 
     rn_psy = mass_mats.M2n.dot(x2_psy, apply_bc=True)
     rJ_psy = mass_mats.M2J.dot(x2_psy, apply_bc=True)
 
+    # Test matrix free operators
+    r0_fre = mass_mats_free.M0.dot(x0_psy, apply_bc=True)
+    r1_fre = mass_mats_free.M1.dot(x1_psy, apply_bc=True)
+    r2_fre = mass_mats_free.M2.dot(x2_psy, apply_bc=True)
+    r3_fre = mass_mats_free.M3.dot(x3_psy, apply_bc=True)
+    rv_fre = mass_mats_free.Mv.dot(xv_psy, apply_bc=True)
+
+    rn_fre = mass_mats_free.M2n.dot(x2_psy, apply_bc=True)
+    rJ_fre = mass_mats_free.M2J.dot(x2_psy, apply_bc=True)
+
     # compare output arrays
     compare_arrays(r0_psy, r0_str, mpi_rank, atol=1e-14)
     compare_arrays(r1_psy, r1_str, mpi_rank, atol=1e-14)
     compare_arrays(r2_psy, r2_str, mpi_rank, atol=1e-14)
     compare_arrays(r3_psy, r3_str, mpi_rank, atol=1e-14)
     compare_arrays(rv_psy, rv_str, mpi_rank, atol=1e-14)
 
     compare_arrays(rn_psy, rn_str, mpi_rank, atol=1e-14)
     compare_arrays(rJ_psy, rJ_str, mpi_rank, atol=1e-14)
 
+    compare_arrays(r0_fre, r0_str, mpi_rank, atol=1e-14)
+    compare_arrays(r1_fre, r1_str, mpi_rank, atol=1e-14)
+    compare_arrays(r2_fre, r2_str, mpi_rank, atol=1e-14)
+    compare_arrays(r3_fre, r3_str, mpi_rank, atol=1e-14)
+    compare_arrays(rv_fre, rv_str, mpi_rank, atol=1e-14)
+
+    compare_arrays(rn_fre, rn_str, mpi_rank, atol=1e-14)
+    compare_arrays(rJ_fre, rJ_str, mpi_rank, atol=1e-14)
+
     # perfrom matrix-vector products (without boundary conditions)
     r0_str = space.M0(x0_str)
     r1_str = space.M1(x1_str)
     r2_str = space.M2(x2_str)
     r3_str = space.M3(x3_str)
     rv_str = space.Mv(xv_str)
 
     r0_psy = mass_mats.M0.dot(x0_psy, apply_bc=False)
     r1_psy = mass_mats.M1.dot(x1_psy, apply_bc=False)
     r2_psy = mass_mats.M2.dot(x2_psy, apply_bc=False)
     r3_psy = mass_mats.M3.dot(x3_psy, apply_bc=False)
     rv_psy = mass_mats.Mv.dot(xv_psy, apply_bc=False)
 
+    r0_fre = mass_mats_free.M0.dot(x0_psy, apply_bc=False)
+    r1_fre = mass_mats_free.M1.dot(x1_psy, apply_bc=False)
+    r2_fre = mass_mats_free.M2.dot(x2_psy, apply_bc=False)
+    r3_fre = mass_mats_free.M3.dot(x3_psy, apply_bc=False)
+    rv_fre = mass_mats_free.Mv.dot(xv_psy, apply_bc=False)
+
     # compare output arrays
     compare_arrays(r0_psy, r0_str, mpi_rank, atol=1e-14)
     compare_arrays(r1_psy, r1_str, mpi_rank, atol=1e-14)
     compare_arrays(r2_psy, r2_str, mpi_rank, atol=1e-14)
     compare_arrays(r3_psy, r3_str, mpi_rank, atol=1e-14)
     compare_arrays(rv_psy, rv_str, mpi_rank, atol=1e-14)
 
+    compare_arrays(r0_fre, r0_str, mpi_rank, atol=1e-14)
+    compare_arrays(r1_fre, r1_str, mpi_rank, atol=1e-14)
+    compare_arrays(r2_fre, r2_str, mpi_rank, atol=1e-14)
+    compare_arrays(r3_fre, r3_str, mpi_rank, atol=1e-14)
+    compare_arrays(rv_fre, rv_str, mpi_rank, atol=1e-14)
+
     print(f'Rank {mpi_rank} | All tests passed!')
 
 
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[8, 12, 6]])
 @pytest.mark.parametrize('p',   [[2, 2, 3]])
 @pytest.mark.parametrize('spl_kind', [[False, True, True], [False, True, False]])
@@ -1033,22 +1070,22 @@
     # =======================================================
 
     time.sleep(2)
     print(f'Rank {mpi_rank} | All tests passed!')
 
 
 if __name__ == '__main__':
-    # test_mass([5, 6, 7], 
-    #           [2, 2, 3], 
-    #           [True, False, True], 
-    #           [[False,  True], [True, False], [False, False]], 
-    #           ['Colella', {'Lx': 1., 'Ly': 6., 'alpha': .1, 'Lz': 10.}], False)
+    test_mass([5, 6, 7], 
+               [2, 2, 3], 
+               [True, False, True], 
+               [[False,  True], [True, False], [False, False]], 
+               ['Colella', {'Lx': 1., 'Ly': 6., 'alpha': .1, 'Lz': 10.}], False)
     # test_mass([8, 6, 4], [2, 3, 2], [False, True, False], [['d', 'd'], [None, None], [None, 'd']], ['Colella', {'Lx' : 1., 'Ly' : 6., 'alpha' : .1, 'Lz' : 10.}], False)
     # test_mass([8, 6, 4], [2, 2, 2], [False, True, True], [['d', 'd'], [None, None], [None, None]], ['HollowCylinder', {'a1': .1, 'a2': 1., 'Lz': 10.}], False)
 
     # test_mass_polar([8, 12, 6], [4, 3, 2], [False, True, False], [[None, 'd'], [None, None], ['d', None]], ['IGAPolarCylinder', {'a': 1., 'Lz': 3.}], False)
 
-    test_mass_preconditioner([8, 6, 4], [2, 2, 2], [False, False, False], [[True, True], [False, False], [False, False]], ['Cuboid', {'l1': 0., 'r1': 1., 'l2': 0., 'r2': 6., 'l3': 0., 'r3': 10.}], False)
+    # test_mass_preconditioner([8, 6, 4], [2, 2, 2], [False, False, False], [[True, True], [False, False], [False, False]], ['Cuboid', {'l1': 0., 'r1': 1., 'l2': 0., 'r2': 6., 'l3': 0., 'r3': 10.}], False)
     # test_mass_preconditioner([8, 6, 4], [2, 2, 2], [False, False, False], [['d', 'd'], [None, None], [None, None]], ['Colella', {'Lx' : 1., 'Ly' : 6., 'alpha' : .05, 'Lz' : 10.}], False)
     # test_mass_preconditioner([6, 9, 4], [4, 3, 2], [False, True, False], [[None, 'd'], [None, None], ['d', None]], ['HollowCylinder', {'a1' : .1, 'a2' : 1., 'Lz' : 18.84955592153876}], False)
 
-    test_mass_preconditioner_polar([8, 12, 6], [4, 3, 2], [False, True, False], [[False, True], [False, False], [True, False]], ['IGAPolarCylinder', {'a': 1., 'Lz': 3.}], False)
+    # test_mass_preconditioner_polar([8, 12, 6], [4, 3, 2], [False, True, False], [[False, True], [False, False], [True, False]], ['IGAPolarCylinder', {'a': 1., 'Lz': 3.}], False)
```

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_toarray_struphy.py` & `struphy-2.3.0/src/struphy/feec/tests/test_toarray_struphy.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/tests/test_tosparse_struphy.py` & `struphy-2.3.0/src/struphy/feec/tests/test_tosparse_struphy.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/tests/xx_test_preconds.py` & `struphy-2.3.0/src/struphy/feec/tests/xx_test_preconds.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/utilities.py` & `struphy-2.3.0/src/struphy/feec/utilities.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/feec/utilities_kernels.py` & `struphy-2.3.0/src/struphy/feec/utilities_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/base.py` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -221,14 +221,23 @@
 
     def a2_2(self, *etas, squeeze_out=False):
         return self.a2(*etas, squeeze_out=squeeze_out)[1]
 
     def a2_3(self, *etas, squeeze_out=False):
         return self.a2(*etas, squeeze_out=squeeze_out)[2]
     
+    def bv_1(self, *etas, squeeze_out=False):
+        return self.bv(*etas, squeeze_out=squeeze_out)[0]
+
+    def bv_2(self, *etas, squeeze_out=False):
+        return self.bv(*etas, squeeze_out=squeeze_out)[1]
+
+    def bv_3(self, *etas, squeeze_out=False):
+        return self.bv(*etas, squeeze_out=squeeze_out)[2]
+    
     def av_1(self, *etas, squeeze_out=False):
         return self.av(*etas, squeeze_out=squeeze_out)[0]
 
     def av_2(self, *etas, squeeze_out=False):
         return self.av(*etas, squeeze_out=squeeze_out)[1]
 
     def av_3(self, *etas, squeeze_out=False):
```

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/equils.py` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/equils.py`

 * *Files 3% similar despite different names*

```diff
@@ -490,15 +490,16 @@
 
             if q0 == q1:
                 pout = (B0**2*eps**2/q0**2)*(1 - r**2/self.params['a']**2)
             else:
                 pout = B0**2*eps**2*q0/(2*(q1 - q0)) * \
                     (1/self.q_r(r)**2 - 1/q1**2)
 
-        return pout
+        # add offset to avoid zero pressure
+        return pout + 1e-8
 
     def n_r(self, r):
         """ Radial ion number density profile n = n(r).
         """
         nout = (1 - self.params['na'])*(1 - (r/self.params['a']) **
                                         self.params['n1'])**self.params['n2'] + self.params['na']
 
@@ -704,17 +705,17 @@
             AdhocTorus :
                 a       : 1.   # minor radius
                 R0      : 3.   # major radius
                 B0      : 1.   # on-axis toroidal magnetic field
                 q_kind  : 0    # which profile (0 : parabolic, 1 : other, see documentation)
                 q0      : 1.05 # safety factor at r=0
                 q1      : 1.80 # safety factor at r=a
-                n1      : 0.   # 1st shape factor for number density profile 
-                n2      : 0.   # 2nd shape factor for number density profile 
-                na      : 1.   # number density at r=a
+                n1      : .5   # 1st shape factor for number density profile 
+                n2      : 1.   # 2nd shape factor for number density profile 
+                na      : .2   # number density at r=a
                 p_kind  : 1    # kind of pressure profile (0 : cylindrical limit, 1 : ad hoc)
                 p1      : .1   # 1st shape factor for ad hoc pressure profile
                 p2      : .1   # 2nd shape factor for ad hoc pressure profile
                 beta    : .01  # plasma beta = p*(2*mu_0)/B^2 for flat safety factor 
                 psi_k   : 3    # spline degree to be used for interpolation of poloidal flux function (only needed if q_kind=1)
                 psi_nel : 50   # number of cells to be used for interpolation of poloidal flux function (only needed if q_kind=1)
     """
@@ -727,17 +728,17 @@
         # parameters
         params_default = {'a': 1.,
                           'R0': 3.,
                           'B0': 2.,
                           'q_kind': 0,
                           'q0': 1.71,
                           'q1': 1.87,
-                          'n1': 0.,
-                          'n2': 0.,
-                          'na': 1.,
+                          'n1': 2.,
+                          'n2': 1.,
+                          'na': .2,
                           'p_kind': 1,
                           'p1': 0.,
                           'p2': 0.,
                           'beta': 0.179,
                           'psi_k': 3,
                           'psi_nel': 50}
 
@@ -1189,17 +1190,17 @@
                 a       : 0.361925 # minor radius
                 R0      : 1.   # major radius
                 B0      : 1.   # on-axis toroidal magnetic field
                 q0      : 0.6  # safety factor at r=0
                 q1      : 2.5  # safety factor at r=a
                 q0p     : 0.78 # derivative of safety factor at r=0 (w.r.t. to poloidal flux function)
                 q1p     : 5.00 # derivative of safety factor at r=a (w.r.t. to poloidal flux function)
-                n1      : 0.   # shape factor for number density profile 
-                n2      : 0.   # shape factor for number density profile 
-                na      : 1.   # number density at r=a
+                n1      : .5   # shape factor for number density profile 
+                n2      : 1.   # shape factor for number density profile 
+                na      : .2   # number density at r=a
                 beta    : .1   # plasma beta = p*(2*mu_0)/B^2 for flat safety factor
                 p1      : 0.25 # shape factor of pressure profile
                 psi_k   : 3    # spline degree to be used for interpolation of poloidal flux function
                 psi_nel : 50   # number of cells to be used for interpolation of poloidal flux functionq_kind=1)
     """
 
     def __init__(self, **params):
@@ -1212,17 +1213,17 @@
         params_default = {'a': 0.361925,
                           'R0': 1.,
                           'B0': 1.,
                           'q0': 0.6,
                           'q1': 2.5,
                           'q0p': 0.78,
                           'q1p': 5.00,
-                          'n1': 0.,
-                          'n2': 0.,
-                          'na': 1.,
+                          'n1': 2.,
+                          'n2': 1.,
+                          'na': .2,
                           'beta': 4.,
                           'p1': 0.25,
                           'psi_k': 3,
                           'psi_nel': 50}
 
         self._params = set_defaults(params, params_default)
 
@@ -1554,17 +1555,17 @@
         params_default = {'rel_path': True,
                           'file': 'AUGNLED_g031213.00830.high',
                           'data_type': 0,
                           'p_for_psi': [3, 3],
                           'psi_resolution': [25., 6.25],
                           'p_for_flux': 3,
                           'flux_resolution': 50.,
-                          'n1': 0.,
-                          'n2': 0.,
-                          'na': 1.,
+                          'n1': 2.,
+                          'n2': 1.,
+                          'na': .2,
                           }
 
         self._params = set_defaults(params, params_default)
 
         if self._params['rel_path']:
             _path = struphy.__path__[0] + \
                 '/fields_background/mhd_equil/eqdsk/data/' + \
@@ -1819,15 +1820,19 @@
 
         R = np.sqrt(x**2 + y**2)
         Z = 1*z
 
         out = self.p_psi(self.psi(R, Z))
 
         # rescale to Struphy units
-        out /= 1.25663706212e-6 * self.units['p']
+        if 'p' in self.units:
+            out /= 1.25663706212e-6 * self.units['p']
+        else:
+            print(
+                f'+++Warning+++: pressure unit not defined, {self.units = }.')
 
         return out
 
     def n_xyz(self, x, y, z):
         """ Number density in physical space. Units from parameter file. 
         """
 
@@ -1885,50 +1890,52 @@
 
         from gvec_to_python.reader.gvec_reader import create_GVEC_json
         from gvec_to_python import GVEC
 
         import struphy
         import os
         from mpi4py import MPI
-        
+
         comm = MPI.COMM_WORLD
         rank = comm.Get_rank()
 
         params_default = {'rel_path': True,
                           'dat_file': 'ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat',
                           'json_file': None,
                           'use_pest': False,
                           'use_nfp': True,
-                          'rmin': 0.0,
+                          'rmin': 0.01,
                           'Nel': (16, 16, 16),
                           'p': (3, 3, 3), }
 
         self._params = set_defaults(params, params_default)
 
         if self._params['dat_file'] is None:
 
             assert self._params['json_file'] is not None
             assert self._params['json_file'][-5:] == '.json'
 
             if self._params['rel_path']:
-                json_file = os.path.join(struphy.__path__[0], 'fields_background/mhd_equil/gvec', self._params['json_file'])
+                json_file = os.path.join(struphy.__path__[
+                                         0], 'fields_background/mhd_equil/gvec', self._params['json_file'])
             else:
                 json_file = self._params['json_file']
 
         else:
 
             assert self._params['dat_file'][-4:] == '.dat'
 
             if self._params['rel_path']:
-                dat_file = os.path.join(struphy.__path__[0], 'fields_background/mhd_equil/gvec', self._params['dat_file'])
+                dat_file = os.path.join(struphy.__path__[
+                                        0], 'fields_background/mhd_equil/gvec', self._params['dat_file'])
             else:
                 dat_file = params['dat_file']
 
             json_file = dat_file[:-4] + '.json'
-            #TODO: better read/write for MPI
+            # TODO: better read/write for MPI
             if rank == 0:
                 create_GVEC_json(dat_file, json_file)
             comm.Barrier()
 
         if self._params['use_pest']:
             mapping = 'unit_pest'
         else:
@@ -1959,36 +1966,100 @@
         return self._gvec
 
     @property
     def params(self):
         '''Parameters describing the equilibrium.'''
         return self._params
 
-    def b2(self, eta1, eta2, eta3, squeeze_out=True):
+    def b2(self, *etas, squeeze_out=False):
         """2-form magnetic field on logical cube [0, 1]^3.
         """
-        return self.gvec.b2(eta1, eta2, eta3)
+        # flat (marker) evaluation
+        if len(etas) == 1:
+            assert etas[0].ndim == 2
+            eta1 = etas[0][:, 0]
+            eta2 = etas[0][:, 1]
+            eta3 = etas[0][:, 2]
+            flat_eval = True
+        # meshgrid evaluation
+        else:
+            assert len(etas) == 3
+            assert etas[0].shape == etas[1].shape == etas[2].shape
+            eta1 = etas[0]
+            eta2 = etas[1]
+            eta3 = etas[2]
+            flat_eval = False
+
+        return self.gvec.b2(eta1, eta2, eta3, flat_eval=flat_eval)
 
-    def j2(self, eta1, eta2, eta3, squeeze_out=True):
+    def j2(self, *etas, squeeze_out=False):
         """2-form current density (=curl B) on logical cube [0, 1]^3.
         """
-        return self.gvec.j2(eta1, eta2, eta3)
+        # flat (marker) evaluation
+        if len(etas) == 1:
+            assert etas[0].ndim == 2
+            eta1 = etas[0][:, 0]
+            eta2 = etas[0][:, 1]
+            eta3 = etas[0][:, 2]
+            flat_eval = True
+        # meshgrid evaluation
+        else:
+            assert len(etas) == 3
+            assert etas[0].shape == etas[1].shape == etas[2].shape
+            eta1 = etas[0]
+            eta2 = etas[1]
+            eta3 = etas[2]
+            flat_eval = False
+
+        return self.gvec.j2(eta1, eta2, eta3, flat_eval=flat_eval)
 
-    def p0(self, eta1, eta2, eta3, squeeze_out=True):
+    def p0(self, *etas, squeeze_out=False):
         """0-form equilibrium pressure on logical cube [0, 1]^3.
         """
-        return self.gvec.p0(eta1, eta2, eta3)
+        # flat (marker) evaluation
+        if len(etas) == 1:
+            assert etas[0].ndim == 2
+            eta1 = etas[0][:, 0]
+            eta2 = etas[0][:, 1]
+            eta3 = etas[0][:, 2]
+            flat_eval = True
+        # meshgrid evaluation
+        else:
+            assert len(etas) == 3
+            assert etas[0].shape == etas[1].shape == etas[2].shape
+            eta1 = etas[0]
+            eta2 = etas[1]
+            eta3 = etas[2]
+            flat_eval = False
 
-    def n0(self, eta1, eta2, eta3, squeeze_out=True):
+        return self.gvec.p0(eta1, eta2, eta3, flat_eval=flat_eval)
+
+    def n0(self, *etas, squeeze_out=False):
         """0-form equilibrium density on logical cube [0, 1]^3.
         """
-        # TODO: which density to set?
-        return self.gvec.p0(eta1, eta2, eta3) * 0
+        # flat (marker) evaluation
+        if len(etas) == 1:
+            assert etas[0].ndim == 2
+            eta1 = etas[0][:, 0]
+            eta2 = etas[0][:, 1]
+            eta3 = etas[0][:, 2]
+            flat_eval = True
+        # meshgrid evaluation
+        else:
+            assert len(etas) == 3
+            assert etas[0].shape == etas[1].shape == etas[2].shape
+            eta1 = etas[0]
+            eta2 = etas[1]
+            eta3 = etas[2]
+            flat_eval = False
+
+        # TODO: which density to set? Is proportional to pressure for the moment
+        return 0.2 * self.p0(*etas)
 
-    def gradB1(self, eta1, eta2, eta3, squeeze_out=True):
+    def gradB1(self, *etas, squeeze_out=False):
         """1-form gradient of magnetic field on logical cube [0, 1]^3.
         """
         raise NotImplementedError(
             '1-form gradient of magnetic field of GVECequilibrium is not implemented')
 
 
 def set_defaults(params_in, params_default):
```

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/parameter.ini` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E1D6_M6N6/parameter.ini`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/parameter.ini` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/newBC_E4D6_M6N6/parameter.ini`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/GVEC_ELLIPSTELL_V2_State_0000_00200000.dat`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/parameter.ini` & `struphy-2.3.0/src/struphy/fields_background/mhd_equil/gvec/ellipstell_v2/oldBC_E40D5M6N6/parameter.ini`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/tests/test_gvec_equil.py` & `struphy-2.3.0/src/struphy/fields_background/tests/test_gvec_equil.py`

 * *Files 1% similar despite different names*

```diff
@@ -12,15 +12,15 @@
     import numpy as np
     import os
     from mpi4py import MPI
     
     comm = MPI.COMM_WORLD
 
     # struphy discrete equilibirum
-    mhd_equil = GVECequilibrium()
+    mhd_equil = GVECequilibrium(rmin=0.)
 
     # gvec continuous equilibirum
     import struphy 
     dat_file_in = os.path.join(struphy.__path__[0], 'fields_background/mhd_equil/gvec', mhd_equil.params['dat_file'])
     json_file_out = dat_file_in[:-4] + '.json'
 
     print(json_file_out)
```

### Comparing `struphy-2.2.0/src/struphy/fields_background/tests/test_mhd_equils.py` & `struphy-2.3.0/src/struphy/fields_background/tests/test_mhd_equils.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/fields_background/tests/test_numerical_mhd_equil.py` & `struphy-2.3.0/src/struphy/fields_background/tests/test_numerical_mhd_equil.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/geometry/base.py` & `struphy-2.3.0/src/struphy/geometry/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -221,15 +221,15 @@
         '''Dictionary of str->int for pull, push and transformation functions.'''
         return self._dict_transformations
 
     # ========================
     def __call__(self, *etas, change_out_order=False, squeeze_out=False, remove_outside=True, identity_map=False):
         r"""
         Evaluates the mapping :math:`F : (0, 1)^3 \to \mathbb R^3,\, \boldsymbol \eta \mapsto \mathbf x`. 
-        
+
         Logical coordinates outside of :math:`(0, 1)^3` are evaluated to -1.
         The type of evaluation depends on the shape of the input ``etas``.
 
         Parameters
         ----------
         *etas : array-like | tuple
             Logical coordinates at which to evaluate. Two cases are possible:
@@ -490,15 +490,15 @@
             If True, logical coordinates outside of (0, 1)^3 are NOT evaluated to -1 and are removed in the output array.
 
         Returns
         -------
         out : ndarray | float
             Pushforward of p-form to Cartesian vector/scalar field evaluated at given logical coordinates.
         """
-
+        
         return self._pull_push_transform('push', a, kind, *etas, change_out_order=change_out_order, squeeze_out=squeeze_out, remove_outside=remove_outside, a_kwargs=a_kwargs)
 
     # ================================
     def transform(self, a, *etas, kind='0_to_3', a_kwargs={}, change_out_order=False, squeeze_out=False, remove_outside=True):
         """
         Transformation between different differential p-forms and/or vector fields. 
 
@@ -581,15 +581,15 @@
             markers = etas[0]
 
             # to keep C-ordering the (3, 3)-part is in the last indices
             out = np.empty((markers.shape[0], 3, 3), dtype=float)
 
             n_inside = evaluation_kernels.kernel_evaluate_pic(
                 markers, which, *self.args_map, out, remove_outside)
-            
+
             # move the (3, 3)-part to front
             out = np.transpose(out, axes=(1, 2, 0))
 
             # remove holes
             out = out[:, :, :n_inside]
 
             if transposed:
@@ -672,15 +672,16 @@
 
         **kwargs
             Addtional keyword arguments (coordinates, change_out_order, squeeze_out, remove_outside, a_kwargs).
 
         Returns
         -------
         out : ndarray | float
-            The metric coefficient evaluated at the given logical coordinates.
+            4D or 2D (for flat eval) array holding the metric coefficient (first index),
+            evaluated at the given logical coordinates (last three indices).
         """
 
         # set default values
         coordinates = kwargs.get('coordinates', 'logical')
         change_out_order = kwargs.get('change_out_order', False)
         squeeze_out = kwargs.get('squeeze_out', True)
         remove_outside = kwargs.get('remove_outside', False)
@@ -914,18 +915,17 @@
             elif arg_x.ndim == 3 and arg_y.ndim == 3 and arg_z.ndim == 3:
                 # Distinguish if input coordinates are from sparse or dense meshgrid.
                 # Sparse: arg_x.shape = (n1, 1, 1), arg_y.shape = (1, n2, 1), arg_z.shape = (1, 1, n3)
                 # Dense : arg_x.shape = (n1, n2, n3), arg_y.shape = (n1, n2, n3) arg_z.shape = (n1, n2, n3)
                 E1, E2, E3 = arg_x, arg_y, arg_z
 
                 # `arg_x` `arg_y` `arg_z` are all sparse meshgrids.
-                if max(arg_x.shape) == arg_x.size or max(arg_y.shape) == arg_y.size or max(arg_z.shape) == arg_z.size:
-                    assert max(arg_x.shape) == arg_x.size
-                    assert max(arg_y.shape) == arg_y.size
-                    assert max(arg_z.shape) == arg_z.size
+                if (arg_x.shape[1] == 1 and arg_x.shape[2] == 1 and 
+                    arg_y.shape[0] == 1 and arg_y.shape[2] == 1 and 
+                    arg_z.shape[0] == 1 and arg_z.shape[1] == 1):
                     is_sparse_meshgrid = True
                 # one of `arg_x` `arg_y` `arg_z` is a dense meshgrid.(i.e., all are dense meshgrid) Process each point as default.
 
             else:
                 raise ValueError('Argument dimensions not supported')
 
             return E1, E2, E3, is_sparse_meshgrid
@@ -976,19 +976,19 @@
                     a_out = a_out[None, :]
             else:
                 if is_sparse_meshgrid:
                     a_out = a_in(
                         *np.meshgrid(Xs[0][:, 0, 0], Xs[1][0, :, 0], Xs[2][0, 0, :], indexing='ij'), **a_kwargs)
                 else:
                     a_out = a_in(*Xs, **a_kwargs)
-                    
+
                 # case of Field.__call__
                 if isinstance(a_out, list):
                     a_out = np.array(a_out)
-                    
+
                 if a_out.ndim == 3:
                     a_out = a_out[None, :, :, :]
 
         # list/tuple of length 1 or 3 containing:
         # callable(s) that must return 3d array(s) for 3d evaluation points
         # 1d array(s) (flat_eval=True)
         # 3d array(s) (flat eval=False)
@@ -1070,15 +1070,16 @@
             assert a_out.shape[0] == 1 or a_out.shape[0] == 3
             a_out = np.ascontiguousarray(np.transpose(a_out, axes=(1, 0)))
 
         # make sure that output array is 4d and of shape (:,:,:, 1) or (:,:,:, 3) for tensor-product/slice evaluation
         else:
             assert a_out.ndim == 4
             assert a_out.shape[0] == 1 or a_out.shape[0] == 3
-            a_out = np.ascontiguousarray(np.transpose(a_out, axes=(1, 2, 3, 0)))
+            a_out = np.ascontiguousarray(
+                np.transpose(a_out, axes=(1, 2, 3, 0)))
 
         return a_out
 
     # ================================
     @staticmethod
     def prepare_params_map(params_user, params_default, return_numpy=True):
         """
```

### Comparing `struphy-2.2.0/src/struphy/geometry/domains.py` & `struphy-2.3.0/src/struphy/geometry/domains.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import numpy as np
 
 
 class Tokamak(PoloidalSplineTorus):
     """
     Mappings for Tokamak MHD equilibria constructed via :ref:`field-line tracing <field_tracing>` of a poloidal flux function :math:`\psi`.
 
-    .. image:: ../pics/mappings/tokamak.png
+    .. image:: ../../pics/mappings/tokamak.png
 
     Parameters
     ----------
     equilibrium : struphy.fields_background.mhd_equil.base.AxisymmMHDequilibrium
         The axisymmetric MHD equilibrium for which a flux-aligned grid shall be constructed (default: AdhocTorus).
     Nel : list[int]
         Number of cells in (radial, angular) direction to be used in spline mapping (default: [8, 32]).
@@ -132,15 +132,15 @@
 
 
 class GVECunit(Spline):
     """
     The mapping ``f_unit`` from `gvec_to_python <https://gitlab.mpcdf.mpg.de/gvec-group/gvec_to_python>`_, 
     computed by the GVEC MHD equilibrium code.
 
-    .. image:: ../pics/mappings/gvec.png
+    .. image:: ../../pics/mappings/gvec.png
 
     Parameters
     ----------
     gvec_equil : struphy.fields_background.mhd_equil.equils.GVECequilibrium
         GVEC MHD equilibrium object.
 
     Note
@@ -195,15 +195,15 @@
     .. math:: 
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &\sum_{ij} c^x_{ij} N_i(\eta_1) N_j(\eta_2)\approx a\,\eta_1\cos(2\pi\eta_2)\,\,\\
         \,\,y= &\sum_{ij} c^y_{ij} N_i(\eta_1) N_j(\eta_2)\approx a\,\eta_1\sin(2\pi\eta_2)\,\,\\
         \,\,z= &L_z\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/iga_cylinder.png
+    .. image:: ../../pics/mappings/iga_cylinder.png
 
     Parameters
     ----------
     Nel : list[int]
         Number of cells in (radial, angular) direction used for spline mapping (default: [8, 24]).
     p : list[int]
         Splines degrees in (radial, angular) direction used for spline mapping (default: [2, 3]).   
@@ -274,15 +274,15 @@
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &\sum_{ij} c^{R}_{ij} N_i(\eta_1) N_j(\eta_2) \cos(\phantom{-}2\pi\eta_3) \approx \left[a\,\eta_1\cos(2\pi\theta(\eta_1, \eta_2)) + R_0\right]\cos(\phantom{-}2\pi\eta_3)\,\,\\
         \,\,y= &\sum_{ij} c^{R}_{ij} N_i(\eta_1) N_j(\eta_2) \sin(-2\pi\eta_3)\approx \left[a\,\eta_1\cos(2\pi\theta(\eta_1, \eta_2)) + R_0\right]\sin(-2\pi\eta_3)\,\,\\
         \,\,z= &\sum_{ij} c^{Z}_{ij} N_i(\eta_1) N_j(\eta_2)\approx a\,\eta_1\sin(2\pi\theta(\eta_1, \eta_2))\,\,\end{bmatrix}
 
     The angular parametrization :math:`\theta(\eta_1, \eta_2)` can either be equal angle or straight field line (see parameters below).
 
-    .. image:: ../pics/mappings/iga_torus.png
+    .. image:: ../../pics/mappings/iga_torus.png
 
     Parameters
     ----------
     Nel : list[int]
         Number of cells in (radial, angular) direction used for spline mapping (default: [8, 24]).
     p : list[int]
         Splines degrees in (radial, angular) direction used for spline mapping (default: [2, 3]).   
@@ -372,15 +372,15 @@
     .. math::
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &l_1 + (r_1 - l_1)\,\eta_1\,\,\\
         \,\,y= &l_2 + (r_2 - l_2)\,\eta_2\,\,\\
         \,\,z= &l_3 + (r_3 - l_3)\,\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/cuboid.png
+    .. image:: ../../pics/mappings/cuboid.png
 
     Parameters
     ----------
     l1 : float
         Start of x-interval (default: 0.).
     r1 : float
         End of x-interval, r1>l1 (default: 2.).
@@ -453,15 +453,15 @@
     .. math:: 
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &L_x\,\left[\,\eta_1 + \alpha\sin(2\pi\,\eta_1)\right]\,\,\\
         \,\,y= &L_y\,\left[\,\eta_2 + \alpha\sin(2\pi\,\eta_2)\right]\,\,\\
         \,\,z= &L_z\,\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/orthogonal.png
+    .. image:: ../../pics/mappings/orthogonal.png
 
     Parameters
     ----------
     Lx : float
         Length of x-interval (default: 2.).
     Ly : float
         Length of y-interval (default: 3.).
@@ -527,15 +527,15 @@
     .. math::
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &L_x\,\left[\,\eta_1 + \alpha\sin(2\pi\,\eta_1)\sin(2\pi\,\eta_2)\,\right]\,\,\\
         \,\,y= &L_y\,\left[\,\eta_2 + \alpha\sin(2\pi\,\eta_2)\sin(2\pi\,\eta_1)\,\right]\,\,\\
         \,\,z= &L_z\,\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/colella.png
+    .. image:: ../../pics/mappings/colella.png
 
     Parameters
     ----------
     Lx : float
         Length of x-interval (default: 2.).
     Ly : float
         Length of y-interval (default: 3.).
@@ -601,15 +601,15 @@
     .. math::
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &\left[\,a_1 + (a_2-a_1)\,\eta_1\,\right]\cos(2\pi\,\eta_2)\,\,\\
         \,\,y= &\left[\,a_1 + (a_2-a_1)\,\eta_1\,\right]\sin(2\pi\,\eta_2)\,\,\\
         \,\,z= &L_z\,\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/hollow_cylinder.png
+    .. image:: ../../pics/mappings/hollow_cylinder.png
 
     Parameters
     ----------
     a1 : float
         Inner radius of cylinder (default: 0.2).
     a2 : float
         Outer radius of cylinder (default: 1.0).
@@ -676,15 +676,15 @@
     .. math::
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &r_x\,\eta_1^s\cos(2\pi\,\eta_2)\,\,\\
         \,\,y= &r_y\,\eta_1^s\sin(2\pi\,\eta_2)\,\,\\
         \,\,z= &L_z\,\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/pow_elliptic_cyl.png
+    .. image:: ../../pics/mappings/pow_elliptic_cyl.png
 
     Parameters
     ----------
     rx : float
         Radius in x-direction (default: 1.0).
     ry : float
         Radius in y-direction (default: 2.0).
@@ -763,15 +763,15 @@
         & 2\pi\,\eta_2\,, \quad &&\textnormal{if}\quad \textnormal{sfl}=\textnormal{False}\,,
 
         &2\arctan\left[\sqrt{\frac{1 + \epsilon(\eta_1)}{1 - \epsilon(\eta_1)}}\,\tan\left(\pi\,\eta_2\right)\right]\quad &&\textnormal{if}\quad \textnormal{sfl}=\textnormal{True}\,,
         \end{aligned}\right.
 
         &\epsilon(\eta_1) = \frac{a_1 + (a_2-a_1)\,\eta_1}{R_0}\,.
 
-    .. image:: ../pics/mappings/hollow_torus.png
+    .. image:: ../../pics/mappings/hollow_torus.png
 
     Parameters
     ----------
     a1 : float
         Inner minor radius of hollow torus (default: 0.2).
     a2 : float
         Outer minor radius of hollow torus (default: 1.0).
@@ -845,15 +845,15 @@
     .. math:: 
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &r_x\,\eta_1\cos(2\pi\,\eta_2)+(1-\eta_1^2)\,r_x\Delta\,\,\\
         \,\,y= &r_y\,\eta_1\sin(2\pi\,\eta_2)\,\,\\
         \,\,z= &L_z\,\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/shafranov_shift.png
+    .. image:: ../../pics/mappings/shafranov_shift.png
 
     Parameters
     ----------
     rx : float
         Radius in x-direction (default: 1.0).
     ry : float
         Radius in y-direction (default: 1.0).
@@ -919,15 +919,15 @@
     .. math:: 
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &r_x\,\eta_1\cos(2\pi\,\eta_2)+(1-\sqrt \eta_1)r_x\Delta\,\,\\
         \,\,y= &r_y\,\eta_1\sin(2\pi\,\eta_2)\,\,\\
         \,\,z= &L_z\,\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/shafranov_sqrt.png
+    .. image:: ../../pics/mappings/shafranov_sqrt.png
 
     Parameters
     ----------
     rx : float
         Radius in x-direction (default: 1.0).
     ry : float
         Radius in y-direction (default: 1.0).
@@ -992,15 +992,15 @@
     .. math:: 
 
         F: \begin{bmatrix}\eta_1\\ \eta_2\\ \eta_3\end{bmatrix}\mapsto \begin{bmatrix}
         \,\,x= &R_0\left[1 + (1 - \eta_1^2)\Delta_x + \eta_1\epsilon\cos(2\pi\,\eta_2 + \arcsin(\delta)\eta_1\sin(2\pi\,\eta_2)) \right]\,\,\\
         \,\,y= &R_0\left[    (1 - \eta_1^2)\Delta_y + \eta_1\epsilon\kappa\sin(2\pi\,\eta_2)\right]\,\,\\
         \,\,z= &L_z\,\eta_3\,\,\end{bmatrix}
 
-    .. image:: ../pics/mappings/shafranov_dshaped.png
+    .. image:: ../../pics/mappings/shafranov_dshaped.png
 
     Parameters
     ----------
     R0 : float 
         Base radius (default: 2.).
     Lz : float 
         Length in z-direction (default: 4.).
```

### Comparing `struphy-2.2.0/src/struphy/geometry/evaluation_kernels.py` & `struphy-2.3.0/src/struphy/geometry/evaluation_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/geometry/mappings_kernels.py` & `struphy-2.3.0/src/struphy/geometry/mappings_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/geometry/tests/test_domain.py` & `struphy-2.3.0/src/struphy/geometry/tests/test_domain.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/geometry/transform_kernels.py` & `struphy-2.3.0/src/struphy/geometry/transform_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/geometry/utilities.py` & `struphy-2.3.0/src/struphy/geometry/utilities.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/geometry/utilities_kernels.py` & `struphy-2.3.0/src/struphy/geometry/utilities_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/initial/eigenfunctions.py` & `struphy-2.3.0/src/struphy/initial/eigenfunctions.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/initial/perturbations.py` & `struphy-2.3.0/src/struphy/initial/perturbations.py`

 * *Files 15% similar despite different names*

```diff
@@ -6,73 +6,86 @@
 
 
 class ModesSin:
     r'''Sinusoidal function in 3D.
 
     .. math::
 
-        u(x, y, z) = \sum_{i} A_i \sin \left(l_i \frac{2\pi}{L_x} x + m_i \frac{2\pi}{L_y} y + n_i \frac{2\pi}{L_z} z \right) \,.
+        u(x, y, z) = \sum_{s} A_s \sin \left(l_s \frac{2\pi}{L_x} x + m_s \frac{2\pi}{L_y} y + n_s \frac{2\pi}{L_z} z \right) \,.
 
-    Can be used in logical space with Lx=Ly=Lz=1.0 (default).
+    Can be used in logical space, where :math:`x \to \eta_1,\, y\to \eta_2,\, z \to \eta_3` 
+    and :math:`L_x=L_y=L_z=1.0` (default).
 
     Note
     ----
-    In the parameter .yml, use the following template in the section ``fluid/<species>``::
+    Example of use in a ``.yml`` parameter file::
 
-        init :
+        perturbations :
             type : ModesSin
             ModesSin :
                 comps :
-                    n3 : null                    # choices: null, 'physical', '0', '3'
-                    u2 : ['physical', 'v', '2']  # choices: null, 'physical', '1', '2', 'v', 'norm'
-                    p3 : H1                      # choices: null, 'physical', '0', '3'
-                ls :
-                    n3: null            # Integer mode numbers in x or eta_1
-                    u2: [[0], [0], [0]] # Integer mode numbers in x or eta_1
-                    p3: [0]             # Integer mode numbers in x or eta_1
-                ms : 
-                    n3: null            # Integer mode numbers in y or eta_2
-                    u2: [[0], [0], [0]] # Integer mode numbers in y or eta_2
-                    p3: [0]             # Integer mode numbers in y or eta_2
-                ns :
-                    n3: null            # Integer mode numbers in z or eta_3
-                    u2: [[1], [1], [1]] # Integer mode numbers in z or eta_3
-                    p3: [1]             # Integer mode numbers in z or eta_3
-                amps :
-                    n3: null                        # amplitudes of each mode
-                    u2: [[0.001], [0.001], [0.001]] # amplitudes of each mode
-                    p3: [0.01]                      # amplitudes of each mode
-                Lx : 7.853981633974483 # domain length in x
-                Ly : 1.                # domain length in y
-                Lz : 1.                # domain length in z
+                    scalar_name : '0' # choices: null, 'physical', '0', '3'
+                    vector_name : [null , 'v', '2']  # choices: null, 'physical', '1', '2', 'v', 'norm'
+                ls : 
+                    scalar_name: [1, 3] # two x-modes for scalar variable
+                    vector_name: [null, [0, 1], [4]] # two x-modes for 2nd comp. and one x-mode for third component of vector-valued variable            
+                Lx : 7.853981633974483 
+                Ly : 1.                
+                Lz : 1.               
     '''
 
-    def __init__(self, ls=[0], ms=[0], ns=[0], amps=[1e-4], Lx=1., Ly=1., Lz=1.):
+    def __init__(self, ls=None, ms=None, ns=None, amps=[1e-4], Lx=1., Ly=1., Lz=1.):
         '''
         Parameters
         ----------
-            ls : list
-                Mode numbers in x-direction (kx = l*2*pi/Lx).
-
-            ms : list
-                Mode numbers in y-direction (ky = m*2*pi/Ly).
+        ls : list
+            Mode numbers in x-direction (kx = l*2*pi/Lx).
 
-            ns : list
-                Mode numbers in z-direction (kz = n*2*pi/Lz).
+        ms : list
+            Mode numbers in y-direction (ky = m*2*pi/Ly).
 
-            amps : list
-                Amplitude of each mode.
+        ns : list
+            Mode numbers in z-direction (kz = n*2*pi/Lz).
 
-            Lx, Ly, Lz : float
-                Domain lengths.
-        '''
-
-        assert len(ls) == len(ms)
-        assert len(ls) == len(ns)
-        assert len(ls) == len(amps)
+        amps : list
+            Amplitude of each mode.
+
+        Lx, Ly, Lz : float
+            Domain lengths.
+        '''
+
+        if ls is not None:
+            n_modes = len(ls)
+        elif ms is not None:
+            n_modes = len(ms)
+            ls = [0]*n_modes
+        elif ns is not None:
+            n_modes = len(ns)
+            ls = [0]*n_modes
+            ms = [0]*n_modes
+        else:
+            n_modes = 1
+            ls = [0]
+            ms = [0]
+            ns = [0]
+            
+        if ms is None:
+            ms = [0]*n_modes
+        else:
+            assert len(ms) == n_modes
+            
+        if ns is None:
+            ns = [0]*n_modes
+        else:
+            assert len(ns) == n_modes
+            
+        if len(amps) == 1:
+            amps = [amps[0]]*n_modes
+        else:
+            assert len(amps) == n_modes
 
         self._ls = ls
         self._ms = ms
         self._ns = ns
         self._amps = amps
         self._Lx = Lx
         self._Ly = Ly
@@ -90,105 +103,119 @@
 
 
 class ModesCos:
     r'''Cosinusoidal function in 3D.
 
     .. math::
 
-        u(x, y, z) = \sum_{i} A_i \cos \left(l_i \frac{2\pi}{L_x} x + m_i \frac{2\pi}{L_y} y + n_i \frac{2\pi}{L_z} z \right) \,.
+        u(x, y, z) = \sum_{s} A_s \cos \left(l_s \frac{2\pi}{L_x} x + m_s \frac{2\pi}{L_y} y + n_s \frac{2\pi}{L_z} z \right) \,.
 
-    Can be used in logical space with Lx=Ly=Lz=1.0 (default).
+    Can be used in logical space, where :math:`x \to \eta_1,\, y\to \eta_2,\, z \to \eta_3` 
+    and :math:`L_x=L_y=L_z=1.0` (default).
 
     Note
     ----
-    In the parameter .yml, use the following template in the section ``fluid/<species>``::
+    Example of use in a ``.yml`` parameter file::
 
-        init :
-            type : ModesCos 
+        perturbations :
+            type : ModesCos
             ModesCos :
                 comps :
-                    n3 : null                     # choices: null, 'physical', '0', '3'
-                    u2 : ['physical', 'v', '2']   # choices: null, 'physical', '1', '2', 'v', 'norm'
-                    p3 : H1                       # choices: null, 'physical', '0', '3'
-                ls :
-                    n3: null            # Integer mode numbers in x or eta_1
-                    u2: [[0], [0], [0]] # Integer mode numbers in x or eta_1
-                    p3: [0]             # Integer mode numbers in x or eta_1
-                ms : 
-                    n3: null            # Integer mode numbers in y or eta_2
-                    u2: [[0], [0], [0]] # Integer mode numbers in y or eta_2
-                    p3: [0]             # Integer mode numbers in y or eta_2
-                ns :
-                    n3: null            # Integer mode numbers in z or eta_3
-                    u2: [[1], [1], [1]] # Integer mode numbers in z or eta_3
-                    p3: [1]             # Integer mode numbers in z or eta_3
-                amps :
-                    n3: null                        # amplitudes of each mode
-                    u2: [[0.001], [0.001], [0.001]] # amplitudes of each mode
-                    p3: [0.01]                      # amplitudes of each mode
-                Lx : 7.853981633974483 # domain length in x
-                Ly : 1.                # domain length in y
-                Lz : 1.                # domain length in z
+                    scalar_name : '0' # choices: null, 'physical', '0', '3'
+                    vector_name : [null , 'v', '2']  # choices: null, 'physical', '1', '2', 'v', 'norm'
+                ls : 
+                    scalar_name: [1, 3] # two x-modes for scalar variable
+                    vector_name: [null, [0, 1], [4]] # two x-modes for 2nd comp. and one x-mode for third component of vector-valued variable            
+                Lx : 7.853981633974483 
+                Ly : 1.                
+                Lz : 1. 
     '''
 
-    def __init__(self, ls=[0], ms=[0], ns=[0], amps=[1e-4], Lx=1., Ly=1., Lz=1.):
+    def __init__(self, ls=None, ms=None, ns=None, amps=[1e-4], Lx=1., Ly=1., Lz=1.):
         '''
         Parameters
         ----------
-            ls : list
-                Mode numbers in x-direction (kx = l*2*pi/Lx).
+        ls : list
+            Mode numbers in x-direction (kx = l*2*pi/Lx).
 
-            ms : list
-                Mode numbers in y-direction (ky = m*2*pi/Ly).
+        ms : list
+            Mode numbers in y-direction (ky = m*2*pi/Ly).
 
-            ns : list
-                Mode numbers in z-direction (kz = n*2*pi/Lz).
+        ns : list
+            Mode numbers in z-direction (kz = n*2*pi/Lz).
 
-            amps : list
-                Amplitude of each mode.
-
-            Lx, Ly, Lz : float
-                Domain lengths.
-        '''
-
-        assert len(ls) == len(ms)
-        assert len(ls) == len(ns)
-        assert len(ls) == len(amps)
+        amps : list
+            Amplitude of each mode.
+
+        Lx, Ly, Lz : float
+            Domain lengths.
+        '''
+
+        if ls is not None:
+            n_modes = len(ls)
+        elif ms is not None:
+            n_modes = len(ms)
+            ls = [0]*n_modes
+        elif ns is not None:
+            n_modes = len(ns)
+            ls = [0]*n_modes
+            ms = [0]*n_modes
+        else:
+            n_modes = 1
+            ls = [0]
+            ms = [0]
+            ns = [0]
+            
+        if ms is None:
+            ms = [0]*n_modes
+        else:
+            assert len(ms) == n_modes
+            
+        if ns is None:
+            ns = [0]*n_modes
+        else:
+            assert len(ns) == n_modes
+            
+        if len(amps) == 1:
+            amps = [amps[0]]*n_modes
+        else:
+            assert len(amps) == n_modes
 
         self._ls = ls
         self._ms = ms
         self._ns = ns
         self._amps = amps
         self._Lx = Lx
         self._Ly = Ly
         self._Lz = Lz
 
     def __call__(self, x, y, z):
 
         val = 0.
 
         for amp, l, m, n in zip(self._amps, self._ls, self._ms, self._ns):
-            val += amp*np.cos(l*2.*np.pi/self._Lx*x + m*2. *
-                              np.pi/self._Ly*y + n*2.*np.pi/self._Lz*z)
+            val += amp * np.cos(l * 2.*np.pi / self._Lx * x
+                                + m * 2.*np.pi / self._Ly * y
+                                + n * 2.*np.pi / self._Lz * z)
 
         return val
 
 
 class TorusModesSin:
     r'''Sinusoidal function in the periodic coordinates of a Torus.
 
     .. math::
 
-        u(\eta_1, \eta_2, \eta_3) = \sum_{i=0}^N \chi_i(\eta_1) A_i \sin(m_i\,2\pi \eta_2 + n_i\,2\pi \eta_3) \,,
+        u(\eta_1, \eta_2, \eta_3) = \sum_{s} \chi_s(\eta_1) A_s \sin(m_s\,2\pi \eta_2 + n_s\,2\pi \eta_3) \,,
 
-    where :math:`\chi_i(\eta_1)` is one of
+    where :math:`\chi_s(\eta_1)` is one of
 
     .. math::
 
-        \chi_i(\eta_1) = \left\{ 
+        \chi_s(\eta_1) = \left\{ 
         \begin{aligned}
         &\sin(\pi\eta_1)\,,
         \\[2mm]
         &\exp^{-(\eta_1 - r_0)^2/\sigma} \,, 
         \\[2mm]
         & -2(\eta_1 - r_0)/\sigma)\exp^{-(\eta_1 - r_0)^2/\sigma} \,.
         \end{aligned}
@@ -196,15 +223,15 @@
 
     Can only be defined in logical coordinates.
 
     Note
     ----
     In the parameter .yml, use the following template in the section ``fluid/<species>``::
 
-        init :
+        perturbations :
             type : TorusModesSin
             TorusModesSin :
                 comps :
                     n3 : null                     # choices: null, 'physical', '0', '3'
                     u2 : ['physical', 'v', '2']   # choices: null, 'physical', '1', '2', 'v', 'norm'
                     p3 : H1                       # choices: null, 'physical', '0', '3'
                 ms : 
@@ -225,42 +252,61 @@
                     p3: [0.01]                      # profile function in eta1-direction ('sin' or 'cos' or 'exp' or 'd_exp')
                 pfun_params :
                     n3: null                      # Provides [r_0, sigma] parameters for each "exp" and "d_exp" profile fucntion, and null for "sin" and "cos"
                     u2: [null, null, [[0.5, 1.]]] # Provides [r_0, sigma] parameters for each "exp" and "d_exp" profile fucntion, and null for "sin" and "cos"
                     p3: [0.01]                    # Provides [r_0, sigma] parameters for each "exp" and "d_exp" profile fucntion, and null for "sin" and "cos"        
     '''
 
-    def __init__(self, ms=[0], ns=[0], amps=[1e-4], pfuns=['sin'], pfun_params=None):
+    def __init__(self, ms=None, ns=None, amps=[1e-4], pfuns=['sin'], pfun_params=None):
         r'''
         Parameters
         ----------
-            ms : list[int]
-                Poloidal mode numbers.
+        ms : list[int]
+            Poloidal mode numbers.
 
-            ns : list[int]
-                Toroidal mode numbers.
+        ns : list[int]
+            Toroidal mode numbers.
 
-            pfuns : list[str]
-                "sin" or "cos" or "exp" to define the profile functions.
-
-            amps : list[float]
-                Amplitudes of each mode (m_i, n_i).
-
-            pfun_params : list
-                Provides :math:`[r_0, \sigma]` parameters for each "exp" profile fucntion, and None for "sin" and "cos".
-        '''
-
-        assert len(ms) == len(ns)
-        assert len(ms) == len(pfuns)
-        assert len(ms) == len(amps)
+        pfuns : list[str]
+            "sin" or "cos" or "exp" to define the profile functions.
 
+        amps : list[float]
+            Amplitudes of each mode (m_i, n_i).
+
+        pfun_params : list
+            Provides :math:`[r_0, \sigma]` parameters for each "exp" profile fucntion, and None for "sin" and "cos".
+        '''
+
+        if ms is not None:
+            n_modes = len(ms)
+        elif ns is not None:
+            n_modes = len(ns)
+            ms = [0]*n_modes
+        else:
+            n_modes = 1
+            ms = [1]
+            ns = [0]
+            
+        if ns is None:
+            ns = [0]*n_modes
+        else:
+            assert len(ns) == n_modes
+            
+        if len(amps) == 1:
+            amps = [amps[0]]*n_modes
+        else:
+            assert len(amps) == n_modes
+
+        if len(pfuns) == 1:
+            pfuns = [pfuns[0]]*n_modes
+        else:
+            assert len(pfuns) == n_modes
+            
         if pfun_params is None:
-            pfun_params = [None]*len(ms)
-
-        assert len(ms) == len(pfun_params)
+            pfun_params = [None]*n_modes
 
         self._ms = ms
         self._ns = ns
         self._amps = amps
 
         self._pfuns = []
         for pfun, params in zip(pfuns, pfun_params):
@@ -286,21 +332,21 @@
 
 
 class TorusModesCos:
     r'''Cosinusoidal function in the periodic coordinates of a Torus.
 
     .. math::
 
-        u(\eta_1, \eta_2, \eta_3) = \sum_{i=0}^N \chi_i(\eta_1) A_i \cos(m_i\,2\pi \eta_2 + n_i\,2\pi \eta_3) \,,
+        u(\eta_1, \eta_2, \eta_3) = \sum_{s} \chi_s(\eta_1) A_s \cos(m_s\,2\pi \eta_2 + n_s\,2\pi \eta_3) \,,
 
-    where :math:`\chi_i(\eta_1)` is one of
+    where :math:`\chi_s(\eta_1)` is one of
 
     .. math::
 
-        \chi_i(\eta_1) = \left\{ 
+        \chi_s(\eta_1) = \left\{ 
         \begin{aligned}
         &\sin(\pi\eta_1)\,,
         \\[2mm]
         &\exp^{-(\eta_1 - r_0)^2/\sigma} \,, 
         \\[2mm]
         & -2(\eta_1 - r_0)/\sigma)\exp^{-(\eta_1 - r_0)^2/\sigma} \,.
         \end{aligned}
@@ -308,15 +354,15 @@
 
     Can only be defined in logical coordinates.
 
     Note
     ----
     In the parameter .yml, use the following template in the section ``fluid/<species>``::
 
-        init :
+        perturbations :
             type : TorusModesCos
             TorusModesCos :
                 comps :
                     n3 : null                     # choices: null, 'physical', '0', '3'
                     u2 : ['physical', 'v', '2']   # choices: null, 'physical', '1', '2', 'v', 'norm'
                     p3 : H1                       # choices: null, 'physical', '0', '3'
                 ms : 
@@ -337,42 +383,61 @@
                     p3: [0.01]                      # profile function in eta1-direction ('sin' or 'cos' or 'exp' or 'd_exp')
                 pfun_params :
                     n3: null                      # Provides [r_0, sigma] parameters for each "exp" and "d_exp" profile fucntion, and null for "sin" and "cos"
                     u2: [null, null, [[0.5, 1.]]] # Provides [r_0, sigma] parameters for each "exp" and "d_exp" profile fucntion, and null for "sin" and "cos"
                     p3: [0.01]                    # Provides [r_0, sigma] parameters for each "exp" and "d_exp" profile fucntion, and null for "sin" and "cos"        
     '''
 
-    def __init__(self, ms=[0], ns=[0], amps=[1e-4], pfuns=['cos'], pfun_params=None):
+    def __init__(self, ms=None, ns=None, amps=[1e-4], pfuns=['sin'], pfun_params=None):
         r'''
         Parameters
         ----------
-            ms : list[int]
-                Poloidal mode numbers.
-
-            ns : list[int]
-                Toroidal mode numbers.
-
-            pfuns : list[str]
-                "sin" or "cos" or "exp" to define the profile functions.
-
-            amps : list[float]
-                Amplitudes of each mode (m_i, n_i).
+        ms : list[int]
+            Poloidal mode numbers.
 
-            pfun_params : list
-                Provides :math:`[r_0, \sigma]` parameters for each "exp" profile fucntion, and None for "sin" and "cos".
-        '''
+        ns : list[int]
+            Toroidal mode numbers.
 
-        assert len(ms) == len(ns)
-        assert len(ms) == len(pfuns)
-        assert len(ms) == len(amps)
+        pfuns : list[str]
+            "sin" or "cos" or "exp" to define the profile functions.
 
+        amps : list[float]
+            Amplitudes of each mode (m_i, n_i).
+
+        pfun_params : list
+            Provides :math:`[r_0, \sigma]` parameters for each "exp" profile fucntion, and None for "sin" and "cos".
+        '''
+
+        if ms is not None:
+            n_modes = len(ms)
+        elif ns is not None:
+            n_modes = len(ns)
+            ms = [0]*n_modes
+        else:
+            n_modes = 1
+            ms = [1]
+            ns = [0]
+            
+        if ns is None:
+            ns = [0]*n_modes
+        else:
+            assert len(ns) == n_modes
+            
+        if len(amps) == 1:
+            amps = [amps[0]]*n_modes
+        else:
+            assert len(amps) == n_modes
+
+        if len(pfuns) == 1:
+            pfuns = [pfuns[0]]*n_modes
+        else:
+            assert len(pfuns) == n_modes
+            
         if pfun_params is None:
-            pfun_params = [None]*len(ms)
-
-        assert len(ms) == len(pfun_params)
+            pfun_params = [None]*n_modes
 
         self._ms = ms
         self._ns = ns
         self._amps = amps
 
         self._pfuns = []
         for pfun, params in zip(pfuns, pfun_params):
@@ -394,57 +459,58 @@
 
         val = 0.
         for mi, ni, pfun, amp in zip(self._ms, self._ns, self._pfuns, self._amps):
             val += amp * pfun(eta1) * np.cos(mi*2.*np.pi *
                                              eta2 + ni*2.*np.pi*eta3)
 
         return val
-   
-    
+
+
 class Shear_x:
     r'''Double shear layer in eta1 (-1 in outer regions, 1 in inner regions).
 
     .. math::
-    
+
         u(\eta_1, \eta_2, \eta_3) = A(-\tanh((\eta_1 - 0.25)/\delta)+\tanh((\eta_1 - 0.75)/\delta) - 1) \,. 
 
     Can only be used in logical space.
 
     Note
     ----
     In the parameter .yml, use the following in the section ``fluid/<species>``::
 
-        init :
+        perturbations :
             type : Shear_x
             Shear_x :
                 comps :
                     rho3 : null                   # choices: null, 'physical', '0', '3'
                     uv : ['physical', 'v', '2']   # choices: null, 'physical', '1', '2', 'v', 'norm'
                     s3 : H1                       # choices: null, 'physical', '0', '3'
                 amp : 0.001 # amplitudes of each mode
                 delta : 0.03333 # characteristic size of the shear layer
     '''
 
-    def __init__(self, amp = 1e-4, delta = 1/15):
+    def __init__(self, amp=1e-4, delta=1/15):
         '''
         Parameters
         ----------
-            amps : float
-                Amplitude of the velocity on each side.
+        amps : float
+            Amplitude of the velocity on each side.
 
-            delta : float
-                Characteristic size of the shear layer
+        delta : float
+            Characteristic size of the shear layer
         '''
 
         self._amp = amp
         self._delta = delta
 
     def __call__(self, e1, e2, e3):
 
-        val = self._amp*(-np.tanh((e1 - 0.75)/self._delta) + np.tanh((e1 - 0.25)/self._delta) - 1)
+        val = self._amp*(-np.tanh((e1 - 0.75)/self._delta) +
+                         np.tanh((e1 - 0.25)/self._delta) - 1)
 
         return val
 
 
 class Shear_y:
     r'''Double shear layer in eta2 (-1 in outer regions, 1 in inner regions).
 
@@ -454,82 +520,136 @@
 
     Can only be used in logical space.
 
     Note
     ----
     In the parameter .yml, use the following in the section ``fluid/<species>``::
 
-        init :
+        perturbations :
             type : Shear_y
             Shear_y :
                 comps :
                     rho3 : null                   # choices: null, 'physical', '0', '3'
                     uv : ['physical', 'v', '2']   # choices: null, 'physical', '1', '2', 'v', 'norm'
                     s3 : H1                       # choices: null, 'physical', '0', '3'
                 amp : 0.001 # amplitudes of each mode
                 delta : 0.03333 # characteristic size of the shear layer
     '''
 
-    def __init__(self, amp = 1e-4, delta = 1/15):
+    def __init__(self, amp=1e-4, delta=1/15):
         '''
         Parameters
         ----------
-            amps : float
-                Amplitude of the velocity on each side.
+        amps : float
+            Amplitude of the velocity on each side.
 
-            delta : float
-                Characteristic size of the shear layer
+        delta : float
+            Characteristic size of the shear layer
         '''
 
         self._amp = amp
         self._delta = delta
 
     def __call__(self, e1, e2, e3):
 
-        val = self._amp*(-np.tanh((e2 - 0.75)/self._delta) + np.tanh((e2 - 0.25)/self._delta) - 1)
+        val = self._amp*(-np.tanh((e2 - 0.75)/self._delta) +
+                         np.tanh((e2 - 0.25)/self._delta) - 1)
 
         return val
-    
+
 
 class Shear_z:
     r'''Double shear layer in eta3 (-1 in outer regions, 1 in inner regions).
 
     .. math::
 
         u(\eta_1, \eta_2, \eta_3) = A(-\tanh((\eta_3 - 0.25)/\delta) + \tanh((\eta_3 - 0.75)/\delta) - 1) \,. 
 
     Can only be used in logical space.
 
     Note
     ----
     In the parameter .yml, use the following in the section ``fluid/<species>``::
 
-        init :
+        perturbations :
             type : Shear_y
             Shear_y :
                 comps :
                     rho3 : null                   # choices: null, 'physical', '0', '3'
                     uv : ['physical', 'v', '2']   # choices: null, 'physical', '1', '2', 'v', 'norm'
                     s3 : H1                       # choices: null, 'physical', '0', '3'
                 amp : 0.001 # amplitudes of each mode
                 delta : 0.03333 # characteristic size of the shear layer
     '''
 
-    def __init__(self, amp = 1e-4, delta = 1/15):
+    def __init__(self, amp=1e-4, delta=1/15):
         '''
         Parameters
         ----------
-            amps : float
-                Amplitude of the velocity on each side.
+        amps : float
+            Amplitude of the velocity on each side.
 
-            delta : float
-                Characteristic size of the shear layer
+        delta : float
+            Characteristic size of the shear layer
         '''
 
         self._amp = amp
         self._delta = delta
 
     def __call__(self, e1, e2, e3):
 
-        val = self._amp*(-np.tanh((e3 - 0.75)/self._delta) + np.tanh((e3- 0.25)/self._delta) - 1)
+        val = self._amp*(-np.tanh((e3 - 0.75)/self._delta) +
+                         np.tanh((e3 - 0.25)/self._delta) - 1)
+
+        return val
+
+
+class ITPA_density:
+    r'''ITPA radial density profile in `A. Könies et al. 2018  <https://iopscience.iop.org/article/10.1088/1741-4326/aae4e6>`_
+
+    .. math::
+
+        n(\eta_1) = n_0*c_3\exp\left[-\frac{c_2}{c_1}\tanh\left(\frac{\eta_1 - c_0}{c_2}\right)\right]\,.
+
+    Note
+    ----
+    In the parameter .yml, use the following template in the section ``kinetic/<species>``::
+
+        perturbation :
+            type : ITPA_density
+            ITPA_density :
+                comps :
+                    n : '0'
+                n0 :
+                    n : 0.00720655
+                c :
+                    n : [0.491230, 0.298228, 0.198739, 0.521298]
+    '''
+
+    def __init__(self, n0=0.00720655, c=[0.491230, 0.298228, 0.198739, 0.521298]):
+        '''
+        Parameters
+        ----------
+        n0 : float
+            ITPA profile density
+
+        c : list
+            4 ITPA profile coefficients
+        '''
+
+        assert len(c) == 4
+
+        self._n0 = n0
+        self._c = c
+
+    def __call__(self, eta1, eta2, eta3):
+
+        val = 0.
+
+        if self._c[2] == 0.:
+            val = self._c[3] - 0*eta1
+        else:
+            val = self._n0 * \
+                self._c[3]*np.exp(-self._c[2]/self._c[1] *
+                                  np.tanh((eta1 - self._c[0])/self._c[2]))
 
         return val
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `struphy-2.2.0/src/struphy/initial/tests/test_init_perturbations.py` & `struphy-2.3.0/src/struphy/initial/tests/test_init_perturbations.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,307 +1,339 @@
 import pytest
 import inspect
 
-#@pytest.mark.mpi(min_size=2)
+# @pytest.mark.mpi(min_size=2)
+# @pytest.mark.parametrize('combine_comps', [('f0', 'f1'), ('f0', 'f3'), ('f1', 'f2'), ('fvec', 'f3'), ('f1', 'fvec', 'f0')])
 @pytest.mark.parametrize('Nel', [[16, 16, 16]])
 @pytest.mark.parametrize('p', [[2, 3, 4]])
 @pytest.mark.parametrize('spl_kind', [[False, True, True]])
-@pytest.mark.parametrize('mapping', [['Cuboid', {'l1': 0., 'r1': 4., 'l2': 0., 'r2': 5., 'l3': 0., 'r3': 6.}],
-                                     ['Colella', {'Lx': 4., 'Ly': 5., 'alpha': .07, 'Lz': 6.}],
-                                     ['HollowCylinder', {'a1': 0.1}],
-                                     ['HollowTorus', {'tor_period': 1}]])
-#@pytest.mark.parametrize('combine_comps', [('f0', 'f1'), ('f0', 'f3'), ('f1', 'f2'), ('fvec', 'f3'), ('f1', 'fvec', 'f0')])
+@pytest.mark.parametrize('mapping', [
+    ['Cuboid',
+     {'l1': 0., 'r1': 4., 'l2': 0., 'r2': 5., 'l3': 0., 'r3': 6.}],
+    ['Colella',
+     {'Lx': 4., 'Ly': 5., 'alpha': .07, 'Lz': 6.}],
+    ['HollowCylinder', {'a1': 0.1}],
+    ['HollowTorus', {'tor_period': 1}]])
 def test_init_modes(Nel, p, spl_kind, mapping, combine_comps=None, do_plot=False):
     '''Test the initialization Field.initialize_coeffs with all "Modes" classes in perturbations.py.'''
 
     from mpi4py import MPI
     import numpy as np
     from matplotlib import pyplot as plt
 
     from struphy.geometry import domains
     from struphy.feec.psydac_derham import Derham
     from struphy.initial import perturbations
 
     comm = MPI.COMM_WORLD
     rank = comm.Get_rank()
-    
-    # Domain 
+
+    # Domain
     domain_class = getattr(domains, mapping[0])
     domain = domain_class(**mapping[1])
-    
+
     # Derham
     derham = Derham(Nel, p, spl_kind, comm=comm)
-    
+
     fields = {}
     for space, form in derham.space_to_form.items():
         fields[form] = derham.create_field(form, space)
 
     form_scalar = ['0', '3', 'physical_at_eta']
     form_vector = ['1', '2', 'v', 'norm', 'physical_at_eta']
-    
+
     # evaluation points
     e1 = np.linspace(0., 1., 30)
     e2 = np.linspace(0., 1., 40)
     e3 = np.linspace(0., 1., 50)
     eee1, eee2, eee3 = np.meshgrid(e1, e2, e3, indexing='ij')
-    
+
     # mode paramters
     kwargs = {}
     kwargs['ms'] = [1, 0]
     kwargs['ns'] = [2, 0]
     kwargs['amps'] = [0.01, 0.]
-    
+
     ls = [0, 0]
     pfuns = ['sin', 'sin']
-    
+
     pmap = domain.params_map
     if isinstance(domain, domains.Cuboid):
         Lx = pmap['r1'] - pmap['l1']
         Ly = pmap['r2'] - pmap['l2']
         Lz = pmap['r3'] - pmap['l3']
         form_scalar += ['physical']
         form_vector += ['physical']
     elif isinstance(domain, domains.Colella):
-        Lx = pmap['Lx'] 
+        Lx = pmap['Lx']
         Ly = pmap['Ly']
         Lz = pmap['Lz']
         form_scalar += ['physical']
         form_vector += ['physical']
-        
+
     for key, val in inspect.getmembers(perturbations):
         if inspect.isclass(val):
             print(key, val)
-            
+
             if 'Modes' not in key:
                 continue
-            
+
             # skip impossible combinations
             if 'Torus' not in key and (isinstance(domain, domains.HollowTorus) or isinstance(domain, domains.HollowCylinder)):
                 continue
-        
+
             # functions to compare to
-            if 'Torus' in key:    
+            if 'Torus' in key:
                 fun = val(**kwargs, pfuns=pfuns)
             else:
                 fun = val(**kwargs, ls=ls)
                 if isinstance(domain, domains.Cuboid) or isinstance(domain, domains.Colella):
                     fun_xyz = val(**kwargs, ls=ls, Lx=Lx, Ly=Ly, Lz=Lz)
 
             # single component is initialized
-            for name, field in fields.items():
-                
+            for space, name in derham.space_to_form.items():
+
                 if do_plot:
-                    plt.figure(key + '_' + name + '-form_e1e2 ' + mapping[0], figsize=(24, 16))
-                    plt.figure(key + '_' + name + '-form_e1e3 ' + mapping[0], figsize=(24, 16))
-                
+                    plt.figure(key + '_' + name + '-form_e1e2 ' +
+                               mapping[0], figsize=(24, 16))
+                    plt.figure(key + '_' + name + '-form_e1e3 ' +
+                               mapping[0], figsize=(24, 16))
+
                 if name in ('0', '3'):
-                    
+
                     for n, fun_form in enumerate(form_scalar):
-                        
-                        params = {'type': key, 
-                                key: {'comps': {name: fun_form},}}
-                        
+
+                        params = {'type': key,
+                                  key: {'comps': {name: fun_form}, }}
+
                         if 'Modes' in key:
                             params[key]['ls'] = {name: ls}
                             params[key]['ms'] = {name: kwargs['ms']}
                             params[key]['ns'] = {name: kwargs['ns']}
                             params[key]['amps'] = {name: kwargs['amps']}
                             if fun_form == 'physical':
                                 params[key]['Lx'] = Lx
                                 params[key]['Ly'] = Ly
                                 params[key]['Lz'] = Lz
                         else:
-                            raise ValueError(f'Perturbation {key} not implemented, only "Modes" are testes.')
-                            
+                            raise ValueError(
+                                f'Perturbation {key} not implemented, only "Modes" are testes.')
+
                         if 'Torus' in key:
                             params[key].pop('ls')
                             if fun_form == 'physical':
                                 continue
-                            params[key]['pfuns'] = {name: pfuns}      
-                         
-                        #print(f'{params = }')  
-                        field.initialize_coeffs(params, domain=domain)  
-                        
-                        field_vals_xyz = domain.push(field, e1, e2, e3, kind=name)
-                        
+                            params[key]['pfuns'] = {name: pfuns}
+
+                        field = derham.create_field(name, space, pert_params=params)
+                        field.initialize_coeffs(domain=domain)
+
+                        field_vals_xyz = domain.push(
+                            field, e1, e2, e3, kind=name)
+
                         x, y, z = domain(e1, e2, e3)
                         r = np.sqrt(x**2 + y**2)
-                        
+
                         if fun_form == 'physical':
                             fun_vals_xyz = fun_xyz(x, y, z)
                         elif fun_form == 'physical_at_eta':
                             fun_vals_xyz = fun(eee1, eee2, eee3)
                         else:
-                            fun_vals_xyz = domain.push(fun, eee1, eee2, eee3, kind=fun_form)
-                            
-                        #print(f'{rank = }\n{np.where(field_vals_xyz == 0.) }')
-                        error = np.max(np.abs(field_vals_xyz - fun_vals_xyz)) / np.max(np.abs(fun_vals_xyz)) 
-                        print(f'{rank=}, {key=}, {name=}, {fun_form=}, {error=}')  
+                            fun_vals_xyz = domain.push(
+                                fun, eee1, eee2, eee3, kind=fun_form)
+
+                        error = np.max(
+                            np.abs(field_vals_xyz - fun_vals_xyz)) / np.max(np.abs(fun_vals_xyz))
+                        print(f'{rank=}, {key=}, {name=}, {fun_form=}, {error=}')
                         assert error < 0.02
-                        
+
                         if do_plot:
-                            plt.figure(key + '_' + name + '-form_e1e2 ' + mapping[0])
+                            plt.figure(key + '_' + name +
+                                       '-form_e1e2 ' + mapping[0])
                             plt.subplot(2, 4, n + 1)
                             if isinstance(domain, domains.HollowTorus):
-                                plt.contourf(r[:, :, 0], z[:, :, 0], field_vals_xyz[:, :, 0])
+                                plt.contourf(r[:, :, 0], z[:, :, 0],
+                                             field_vals_xyz[:, :, 0])
                                 plt.xlabel('R')
                                 plt.ylabel('Z')
                             else:
-                                plt.contourf(x[:, :, 0], y[:, :, 0], field_vals_xyz[:, :, 0])
+                                plt.contourf(x[:, :, 0], y[:, :, 0],
+                                             field_vals_xyz[:, :, 0])
                                 plt.xlabel('x')
                                 plt.ylabel('y')
                             plt.colorbar()
-                            plt.title(f'init was {fun_form}, (m,n)=({kwargs["ms"][0]},{kwargs["ns"][0]})')  
+                            plt.title(
+                                f'init was {fun_form}, (m,n)=({kwargs["ms"][0]},{kwargs["ns"][0]})')
                             ax = plt.gca()
                             ax.set_aspect('equal', adjustable='box')
-                            
+
                             plt.subplot(2, 4, 4 + n + 1)
                             if isinstance(domain, domains.HollowTorus):
-                                plt.contourf(r[:, :, 0], z[:, :, 0], fun_vals_xyz[:, :, 0])
+                                plt.contourf(
+                                    r[:, :, 0], z[:, :, 0], fun_vals_xyz[:, :, 0])
                                 plt.xlabel('R')
                                 plt.ylabel('Z')
                             else:
-                                plt.contourf(x[:, :, 0], y[:, :, 0], fun_vals_xyz[:, :, 0])
+                                plt.contourf(
+                                    x[:, :, 0], y[:, :, 0], fun_vals_xyz[:, :, 0])
                                 plt.xlabel('x')
                                 plt.ylabel('y')
                             plt.colorbar()
-                            plt.title(f'exact function')  
+                            plt.title(f'exact function')
                             ax = plt.gca()
                             ax.set_aspect('equal', adjustable='box')
-                            
-                            plt.figure(key + '_' + name + '-form_e1e3 ' + mapping[0])
+
+                            plt.figure(key + '_' + name +
+                                       '-form_e1e3 ' + mapping[0])
                             plt.subplot(2, 4, n + 1)
                             if isinstance(domain, domains.HollowTorus):
-                                plt.contourf(x[:, 0, :], y[:, 0, :], field_vals_xyz[:, 0, :])
+                                plt.contourf(x[:, 0, :], y[:, 0, :],
+                                             field_vals_xyz[:, 0, :])
                                 plt.xlabel('x')
                                 plt.ylabel('y')
                             else:
-                                plt.contourf(x[:, 0, :], z[:, 0, :], field_vals_xyz[:, 0, :])
+                                plt.contourf(x[:, 0, :], z[:, 0, :],
+                                             field_vals_xyz[:, 0, :])
                                 plt.xlabel('x')
                                 plt.ylabel('z')
                             plt.colorbar()
-                            plt.title(f'init was {fun_form}, (m,n)=({kwargs["ms"][0]},{kwargs["ns"][0]})')  
+                            plt.title(
+                                f'init was {fun_form}, (m,n)=({kwargs["ms"][0]},{kwargs["ns"][0]})')
                             ax = plt.gca()
                             ax.set_aspect('equal', adjustable='box')
-                            
+
                             plt.subplot(2, 4, 4 + n + 1)
                             if isinstance(domain, domains.HollowTorus):
-                                plt.contourf(x[:, 0, :], y[:, 0, :], fun_vals_xyz[:, 0, :])
+                                plt.contourf(
+                                    x[:, 0, :], y[:, 0, :], fun_vals_xyz[:, 0, :])
                                 plt.xlabel('x')
                                 plt.ylabel('y')
                             else:
-                                plt.contourf(x[:, 0, :], z[:, 0, :], fun_vals_xyz[:, 0, :])
+                                plt.contourf(
+                                    x[:, 0, :], z[:, 0, :], fun_vals_xyz[:, 0, :])
                                 plt.xlabel('x')
                                 plt.ylabel('z')
                             plt.colorbar()
-                            plt.title(f'exact function')  
+                            plt.title(f'exact function')
                             ax = plt.gca()
                             ax.set_aspect('equal', adjustable='box')
-                            
+
                 else:
-                    
+
                     for n, fun_form in enumerate(form_vector):
-                        
-                        params = {'type': key, 
-                                key: {'comps': {name: [fun_form]*3},}}
-                        
+
+                        params = {'type': key,
+                                  key: {'comps': {name: [fun_form]*3}, }}
+
                         if 'Modes' in key:
                             params[key]['ms'] = {name: [kwargs['ms']]*3}
                             params[key]['ns'] = {name: [kwargs['ns']]*3}
                             params[key]['amps'] = {name: [kwargs['amps']]*3}
                         else:
-                            raise ValueError(f'Perturbation {key} not implemented, only "Modes" are testes.')
-                            
+                            raise ValueError(
+                                f'Perturbation {key} not implemented, only "Modes" are testes.')
+
                         if 'Torus' in key:
                             # params[key].pop('ls')
                             if fun_form == 'physical':
                                 continue
-                            params[key]['pfuns'] = {name: [pfuns]*3}      
+                            params[key]['pfuns'] = {name: [pfuns]*3}
                         else:
                             params[key]['ls'] = {name: [ls]*3}
                             if fun_form == 'physical':
                                 params[key]['Lx'] = Lx
                                 params[key]['Ly'] = Ly
                                 params[key]['Lz'] = Lz
                             if isinstance(domain, domains.HollowTorus):
                                 continue
-                         
-                        #print(f'{params = }')  
-                        field.initialize_coeffs(params, domain=domain)  
-                        
-                        f1_xyz, f2_xyz, f3_xyz = domain.push(field, e1, e2, e3, kind=name)
+
+                        field = derham.create_field(name, space, pert_params=params)
+                        field.initialize_coeffs(domain=domain)
+
+                        f1_xyz, f2_xyz, f3_xyz = domain.push(
+                            field, e1, e2, e3, kind=name)
                         f_xyz = [f1_xyz, f2_xyz, f3_xyz]
-                        
+
                         x, y, z = domain(e1, e2, e3)
                         r = np.sqrt(x**2 + y**2)
-                        
+
                         # exact values
                         if fun_form == 'physical':
                             fun1_xyz = fun_xyz(x, y, z)
                             fun2_xyz = fun_xyz(x, y, z)
                             fun3_xyz = fun_xyz(x, y, z)
                         elif fun_form == 'physical_at_eta':
                             fun1_xyz = fun(eee1, eee2, eee3)
                             fun2_xyz = fun(eee1, eee2, eee3)
                             fun3_xyz = fun(eee1, eee2, eee3)
                         elif fun_form == 'norm':
-                            tmp1, tmp2, tmp3 = domain.transform([fun, fun, fun], eee1, eee2, eee3, kind=fun_form + '_to_v')
-                            fun1_xyz, fun2_xyz, fun3_xyz = domain.push([tmp1, tmp2, tmp3], eee1, eee2, eee3, kind='v')
+                            tmp1, tmp2, tmp3 = domain.transform(
+                                [fun, fun, fun], eee1, eee2, eee3, kind=fun_form + '_to_v')
+                            fun1_xyz, fun2_xyz, fun3_xyz = domain.push(
+                                [tmp1, tmp2, tmp3], eee1, eee2, eee3, kind='v')
                         else:
-                            fun1_xyz, fun2_xyz, fun3_xyz = domain.push([fun, fun, fun], eee1, eee2, eee3, kind=fun_form)
-                            
+                            fun1_xyz, fun2_xyz, fun3_xyz = domain.push(
+                                [fun, fun, fun], eee1, eee2, eee3, kind=fun_form)
+
                         fun_xyz_vec = [fun1_xyz, fun2_xyz, fun3_xyz]
-                            
-                        #print(f'{rank=}, {f3_xyz[:, :, 0] = }')
+
                         error = 0.
                         for fi, funi in zip(f_xyz, fun_xyz_vec):
-                            error += np.max(np.abs(fi - funi)) / np.max(np.abs(funi)) 
-                        error /= 3. 
-                        print(f'{rank=}, {key=}, {name=}, {fun_form=}, {error=}')  
+                            error += np.max(np.abs(fi - funi)) / \
+                                np.max(np.abs(funi))
+                        error /= 3.
+                        print(f'{rank=}, {key=}, {name=}, {fun_form=}, {error=}')
                         assert error < 0.02
-                        
+
                         if do_plot:
                             rn = len(form_vector)
                             for c, (fi, f) in enumerate(zip(f_xyz, fun_xyz_vec)):
-                                plt.figure(key + '_' + name + '-form_e1e2 ' + mapping[0])
+                                plt.figure(key + '_' + name +
+                                           '-form_e1e2 ' + mapping[0])
                                 plt.subplot(3, rn, rn*c + n + 1)
                                 if isinstance(domain, domains.HollowTorus):
-                                    plt.contourf(r[:, :, 0], z[:, :, 0], fi[:, :, 0])
+                                    plt.contourf(
+                                        r[:, :, 0], z[:, :, 0], fi[:, :, 0])
                                     plt.xlabel('R')
                                     plt.ylabel('Z')
                                 else:
-                                    plt.contourf(x[:, :, 0], y[:, :, 0], fi[:, :, 0])
+                                    plt.contourf(
+                                        x[:, :, 0], y[:, :, 0], fi[:, :, 0])
                                     plt.xlabel('x')
                                     plt.ylabel('y')
                                 plt.colorbar()
-                                plt.title(f'component {c + 1}, init was {fun_form}, (m,n)=({kwargs["ms"][0]},{kwargs["ns"][0]})')  
+                                plt.title(
+                                    f'component {c + 1}, init was {fun_form}, (m,n)=({kwargs["ms"][0]},{kwargs["ns"][0]})')
                                 ax = plt.gca()
                                 ax.set_aspect('equal', adjustable='box')
-                                
-                                plt.figure(key + '_' + name + '-form_e1e3 ' + mapping[0])
+
+                                plt.figure(key + '_' + name +
+                                           '-form_e1e3 ' + mapping[0])
                                 plt.subplot(3, rn, rn*c + n + 1)
                                 if isinstance(domain, domains.HollowTorus):
-                                    plt.contourf(x[:, 0, :], y[:, 0, :], fi[:, 0, :])
+                                    plt.contourf(
+                                        x[:, 0, :], y[:, 0, :], fi[:, 0, :])
                                     plt.xlabel('x')
                                     plt.ylabel('y')
                                 else:
-                                    plt.contourf(x[:, 0, :], z[:, 0, :], fi[:, 0, :])
+                                    plt.contourf(
+                                        x[:, 0, :], z[:, 0, :], fi[:, 0, :])
                                     plt.xlabel('x')
                                     plt.ylabel('z')
                                 plt.colorbar()
-                                plt.title(f'component {c + 1}, init was {fun_form}, (m,n)=({kwargs["ms"][0]},{kwargs["ns"][0]})')  
+                                plt.title(
+                                    f'component {c + 1}, init was {fun_form}, (m,n)=({kwargs["ms"][0]},{kwargs["ns"][0]})')
                                 ax = plt.gca()
                                 ax.set_aspect('equal', adjustable='box')
-                                
-                        
+
     if do_plot and rank == 0:
-        plt.show() 
-                        
-    
+        plt.show()
+
+
 if __name__ == '__main__':
     # mapping = ['Colella', {'Lx': 4., 'Ly': 5., 'alpha': .07, 'Lz': 6.}]
     # mapping = ['HollowCylinder', {'a1': 0.1}]
     mapping = ['HollowTorus', {'tor_period': 1}]
-    test_init_modes([16, 14, 14], [2, 3, 4], [False, True, True], 
-                    mapping, 
-                    combine_comps=None,     
-                    do_plot=True)
+    test_init_modes([16, 14, 14], [2, 3, 4], [False, True, True],
+                    mapping,
+                    combine_comps=None,
+                    do_plot=True)
```

### Comparing `struphy-2.2.0/src/struphy/initial/utilities.py` & `struphy-2.3.0/src/struphy/initial/utilities.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/batch/batch_cobra.sh` & `struphy-2.3.0/src/struphy/io/batch/batch_cobra.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/batch/p_016.sh` & `struphy-2.3.0/src/struphy/io/batch/p_016.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/batch/p_032.sh` & `struphy-2.3.0/src/struphy/io/batch/p_032.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/batch/p_064.sh` & `struphy-2.3.0/src/struphy/io/batch/p_064.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/batch/p_128.sh` & `struphy-2.3.0/src/struphy/io/batch/p_128.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/batch/p_256.sh` & `struphy-2.3.0/src/struphy/io/batch/p_256.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/batch/p_512.sh` & `struphy-2.3.0/src/struphy/io/batch/p_512.sh`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/inp/longer_examples/params_TAE_tokamak.yml` & `struphy-2.3.0/src/struphy/io/inp/longer_examples/params_TAE_tokamak.yml`

 * *Files 2% similar despite different names*

```diff
@@ -58,15 +58,14 @@
             scaling : 1. # scaling factor to scale the amplitude of the eigenfunction
 
 fluid : 
     mhd :
         phys_params:
             A : 1 # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
-        mhd_u_space : Hdiv # Hdiv | H1vec
         init :
             type : InitialMHDAxisymHdivEigFun # initial conditions (possible types seen below)
             InitialMHDAxisymHdivEigFun :
                 spec : 'sim_example_TAE_tokamak/spec_0.1_0.2_n_-1.npy' # relative path (to <install_path>/io/out/) of the .npy spectrum
                 spec_abs : null # absolute path of .npy spectrum (is used instead of "spec", if "spec_abs" is not null)
                 eig_freq_upper : 0.14855 # upper search limit of squared eigenfrequency to identify eigenfunction
                 eig_freq_lower : 0.14850 # lower search limit of squared eigenfrequency to identify eigenfunction
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/longer_examples/params_hybridmhdvlasovcc.yml` & `struphy-2.3.0/src/struphy/io/inp/longer_examples/params_hybridmhdvlasovcc.yml`

 * *Files 2% similar despite different names*

```diff
@@ -42,15 +42,14 @@
         type : null # type of initialization
 
 fluid :
     mhd :
         phys_params:
             A : 1 # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
-        mhd_u_space : H1vec # Hdiv | H1vec
         init :
             type : null # type of initialization
             ModesCos :
                 coords : 'physical' # in which coordinates (logical or physical)
                 comps :
                     n3 : False                # components to be initialized (for scalar fields: no list)
                     uv : [False, True, False] # components to be initialized (for scalar fields: no list)
@@ -83,16 +82,16 @@
                 type    : [periodic, periodic, periodic] # marker boundary conditions: remove, reflect or periodic
             loading :
                 type    : pseudo_random # particle loading mechanism
                 seed    : 1234 # seed for random number generator
                 moments : [0., 0., 2.5, 1., 1., 1.] # moments of Gaussian s3, see background/moms_spec
                 spatial : uniform # uniform or disc
         init :
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
+            type : Maxwellian6D
+            Maxwellian6D :
                 n  : 0.05
                 u3 : 2.5
         save_data :
             n_markers : 10 # number of markers to be save during simulation
             f :
                 slices : [v3] # in which directions to bin (e.g. [e1_e2, v1_v2_v3])
                 n_bins : [[32]] # number of bins in each direction (e.g. [[16, 20], [16, 18, 22]])
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/longer_examples/params_hybridmhdvlasovpc.yml` & `struphy-2.3.0/src/struphy/io/inp/longer_examples/params_hybridmhdvlasovpc.yml`

 * *Files 2% similar despite different names*

```diff
@@ -42,15 +42,14 @@
         type : null # initial conditions (possible types seen below)
 
 fluid :
     mhd :
         phys_params:
             A : 1 # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
-        mhd_u_space : H1vec # Hdiv | H1vec
         init :
             type : null # type of initialization
             ModesCos :
                 coords : 'physical' # in which coordinates (logical or physical)
                 comps :
                     n3 : False                # components to be initialized (for scalar fields: no list)
                     uv : [False, True, False] # components to be initialized (for scalar fields: no list)
@@ -82,17 +81,17 @@
             bc : 
                 type    : [periodic, periodic, periodic] # marker boundary conditions: remove, reflect or periodic
             loading :
                 type    : pseudo_random # particle loading mechanism
                 seed    : 1234 # seed for random number generator
                 moments : [0., 0., 2.5, 1., 1., 1.] # moments of Gaussian s3, see background/moms_spec
                 spatial : uniform # uniform or disc
-        init :
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
+        background :
+            type : Maxwellian6D
+            Maxwellian6D :
                 n  : 0.05
                 u3 : 2.5
         save_data :
             n_markers : 10 # number of markers to be save during simulation
             f :
                 slices : [v3] # in which directions to bin (e.g. [e1_e2, v1_v2_v3])
                 n_bins : [[32]] # number of bins in each direction (e.g. [[16, 20], [16, 18, 22]])
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/longer_examples/params_linearextendedmhd.yml` & `struphy-2.3.0/src/struphy/io/inp/longer_examples/params_linearextendedmhd.yml`

 * *Files 1% similar despite different names*

```diff
@@ -50,15 +50,15 @@
             type : noise # initialization
             noise :
                 comps :
                     n3 : False              # components to be initialized (for scalar fields: no list)
                     u2 : [True, True, True] # components to be initialized (for scalar fields: no list)
                     pi3 : False              # components to be initialized (for scalar fields: no list)
                     pe3 : False             # components to be initialized (for scalar fields: no list)
-                variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
+                direction : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.1 # noise amplitude
                 seed : 1234    # seed for random number generator
 
 solvers :
     solver_1 :
         type : PConjugateGradient
         pc : MassMatrixPreconditioner # null or name of preconditioner class
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_landau.yml` & `struphy-2.3.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_landau.yml`

 * *Files 9% similar despite different names*

```diff
@@ -44,19 +44,14 @@
     HomogenSlab :
         B0x  : 0. # magnetic field in x
         B0y  : 0. # magnetic field in y
         B0z  : 0. # magnetic field in z
         beta : 0. # plasma beta = 2*p*mu_0/B^2
         n0   : 1. # number density
 
-electric_equilibrium :
-    type : HomogenSlab # (possible choices seen below)
-    HomogenSlab :
-        phi0  : 1. # constant electric potential
-
 em_fields :
     init :
         type : null # initial conditions (possible types seen below)
     options:
         solvers:
             maxwell:
                 type: [PConjugateGradient, MassMatrixPreconditioner]
@@ -84,47 +79,33 @@
                 type    : [periodic, periodic, periodic] # marker boundary conditions: remove, reflect or periodic
             loading :
                 type          : pseudo_random # particle loading mechanism
                 seed          : 1234 # seed for random number generator
                 dir_particles : path_to_particles # directory of particles if loaded externally
                 moments       : [0., 0., 0., 1., 1., 1.] # moments of Gaussian s3, see background/moms_spec
                 spatial       : uniform # uniform or disc
-        init :  # f_1
-            type : Maxwellian6DPerturbed
-            Maxwellian6DPerturbed :
-                n :
-                    n0 : 0.
-                    perturbation :
-                        l : [1]
-                        m : [0]
-                        n : [0]
-                        amps_sin : [0.]
-                        amps_cos : [0.5]
-                u1 :
-                    u01 : 0.
-                u2 :
-                    u02 : 0.
-                u3 :
-                    u03 : 0.
-                vth1 :
-                    vth01 : 1.
-                vth2 :
-                    vth02 : 1.
-                vth3 :
-                    vth03 : 1.
         background :  # f_0
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
+            type : Maxwellian6D
+            Maxwellian6D :
                 n  : 1.
                 u1 : 0.
                 u2 : 0.
                 u3 : 0.
                 vth1 : 1.
                 vth2 : 1.
                 vth3 : 1.
+        perturbation :
+            type: ModesCos
+            ModesCos:
+                comps:
+                    n: '0'
+                ls:
+                    n: [1]
+                amps:
+                    n: [0.5]
         options:
             algos: {push_eta: rk4, push_vxb: analytic}
             solver:
                 type: [PConjugateGradient, MassMatrixPreconditioner]
                 tol: 1.0e-10
                 maxiter: 3000
                 info: false
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_streaming_weibel.yml` & `struphy-2.3.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_streaming_weibel.yml`

 * *Files 6% similar despite different names*

```diff
@@ -47,19 +47,14 @@
     HomogenSlab :
         B0x  : 0. # magnetic field in x
         B0y  : 0. # magnetic field in y
         B0z  : 0. # magnetic field in z
         beta : 0. # plasma beta = 2*p*mu_0/B^2
         n0   : 1. # number density
 
-electric_equilibrium :
-    type : HomogenSlab # (possible choices seen below)
-    HomogenSlab :
-        phi0  : 1. # constant electric potential
-
 em_fields :
     init :
         type : ModesSin # initial conditions (possible types seen below)
         ModesSin :
             coords : 'physical' # in which coordinates (logical or physical)
             comps :
                 e_field : [False, False, False]  # components to be initialized (for scalar fields: no list)
@@ -81,34 +76,17 @@
             eps     : 0.25 # MPI send/receive buffer (0.1 <= eps <= 1.0)
             bc : 
                 type    : [periodic, periodic, periodic] # marker boundary conditions: remove, reflect or periodic
             loading :
                 type    : pseudo_random # particle loading mechanism
                 seed    : 4247 # seed for random number generator
                 moments : [0., 0., 0., 0.1, 0.1, 0.1] # moments of Gaussian s3, see background/moms_spec
-        init :
-            type : Maxwellian6DPerturbed
-            Maxwellian6DPerturbed :
-                n :
-                    n0 : 0 # here 0 because we want to initialize f1
-                u1 :
-                    u01 : 0.
-                u2 :
-                    u02 : 0.
-                u3 :
-                    u03 : 0.
-                vth1 :
-                    vth01 : 0.1
-                vth2 :
-                    vth02 : 0.1
-                vth3 :
-                    vth03 : 0.1
         background :
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
+            type : Maxwellian6D
+            Maxwellian6D :
                 n  : 1.
                 u1 : 0.
                 u2 : 0.
                 u3 : 0.
                 vth1 : 0.1
                 vth2 : 0.1
                 vth3 : 0.1
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_weibel.yml` & `struphy-2.3.0/src/struphy/io/inp/longer_examples/params_linvlasovmaxwell_weibel.yml`

 * *Files 8% similar despite different names*

```diff
@@ -46,19 +46,14 @@
     HomogenSlab :
         B0x  : 0. # magnetic field in x
         B0y  : 0. # magnetic field in y
         B0z  : 0. # magnetic field in z
         beta : 0. # plasma beta = 2*p*mu_0/B^2
         n0   : 1. # number density
 
-electric_equilibrium :
-    type : HomogenSlab # (possible choices seen below)
-    HomogenSlab :
-        phi0  : 1. # constant electric potential
-
 em_fields :
     init :
         type : ModesCos # initial conditions (possible types seen below)
         ModesCos :
             coords : 'physical' # in which coordinates (logical or physical)
             comps :
                 e_field : [False, False, False]  # components to be initialized (for scalar fields: no list)
@@ -81,47 +76,33 @@
             bc : 
                 type    : [periodic, periodic, periodic] # marker boundary conditions: remove, reflect or periodic
             loading :
                 type    : pseudo_random # particle loading mechanism
                 seed    : 1234 # seed for random number generator
                 moments : [0., 0., 0., 0.014, 0.049, 0.014] # sample after f1
                 spatial : uniform # uniform or disc
-        init :
-            type : Maxwellian6DPerturbed
-            Maxwellian6DPerturbed :
-                n :
-                    n0 : 0 # here 0 because we want to initialize f1
-                    perturbation :
-                        l : [1.]
-                        m : [0.]
-                        n : [0.]
-                        amps_sin : [0.]
-                        amps_cos : [-0.0001] # alpha
-                u1 :
-                    u01 : 0.
-                u2 :
-                    u02 : 0.
-                u3 :
-                    u03 : 0.
-                vth1 :
-                    vth01 : 0.014142135623730949
-                vth2 :
-                    vth02 : 0.04898979485566356
-                vth3 :
-                    vth03 : 0.014142135623730949
         background :
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
+            type : Maxwellian6D
+            Maxwellian6D :
                 n  : 1.
                 u1 : 0.
                 u2 : 0.
                 u3 : 0.
                 vth1 : 0.014142135623730949
                 vth2 : 0.04898979485566356
                 vth3 : 0.014142135623730949
+        perturbation :
+            type: ModesCos
+            ModesCos:
+                comps:
+                    n: '0'
+                ls:
+                    n: [1]
+                amps:
+                    n: [-0.0001] # alpha
         save_data :
             n_markers : 1 # number of markers to be saved during simulation
             f :
                 slices : [e1, v1_v2] # in which directions to bin (e.g. [e1_e2, v1_v2_v3])
                 n_bins : [[32], [64, 64]] # number of bins in each direction (e.g. [[16, 20], [16, 18, 22]])
                 ranges : [[[0., 1.]], [[-0.1, 0.1], [-0.1, 0.1]]] # bin range in each direction (e.g. [[[0., 1.], [0., 1.]], [[-3., 3.], [-4., 4.], [-5., 5.]]])
         push_algos :
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/tutorials/params_02.yml` & `struphy-2.3.0/src/struphy/io/inp/tutorials/params_02.yml`

 * *Files 8% similar despite different names*

```diff
@@ -34,33 +34,29 @@
         B0x  : 1. # magnetic field in x
         B0y  : 0. # magnetic field in y
         B0z  : 0. # magnetic field in z
         beta : 0.1 # plasma beta = 2*p*mu_0/B^2
         n0   : 1. # number density
 
 em_fields :
-    init :
+    perturbation :
         type : ModesSin # type of initialization
         ModesSin :
             comps : {b2: [null, null, 'physical']} # components to be initialized (for scalar fields: no list)
             ls : {b2: [null, null, [1]]} # Integer mode numbers in x or eta_1 (depending on coords)
-            ms : {b2: [null, null, [0]]} # Integer mode numbers in y or eta_2 (depending on coords)
-            ns : {b2: [null, null, [0]]} # Integer mode numbers in z or eta_3 (depending on coords)
             amps : {b2: [null, null, [0.001]]} # amplitudes of each mode
             Lx : 7.853981633974483 # 2*pi/0.8
             Ly : 1.
             Lz : 1.
 
 fluid :
     mhd :
         phys_params:
             A : 1  # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
-        init :
-            type : null # type of initialization
         options:
             solvers:
                 shear_alfven:
                     type: [pcg, MassMatrixPreconditioner]
                     tol: 1.0e-08
                     maxiter: 3000
                     info: false
@@ -84,29 +80,19 @@
             bc : 
                 type    : [periodic, periodic, periodic] # marker boundary conditions: remove, reflect or periodic
             loading :
                 type    : pseudo_random # particle loading mechanism
                 seed    : null # seed for random number generator
                 moments : [2.5, 0., 0., 1., 1., 1.] # moments of Gaussian s3, see background/moms_spec
                 spatial : disc # uniform or disc
-        init :
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
+        background :
+            type : Maxwellian6D
+            Maxwellian6D :
                 n : 0.05
                 u1 : 2.5
-        background :
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
-                n  : 1.
-                u1 : 0.
-                u2 : 0.
-                u3 : 0.
-                vth1 : 1.
-                vth2 : 1.
-                vth3 : 1.
         save_data :
             n_markers : 200 # number of markers to be save during simulation
             f :
                 slices : [v1, e1_v1] # in which directions to bin (e.g. [e1_e2, v1_v2_v3])
                 n_bins : [[32], [32, 32]] # number of bins in each direction (e.g. [[16, 20], [16, 18, 22]])
                 ranges : [[[-5.5, 5.5]], [[0., 1.], [-5.5, 5.5]]] # bin range in each direction
         push_algos :
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/tutorials/params_03.yml` & `struphy-2.3.0/src/struphy/io/inp/tutorials/params_03.yml`

 * *Files 1% similar despite different names*

```diff
@@ -50,15 +50,15 @@
         type : null # initialization
 
 fluid :
     mhd :
         phys_params:
             A : 1  # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
-        init :
+        perturbation :
             type : TorusModesSin # initialization
             TorusModesSin :
                 comps :
                     n3 : null              # components to be initialized (for scalar fields: no list)
                     u2 : [null, '2', null] # components to be initialized (for scalar fields: no list)
                     p3 : null              # components to be initialized (for scalar fields: no list)
                 ms : {u2: [null, [3], null]} # poloidal mode numbers
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/tutorials/params_04a.yml` & `struphy-2.3.0/src/struphy/io/inp/tutorials/params_04a.yml`

 * *Files 4% similar despite different names*

```diff
@@ -7,14 +7,15 @@
     nq_el    : [1, 1, 4] # quadrature points per grid cell
     nq_pr    : [1, 1, 4] # quadrature points per histopolation cell (for commuting projectors)
     polar_ck : -1 # C^k smoothness at polar singularity at eta_1=0 (default: -1 --> standard tensor product, 1 : polar splines)
 
 units : # units not stated here can be viewed via "struphy units -h"
     x : 1. # length scale unit in m
     B : 1. # magnetic field unit in T
+    n : 1.
 
 time :
     dt         : 0.05 # time step
     Tend       : 100 # simulation time interval is [0, Tend]
     split_algo : LieTrotter # LieTrotter | Strang
 
 geometry :
@@ -24,21 +25,21 @@
         r1 : 1. # end of interval in eta1, r1>l1
         l2 : 0. # start of interval in eta2
         r2 : 1. # end of interval in eta2, r2>l2
         l3 : 0. # start of interval in eta3
         r3 : 20. # end of interval in eta3, r3>l3
 
 em_fields :
-    init :
+    perturbation :
         type : noise
         noise :
             comps :
                 e1 : [True, True, False]   # components to be initialized (for scalar fields: no list)
                 b2: [False, False, False] # components to be initialized (for scalar fields: no list)
-            variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
+            direction : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
             amp : 0.1 # noise amplitude
             seed : 1234    # seed for random number generator
     options:
         solver:
             type: [pcg, MassMatrixPreconditioner]
             tol: 1.0e-08
             maxiter: 3000
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/tutorials/params_04b.yml` & `struphy-2.3.0/src/struphy/io/inp/tutorials/params_04b.yml`

 * *Files 13% similar despite different names*

```diff
@@ -33,31 +33,29 @@
     HomogenSlab :
         B0x  : 0. # magnetic field in x
         B0y  : 1. # magnetic field in y
         B0z  : 1. # magnetic field in z
         beta : 1. # plasma beta = 2*p*mu_0/B^2
         n0   : 1. # number density
 
-em_fields :
-    init :
-        type : null # initialization
+em_fields : {}
 
 fluid :
     mhd :
         phys_params:
             A : 1  # mass number in units of proton mass
             Z : 1 # signed charge number in units of elementary charge
-        init :
+        perturbation :
             type : noise # initialization
             noise :
                 comps :
                     n3 : False              # components to be initialized (for scalar fields: no list)
                     u2 : [True, True, True] # components to be initialized (for scalar fields: no list)
                     p3 : False              # components to be initialized (for scalar fields: no list)
-                variation_in : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
+                direction : e3 # noise variation (logical space): e1, e2, e3 (1d), e1e2, e1e3, e2e3 (2d), e1e2e3 (3d)
                 amp : 0.1 # noise amplitude
                 seed : 1234    # seed for random number generator
         options:
             solvers:
                 shear_alfven:
                     type: [pcg, MassMatrixPreconditioner]
                     tol: 1.0e-08
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/tutorials/params_05a.yml` & `struphy-2.3.0/src/struphy/io/inp/tutorials/params_05a.yml`

 * *Files 8% similar despite different names*

```diff
@@ -62,24 +62,14 @@
                 seed    : 1608 # seed for random number generator
                 moments : [0., 0., 0., 1., 1., 1.] # moments of Gaussian s3, see background/moms_spec
                 spatial : uniform # uniform or disc
                 initial : [[.501, 0.001, 0.001, 0.,  0.0450, -0.04], # co-passing particle
                            [.501, 0.001, 0.001, 0., -0.0450, -0.04], # counter passing particle
                            [.501, 0.001, 0.001, 0.,  0.0105, -0.04], # co-trapped particle
                            [.501, 0.001, 0.001, 0., -0.0155, -0.04]] # counter-trapped particle
-        init : 
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform:
-                n : 0.05
         background :
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
-                n  : 1.
-                u1 : 0.
-                u2 : 0.
-                u3 : 0.
-                vth1 : 1.
-                vth2 : 1.
-                vth3 : 1.
+            type : Maxwellian6D
+            Maxwellian6D :
+                n : 0.05
         save_data :
             n_markers : 4 # number of markers to be save during simulation
         options: {push_eta: rk4, push_vxb: analytic}
```

### Comparing `struphy-2.2.0/src/struphy/io/inp/tutorials/params_05b.yml` & `struphy-2.3.0/src/struphy/io/inp/tutorials/params_05b.yml`

 * *Files 10% similar despite different names*

```diff
@@ -65,28 +65,16 @@
                 seed    : 1608 # seed for random number generator
                 moments : [0., 0., 1., 1.] # moments of Gaussian s3, see background/moms_spec
                 spatial : uniform # uniform or disc
                 initial : [[.501, 0.001, 0.001, -1.935 , -1.72], # co-passing particle
                            [.501, 0.001, 0.001,  1.935 , -1.72], # couner-passing particle
                            [.501, 0.001, 0.001, -0.6665, -1.72], # co-trapped particle
                            [.501, 0.001, 0.001,  0.4515, -1.72]] # counter-trapped particle
-                           
-
-        init :
-            type : Maxwellian5DUniform
-            Maxwellian5DUniform:
-                n : 0.05
         background :
-            type : Maxwellian6DUniform
-            Maxwellian6DUniform :
-                n  : 1.
-                u1 : 0.
-                u2 : 0.
-                u3 : 0.
-                vth1 : 1.
-                vth2 : 1.
-                vth3 : 1.
+            type : Maxwellian5D
+            Maxwellian5D:
+                n : 0.05
         save_data :
             n_markers : 4 # number of markers to be save during simulation
         options:
             push_bxEstar: {method: discrete_gradient, maxiter: 20, tol: 1.0e-05}
             push_Bstar: {method: discrete_gradient, maxiter: 20, tol: 1.0e-05}
```

### Comparing `struphy-2.2.0/src/struphy/io/output_handling.py` & `struphy-2.3.0/src/struphy/io/output_handling.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/io/setup.py` & `struphy-2.3.0/src/struphy/io/setup.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 import numpy as np
 
 
-def derive_units(Z_bulk=1, A_bulk=1., x=1., B=1., n=1., velocity_scale='alfvén'):
-    """ Computes Struphy units used in Struphy model implementations.
+def derive_units(Z_bulk=None, A_bulk=None, x=1., B=1., n=1., velocity_scale='alfvén'):
+    """ Computes units used in Struphy model :ref:`normalization`.
 
     Input units from parameter file:
 
-        * Length (m)
-        * Magnetic field (T)
-        * number density (10^20 1/m^3)
+    * Length (m)
+    * Magnetic field (T)
+    * number density (10^20 1/m^3)
 
-    Velocity unit must be defined in each model as one of "light", "alfvén" or "cyclotron":
+    Velocity unit is defined here:
 
-        * Velocity (m/s)
+    * Velocity (m/s)
 
     Derived units using mass and charge number of bulk species:
 
-        * Time (s)
-        * Mass density (kg/m^3)
-        * Pressure (Pa)
+    * Time (s)
+    * Mass density (kg/m^3)
+    * Pressure (Pa)
 
     Parameters
     ---------
     Z_bulk : int
-        Charge number of bulkd species.
+        Charge number of bulk species.
 
     A_bulk : int
         Mass number of bulk species.
 
     x : float
         Unit of length (in meters).
 
@@ -61,24 +61,36 @@
 
     # length (m)
     units['x'] = x
     # magnetic field (T)
     units['B'] = B
     # number density (1/m^3)
     units['n'] = n * 1e20
+    
     # velocity (m/s)
-    if velocity_scale == 'light':
-        units['v'] = 1*c
+    if velocity_scale is None:
+        units['v'] = 1.
+        
+    elif velocity_scale == 'light':
+        units['v'] = 1.*c
+        
     elif velocity_scale == 'alfvén':
+        assert A_bulk is not None, 'Need bulk species to choose velocity scale "alfvén".'
         units['v'] = units['B'] / np.sqrt(units['n'] * A_bulk * mH * mu0)
+        
     elif velocity_scale == 'cyclotron':
+        assert A_bulk is not None, 'Need bulk species to choose velocity scale "cyclotron".'
         units['v'] = Z_bulk * e * units['B'] / \
             (A_bulk * mH) / (2*np.pi) * units['x']
+            
     # time (s)
     units['t'] = units['x'] / units['v']
+    if A_bulk is None:
+        return units
+    
     # pressure (Pa)
     units['p'] = A_bulk * mH * units['n'] * units['x']**3 / \
         (units['x'] * units['t']**2)  # this is equal to B^2/(mu0*n) if velocity_scale='alfvén'
     # mass density (kg/m^3)
     units['rho'] = A_bulk * mH * units['n']
 
     return units
@@ -145,47 +157,14 @@
         domain = dom_class(**params['geometry'][dom_type])
 
         mhd = None
 
     return domain, mhd
 
 
-def setup_electric_background(params, domain):
-    """
-    Creates an electric background field for a given parameter file.
-
-    Parameters
-    ----------
-    params : dict
-        The full simulation parameter dictionary.
-
-    domain : struphy.geometry.base.Domain
-        The Struphy domain object for evaluating the mapping F : [0, 1]^3 --> R^3 and the corresponding metric coefficients.
-
-    Returns
-    -------
-    electric_background : struphy.fields_background.electric_equil.base.EquilibriumElectric
-        The electric background object.
-    """
-
-    from struphy.fields_background.electric_equil import analytical
-
-    if 'electric_equilibrium' in params:
-
-        electric_type = params['electric_equilibrium']['type']
-        electric_class = getattr(analytical, electric_type)
-        electric_background = electric_class(
-            params['electric_equilibrium'][electric_type], domain)
-
-    else:
-        electric_background = None
-
-    return electric_background
-
-
 def setup_derham(params_grid, comm, domain=None, mpi_dims_mask=None):
     """
     Creates the 3d derham sequence for given grid parameters.
 
     Parameters
     ----------
     params_grid : dict
```

### Comparing `struphy-2.2.0/src/struphy/linear_algebra/linalg_kernels.py` & `struphy-2.3.0/src/struphy/linear_algebra/linalg_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/linear_algebra/linalg_kron.py` & `struphy-2.3.0/src/struphy/linear_algebra/linalg_kron.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/linear_algebra/schur_solver.py` & `struphy-2.3.0/src/struphy/linear_algebra/schur_solver.py`

 * *Files 2% similar despite different names*

```diff
@@ -55,14 +55,18 @@
 
         # linear operators
         self._A = A
         self._BC = BC
 
         # initialize solver with dummy matrix A
         self._solver_name = solver_name
+
+        if solver_params['pc'] is None:
+            solver_params.pop('pc')
+
         self._solver = inverse(A, solver_name, **solver_params)
 
         # right-hand side vector (avoids temporary memory allocation!)
         self._rhs = A.codomain.zeros()
 
     @property
     def A(self):
```

### Comparing `struphy-2.2.0/src/struphy/linear_algebra/stencil_dot_kernels.py` & `struphy-2.3.0/src/struphy/linear_algebra/stencil_dot_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/linear_algebra/stencil_transpose_kernels.py` & `struphy-2.3.0/src/struphy/linear_algebra/stencil_transpose_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/linear_algebra/tests/test_stencil_dot_kernels.py` & `struphy-2.3.0/src/struphy/linear_algebra/tests/test_stencil_dot_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/linear_algebra/tests/test_stencil_transpose_kernels.py` & `struphy-2.3.0/src/struphy/linear_algebra/tests/test_stencil_transpose_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/main.py` & `struphy-2.3.0/src/struphy/main.py`

 * *Files 2% similar despite different names*

```diff
@@ -88,18 +88,19 @@
 
         time_state['value'][0] = data.file['restart/time/value'][-1]
         time_state['index'][0] = data.file['restart/time/index'][-1]
 
         total_steps = str(
             int(round((time_params['Tend'] - time_state['value'][0])/time_params['dt'])))
 
-    # compute initial scalars and kinetic data
+    # compute initial scalars and kinetic data, pass time state to all propagators
     model.update_scalar_quantities()
     model.update_markers_to_be_saved()
     model.update_distr_function()
+    model.add_time_state(time_state['value'])
 
     # add all variables to be saved to data object
     save_keys_all, save_keys_end = model.initialize_data_output(data, size)
 
     # ======================== main time loop ======================
     if rank == 0:
         print('\nINITIAL SCALAR QUANTITIES:')
```

### Comparing `struphy-2.2.0/src/struphy/models/base.py` & `struphy-2.3.0/src/struphy/models/base.py`

 * *Files 6% similar despite different names*

```diff
@@ -19,17 +19,19 @@
 
     Note
     ----
     All Struphy models are subclasses of ``StruphyModel`` and should be added to ``struphy/models/``
     in one of the modules ``fluid.py``, ``kinetic.py``, ``hybrid.py`` or ``toy.py``.  
     """
 
-    def __init__(self, params, comm):
+    def __init__(self, params, comm=None):
 
-        from struphy.io.setup import setup_domain_mhd, setup_electric_background, setup_derham
+        # TODO: comm=None does not work yet.
+
+        from struphy.io.setup import setup_domain_mhd, setup_derham
 
         from struphy.propagators.base import Propagator
         from struphy.propagators import propagators_fields, propagators_coupling, propagators_markers
         from struphy.feec.basis_projection_ops import BasisProjectionOperators
         from struphy.feec.mass import WeightedMassOperators
 
         assert 'em_fields' in self.species()
@@ -49,33 +51,27 @@
         # compute model units
         self._units, self._equation_params = self.model_units(
             self.params, verbose=True, comm=self._comm)
 
         # create domain, MHD equilibrium, background electric field
         self._domain, self._mhd_equil = setup_domain_mhd(
             params, units=self.units)
-        self._electric_equil = setup_electric_background(params, self.domain)
 
         if comm.Get_rank() == 0:
             print('\nDOMAIN:')
             print(f'type:'.ljust(25), self.domain.__class__.__name__)
             for key, val in self.domain.params_map.items():
                 if key not in {'cx', 'cy', 'cz'}:
                     print((key + ':').ljust(25), val)
 
             if 'mhd_equilibrium' in params:
                 print('\nMHD EQUILIBRIUM:')
                 print('type:'.ljust(25), self.mhd_equil.__class__.__name__)
                 for key, val in self.mhd_equil.params.items():
                     print((key + ':').ljust(25), val)
-            if 'electric_equilibrium' in params:
-                print('\nELECTRIC EQUILIBRIUM:')
-                print('type:', self.electric_equil.__class__.__name__)
-                for key, val in self.electric_equil.params.items():
-                    print((key + ':').ljust(25), val)
 
         # create discrete derham sequence
         dims_mask = params['grid']['dims_mask']
         if dims_mask is None:
             dims_mask = [True]*3
 
         self._derham = setup_derham(
@@ -95,17 +91,14 @@
         else:
             self._pparams = self._print_plasma_params(verbose=False)
 
         # options of current run
         if comm.Get_rank() == 0:
             self._show_chosen_options()
 
-        if comm.Get_rank() == 0:
-            print('\nOPERATOR ASSEMBLY:')
-
         # expose propagator modules
         self._prop = Propagator
         self._prop_fields = propagators_fields
         self._prop_coupling = propagators_coupling
         self._prop_markers = propagators_markers
 
         # set propagators base class attributes (available to all propagators)
@@ -258,19 +251,14 @@
 
     @property
     def mhd_equil(self):
         '''MHD equilibrium object, see :ref:`mhd_equil`.'''
         return self._mhd_equil
 
     @property
-    def electric_equil(self):
-        '''Eelctric equilibrium object, see :ref:`electric_equil`.'''
-        return self._electric_equil
-
-    @property
     def derham(self):
         '''3d Derham sequence, see :ref:`derham`.'''
         return self._derham
 
     @property
     def units(self):
         '''All Struphy units.
@@ -308,14 +296,33 @@
         return self._propagators
 
     @property
     def scalar_quantities(self):
         '''A dictionary of scalar quantities to be saved during the simulation.'''
         return self._scalar_quantities
 
+    @property
+    def time_state(self):
+        '''A pointer to the time variable of the dynamics ('t').'''
+        return self._time_state
+
+    def add_time_state(self, time_state):
+        '''Add a pointer to the time variable of the dynamics ('t')
+        to the model and to all propagators of the model.
+
+        Parameters
+        ----------
+        time_state : ndarray
+            Of size 1, holds the current physical time 't'.
+        '''
+        assert time_state.size == 1
+        self._time_state = time_state
+        for prop in self.propagators:
+            prop.add_time_state(time_state)
+
     def add_propagator(self, prop_instance):
         '''Add a propagator to a Struphy model.
 
         Parameters
         ----------
             prop_instance : obj
                 An instance of :class:`struphy.propagator.base.Propagator`.
@@ -408,16 +415,16 @@
         for val in self.kinetic.values():
 
             if 'f' in val['params']['save_data']:
 
                 # if diffential forms is not specified, bin the initialized forms
                 if 'pforms' not in val['params']['save_data']['f']:
 
-                    if 'pforms' in val['params']['init']:
-                        pforms = val['params']['init']['pforms']
+                    if 'pforms' in val['params']['background']:
+                        pforms = val['params']['background']['pforms']
 
                     else:
                         pforms = ['0', '0']
 
                 else:
                     pforms = val['params']['save_data']['f']['pforms']
 
@@ -441,111 +448,156 @@
         for key, val in self._scalar_quantities.items():
             assert not np.isnan(val[0]), f'Scalar {key} is {val[0]}.'
             sq_str += key + ': {:14.11f}'.format(val[0]) + '   '
         print(sq_str)
 
     def initialize_from_params(self):
         """
-        Set initial conditions for FE coefficients (electromagnetic and fluid) and markers according to parameter file.
+        Set initial conditions for FE coefficients (electromagnetic and fluid) 
+        and markers according to parameter file.
         """
 
         if self.comm.Get_rank() == 0:
             print('\nINITIAL CONDITIONS:')
 
         # initialize em fields
         if len(self.em_fields) > 0:
 
             for key, val in self.em_fields.items():
                 if 'params' not in key:
                     val['obj'].initialize_coeffs(
-                        self.em_fields['params']['init'], domain=self.domain)
+                        domain=self.domain, mhd_equil=self.mhd_equil)
 
                     if self.comm.Get_rank() == 0:
-                        init_type = self.em_fields['params']['init']['type']
                         print(f'EM field "{key}" was initialized with:')
-                        print('type:'.ljust(25), init_type)
-
-                        if init_type is None:
-                            pass
-
-                        elif type(init_type) == str:
-                            init_types = [init_type]
-
-                        elif type(init_type) == list:
-                            init_types = init_type
 
+                        if 'background' in self.em_fields['params']:
+                            bckgr_type = self.em_fields['params']['background']['type']
+                            print('background:'.ljust(25), bckgr_type)
+
+                            if bckgr_type is None:
+                                pass
+                            elif type(bckgr_type) == str:
+                                bckgr_types = [bckgr_type]
+                            elif type(bckgr_type) == list:
+                                bckgr_types = bckgr_type
+                            else:
+                                raise NotImplemented(
+                                    f'The type of initial background must be null or str or list.')
+
+                            if bckgr_type is not None:
+                                for _type in bckgr_types:
+                                    print(_type, ':')
+                                    for key, val2 in self.em_fields['params']['background'][_type].items():
+                                        print((key + ':').ljust(25), val2)
                         else:
-                            raise NotImplemented(
-                                f'The type of initial condition must be null or str or list.')
-
-                        if init_type is not None:
+                            print('No background.')
 
-                            for _type in init_types:
-                                print(_type, ':')
-                                for key, val2 in self.em_fields['params']['init'][_type].items():
-                                    print((key + ':').ljust(25), val2)
+                        if 'perturbation' in self.em_fields['params']:
+                            pert_type = self.em_fields['params']['perturbation']['type']
+                            print('perturbation:'.ljust(25), pert_type)
+
+                            if pert_type is None:
+                                pass
+                            elif type(pert_type) == str:
+                                pert_types = [pert_type]
+                            elif type(pert_type) == list:
+                                pert_types = pert_type
+                            else:
+                                raise NotImplemented(
+                                    f'The type of initial perturbation must be null or str or list.')
+
+                            if pert_type is not None:
+                                for _type in pert_types:
+                                    print(_type, ':')
+                                    for key, val2 in self.em_fields['params']['perturbation'][_type].items():
+                                        print((key + ':').ljust(25), val2)
+                        else:
+                            print('No perturbation.')
 
         # initialize fields
         if len(self.fluid) > 0:
 
             for species, val in self.fluid.items():
 
                 for variable, subval in val.items():
                     if 'params' not in variable:
                         subval['obj'].initialize_coeffs(
-                            val['params']['init'], domain=self.domain, species=species)
+                            domain=self.domain, mhd_equil=self.mhd_equil, species=species)
 
                 if self.comm.Get_rank() == 0:
-                    init_type = val['params']['init']['type']
                     print(f'Fluid species "{species}" was initialized with:')
-                    print('type:'.ljust(25), init_type)
 
-                    if init_type is None:
-                        pass
+                    if 'background' in val['params']:
+                        bckgr_type = val['params']['background']['type']
+                        print('type:'.ljust(25), bckgr_type)
 
-                    elif type(init_type) == str:
-                        init_types = [init_type]
-
-                    elif type(init_type) == list:
-                        init_types = init_type
+                        if bckgr_type is None:
+                            pass
+                        elif type(bckgr_type) == str:
+                            bckgr_types = [bckgr_type]
+                        elif type(bckgr_type) == list:
+                            bckgr_types = bckgr_type
+                        else:
+                            raise NotImplemented(
+                                f'The type of initial perturbation must be null or str or list.')
 
+                        if bckgr_type is not None:
+                            for _type in bckgr_types:
+                                print(_type, ':')
+                                for key, val2 in val['params']['background'][_type].items():
+                                    print((key + ':').ljust(25), val2)
                     else:
-                        raise NotImplemented(
-                            f'The type of initial condition must be null or str or list.')
+                        print('No background.')
 
-                    if init_type is not None:
+                    if 'perturbation' in val['params']:
+                        pert_type = val['params']['perturbation']['type']
+                        print('type:'.ljust(25), pert_type)
 
-                        for _type in init_types:
-                            print(_type, ':')
-                            for key, val2 in val['params']['init'][_type].items():
-                                print((key + ':').ljust(25), val2)
+                        if pert_type is None:
+                            pass
+                        elif type(pert_type) == str:
+                            pert_types = [pert_type]
+                        elif type(pert_type) == list:
+                            pert_types = pert_type
+                        else:
+                            raise NotImplemented(
+                                f'The type of initial perturbation must be null or str or list.')
+
+                        if pert_type is not None:
+                            for _type in pert_types:
+                                print(_type, ':')
+                                for key, val2 in val['params']['perturbation'][_type].items():
+                                    print((key + ':').ljust(25), val2)
+                    else:
+                        print('No perturbation.')
 
         # initialize particles
         if len(self.kinetic) > 0:
 
             for species, val in self.kinetic.items():
 
                 if self.comm.Get_rank() == 0:
-                    _type = val['params']['init']['type']
+                    _type = val['params']['background']['type']
                     print(f'Kinetic species "{species}" was initialized with:')
                     print('type:'.ljust(25), _type)
                     if _type is not None:
-                        for key, par in val['params']['init'][_type].items():
+                        for key, par in val['params']['background'][_type].items():
                             print((key + ':').ljust(25), par)
 
                 val['obj'].draw_markers()
                 val['obj'].mpi_sort_markers(do_test=True)
 
                 if not val['params']['markers']['loading']['type'] == 'restart':
 
                     typ = val['params']['markers']['type']
                     assert typ in ['full_f', 'delta_f', 'control_variate'], \
                         f'Type {typ} for distribution function is not known!'
 
-                    val['obj'].initialize_weights(val['params']['init'])
+                    val['obj'].initialize_weights()
 
                     if val['space'] == 'Particles5D':
                         val['obj'].save_magnetic_moment()
 
     def initialize_from_restart(self, data):
         """
         Set initial conditions for FE coefficients (electromagnetic and fluid) and markers from restart group in hdf5 files.
@@ -608,18 +660,21 @@
 
         # save scalar quantities in group 'scalar/'
         for key, val in self.scalar_quantities.items():
             key_scalar = 'scalar/' + key
             data.add_data({key_scalar: val})
 
         # store grid_info only for runs with 512 ranks or smaller
-        if size <= 512:
-            data.file['scalar'].attrs['grid_info'] = self.derham.domain_array
+        if self._scalar_quantities:
+            if size <= 512:
+                data.file['scalar'].attrs['grid_info'] = self.derham.domain_array
+            else:
+                data.file['scalar'].attrs['grid_info'] = self.derham.domain_array[0]
         else:
-            data.file['scalar'].attrs['grid_info'] = self.derham.domain_array[0]
+            pass
 
         # save electromagentic fields/potentials data in group 'feec/'
         for key, val in self.em_fields.items():
             if 'params' not in key:
 
                 # in-place extraction of FEM coefficients from field.vector --> field.vector_stencil!
                 val['obj'].extract_coeffs(update_ghost_regions=False)
@@ -766,126 +821,108 @@
 
         units_der : dict
             Derived units for velocity, pressure, mass density and particle density.
         """
 
         from struphy.io.setup import derive_units
 
-        # physics constants
-        e = 1.602176634e-19  # elementary charge (C)
-        mH = 1.67262192369e-27  # proton mass (kg)
-        eps0 = 8.8541878128e-12  # vacuum permittivity (F/m)
-
-        x_unit = params['units']['x']
-        B_unit = params['units']['B']
-
         if comm is None:
             rank = 0
         else:
             rank = comm.Get_rank()
 
+        # look for bulk species in fluid OR kinetic parameter dictionaries
+        Z_bulk = None
+        A_bulk = None
+        if 'fluid' in params:
+            if cls.bulk_species() in params['fluid']:
+                Z_bulk = params['fluid'][cls.bulk_species()
+                                         ]['phys_params']['Z']
+                A_bulk = params['fluid'][cls.bulk_species()
+                                         ]['phys_params']['A']
+        if 'kinetic' in params:
+            if cls.bulk_species() in params['kinetic']:
+                Z_bulk = params['kinetic'][cls.bulk_species()
+                                           ]['phys_params']['Z']
+                A_bulk = params['kinetic'][cls.bulk_species()
+                                           ]['phys_params']['A']
+
+        # compute model units
+        units = derive_units(
+            Z_bulk, A_bulk, params['units']['x'], params['units']['B'], params['units']['n'], cls.velocity_scale())
+
+        # print to screen
         if verbose and rank == 0:
+
             print('\nUNITS:')
             print(f'Unit of length:'.ljust(25),
-                  '{:4.3e}'.format(x_unit) + ' m')
+                  '{:4.3e}'.format(units['x']) + ' m')
+            print(f'Unit of time:'.ljust(25),
+                  '{:4.3e}'.format(units['t']) + ' s')
+            print(f'Unit of velocity:'.ljust(25),
+                  '{:4.3e}'.format(units['v']) + ' m/s')
+            print(f'Unit of magnetic field:'.ljust(25),
+                  '{:4.3e}'.format(units['B']) + ' T')
 
-        # special case for model Maxwell (no plasma species)
-        if cls.bulk_species() is None:
-            if verbose and rank == 0:
-                print(f'Unit of time:'.ljust(25),
-                      '{:4.3e}'.format(x_unit / 299792458) + ' s')
-                print(f'Unit of velocity:'.ljust(25),
-                      '{:4.3e}'.format(299792458) + ' m/s')
-                print(f'Unit of magnetic field:'.ljust(
-                    25), '{:4.3e}'.format(B_unit) + ' T')
-                print(f'Unit of electric field:'.ljust(25),
-                      '{:4.3e}'.format(299792458*B_unit) + ' V/m')
-
-            units = {}
-            units['t'] = x_unit / 299792458
-            units['x'] = x_unit
-            units['B'] = B_unit
-
-            equation_params = {}
-        else:
-
-            # look for bulk species in fluid OR kinetic parameter dictionaries
-            if 'fluid' in params:
-                if cls.bulk_species() in params['fluid']:
-                    Z_bulk = params['fluid'][cls.bulk_species()
-                                             ]['phys_params']['Z']
-                    A_bulk = params['fluid'][cls.bulk_species()
-                                             ]['phys_params']['A']
-            if 'kinetic' in params:
-                if cls.bulk_species() in params['kinetic']:
-                    Z_bulk = params['kinetic'][cls.bulk_species()
-                                               ]['phys_params']['Z']
-                    A_bulk = params['kinetic'][cls.bulk_species()
-                                               ]['phys_params']['A']
-
-            # compute units
-            units = derive_units(
-                Z_bulk, A_bulk, params['units']['x'], params['units']['B'], params['units']['n'], cls.velocity_scale())
-
-            if verbose and rank == 0:
-                print(f'Unit of time:'.ljust(25),
-                      '{:4.3e}'.format(units['t']) + ' s')
-                print(f'Unit of velocity:'.ljust(25),
-                      '{:4.3e}'.format(units['v']) + ' m/s')
-                print(f'Unit of magnetic field:'.ljust(25),
-                      '{:4.3e}'.format(units['B']) + ' T')
+            if A_bulk is not None:
                 print(f'Unit of particle density:'.ljust(25),
                       '{:4.3e}'.format(units['n']) + ' m⁻³')
                 print(f'Unit of mass density:'.ljust(25),
                       '{:4.3e}'.format(units['rho']) + ' kg/m³')
                 print(f'Unit of pressure:'.ljust(25),
                       '{:4.3e}'.format(units['p'] * 1e-5) + ' bar')
 
-            # compute equation parameters arising from Struphy normalization
-            equation_params = {}
-            if 'fluid' in params:
-                for species in params['fluid']:
-
-                    Z = params['fluid'][species]['phys_params']['Z']
-                    A = params['fluid'][species]['phys_params']['A']
-
-                    # compute equation parameters
-                    om_p = np.sqrt(units['n'] * (Z*e)**2 / (eps0 * A*mH))
-                    om_c = Z*e * units['B'] / (A*mH)
-                    equation_params[species] = {}
-                    equation_params[species]['alpha_unit'] = om_p / om_c
-                    equation_params[species]['epsilon_unit'] = 1. / \
-                        (om_c * units['t'])
-
-                    if verbose and rank == 0:
-                        print('\nEQUATION PARAMETERS:')
-                        print('- ' + species + ':')
-                        for key, val in equation_params[species].items():
-                            print((key + ':').ljust(25), '{:4.3e}'.format(val))
-
-            if 'kinetic' in params:
-                for species in params['kinetic']:
-
-                    Z = params['kinetic'][species]['phys_params']['Z']
-                    A = params['kinetic'][species]['phys_params']['A']
-
-                    # compute equation parameters
-                    om_p = np.sqrt(units['n'] * (Z*e)**2 / (eps0 * A*mH))
-                    om_c = Z*e * units['B'] / (A*mH)
-                    equation_params[species] = {}
-                    equation_params[species]['alpha_unit'] = om_p / om_c
-                    equation_params[species]['epsilon_unit'] = 1. / \
-                        (om_c * units['t'])
-
-                    if verbose and rank == 0:
-                        if 'fluid' not in params:
-                            print('\nEQUATION PARAMETERS:')
-                        print('- ' + species + ':')
-                        for key, val in equation_params[species].items():
-                            print((key + ':').ljust(25), '{:4.3e}'.format(val))
+        # compute equation parameters for each species
+        e = 1.602176634e-19  # elementary charge (C)
+        mH = 1.67262192369e-27  # proton mass (kg)
+        eps0 = 8.8541878128e-12  # vacuum permittivity (F/m)
+
+        equation_params = {}
+        if 'fluid' in params:
+            for species in params['fluid']:
+
+                Z = params['fluid'][species]['phys_params']['Z']
+                A = params['fluid'][species]['phys_params']['A']
+
+                # compute equation parameters
+                om_p = np.sqrt(units['n'] * (Z*e)**2 / (eps0 * A*mH))
+                om_c = Z*e * units['B'] / (A*mH)
+                equation_params[species] = {}
+                equation_params[species]['alpha'] = om_p / om_c
+                equation_params[species]['epsilon'] = 1. / \
+                    (om_c * units['t'])
+                equation_params[species]['kappa'] = (om_p * units['t'])
+
+                if verbose and rank == 0:
+                    print('\nNORMALIZATION PARAMETERS:')
+                    print('- ' + species + ':')
+                    for key, val in equation_params[species].items():
+                        print((key + ':').ljust(25), '{:4.3e}'.format(val))
+
+        if 'kinetic' in params:
+            for species in params['kinetic']:
+
+                Z = params['kinetic'][species]['phys_params']['Z']
+                A = params['kinetic'][species]['phys_params']['A']
+
+                # compute equation parameters
+                om_p = np.sqrt(units['n'] * (Z*e)**2 / (eps0 * A*mH))
+                om_c = Z*e * units['B'] / (A*mH)
+                equation_params[species] = {}
+                equation_params[species]['alpha'] = om_p / om_c
+                equation_params[species]['epsilon'] = 1. / \
+                    (om_c * units['t'])
+                equation_params[species]['kappa'] = (om_p * units['t'])
+
+                if verbose and rank == 0:
+                    if 'fluid' not in params:
+                        print('\nNORMALIZATION PARAMETERS:')
+                    print('- ' + species + ':')
+                    for key, val in equation_params[species].items():
+                        print((key + ':').ljust(25), '{:4.3e}'.format(val))
 
         return units, equation_params
 
     @classmethod
     def show_options(cls):
         '''Print available model options to screen.'''
 
@@ -975,25 +1012,23 @@
                     yaml.dump(parameters, outfile, Dumper=MyDumper,
                               default_flow_style=None, sort_keys=False, indent=4, line_break='\n')
                 print(
                     f'Default parameter file for {cls.__name__} has been created; you can now launch with "struphy run {cls.__name__}".')
             else:
                 pass
 
-        
-    
     @classmethod
     def generate_default_parameter_file(cls, file=None, save=True, prompt=True):
         '''Generate a parameter file with default options for each species,
         and save it to the current input path.
 
         The default name is params_<model_name>.yml.
 
         Parameters
-        -------
+        ----------
         file : str
             Alternative filename to params_<model_name>.yml.
 
         save : bool
             Whether to save the parameter file in the current input path.
 
         prompt : bool
@@ -1010,70 +1045,94 @@
 
         libpath = struphy.__path__[0]
 
         # load a standard parameter file
         with open(os.path.join(libpath, 'io/inp/parameters.yml')) as tmp:
             parameters = yaml.load(tmp, Loader=yaml.FullLoader)
 
-        # extract default init params
-        init_kind = list(parameters['fluid']['mhd']['init'])[-1]
+        # extract default fields background params
+        bckgr_type = parameters['em_fields']['background']['type']
 
-        init_params = {}
-        init_params_scalar = {}
+        bckgr_params = {}
+        bckgr_params_scalar = {}
 
-        for keys, vals in parameters['fluid']['mhd']['init'][init_kind].items():
-            init_params[keys] = vals['u2']
-            init_params_scalar[keys] = vals['p3']
+        for keys, vals in parameters['em_fields']['background'][bckgr_type].items():
+            bckgr_params_scalar[keys] = vals['potential_name']
+            bckgr_params[keys] = vals['field_name']
+
+        # extract default fields perturbation params
+        pert_type = parameters['em_fields']['perturbation']['type']
+
+        pert_params = {}
+        pert_params_scalar = {}
+
+        for keys, vals in parameters['em_fields']['perturbation'][pert_type].items():
+            pert_params_scalar[keys] = vals['potential_name']
+            pert_params[keys] = vals['field_name']
 
         # get rid of species names in initial conditions (add back later)
-        parameters['kinetic']['ions'].pop('init')
-        parameters['kinetic']['ions'].pop('background')
-        parameters['kinetic']['ions']['markers']['loading'].pop('moments')
-
-        for keys in init_params_scalar.keys():
-
-            parameters['em_fields']['init'][init_kind].pop(keys)
-            parameters['em_fields']['init'][init_kind][keys] = {}
-            parameters['fluid']['mhd']['init'][init_kind].pop(keys)
-            parameters['fluid']['mhd']['init'][init_kind][keys] = {}
+        parameters['kinetic']['species_name'].pop('background')
+        parameters['kinetic']['species_name']['markers']['loading'].pop(
+            'moments')
+
+        for keys in bckgr_params_scalar:
+            parameters['em_fields']['background'][bckgr_type].pop(keys)
+            parameters['em_fields']['background'][bckgr_type][keys] = {}
+            parameters['fluid']['species_name']['background'][bckgr_type].pop(
+                keys)
+            parameters['fluid']['species_name']['background'][bckgr_type][keys] = {}
+
+        for keys in pert_params_scalar:
+            parameters['em_fields']['perturbation'][pert_type].pop(keys)
+            parameters['em_fields']['perturbation'][pert_type][keys] = {}
+            parameters['fluid']['species_name']['perturbation'][pert_type].pop(
+                keys)
+            parameters['fluid']['species_name']['perturbation'][pert_type][keys] = {}
+            parameters['kinetic']['species_name']['perturbation'][pert_type].pop(
+                keys)
+            parameters['kinetic']['species_name']['perturbation'][pert_type][keys] = {}
 
         # standard moments of Maxwellians
         moms = {'6D': [0., 0., 0., 1., 1., 1.],
                 '5D': [0., 0., 1., 1.]}
 
         # init options dicts
         d_opts = {'em_fields': [], 'fluid': {}, 'kinetic': {}}
 
         # set the correct names in the parameter file
         if len(cls.species()['em_fields']) > 0:
 
             for name, space in cls.species()['em_fields'].items():
                 # default initial condition for scalar-valued field
                 if space in {'H1', 'L2'}:
-                    for keys, vals in init_params_scalar.items():
-                        parameters['em_fields']['init'][init_kind][keys][name] = vals
+                    for keys, vals in bckgr_params_scalar.items():
+                        parameters['em_fields']['background'][bckgr_type][keys][name] = vals
+                    for keys, vals in pert_params_scalar.items():
+                        parameters['em_fields']['perturbation'][pert_type][keys][name] = vals
 
                 # default initial condition for vector-valued field
                 elif space in {'Hcurl', 'Hdiv', 'H1vec'}:
-                    for keys, vals in init_params.items():
-                        parameters['em_fields']['init'][init_kind][keys][name] = vals
+                    for keys, vals in bckgr_params.items():
+                        parameters['em_fields']['background'][bckgr_type][keys][name] = vals
+                    for keys, vals in pert_params.items():
+                        parameters['em_fields']['perturbation'][pert_type][keys][name] = vals
 
         else:
             parameters.pop('em_fields')
 
         # find out the default em_fields options of the model
         if 'options' in cls.options()['em_fields']:
             # create the default options parameters
             d_default = descend_options_dict(cls.options()['em_fields']['options'],
                                              d_opts['em_fields'])
 
             parameters['em_fields']['options'] = d_default
 
         # fluid
-        fluid_params = parameters['fluid'].pop('mhd')
+        fluid_params = parameters['fluid'].pop('species_name')
 
         if len(cls.species()['fluid']) > 0:
 
             for name, dct in cls.species()['fluid'].items():
 
                 parameters['fluid'][name] = fluid_params
 
@@ -1088,55 +1147,64 @@
 
                     parameters['fluid'][name]['options'] = d_default
 
                 # set the correct names parameter file
                 for sub_name, space in dct.items():
                     # default initial condition for scalar-valued field
                     if space in {'H1', 'L2'}:
-                        for keys, vals in init_params_scalar.items():
-                            parameters['fluid'][name]['init'][init_kind][keys][sub_name] = vals
+                        for keys, vals in bckgr_params_scalar.items():
+                            parameters['fluid'][name]['background'][bckgr_type][keys][sub_name] = vals
+                        for keys, vals in pert_params_scalar.items():
+                            parameters['fluid'][name]['perturbation'][pert_type][keys][sub_name] = vals
 
                     # default initial condition for scalar-valued field
                     elif space in {'Hcurl', 'Hdiv', 'H1vec'}:
-                        for keys, vals in init_params.items():
-                            parameters['fluid'][name]['init'][init_kind][keys][sub_name] = vals
+                        for keys, vals in bckgr_params.items():
+                            parameters['fluid'][name]['background'][bckgr_type][keys][sub_name] = vals
+                        for keys, vals in pert_params.items():
+                            parameters['fluid'][name]['perturbation'][pert_type][keys][sub_name] = vals
 
         else:
             parameters.pop('fluid')
 
         # kinetic
-        kinetic_params = parameters['kinetic'].pop('ions')
+        kinetic_params = parameters['kinetic'].pop('species_name')
 
         if len(cls.species()['kinetic']) > 0:
             parameters['kinetic'] = {}
 
-        for name, space in cls.species()['kinetic'].items():
+            for name, space in cls.species()['kinetic'].items():
 
-            parameters['kinetic'][name] = kinetic_params
+                parameters['kinetic'][name] = kinetic_params
 
-            # find out the default kinetic options of the model
-            if name in cls.options()['kinetic']:
+                # find out the default kinetic options of the model
+                if name in cls.options()['kinetic']:
 
-                d_opts['kinetic'][name] = []
+                    d_opts['kinetic'][name] = []
 
-                # create the default options parameters
-                d_default = descend_options_dict(cls.options()['kinetic'][name]['options'],
-                                                 d_opts['kinetic'][name])
+                    # create the default options parameters
+                    d_default = descend_options_dict(cls.options()['kinetic'][name]['options'],
+                                                     d_opts['kinetic'][name])
 
-                parameters['kinetic'][name]['options'] = d_default
+                    parameters['kinetic'][name]['options'] = d_default
 
-            # set the correct names in the parameter file
-            dim = space[-2:]
-            parameters['kinetic'][name]['init'] = {'type': 'Maxwellian' + dim + 'Uniform',
-                                                   'Maxwellian' + dim + 'Uniform': {'n': 0.05}}
-            parameters['kinetic'][name]['background'] = {'type': 'Maxwellian' + dim + 'Uniform',
-                                                         'Maxwellian' + dim + 'Uniform': {'n': 0.8}}
-            parameters['kinetic'][name]['markers']['loading']['moments'] = moms[dim]
+                # set the correct names in the parameter file
+                dim = space[-2:]
+                parameters['kinetic'][name]['background'] = {'type': 'Maxwellian' + dim,
+                                                             'Maxwellian' + dim: {'n': 0.05}}
+                parameters['kinetic'][name]['markers']['loading']['moments'] = moms[dim]
+                
+                for keys, vals in pert_params_scalar.items():
+                    parameters['kinetic'][name]['perturbation'][pert_type][keys]['n'] = vals   
+                    
+        else:
+            parameters.pop('kinetic')
 
-        cls.write_parameters_to_file(parameters=parameters, file=file, save=save, prompt=prompt)
+        cls.write_parameters_to_file(
+            parameters=parameters, file=file, save=save, prompt=prompt)
 
         return parameters
 
     ###################
     # Private methods :
     ###################
 
@@ -1215,60 +1283,93 @@
         """
 
         from struphy.pic import particles
 
         # allocate memory for FE coeffs of electromagnetic fields/potentials
         if 'em_fields' in self.params:
 
+            # background parameters
+            if 'background' in self.params['em_fields']:
+                bckgr_params = self.params['em_fields']['background']
+            else:
+                bckgr_params = None
+
+            # perturbation parameters
+            if 'perturbation' in self.params['em_fields']:
+                pert_params = self.params['em_fields']['perturbation']
+            else:
+                pert_params = None
+
             for key, val in self.em_fields.items():
 
                 if 'params' not in key:
-                    val['obj'] = self.derham.create_field(key, val['space'])
+                    val['obj'] = self.derham.create_field(key,
+                                                          val['space'],
+                                                          bckgr_params=bckgr_params,
+                                                          pert_params=pert_params)
 
                     self._pointer[key] = val['obj'].vector
 
         # allocate memory for FE coeffs of fluid variables
         if 'fluid' in self.params:
 
             for species, val in self.fluid.items():
 
+                # background parameters
+                if 'background' in val['params']:
+                    bckgr_params = val['params']['background']
+                else:
+                    bckgr_params = None
+
+                # perturbation parameters
+                if 'perturbation' in val['params']:
+                    pert_params = val['params']['perturbation']
+                else:
+                    pert_params = None
+
                 for variable, subval in val.items():
 
                     if 'params' not in variable:
                         subval['obj'] = self.derham.create_field(
-                            variable, subval['space'])
+                            variable,
+                            subval['space'],
+                            bckgr_params=bckgr_params,
+                            pert_params=pert_params)
 
                         self._pointer[species + '_' +
                                       variable] = subval['obj'].vector
 
         # marker arrays and plasma parameters of kinetic species
         if 'kinetic' in self.params:
 
             for species, val in self.kinetic.items():
 
-                if self.params['kinetic'][species]['markers']['type'] in ['control_variate', 'delta_f']:
-                    assert 'background' in self.params['kinetic'][species], \
-                        f'If a control variate or delta-f method is used, a maxwellians background must be given!'
+                # background parameters
+                if 'background' in val['params']:
+                    bckgr_params = val['params']['background']
+                else:
+                    bckgr_params = None
 
-                if 'background' in self.params['kinetic'][species]:
-                    f0_params = val['params']['background']
+                # perturbation parameters
+                if 'perturbation' in val['params']:
+                    pert_params = val['params']['perturbation']
                 else:
-                    f0_params = None
+                    pert_params = None
 
                 kinetic_class = getattr(particles, val['space'])
 
-                val['obj'] = kinetic_class(species,
-                                           **val['params']['phys_params'],
-                                           **val['params']['markers'],
-                                           derham=self.derham,
-                                           domain=self.domain,
-                                           mhd_equil=self.mhd_equil,
-                                           epsilon=self.equation_params[species]['epsilon_unit'],
-                                           units_basic=self.units,
-                                           f0_params=f0_params)
+                val['obj'] = kinetic_class(
+                    species,
+                    **val['params']['markers'],
+                    derham=self.derham,
+                    domain=self.domain,
+                    mhd_equil=self.mhd_equil,
+                    bckgr_params=bckgr_params,
+                    pert_params=pert_params
+                )
 
                 self._pointer[species] = val['obj']
 
                 # for storing markers
                 n_markers = val['params']['save_data']['n_markers']
                 assert n_markers <= val['obj'].n_mks
                 if n_markers > 0:
@@ -1435,41 +1536,42 @@
                 # thermal energy (keV)
                 pparams[species]['kBT'] = pparams[species]['pressure'] * \
                     1e5 / pparams[species]['density'] / e * 1e-3
 
         if len(self.kinetic) > 0:
 
             eta1mg, eta2mg, eta3mg = np.meshgrid(
-                eta1, eta2, eta3, indexing='ij')
+                eta1, eta2, eta3, indexing='ij'
+            )
 
             for species, val in self.kinetic.items():
                 pparams[species] = {}
                 # type
                 pparams[species]['type'] = 'kinetic'
                 # mass (kg)
                 pparams[species]['mass'] = val['params']['phys_params']['A'] * m_p
                 # charge (C)
                 pparams[species]['charge'] = val['params']['phys_params']['Z'] * e
 
                 # create temp kinetic object for (default) parameter extraction
-                if 'background' in val['params']:
-                    tmp_str = 'background'
-                else:
-                    tmp_str = 'init'
-                tmp_type = val['params'][tmp_str]['type']
-                tmp_params = val['params'][tmp_str][tmp_type]
-                tmp = getattr(maxwellians, tmp_type)(**tmp_params)
+                tmp_type = val['params']['background']['type']
+                tmp_params = val['params']['background'][tmp_type]
+                tmp = getattr(maxwellians, tmp_type)(maxw_params=tmp_params)
 
                 # density (m⁻³)
                 pparams[species]['density'] = np.mean(tmp.n(
                     eta1mg, eta2mg, eta3mg) * np.abs(det_tmp)) * units['x']**3 / plasma_volume * units['n']
                 # thermal speeds (m/s)
-                vth = tmp.vth(eta1mg, eta2mg, eta3mg) * \
-                    np.abs(det_tmp) * units['x']**3 / \
-                    plasma_volume * units['v']
+                vth = []
+                vths = tmp.vth(eta1mg, eta2mg, eta3mg)
+                for k in range(len(vths)):
+                    vth += [
+                        vths[k] * np.abs(det_tmp) *
+                        units['x']**3 / plasma_volume * units['v']
+                    ]
                 thermal_speed = 0.
                 for dir in range(val['obj'].vdim):
                     pparams[species]['vth' + str(dir + 1)] = np.mean(vth[dir])
                     thermal_speed += pparams[species]['vth' + str(dir + 1)]
                 # TODO: here it is assumed that background density parameter is called "n",
                 # and that background thermal speeds are called "vthn"; make this a convention?
                 pparams[species]['v_th'] = thermal_speed / \
```

### Comparing `struphy-2.2.0/src/struphy/models/fluid.py` & `struphy-2.3.0/src/struphy/models/fluid.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,28 +1,29 @@
 from struphy.models.base import StruphyModel
+import numpy as np
 
 
 class LinearMHD(StruphyModel):
     r'''Linear ideal MHD with zero-flow equilibrium (:math:`\mathbf U_0 = 0`).
 
     Find :math:`(\tilde n, \tilde{\mathbf{U}}, \tilde p, \tilde{\mathbf{B}}) \in L^2 \times H(\textrm{div}) \times L^2 \times H(\textrm{div})` such that
 
     .. math::
         &\frac{\partial \tilde n}{\partial t}+\nabla\cdot(n_0 \tilde{\mathbf{U}})=0\,, 
 
-        \int n_0&\frac{\partial \tilde{\mathbf{U}}}{\partial t} \cdot \tilde{\mathbf{V}}\,\textrm d \mathbf x  + \int \tilde p\, \nabla \cdot \tilde{\mathbf{V}} \,\textrm d \mathbf x
+        \int n_0&\frac{\partial \tilde{\mathbf{U}}}{\partial t} \cdot \tilde{\mathbf{V}}\,\textrm d \mathbf x  - \int \tilde p\, \nabla \cdot \tilde{\mathbf{V}} \,\textrm d \mathbf x
         =\int \tilde{\mathbf{B}}\cdot \nabla \times (\mathbf{B}_0 \times \tilde{\mathbf{V}})\,\textrm d \mathbf x + \int (\nabla\times\mathbf{B}_0)\times \tilde{\mathbf{B}} \cdot \tilde{\mathbf{V}}\,\textrm d \mathbf x
         \qquad \forall \ \tilde{\mathbf{V}} \in H(\textrm{div})\,,
 
         &\frac{\partial \tilde p}{\partial t} + \nabla\cdot(p_0 \tilde{\mathbf{U}}) 
         + \frac{2}{3}\,p_0\nabla\cdot \tilde{\mathbf{U}}=0\,,
 
         &\frac{\partial \tilde{\mathbf{B}}}{\partial t} - \nabla\times(\tilde{\mathbf{U}} \times \mathbf{B}_0)
         = 0\,.
-        
+
     :ref:`normalization`:
 
     .. math::
 
         \hat U = \hat v_\textnormal{A, bulk} \,, \qquad \hat p = \frac{\hat B^2}{\mu_0}\,.
 
     Parameters
@@ -249,15 +250,15 @@
 
         if isinstance(self._ones, PolarVector):
             self._ones.tp[:] = 1.
         else:
             self._ones[:] = 1.
 
         # compute coupling parameters
-        kappa = 1. / self.equation_params['mhd']['epsilon_unit']
+        kappa = 1. / self.equation_params['mhd']['epsilon']
 
         if abs(kappa - 1) < 1e-6:
             kappa = 1.
 
         self._coupling_params = {}
         self._coupling_params['kappa'] = kappa
 
@@ -406,16 +407,16 @@
         return dct
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm)
 
         # model parameters
-        self._alpha = self.equation_params['electrons']['alpha_unit']
-        self._epsilon = self.equation_params['electrons']['epsilon_unit']
+        self._alpha = self.equation_params['electrons']['alpha']
+        self._epsilon = self.equation_params['electrons']['epsilon']
 
         # solver parameters
         params_maxwell = params['em_fields']['options']['solver']['maxwell']
         params_ohmcold = params['fluid']['electrons']['options']['solvers']['ohmcold']
         params_jxbcold = params['fluid']['electrons']['options']['solvers']['jxbcold']
 
         # Initialize propagators/integrators used in splitting substeps
@@ -470,28 +471,28 @@
     .. math::
 
         \frac{\hat B}{\sqrt{A_\textnormal{b} m_\textnormal{H} \hat \rho \mu_0}} =: \hat v_\textnormal{A} = \frac{\hat \omega}{\hat k} = \hat U \,, \qquad \hat p = (\gamma - 1) \hat \rho^{\gamma} \exp(\hat s / \hat \rho) = \frac{\hat B^2}{\mu_0}\,.
 
     Implemented equations:
 
     .. math::
-        
+
         \int_{\Omega} \partial_t (\rho \mathbf u) \cdot \mathbf v \, \textnormal d^3 \mathbf x 
         - \int_{\Omega} \mathbf \rho u \cdot [\mathbf u, \mathbf v] \, \textnormal d^3 \mathbf x 
         + \int_{\Omega} \big( \frac{| \mathbf u |^2}{2} - \frac{\partial \rho e}{\partial \rho} \big) \nabla \cdot (\rho \mathbf v) \, \textnormal d^3 \mathbf x &
-        
+
         - \int_{\Omega} \big( \frac{\partial \rho e}{\partial s} \big) \nabla \cdot (s \mathbf v) \, \textnormal d^3 \mathbf x 
         - \int_{\Omega} \mathbf B \cdot \nabla \times (\mathbf B \mathbf v) \, \textnormal d^3 \mathbf x& = 0 ~ , 
 
         \partial_t \rho + \nabla \cdot ( \rho \mathbf u ) & = 0 ~ , 
 
         \partial_t s + \nabla \cdot ( s \mathbf u ) & = 0 ~ , 
 
         \partial_t \mathbf B + \nabla \times ( \mathbf B \times \mathbf u ) & = 0 ~ , 
-        
+
     where
 
     .. math::
         [\mathbf u,\mathbf v] = \mathbf u \cdot \nabla \mathbf v - \mathbf v \cdot \nabla \mathbf u ~ .
 
     and
 
@@ -506,15 +507,15 @@
     comm : mpi4py.MPI.Intracomm
         MPI communicator used for parallelization.
     '''
     @classmethod
     def species(cls):
         dct = {'em_fields': {}, 'fluid': {}, 'kinetic': {}}
         dct['em_fields']['b2'] = 'Hdiv'
-        dct['fluid']['mhd'] = {'rho3' : 'L2', 's3' : 'L2', 'uv': 'H1vec'}
+        dct['fluid']['mhd'] = {'rho3': 'L2', 's3': 'L2', 'uv': 'H1vec'}
         return dct
 
     @classmethod
     def bulk_species(cls):
         return 'mhd'
 
     @classmethod
@@ -523,58 +524,81 @@
 
     @classmethod
     def options(cls):
         # import propagator options
         from struphy.propagators.propagators_fields import VariationalMomentumAdvection, VariationalDensityEvolve, VariationalEntropyEvolve, VariationalMagFieldEvolve
         dct = {}
 
-        cls.add_option(species=['fluid', 'mhd'], key=['solvers'],
+        cls.add_option(species=['fluid', 'mhd'], key=['solver_momentum'],
                        option=VariationalMomentumAdvection.options()['solver'], dct=dct)
-        cls.add_option(species=['fluid', 'mhd'], key=['solvers'],
+        cls.add_option(species=['fluid', 'mhd'], key=['solver_density'],
                        option=VariationalDensityEvolve.options()['solver'], dct=dct)
-        cls.add_option(species=['fluid', 'mhd'], key=['solvers'],
+        cls.add_option(species=['fluid', 'mhd'], key=['solver_entropy'],
                        option=VariationalEntropyEvolve.options()['solver'], dct=dct)
+        cls.add_option(species=['fluid', 'mhd'], key=['solver_magnetic'],
+                       option=VariationalMagFieldEvolve.options()['solver'], dct=dct)
+        cls.add_option(species=['fluid', 'mhd'], key=['physics'],
+                       option=VariationalDensityEvolve.options()['physics'], dct=dct)
 
         return dct
 
     def __init__(self, params, comm):
 
         from struphy.feec.projectors import L2Projector
         from struphy.feec.mass import WeightedMassOperator
         import numpy as np
 
         # initialize base class
         super().__init__(params, comm)
         # Initialize mass matrix
-        self.WMM = WeightedMassOperator(self.derham.Vh_fem['v'], self.derham.Vh_fem['v'], matrix_free=True) 
+        self.WMM = WeightedMassOperator(
+            self.derham.Vh_fem['v'], self.derham.Vh_fem['v'])
 
         # Initialize propagators/integrators used in splitting substeps
-        gamma = params['fluid']['mhd']['options']['solvers']['gamma']
+        solver_momentum = params['fluid']['mhd']['options']['solver_momentum']
+        solver_density = params['fluid']['mhd']['options']['solver_density']
+        solver_entropy = params['fluid']['mhd']['options']['solver_entropy']
+        solver_magnetic = params['fluid']['mhd']['options']['solver_magnetic']
+
+        gamma = params['fluid']['mhd']['options']['physics']['gamma']
 
         self.add_propagator(self.prop_fields.VariationalDensityEvolve(
-            self.pointer['mhd_rho3'], self.pointer['mhd_uv'], model='full', s = self.pointer['mhd_s3'], gamma = gamma, mass_ops = self.WMM))
+            self.pointer['mhd_rho3'], self.pointer['mhd_uv'],
+            model='full',
+            s=self.pointer['mhd_s3'],
+            gamma=gamma,
+            mass_ops=self.WMM,
+            **solver_density))
         self.add_propagator(self.prop_fields.VariationalMomentumAdvection(
-         self.pointer['mhd_uv'], mass_ops = self.WMM))
+            self.pointer['mhd_uv'],
+            mass_ops=self.WMM,
+            **solver_momentum))
         self.add_propagator(self.prop_fields.VariationalEntropyEvolve(
-            self.pointer['mhd_s3'], self.pointer['mhd_uv'], model='full', rho = self.pointer['mhd_rho3'], gamma = gamma, mass_ops = self.WMM))
+            self.pointer['mhd_s3'], self.pointer['mhd_uv'],
+            model='full',
+            rho=self.pointer['mhd_rho3'],
+            gamma=gamma,
+            mass_ops=self.WMM,
+            **solver_entropy))
         self.add_propagator(self.prop_fields.VariationalMagFieldEvolve(
-            self.pointer['b2'], self.pointer['mhd_uv'], mass_ops = self.WMM))
-        
+            self.pointer['b2'], self.pointer['mhd_uv'],
+            mass_ops=self.WMM,
+            **solver_magnetic))
 
         # Scalar variables to be saved during simulation
         self.add_scalar('en_U')
         self.add_scalar('en_thermo')
         self.add_scalar('en_mag')
         self.add_scalar('en_tot')
 
         # temporary vectors for scalar quantities
         self._tmp_m1 = self.derham.Vh['v'].zeros()
         self._tmp_wb2 = self.derham.Vh['2'].zeros()
         projV3 = L2Projector('L2', self._mass_ops)
-        f = lambda e1, e2, e3 : 1
+        def f(e1, e2, e3): return 1
         f = np.vectorize(f)
         self._integrator = projV3(f)
 
     def update_scalar_quantities(self):
 
         WMM = self.WMM
         m1 = WMM.dot(self.pointer['mhd_uv'], out=self._tmp_m1)
@@ -589,22 +613,29 @@
         en_thermo = self.update_thermo_energy()
 
         en_tot = en_U + en_thermo + en_mag
         self.update_scalar('en_tot', en_tot)
 
     def update_thermo_energy(self):
         '''Reuse tmp used in VariationalEntropyEvolve to compute the thermodynamical energy.
-        
+
         :meta private:
         '''
         en_prop = self._propagators[2]
         en_prop.sf.vector = self.pointer['mhd_s3']
         en_prop.rhof.vector = self.pointer['mhd_rho3']
-        sf_values = en_prop.sf.eval_tp_fixed_loc(en_prop.integration_grid_V3_spans, en_prop.integration_grid_V3_bd, out=en_prop._sf_values_V3)
-        rhof_values = en_prop.rhof.eval_tp_fixed_loc(en_prop.integration_grid_V3_spans, en_prop.integration_grid_V3_bd, out=en_prop._rhof_values_V3)
-        e = en_prop._ener
-        ener_values = en_prop._proj_ener_metric_term*e(rhof_values,sf_values)
+        sf_values = en_prop.sf.eval_tp_fixed_loc(
+            en_prop.integration_grid_spans, en_prop.integration_grid_bd, out=en_prop._sf_values)
+        rhof_values = en_prop.rhof.eval_tp_fixed_loc(
+            en_prop.integration_grid_spans, en_prop.integration_grid_bd, out=en_prop._rhof_values)
+        e = self.__ener
+        ener_values = en_prop._proj_rho2_metric_term*e(rhof_values, sf_values)
         en_prop._get_L2dofs_V3(ener_values, dofs=en_prop._linear_form_dl_ds)
         en_thermo = self._integrator.dot(en_prop._linear_form_dl_ds)
         self.update_scalar('en_thermo', en_thermo)
         return en_thermo
-
+    
+    def __ener(self, rho, s):
+        """Themodynamical energy as a function of rho and s, usign the perfect gaz hypothesis
+        E(rho, s) = rho^gamma*exp(s/rho)"""
+        gam = self._params['fluid']['mhd']['options']['physics']['gamma']
+        return np.power(rho, gam)*np.exp(s/rho)
```

### Comparing `struphy-2.2.0/src/struphy/models/hybrid.py` & `struphy-2.3.0/src/struphy/models/hybrid.py`

 * *Files 5% similar despite different names*

```diff
@@ -113,15 +113,15 @@
         algo_vxb = params['kinetic']['energetic_ions']['options']['algos']['push_vxb']
         params_density = params['kinetic']['energetic_ions']['options']['solvers']['density']
         params_current = params['kinetic']['energetic_ions']['options']['solvers']['current']
 
         # compute coupling parameters
         Ab = params['fluid']['mhd']['phys_params']['A']
         Ah = params['kinetic']['energetic_ions']['phys_params']['A']
-        kappa = 1. / self.equation_params['energetic_ions']['epsilon_unit']
+        kappa = 1. / self.equation_params['energetic_ions']['epsilon']
 
         if abs(kappa - 1) < 1e-6:
             kappa = 1.
 
         self._coupling_params = {}
         self._coupling_params['Ab'] = Ab
         self._coupling_params['Ah'] = Ah
@@ -129,15 +129,15 @@
 
         # background distribution function used as control variate
         if params['kinetic']['energetic_ions']['markers']['type'] == 'control_variate':
             assert 'background' in params['kinetic']['energetic_ions'], 'no background distribution function for control variate specified'
             control = True
             f0_name = params['kinetic']['energetic_ions']['background']['type']
             f0 = getattr(kin_ana, f0_name)(
-                **params['kinetic']['energetic_ions']['background'][f0_name])
+                maxw_params=params['kinetic']['energetic_ions']['background'][f0_name])
         else:
             control = False
             f0 = None
 
         # project background magnetic field (2-form) and background pressure (3-form)
         self._b_eq = self.derham.P['2']([self.mhd_equil.b2_1,
                                          self.mhd_equil.b2_2,
@@ -368,15 +368,15 @@
         use_perp_model = params['kinetic']['energetic_ions']['options']['use_perp_model']
         algo_vxb = params['kinetic']['energetic_ions']['options']['push_vxb']
         params_pc_solver = params['kinetic']['energetic_ions']['options']['solver']
 
         # compute coupling parameters
         Ab = params['fluid']['mhd']['phys_params']['A']
         Ah = params['kinetic']['energetic_ions']['phys_params']['A']
-        kappa = 1. / self.equation_params['energetic_ions']['epsilon_unit']
+        kappa = 1. / self.equation_params['energetic_ions']['epsilon']
 
         if abs(kappa - 1) < 1e-6:
             kappa = 1.
 
         self._coupling_params = {}
         self._coupling_params['Ab'] = Ab
         self._coupling_params['Ah'] = Ah
@@ -384,15 +384,15 @@
 
         # background distribution function used as control variate
         if params['kinetic']['energetic_ions']['markers']['type'] == 'control_variate':
             assert 'background' in params['kinetic']['energetic_ions'], 'no background distribution function for control variate specified'
             control = True
             f0_name = params['kinetic']['energetic_ions']['background']['type']
             f0 = getattr(kin_ana, f0_name)(
-                **params['kinetic']['energetic_ions']['background'][f0_name])
+                maxw_params=params['kinetic']['energetic_ions']['background'][f0_name])
         else:
             control = False
             f0 = None
 
         # Project magnetic field
         self._b_eq = self.derham.P['2']([self.mhd_equil.b2_1,
                                          self.mhd_equil.b2_2,
@@ -507,27 +507,30 @@
     r"""
     Hybrid linear MHD + energetic ions (5D Driftkinetic) with **current coupling scheme**. 
 
     :ref:`normalization`: 
 
     .. math::
 
-        \frac{\hat B}{\sqrt{A_\textnormal{b} m_\textnormal{H} \hat n \mu_0}} =: \hat v_\textnormal{A} = \frac{\hat \omega}{\hat k} = \hat U = \hat v = \hat u_\textnormal{h} \,, \qquad \hat p = \frac{\hat B^2}{\mu_0} \, \,,\qquad \hat f_\textnormal{h} = \frac{\hat n}{\hat v_\textnormal{A}^3} \,,\qquad \hat n_\textnormal{h} = \hat n\,.
+        \hat U = \hat v_\textnormal{h} =: \hat v_\textnormal{A, bulk} \,, \qquad \hat p = \frac{\hat B^2}{\mu_0} \, \qquad
+        \hat f_\textnormal{h} = \frac{\hat n}{\hat v_\textnormal{A,bulk} \hat \mu \hat B} \,,\qquad \hat \mu = \frac{A_\textnormal{h} m_\textnormal{H} \hat v_\textnormal{A,bulk}^2}{\hat B} \,.
 
-    Implemented equations:
+    Implemented equations: find :math:`(\tilde n, \tilde{\mathbf{U}}, \tilde p, \tilde{\mathbf{B}}, f_\textnormal{h}) \in L^2 \times H(\textrm{div}) \times L^2 \times H(\textrm{div}) \times C^\infty` such that
 
     .. math::
 
         \begin{align}
         \textnormal{MHD} &\left\{
         \begin{aligned}
-        &\frac{\partial \tilde n}{\partial t}+\nabla\cdot(n_0 \tilde{\mathbf{U}})=0\,, 
+        &\frac{\partial \tilde n}{\partial t}+\nabla\cdot(n_{0} \tilde{\mathbf{U}})=0\,, 
+        \\
+        \int n_{0} &\frac{\partial \tilde{\mathbf{U}}}{\partial t} \cdot \tilde{\mathbf V}\, \textnormal{d}\mathbf{x} - \int \tilde p\, \nabla \cdot \tilde{\mathbf{V}} \,\textrm d \mathbf x
+         = \int \tilde{\mathbf{B}} \cdot \nabla \times(\mathbf{B}_0 \times \tilde{\mathbf V})\, \textnormal{d}\mathbf{x} + \int (\nabla \times \mathbf B_0) \times \tilde{\mathbf{B}} \cdot \tilde{\mathbf V} \, \textnormal{d}\mathbf{x}
         \\
-        n_0 &\frac{\partial \tilde{\mathbf{U}}}{\partial t} + \nabla \tilde p
-        =(\nabla\times \tilde{\mathbf{B}})\times\mathbf{B}_0 + \mathbf J_0 \times \tilde{\mathbf{B}} \color{blue} + \frac{A_\textnormal{h}}{A_\textnormal{b}} \frac{1}{\epsilon} \,(n_\textnormal{h} \tilde{\mathbf{U}} - \mathbf{J}_\textnormal{gc} - \epsilon \nabla \times \mathbf{M}_\textnormal{gc}) \times (\mathbf{B}_0 + \tilde{\mathbf{B}}) \color{black}\,,
+        &\qquad \qquad \color{blue}+ \frac{A_\textnormal{h}}{A_\textnormal{b}} \int \left[ \frac{1}{\epsilon} n_\textnormal{gc} \tilde{\mathbf{U}} \times \mathbf{B} \cdot \tilde{\mathbf V} - \frac{1}{\epsilon} \mathbf{J}_\textnormal{gc} \times \mathbf{B} \cdot \tilde{\mathbf V} -\mathbf{M}_\textnormal{gc} \cdot \nabla \times (\mathbf{B} \times \tilde{\mathbf V}) \right] \textnormal{d} \mathbf{x} \color{black} \,, \quad \forall \ \tilde{\mathbf V} \in H(\text{div})\,,
         \\
         &\frac{\partial \tilde p}{\partial t} + \nabla\cdot(p_0 \tilde{\mathbf{U}}) 
         + \frac{2}{3}\,p_0\nabla\cdot \tilde{\mathbf{U}}=0\,, 
         \\
         &\frac{\partial \tilde{\mathbf{B}}}{\partial t} - \nabla\times(\tilde{\mathbf{U}} \times \mathbf{B}_0)
         = 0\,,
         \end{aligned}
@@ -535,38 +538,38 @@
         \\[2mm]
         \textnormal{EPs}\,\, &\left\{\,\,
         \begin{aligned}
         \quad &\frac{\partial f_\textnormal{h}}{\partial t} + \frac{1}{B_\parallel^*}(v_\parallel \mathbf{B}^* - \mathbf{b}_0 \times \mathbf{E}^*)\cdot\nabla f_\textnormal{h}
         + \frac{1}{\epsilon} \frac{1}{B_\parallel^*} (\mathbf{B}^* \cdot \mathbf{E}^*) \frac{\partial f_\textnormal{h}}{\partial v_\parallel}
         = 0\,,
         \\
-        & n_\textnormal{h} = \int f_\textnormal{h} \,\textnormal dv_\parallel \textnormal d\mu \,,
+        & n_\textnormal{gc} = \int f_\textnormal{h} B_\parallel^* \,\textnormal dv_\parallel \textnormal d\mu \,,
         \\
-        & \mathbf{J}_\textnormal{gc} = q \int \frac{1}{B^*_\parallel} f_\textnormal{h} (v_\parallel \mathbf{B}^* - \mathbf{b}_0 \times \mathbf{E}^*) \,\textnormal dv_\parallel \textnormal d\mu \,,
+        & \mathbf{J}_\textnormal{gc} = \int f_\textnormal{h}(v_\parallel \mathbf{B}^* - \mathbf{b}_0 \times \mathbf{E}^*) \,\textnormal dv_\parallel \textnormal d\mu \,,
         \\
-        & \mathbf{M}_\textnormal{gc} = - \int f_\textnormal{h} \mu \mathbf{b}_0 \,\textnormal dv_\parallel \textnormal d\mu \,,
+        & \mathbf{M}_\textnormal{gc} = - \int f_\textnormal{h} B_\parallel^* \mu \mathbf{b}_0 \,\textnormal dv_\parallel \textnormal d\mu \,,
         \end{aligned}
         \right.
         \end{align}
 
-    where :math:`\mathbf J_0 = \nabla \times \mathbf B_0` and
+    where 
 
     .. math::
 
         \begin{align}
         \mathbf{B}^* &= \mathbf{B} + \epsilon v_\parallel \nabla \times \mathbf{b}_0 \,,\qquad B^*_\parallel = \mathbf{b}_0 \cdot \mathbf{B}^*\,,
-        \\
-        \mathbf{E}^* &= \color{blue} - \tilde{\mathbf{U}} \times \mathbf{B} \color{black} - \epsilon \mu \nabla B_\parallel \,.
+        \\[2mm]
+        \mathbf{E}^* &=  \color{blue}- \tilde{\mathbf{U}} \times \mathbf{B} \color{black} - \epsilon \mu \nabla B_\parallel \,,
         \end{align}
-
-    Moreover,
-
+        
+    and with the normalization parameter 
+    
     .. math::
-
-        \epsilon =  \frac{\hat \omega}{2 \pi \, \hat \Omega_{\textnormal{ch}}}\,,\qquad \textnormal{with} \qquad\hat \Omega_{\textnormal{ch}} = \frac{Z_\textnormal{h}e \hat B}{A_\textnormal{h} m_\textnormal{H}}\,.    
+    
+        \epsilon = \frac{1}{\hat \Omega_\textnormal{ch} \hat t} \,, \qquad \hat \Omega_\textnormal{ch} = \frac{Z_\textnormal{h} e \hat B}{A_\textnormal{h} m_\textnormal{H}} \,.
 
     Parameters
     ----------
     params : dict
         Simulation parameters, see from :ref:`params_yml`.
 
     comm : mpi4py.MPI.Intracomm
@@ -591,15 +594,15 @@
         return 'alfvén'
 
     @classmethod
     def options(cls):
         # import propagator options
         from struphy.propagators.propagators_fields import ShearAlfvénCurrentCoupling5D, MagnetosonicCurrentCoupling5D, CurrentCoupling5DDensity
         from struphy.propagators.propagators_markers import PushDriftKineticbxGradB, PushDriftKineticBstar
-        from struphy.propagators.propagators_coupling import CurrentCoupling5DCurlb, CurrentCoupling5DGradBxB
+        from struphy.propagators.propagators_coupling import CurrentCoupling5DCurlb, CurrentCoupling5DGradB
 
         dct = {}
         cls.add_option(species=['fluid', 'mhd'], key=['solvers', 'shear_alfven'],
                        option=ShearAlfvénCurrentCoupling5D.options()['solver'], dct=dct)
         cls.add_option(species=['fluid', 'mhd'], key=['solvers', 'magnetosonic'],
                        option=MagnetosonicCurrentCoupling5D.options()['solver'], dct=dct)
         cls.add_option(species=['kinetic', 'energetic_ions'], key=['solvers', 'density'],
@@ -607,54 +610,54 @@
         cls.add_option(species=['kinetic', 'energetic_ions'], key=['algos', 'push_bxgradb'],
                        option=PushDriftKineticbxGradB.options()['algo'], dct=dct)
         cls.add_option(species=['kinetic', 'energetic_ions'], key=['algos', 'push_bstar'],
                        option=PushDriftKineticBstar.options()['algo'], dct=dct)
         cls.add_option(species=['kinetic', 'energetic_ions'], key=['solvers', 'cc1'],
                        option=CurrentCoupling5DCurlb.options()['solver'], dct=dct)
         cls.add_option(species=['kinetic', 'energetic_ions'], key=['solvers', 'cc2'],
-                       option=CurrentCoupling5DGradBxB.options()['solver'], dct=dct)
+                       option=CurrentCoupling5DGradB.options()['solver'], dct=dct)
         cls.add_option(species=['kinetic', 'energetic_ions'], key=['algos', 'push_cc2'],
-                       option=CurrentCoupling5DGradBxB.options()['algo'], dct=dct)
+                       option=CurrentCoupling5DGradB.options()['algo'], dct=dct)
         return dct
 
     def __init__(self, params, comm):
 
         # initialize base class
         super().__init__(params, comm)
 
         from struphy.polar.basic import PolarVector
         from struphy.kinetic_background import maxwellians as kin_ana
         from mpi4py.MPI import SUM, IN_PLACE
 
         # compute coupling parameters
         Ab = params['fluid']['mhd']['phys_params']['A']
         Ah = params['kinetic']['energetic_ions']['phys_params']['A']
-        epsilon = self.equation_params['energetic_ions']['epsilon_unit']
+        epsilon = self.equation_params['energetic_ions']['epsilon']
 
         self._coupling_params = {}
         self._coupling_params['Ab'] = Ab
         self._coupling_params['Ah'] = Ah
 
         # background distribution function used as control variate
         if params['kinetic']['energetic_ions']['markers']['type'] == 'control_variate':
             assert 'background' in params['kinetic']['energetic_ions'], 'no background distribution function for control variate specified'
             control = True
             f0_name = params['kinetic']['energetic_ions']['background']['type']
             f0 = getattr(kin_ana, f0_name)(
-                **params['kinetic']['energetic_ions']['background'][f0_name])
+                maxw_params=params['kinetic']['energetic_ions']['background'][f0_name])
         else:
             control = False
             f0 = None
 
         # Project magnetic field
         self._b_eq = self.derham.P['2']([self.mhd_equil.b2_1,
                                          self.mhd_equil.b2_2,
                                          self.mhd_equil.b2_3])
 
-        self._abs_b = self.derham.P['0'](self.mhd_equil.absB0)
+        self._absB0 = self.derham.P['0'](self.mhd_equil.absB0)
 
         self._unit_b1 = self.derham.P['1']([self.mhd_equil.unit_b1_1,
                                            self.mhd_equil.unit_b1_2,
                                            self.mhd_equil.unit_b1_3])
 
         self._unit_b2 = self.derham.P['2']([self.mhd_equil.unit_b2_1,
                                            self.mhd_equil.unit_b2_2,
@@ -694,38 +697,37 @@
         self.add_propagator(self.prop_markers.PushDriftKineticbxGradB(
             self.pointer['energetic_ions'],
             epsilon=epsilon,
             b=self.pointer['b2'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
-            abs_b=self._abs_b,
+            abs_b=self._absB0,
             gradB1=self._gradB1,
             curl_unit_b2=self._curl_unit_b2,
             **algo_bxgradb))
         self.add_propagator(self.prop_markers.PushDriftKineticBstar(
             self.pointer['energetic_ions'],
             epsilon=epsilon,
             b=self.pointer['b2'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
-            abs_b=self._abs_b,
+            abs_b=self._absB0,
             gradB1=self._gradB1,
             curl_unit_b2=self._curl_unit_b2,
             **algo_bstar))
-        self.add_propagator(self.prop_coupling.CurrentCoupling5DGradBxB(
+        self.add_propagator(self.prop_coupling.CurrentCoupling5DGradB(
             self.pointer['energetic_ions'],
             self.pointer['mhd_u2'],
             epsilon=epsilon,
             b=self.pointer['b2'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
-            abs_b=self._abs_b,
             gradB1=self._gradB1,
             curl_unit_b2=self._curl_unit_b2,
             f0=f0,
             u_space='Hdiv',
             **params_cc2,
             **self._coupling_params,
             method=algo_cc2))
@@ -745,37 +747,34 @@
             self.pointer['mhd_u2'],
             particles=self.pointer['energetic_ions'],
             epsilon=epsilon,
             u_space='Hdiv',
             b_eq=self._b_eq,
             b_tilde=self.pointer['b2'],
             unit_b1=self._unit_b1,
-            abs_b=self._abs_b,
-            gradB1=self._gradB1,
             curl_unit_b2=self._curl_unit_b2,
             f0=f0,
             **params_density,
             **self._coupling_params))
         self.add_propagator(self.prop_fields.ShearAlfvénCurrentCoupling5D(
             self.pointer['mhd_u2'],
             self.pointer['b2'],
             particles=self.pointer['energetic_ions'],
-            b_eq=self._b_eq,
+            unit_b1=self._unit_b1,
             f0=f0,
             u_space='Hdiv',
             **params_shear_alfven,
             **self._coupling_params))
         self.add_propagator(self.prop_fields.MagnetosonicCurrentCoupling5D(
             self.pointer['mhd_n3'],
             self.pointer['mhd_u2'],
             self.pointer['mhd_p3'],
             b=self.pointer['b2'],
             particles=self.pointer['energetic_ions'],
             unit_b1=self._unit_b1,
-            curl_unit_b2=self._curl_unit_b2,
             f0=f0,
             u_space='Hdiv',
             **params_magnetosonic,
             **self._coupling_params))
 
         # Scalar variables to be saved during simulation
         self.add_scalar('en_U')
@@ -789,42 +788,29 @@
 
         # things needed in update_scalar_quantities
         self._mpi_sum = SUM
         self._mpi_in_place = IN_PLACE
 
         # temporaries
         self._b_full1 = self._b_eq.space.zeros()
-        self._PBb = self._abs_b.space.zeros()
+        self._PBb = self._absB0.space.zeros()
 
         self._en_fv = np.empty(1, dtype=float)
         self._en_fB = np.empty(1, dtype=float)
         self._en_fv_lost = np.empty(1, dtype=float)
         self._en_fB_lost = np.empty(1, dtype=float)
         self._n_lost_particles = np.empty(1, dtype=float)
 
-        if 'Hdiv' == 'Hcurl':
-            self._tmp_u = self.derham.Vh['1'].zeros()
-        elif 'Hdiv' == 'Hdiv':
-            self._tmp_u = self.derham.Vh['2'].zeros()
-        else:
-            self._tmp_u = self.derham.Vh['v'].zeros()
-
+        self._tmp_u = self.derham.Vh['2'].zeros()
         self._tmp_b = self.derham.Vh['2'].zeros()
 
     def update_scalar_quantities(self):
 
-        if 'Hdiv' == 'Hcurl':
-            self._mass_ops.M1n.dot(self.pointer['mhd_u2'], out=self._tmp_u)
-            en_U = self.pointer['mhd_u2'].dot(self._tmp_u)/2
-        elif 'Hdiv' == 'Hdiv':
-            self._mass_ops.M2n.dot(self.pointer['mhd_u2'], out=self._tmp_u)
-            en_U = self.pointer['mhd_u2'].dot(self._tmp_u)/2
-        else:
-            self._mass_ops.Mvn.dot(self.pointer['mhd_u2'], out=self._tmp_u)
-            en_U = self.pointer['mhd_u2'].dot(self._tmp_u)/2
+        self._mass_ops.M2n.dot(self.pointer['mhd_u2'], out=self._tmp_u)
+        en_U = self.pointer['mhd_u2'].dot(self._tmp_u)/2
 
         en_p = self.pointer['mhd_p3'].toarray().sum()/(5/3 - 1)
         self._mass_ops.M2.dot(self.pointer['b2'], out=self._tmp_b)
         en_B = self.pointer['b2'].dot(self._tmp_b)/2
 
         self.update_scalar('en_U', en_U)
         self.update_scalar('en_p', en_p)
@@ -833,60 +819,55 @@
         # self._scalar_quantities['en_p_eq'][0] = self._p_eq.dot(
         #     self._ones)/(5/3 - 1)
         # self._scalar_quantities['en_B_eq'][0] = self._b_eq.dot(
         #     self._mass_ops.M2.dot(self._b_eq, apply_bc=False))/2
 
         # calculate particle kinetic energy
         self._en_fv[0] = self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 5].dot(
-            self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 3]**2) / (2*self.pointer['energetic_ions'].n_mks)
+            self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 3]**2) / (2*self.pointer['energetic_ions'].n_mks)*self._coupling_params['Ah']/self._coupling_params['Ab']
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._en_fv, op=self._mpi_sum)
 
         self.update_scalar('en_fv', self._en_fv[0])
 
         self._en_fv_lost[0] = self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 5].dot(
-            self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 3]**2) / (2.*self.pointer['energetic_ions'].n_mks)
+            self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 3]**2) / (2.*self.pointer['energetic_ions'].n_mks)*self._coupling_params['Ah']/self._coupling_params['Ab']
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._en_fv_lost, op=self._mpi_sum)
 
         self.update_scalar('en_fv_lost', self._en_fv_lost[0])
 
-        # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
-        self._b_eq.copy(out=self._b_full1)
-        self._b_full1 += self.pointer['b2']
-        self._b_full1.update_ghost_regions()
-
-        # self._scalar_quantities['en_B_tot'][0] = (self._b_full1).dot(
-        #     self._mass_ops.M2.dot(self._b_full1, apply_bc=False))/2.
-
-        # absolute value of parallel magnetic field
-        self._prop.basis_ops.PB.dot(self.pointer['b2'], out=self._PBb)
-        self._PBb += self._abs_b
+        # calculate particle magnetic energy
+        self.pointer['energetic_ions'].save_magnetic_energy(self._absB0, 
+                                                            self._unit_b1, 
+                                                            self.pointer['b2'])
 
-        self.pointer['energetic_ions'].save_magnetic_energy(self._PBb)
         self._en_fB[0] = self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 5].dot(
-            self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 8])/self.pointer['energetic_ions'].n_mks
+            self.pointer['energetic_ions'].markers[~self.pointer['energetic_ions'].holes, 8])/self.pointer['energetic_ions'].n_mks*self._coupling_params['Ah']/self._coupling_params['Ab']
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._en_fB, op=self._mpi_sum)
 
         self.update_scalar('en_fB', self._en_fB[0])
 
         self._en_fB_lost[0] = self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 5].dot(
-            self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 8]) / self.pointer['energetic_ions'].n_mks
+            self.pointer['energetic_ions'].lost_markers[:self.pointer['energetic_ions'].n_lost_markers, 8]) / self.pointer['energetic_ions'].n_mks*self._coupling_params['Ah']/self._coupling_params['Ab']
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._en_fB_lost, op=self._mpi_sum)
 
         self.update_scalar('en_fB_lost', self._en_fB_lost[0])
 
-        self.update_scalar('en_tot', en_U + en_p + en_B +
-                           self._en_fv[0] + self._en_fv_lost[0] + self._en_fB[0] + self._en_fB_lost[0])
+        # self.update_scalar('en_tot', en_U + en_p + en_B +
+        #                    self._en_fv[0] + self._en_fv_lost[0] + self._en_fB[0] + self._en_fB_lost[0])
+    
+        self.update_scalar('en_tot', en_U + en_B + en_p + self._en_fv[0] + self._en_fB[0])
         
         self._n_lost_particles[0] = self.pointer['energetic_ions'].n_lost_markers
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._n_lost_particles, op=self._mpi_sum)
+
         if self.derham.comm.Get_rank() == 0 :
             print('ratio of lost particles: ',self._n_lost_particles[0]/self.pointer['energetic_ions'].n_mks*100,'%')
 
 
 class ColdPlasmaVlasov(StruphyModel):
     r'''Cold plasma hybrid model
 
@@ -957,15 +938,15 @@
         return 'light'
 
     @classmethod
     def options(cls):
         # import propagator options
         from struphy.propagators.propagators_fields import Maxwell, OhmCold, JxBCold, ImplicitDiffusion
         from struphy.propagators.propagators_markers import PushEta, PushVxB
-        from struphy.propagators.propagators_coupling import VlasovMaxwell
+        from struphy.propagators.propagators_coupling import VlasovAmpere
 
         dct = {}
         cls.add_option(species=['em_fields'], key=['solvers', 'maxwell'],
                        option=Maxwell.options()['solver'], dct=dct)
         cls.add_option(species=['em_fields'], key=['solvers', 'poisson'],
                        option=ImplicitDiffusion.options()['solver'], dct=dct)
         cls.add_option(species=['fluid', 'coldelectrons'], key=['solvers', 'ohmcold'],
@@ -973,15 +954,15 @@
         cls.add_option(species=['fluid', 'coldelectrons'], key=['solvers', 'jxbcold'],
                        option=JxBCold.options()['solver'], dct=dct)
         cls.add_option(species=['kinetic', 'hotelectrons'], key=['algos', 'push_eta'],
                        option=PushEta.options()['algo'], dct=dct)
         cls.add_option(species=['kinetic', 'hotelectrons'], key=['algos', 'push_vxb'],
                        option=PushVxB.options()['algo'], dct=dct)
         cls.add_option(species=['kinetic', 'hotelectrons'], key=['solver'],
-                       option=VlasovMaxwell.options()['solver'], dct=dct)
+                       option=VlasovAmpere.options()['solver'], dct=dct)
         return dct
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm)
 
         from mpi4py.MPI import SUM, IN_PLACE
@@ -990,17 +971,17 @@
         self._rank = comm.Get_rank()
 
         # prelim
         electron_params = params['kinetic']['hotelectrons']
 
         # model parameters
         self._alpha = np.abs(
-            self.equation_params['coldelectrons']['alpha_unit'])
-        self._epsilon_cold = self.equation_params['coldelectrons']['epsilon_unit']
-        self._epsilon_hot = self.equation_params['hotelectrons']['epsilon_unit']
+            self.equation_params['coldelectrons']['alpha'])
+        self._epsilon_cold = self.equation_params['coldelectrons']['epsilon']
+        self._epsilon_hot = self.equation_params['hotelectrons']['epsilon']
 
         self._nu = electron_params['phys_params']['Z'] / \
             params['fluid']['coldelectrons']['phys_params']['Z']
 
         # Initialize background magnetic field from MHD equilibrium
         self._b_background = self.derham.P['2']([self.mhd_equil.b2_1,
                                                  self.mhd_equil.b2_2,
@@ -1036,15 +1017,15 @@
             bc_type=electron_params['markers']['bc']['type']))
         self.add_propagator(self.prop_markers.PushVxB(
             self.pointer['hotelectrons'],
             algo=algo_vxb,
             scale_fac=1/self._epsilon_cold,
             b_eq=self._b_background,
             b_tilde=self.pointer['b2']))
-        self.add_propagator(self.prop_coupling.VlasovMaxwell(
+        self.add_propagator(self.prop_coupling.VlasovAmpere(
             self.pointer['e1'],
             self.pointer['hotelectrons'],
             c1=self._nu * self._alpha**2/self._epsilon_cold,
             c2=1/self._epsilon_hot,
             **params_coupling))
 
         # Scalar variables to be saved during simulation
@@ -1081,16 +1062,16 @@
             charge_accum._vectors[0][:] -= np.mean(charge_accum.vectors[0].toarray()[
                                                    charge_accum.vectors[0].toarray() != 0])
 
         # Instantiate Poisson solver
         _phi = StencilVector(self.derham.Vh['0'])
         poisson_solver = self.prop_fields.ImplicitDiffusion(
             _phi,
-            sigma=0,
-            phi_n=self._nu * self._alpha**2 /
+            sigma_1=0,
+            rho=self._nu * self._alpha**2 /
             self._epsilon_cold * charge_accum.vectors[0],
             x0=self._nu * self._alpha**2 /
             self._epsilon_cold * charge_accum.vectors[0],
             **self._poisson_params)
 
         # Solve with dt=1. and compute electric field
         poisson_solver(1.)
```

### Comparing `struphy-2.2.0/src/struphy/models/kinetic.py` & `struphy-2.3.0/src/struphy/models/kinetic.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,47 +1,340 @@
 import numpy as np
 from struphy.models.base import StruphyModel
 
 
-class VlasovMaxwell(StruphyModel):
-    r'''Vlasov Maxwell equations with Poisson splitting.
+class VlasovAmpereOneSpecies(StruphyModel):
+    r'''Vlasov-Ampère equations for one species.
 
     :ref:`normalization`:
 
     .. math::
 
+        \hat v = c\,,\qquad \hat E = \frac{(A m_\textnormal{H})\hat v^2}{(Z e) \hat x} \,, \qquad  \hat \phi = \hat E \hat x \,.
+
+    Implemented equations: find :math:`(\mathbf E, f) \in H(\textnormal{curl}) \times C^\infty` such that
+
+    .. math::
+
         \begin{align}
-            c & = \frac{\hat \omega}{\hat k} = \frac{\hat E}{\hat B} = \hat v \,, \qquad  \hat f = \frac{\hat n}{c^3} \,.
+            -\int_\Omega \mathbf F\, \cdot \, &\frac{\partial \mathbf{E}}{\partial t}\,\textrm d \mathbf x = 
+            \kappa^2 \int_\Omega \int_{\mathbb{R}^3} \mathbf F \cdot \mathbf{v} f \, \text{d}^3 \mathbf{v}\,\textrm d \mathbf x \qquad \forall \ \mathbf F \in H(\textnormal{curl})\,,
+            \\[2mm]
+            &\frac{\partial f}{\partial t} + \mathbf{v} \cdot \, \nabla f + \mathbf{E}
+            \cdot \frac{\partial f}{\partial \mathbf{v}} = 0 \,,
         \end{align}
 
-    Implemented equations:
+    with the normalization parameter
+
+    .. math::
+
+        \kappa = \hat \Omega_\textnormal{p}\hat t\,,\qquad \textnormal{with} \qquad \hat\Omega_\textnormal{p} = \sqrt{\frac{\hat n (Ze)^2}{\epsilon_0 (A m_\textnormal{H})}} \,,
+
+    where :math:`Z=-1` and :math:`A=1/1836` for electrons. 
+    At initial time the weak Poisson equation is solved once to weakly satisfy Gauss' law,
+
+    .. math::
+
+            \begin{align}
+            \int_\Omega \nabla \psi^\top \cdot \nabla \phi \,\textrm d \mathbf x &= \kappa^2 \left(\frac{Z_0}{Z}\int_\Omega \psi\, n_0\,\textrm d \mathbf x + \int_\Omega \int_{\mathbb{R}^3} \psi\, f(t=0) \, \text{d}^3 \mathbf{v}\,\textrm d \mathbf x \right) \qquad \forall \ \psi \in H^1\,,
+            \\[2mm]
+            \mathbf{E}(t=0) &= -\nabla \phi(t=0)\,,
+            \end{align}
+
+    where :math:`Z_0 \in \mathbb Z` and :math:`n_0:\Omega \to \mathbb R^+` denote the charge number and the number density 
+    of the neutralizing background, respectively, such that
+
+    .. math::
+
+        \frac{Z_0}{Z} n_0 = - \int_{\mathbb{R}^3} f_0 \, \text{d}^3 \mathbf{v} < 0\,,
+
+    where :math:`f_0` is the kinetic background distribution (static). 
+    Moreover, it is assumed that
+
+    .. math::
+
+        \int_{\mathbb{R}^3} \mathbf{v} f_0 \, \text{d}^3 \mathbf{v} = 0\,.
+
+    Notes
+    -----
+
+    * The Poisson equation is solved with the :ref:`control_var`.
+
+    * The :ref:`control_var` for Ampère's law is optional; in case it is enabled via the parameter file, the following system is solved: 
+    Find :math:`(\mathbf E, f) \in H(\textnormal{curl}) \times C^\infty` such that
 
     .. math::
 
         \begin{align}
-            &\frac{\partial \mathbf{E}}{\partial t} - \nabla \times \mathbf{B} = -
-            \frac{\alpha^2}{\varepsilon} \int_{\mathbb{R}^3} \mathbf{v} f \, \text{d}^3 \mathbf{v} \,,
-            \\[1mm]
+            -\int_\Omega \mathbf F\, \cdot \, &\frac{\partial \mathbf{E}}{\partial t}\,\textrm d \mathbf x = 
+            \kappa^2 \int_\Omega \int_{\mathbb{R}^3} \mathbf F \cdot \mathbf{v} (f - f_0) \, \text{d}^3 \mathbf{v}\,\textrm d \mathbf x \qquad \forall \ \mathbf F \in H(\textnormal{curl}) \,,
+            \\[2mm]
+            &\frac{\partial f}{\partial t} + \mathbf{v} \cdot \, \nabla f + \mathbf{E} \cdot \frac{\partial f}{\partial \mathbf{v}} = 0 \,.
+        \end{align}
+
+
+    Parameters
+    ----------
+    params : dict
+        Simulation parameters, see from :ref:`params_yml`.
+
+    comm : mpi4py.MPI.Intracomm
+        MPI communicator used for parallelization.
+    '''
+
+    @classmethod
+    def species(cls):
+        dct = {'em_fields': {}, 'fluid': {}, 'kinetic': {}}
+
+        dct['em_fields']['e1'] = 'Hcurl'
+        dct['kinetic']['species1'] = 'Particles6D'
+        return dct
+
+    @classmethod
+    def bulk_species(cls):
+        return 'species1'
+
+    @classmethod
+    def velocity_scale(cls):
+        return 'light'
+
+    @classmethod
+    def options(cls):
+        # import propagator options
+        from struphy.propagators.propagators_fields import ImplicitDiffusion
+        from struphy.propagators.propagators_markers import PushEta
+        from struphy.propagators.propagators_coupling import VlasovAmpere
+
+        dct = {}
+        cls.add_option(species='em_fields', key=['solvers', 'poisson'],
+                       option=ImplicitDiffusion.options()['solver'], dct=dct)
+        cls.add_option(species=['kinetic', 'species1'], key=['algos', 'push_eta'],
+                       option=PushEta.options()['algo'], dct=dct)
+        cls.add_option(species=['kinetic', 'species1'], key='coupling_solver',
+                       option=VlasovAmpere.options()['solver'], dct=dct)
+        cls.add_option(species=['kinetic', 'species1'], key='verification',
+                       option={'set_kappa': False, 'value': 1.}, dct=dct)
+        cls.add_option(species=['kinetic', 'species1'], key='Z0',
+                       option=-1., dct=dct)
+
+        return dct
+
+    def __init__(self, params, comm=None):
+
+        super().__init__(params, comm=comm)
+
+        from mpi4py.MPI import SUM, IN_PLACE
+
+        # get rank and size
+        if self.comm is None:
+            self._rank = 0
+        else:
+            self._rank = self.comm.Get_rank()
+
+        # get species paramaters
+        spec_params = params['kinetic']['species1']
+
+        # equation parameters
+        if spec_params['options']['verification']['set_kappa']:
+            self._kappa = spec_params['options']['verification']['value']
+            print(
+                f'\n!!! Verification run: equation parameters set to {self._kappa = }.')
+        else:
+            self._kappa = self.equation_params['species1']['kappa']
+
+        # set background density factor
+        Z0 = spec_params['options']['Z0']
+        Z = spec_params['phys_params']['Z']
+        assert Z0 * \
+            Z < 0, f'Neutralizing background has wrong polarity {Z0 = } to {Z = }.'
+
+        self.pointer['species1'].f_backgr.moment_factors['n'] = - Z0/Z
+
+        # check mean velocity
+        # TODO: assert f_backgr.params[] == 0.
+
+        # propagator parameters
+        self._poisson_params = params['em_fields']['options']['solvers']['poisson']
+        algo_eta = params['kinetic']['species1']['options']['algos']['push_eta']
+        params_coupling = params['kinetic']['species1']['options']['coupling_solver']
+
+        self.add_propagator(self.prop_markers.PushEta(
+            self.pointer['species1'],
+            algo=algo_eta,
+            bc_type=spec_params['markers']['bc']['type']))
+
+        self.add_propagator(self.prop_coupling.VlasovAmpere(
+            self.pointer['e1'],
+            self.pointer['species1'],
+            c1=self._kappa**2,
+            **params_coupling))
+
+        # Scalar variables to be saved during the simulation
+        self.add_scalar('en_E')
+        self.add_scalar('en_f')
+        self.add_scalar('en_tot')
+
+        # MPI operations needed for scalar variables
+        self._mpi_sum = SUM
+        self._mpi_in_place = IN_PLACE
+
+        # temporaries
+        self._tmp1 = self.derham.Vh['1'].zeros()
+        self._tmp = np.empty(1, dtype=float)
+
+    def initialize_from_params(self):
+        '''Solve initial Poisson equation.
+
+        :meta private:
+        '''
+
+        from struphy.pic.accumulation.particles_to_grid import AccumulatorVector
+
+        # initialize fields and particles
+        super().initialize_from_params()
+
+        if self._rank == 0:
+            print('\nINITIAL POISSON SOLVE:')
+
+        # use control variate method
+        self.pointer['species1'].update_weights()
+
+        # sanity check
+        # self.pointer['species1'].show_distribution_function(
+        #     [True] + [False]*5, [np.linspace(0, 1, 32)])
+
+        # accumulate charge density
+        charge_accum = AccumulatorVector(
+            self.derham, self.domain, "H1", "charge_density_0form")
+        charge_accum.accumulate(self.pointer['species1'])
+
+        # another sanity check: compute FE coeffs of density
+        # charge_accum.show_accumulated_spline_field(self.mass_ops)
+
+        # Instantiate Poisson solver
+        _phi = self.derham.Vh['0'].zeros()
+        poisson_solver = self.prop_fields.ImplicitDiffusion(
+            _phi,
+            sigma_1=0.,
+            sigma_2=0.,
+            sigma_3=1.,
+            rho=self._kappa**2 * charge_accum.vectors[0],
+            **self._poisson_params)
+
+        # Solve with dt=1. and compute electric field
+        if self._rank == 0:
+            print('\nSolving initial Poisson problem...')
+        poisson_solver(1.)
+
+        self.derham.grad.dot(-_phi, out=self.pointer['e1'])
+        if self._rank == 0:
+            print('Done.')
+
+    def update_scalar_quantities(self):
+
+        # e*M1*e/2
+        self.mass_ops.M1.dot(self.pointer['e1'], out=self._tmp1)
+        en_E = self.pointer['e1'].dot(self._tmp1) / 2.
+        self.update_scalar('en_E', en_E)
+
+        # kappa^2 / 2 / N * sum_p w_p v_p^2
+        self._tmp[0] = self._kappa**2 / (2 * self.pointer['species1'].n_mks) * \
+            np.dot(self.pointer['species1'].markers_wo_holes[:, 3]**2 +
+                   self.pointer['species1'].markers_wo_holes[:, 4]**2 +
+                   self.pointer['species1'].markers_wo_holes[:, 5]**2,
+                   self.pointer['species1'].markers_wo_holes[:, 6])
+        if self.comm is not None:
+            self.comm.Allreduce(
+                self._mpi_in_place, self._tmp, op=self._mpi_sum)
+        self.update_scalar('en_f', self._tmp[0])
+
+        # en_tot = en_w + en_e
+        self.update_scalar('en_tot', en_E + self._tmp[0])
+
+
+class VlasovMaxwellOneSpecies(StruphyModel):
+    r'''Vlasov-Maxwell equations for one species.
+
+    :ref:`normalization`:
+
+    .. math::
+
+        \begin{align}
+            \hat v  = c \,, \qquad \hat E = \hat B \hat v\,,\qquad  \hat \phi = \hat E \hat x \,.
+        \end{align}
+
+    Implemented equations: find :math:`(\mathbf E, \mathbf B, f) \in H(\textnormal{curl}) \times H(\textnormal{div}) \times C^\infty` such that
+
+    .. math::
+
+        \begin{align}
+            -\int_\Omega \mathbf F\, \cdot \, &\frac{\partial \mathbf{E}}{\partial t}\,\textrm d \mathbf x + \int_\Omega \nabla \times \mathbf{F} \cdot \mathbf B\,\textrm d \mathbf x = 
+            \frac{\alpha^2}{\varepsilon} \int_\Omega \int_{\mathbb{R}^3} \mathbf F \cdot \mathbf{v} f \, \text{d}^3 \mathbf{v}\,\textrm d \mathbf x \qquad \forall \ \mathbf F \in H(\textnormal{curl})\,,
+            \\[2mm]
             &\frac{\partial \mathbf{B}}{\partial t} + \nabla \times \mathbf{E} = 0 \,,
-            \\[1mm]
-            &\partial_t f + \mathbf{v} \cdot \, \nabla f + \frac{1}{\varepsilon}\Big[ \mathbf{E} + \mathbf{v} \times \left( \mathbf{B} + \mathbf{B}_0 \right) \Big]
-            \cdot \frac{\partial f}{\partial \mathbf{v}} = 0 \,.
+            \\[2mm]
+            &\frac{\partial f}{\partial t} + \mathbf{v} \cdot \, \nabla f + \frac{1}{\varepsilon}\Big[ \mathbf{E} + \mathbf{v} \times \mathbf{B} \Big]
+            \cdot \frac{\partial f}{\partial \mathbf{v}} = 0 \,,
         \end{align}
 
-    where :math:`\mathbf B_0` is an equilibrium magnetic field and
+    with the normalization parameters
+
+    .. math::
+
+        \alpha = \frac{\hat \Omega_\textnormal{p}}{\hat \Omega_\textnormal{c}}\,,\qquad \varepsilon = \frac{1}{\hat \Omega_\textnormal{c} \hat t} \,,\qquad \textnormal{with} \qquad \hat\Omega_\textnormal{p} = \sqrt{\frac{\hat n (Ze)^2}{\epsilon_0 (A m_\textnormal{H})}} \,,\qquad \hat \Omega_{\textnormal{c}} = \frac{(Ze) \hat B}{(A m_\textnormal{H})}\,,
+
+    where :math:`Z=-1` and :math:`A=1/1836` for electrons. 
+    At initial time the weak Poisson equation is solved once to weakly satisfy Gauss' law,
 
     .. math::
 
-        \alpha = \frac{\hat \Omega_\textnormal{p}}{\hat \Omega_\textnormal{c}}\,,\qquad \varepsilon = \frac{\hat \omega}{\hat \Omega_\textnormal{c}} \,,\qquad \textnormal{with} \qquad \hat\Omega_\textnormal{p} = \sqrt{\frac{\hat n (Ze)^2}{\epsilon_0 A m_\textnormal{H}}} \,,\qquad \hat \Omega_{\textnormal{c}} = \frac{Ze \hat B}{A m_\textnormal{H}}\,.
+            \begin{align}
+            \int_\Omega \nabla \psi^\top \cdot \nabla \phi \,\textrm d \mathbf x &= \frac{\alpha^2}{\varepsilon} \left( \frac{Z_0}{Z}\int_\Omega \psi\, n_0\,\textrm d \mathbf x + \int_\Omega \int_{\mathbb{R}^3} \psi\, f(t=0) \, \text{d}^3 \mathbf{v}\,\textrm d \mathbf x \right) \qquad \forall \ \psi \in H^1\,,
+            \\[2mm]
+            \mathbf{E}(t=0) &= -\nabla \phi(t=0)\,,
+            \end{align}
+
+    where :math:`Z_0 \in \mathbb Z` and :math:`n_0:\Omega \to \mathbb R^+` denote the charge number and the number density 
+    of the neutralizing background, respectively, such that
+
+    .. math::
+
+        \frac{Z_0}{Z} n_0 = - \int_{\mathbb{R}^3} f_0 \, \text{d}^3 \mathbf{v} < 0\,,
 
-    At initial time the Poisson equation is solved once to weakly satisfy Gauss' law
+    where :math:`f_0` is the kinetic background distribution (static). 
+    Moreover, it is assumed that
 
     .. math::
 
-            \nabla \cdot \mathbf{E} = \frac{\alpha^2}{\varepsilon} \int_{\mathbb{R}^3} f \, \text{d}^3 \mathbf{v}\,.
+        \nabla \times \mathbf B_0 = \frac{\alpha^2}{\varepsilon} \int_{\mathbb{R}^3} \mathbf{v} f_0 \, \text{d}^3 \mathbf{v}\,,
+
+    where :math:`\mathbf B_0` is the static equilibirum magnetic field.
+
+    Notes
+    -----
+
+    * The Poisson equation is solved with the :ref:`control_var`.
+
+    * The :ref:`control_var` for Ampère's law is optional; in case it is enabled via the parameter file, the following system is solved: 
+    Find :math:`(\mathbf E, \tilde{\mathbf B}, f) \in H(\textnormal{curl}) \times H(\textnormal{div}) \times C^\infty` such that
+
+    .. math::
+
+        \begin{align}
+            -\int_\Omega \mathbf F\, \cdot \, &\frac{\partial \mathbf{E}}{\partial t}\,\textrm d \mathbf x + \int_\Omega \nabla \times \mathbf{F} \cdot \tilde{\mathbf B}\,\textrm d \mathbf x = 
+            \frac{\alpha^2}{\varepsilon} \int_\Omega \int_{\mathbb{R}^3} \mathbf F \cdot \mathbf{v} (f - f_0) \, \text{d}^3 \mathbf{v}\,\textrm d \mathbf x \qquad \forall \ \mathbf F \in H(\textnormal{curl}) \,,
+            \\[2mm]
+            &\frac{\partial \tilde{\mathbf B}}{\partial t} + \nabla \times \mathbf{E} = 0 \,,
+            \\[2mm]
+            &\frac{\partial f}{\partial t} + \mathbf{v} \cdot \, \nabla f + \frac{1}{\varepsilon}\Big[ \mathbf{E} + \mathbf{v} \times (\mathbf{B}_0 + \tilde{\mathbf B}) \Big]
+            \cdot \frac{\partial f}{\partial \mathbf{v}} = 0 \,,
+        \end{align}
+
+    where :math:`\tilde{\mathbf B} = \mathbf B - \mathbf B_0` denotes the magnetic perturbation.
+
 
     Parameters
     ----------
     params : dict
         Simulation parameters, see from :ref:`params_yml`.
 
     comm : mpi4py.MPI.Intracomm
@@ -50,103 +343,117 @@
 
     @classmethod
     def species(cls):
         dct = {'em_fields': {}, 'fluid': {}, 'kinetic': {}}
 
         dct['em_fields']['e1'] = 'Hcurl'
         dct['em_fields']['b2'] = 'Hdiv'
-        dct['kinetic']['electrons'] = 'Particles6D'
+        dct['kinetic']['species1'] = 'Particles6D'
         return dct
 
     @classmethod
     def bulk_species(cls):
-        return 'electrons'
+        return 'species1'
 
     @classmethod
     def velocity_scale(cls):
         return 'light'
 
     @classmethod
     def options(cls):
         # import propagator options
         from struphy.propagators.propagators_fields import Maxwell, ImplicitDiffusion
         from struphy.propagators.propagators_markers import PushEta, PushVxB
-        from struphy.propagators.propagators_coupling import VlasovMaxwell
+        from struphy.propagators.propagators_coupling import VlasovAmpere
 
         dct = {}
         cls.add_option(species='em_fields', key=['solvers', 'maxwell'],
                        option=Maxwell.options()['solver'], dct=dct)
         cls.add_option(species='em_fields', key=['solvers', 'poisson'],
                        option=ImplicitDiffusion.options()['solver'], dct=dct)
-        cls.add_option(species=['kinetic', 'electrons'], key=['algos', 'push_eta'],
+        cls.add_option(species=['kinetic', 'species1'], key=['algos', 'push_eta'],
                        option=PushEta.options()['algo'], dct=dct)
-        cls.add_option(species=['kinetic', 'electrons'], key=['algos', 'push_vxb'],
+        cls.add_option(species=['kinetic', 'species1'], key=['algos', 'push_vxb'],
                        option=PushVxB.options()['algo'], dct=dct)
-        cls.add_option(species=['kinetic', 'electrons'], key='solver',
-                       option=VlasovMaxwell.options()['solver'], dct=dct)
+        cls.add_option(species=['kinetic', 'species1'], key='coupling_solver',
+                       option=VlasovAmpere.options()['solver'], dct=dct)
+        cls.add_option(species=['kinetic', 'species1'], key='verification',
+                       option=False, dct=dct)
+        cls.add_option(species=['kinetic', 'species1'], key='Z0',
+                       option=-1., dct=dct)
 
         return dct
 
-    def __init__(self, params, comm):
+    def __init__(self, params, comm=None):
 
-        super().__init__(params, comm)
+        super().__init__(params, comm=comm)
 
         from mpi4py.MPI import SUM, IN_PLACE
 
-        # Get rank and size
-        self._rank = comm.Get_rank()
+        # get rank and size
+        if self.comm is None:
+            self._rank = 0
+        else:
+            self._rank = self.comm.Get_rank()
 
-        # prelim
-        electron_params = params['kinetic']['electrons']
+        # get species paramaters
+        spec_params = params['kinetic']['species1']
 
-        self._marker_type = electron_params['markers']['type']
-        assert self._marker_type in ['full_f', 'control_variate']
-        if self._marker_type == 'full_f':
-            f0 = None
+        # equation parameters
+        if spec_params['options']['verification']:
+            self._alpha = 1.
+            self._epsilon = -1.
+            print(
+                f'\n!!! Verification run: equation parameters set to {self._alpha = } and {self._epsilon = }.')
         else:
-            f0 = self.pointer['electrons'].f_backgr
+            self._alpha = self.equation_params['species1']['alpha']
+            self._epsilon = self.equation_params['species1']['epsilon']
 
-        # model parameters
-        self._alpha = self.equation_params['electrons']['alpha_unit']
-        self._epsilon = self.equation_params['electrons']['epsilon_unit']
+        # set background density and mean velocity factors
+        Z0 = spec_params['options']['Z0']
+        Z = spec_params['phys_params']['Z']
+        assert Z0 * \
+            Z < 0, f'Neutralizing background has wrong polarity {Z0 = } to {Z = }.'
+
+        self.pointer['species1'].f_backgr.moment_factors['n'] = - Z0/Z
+        self.pointer['species1'].f_backgr.moment_factors['u'] = [self._epsilon/self._alpha**2]*3
 
-        # ====================================================================================
         # Initialize background magnetic field from MHD equilibrium
-        self._b_background = self.derham.P['2']([self.mhd_equil.b2_1,
-                                                 self.mhd_equil.b2_2,
-                                                 self.mhd_equil.b2_3])
+        b_backgr = self.derham.P['2']([self.mhd_equil.b2_1,
+                                       self.mhd_equil.b2_2,
+                                       self.mhd_equil.b2_3])
 
-        # propagator params
+        # propagator parameters
         params_maxwell = params['em_fields']['options']['solvers']['maxwell']
         self._poisson_params = params['em_fields']['options']['solvers']['poisson']
-        algo_eta = params['kinetic']['electrons']['options']['algos']['push_eta']
-        algo_vxb = params['kinetic']['electrons']['options']['algos']['push_vxb']
-        params_coupling = params['kinetic']['electrons']['options']['solver']
+        algo_eta = params['kinetic']['species1']['options']['algos']['push_eta']
+        algo_vxb = params['kinetic']['species1']['options']['algos']['push_vxb']
+        params_coupling = params['kinetic']['species1']['options']['coupling_solver']
 
         # Initialize propagators/integrators used in splitting substeps
         self.add_propagator(self.prop_fields.Maxwell(
             self.pointer['e1'],
             self.pointer['b2'],
             **params_maxwell))
 
         self.add_propagator(self.prop_markers.PushEta(
-            self.pointer['electrons'],
+            self.pointer['species1'],
             algo=algo_eta,
-            bc_type=electron_params['markers']['bc']['type']))
+            bc_type=spec_params['markers']['bc']['type']))
 
         self.add_propagator(self.prop_markers.PushVxB(
-            self.pointer['electrons'],
+            self.pointer['species1'],
             algo=algo_vxb,
             scale_fac=1/self._epsilon,
-            b_eq=self._b_background,
+            b_eq=b_backgr,
             b_tilde=self.pointer['b2']))
 
-        self.add_propagator(self.prop_coupling.VlasovMaxwell(
+        self.add_propagator(self.prop_coupling.VlasovAmpere(
             self.pointer['e1'],
-            self.pointer['electrons'],
+            self.pointer['species1'],
             c1=self._alpha**2/self._epsilon,
             c2=1/self._epsilon,
             **params_coupling))
 
         # Scalar variables to be saved during the simulation
         self.add_scalar('en_E')
         self.add_scalar('en_B')
@@ -162,68 +469,74 @@
         self._tmp2 = self.derham.Vh['2'].zeros()
         self._tmp = np.empty(1, dtype=float)
 
     def initialize_from_params(self):
         ''':meta private:'''
 
         from struphy.pic.accumulation.particles_to_grid import AccumulatorVector
-        from struphy.feec.projectors import L2Projector
-        from psydac.linalg.stencil import StencilVector
 
-        # Initialize fields and particles
+        # initialize fields and particles
         super().initialize_from_params()
 
         if self._rank == 0:
             print('\nINITIAL POISSON SOLVE:')
 
-        # Accumulate charge density
+        # use control variate method
+        self.pointer['species1'].update_weights()
+
+        # sanity check
+        # self.pointer['species1'].show_distribution_function(
+        #     [True] + [False]*5, [np.linspace(0, 1, 32)])
+
+        # accumulate charge density
         charge_accum = AccumulatorVector(
-            self.derham, self.domain, "H1", "vlasov_maxwell_poisson")
-        charge_accum.accumulate(self.pointer['electrons'])
+            self.derham, self.domain, "H1", "charge_density_0form")
+        charge_accum.accumulate(self.pointer['species1'])
 
-        # add contribution from background in control variate method
-        if self._marker_type == 'control_variate':
-            _proj = L2Projector(self._mass_ops.M0, space='H1', derham=self.derham)
-            _phi_bckgr = _proj(self.pointer['electrons'].f_backgr.n)
-            # TODO: what to do with this?
+        # another sanity check: compute FE coeffs of density
+        # charge_accum.show_accumulated_spline_field(self.mass_ops)
 
         # Instantiate Poisson solver
-        _phi = StencilVector(self.derham.Vh['0'])
+        _phi = self.derham.Vh['0'].zeros()
         poisson_solver = self.prop_fields.ImplicitDiffusion(
             _phi,
-            sigma=1e-11,
-            phi_n=self._alpha**2 / self._epsilon * charge_accum.vectors[0],
-            x0=self._alpha**2 / self._epsilon * charge_accum.vectors[0],
+            sigma_1=0.,
+            sigma_2=0.,
+            sigma_3=1.,
+            rho=self._alpha**2 / self._epsilon * charge_accum.vectors[0],
             **self._poisson_params)
 
         # Solve with dt=1. and compute electric field
         if self._rank == 0:
-            print('Solving ...')
+            print('\nSolving initial Poisson problem...')
         poisson_solver(1.)
 
         self.derham.grad.dot(-_phi, out=self.pointer['e1'])
         if self._rank == 0:
             print('Done.')
 
     def update_scalar_quantities(self):
+
+        # e*M1*e and b*M2*b
         self._mass_ops.M1.dot(self.pointer['e1'], out=self._tmp1)
         self._mass_ops.M2.dot(self.pointer['b2'], out=self._tmp2)
         en_E = self.pointer['e1'].dot(self._tmp1) / 2.
         en_B = self.pointer['b2'].dot(self._tmp2) / 2.
         self.update_scalar('en_E', en_E)
         self.update_scalar('en_B', en_B)
 
         # alpha^2 / 2 / N * sum_p w_p v_p^2
-        self._tmp[0] = self._alpha**2 / (2 * self.pointer['electrons'].n_mks) * \
-            np.dot(self.pointer['electrons'].markers_wo_holes[:, 3]**2 +
-                   self.pointer['electrons'].markers_wo_holes[:, 4] ** 2 +
-                   self.pointer['electrons'].markers_wo_holes[:, 5]**2,
-                   self.pointer['electrons'].markers_wo_holes[:, 6])
-        self.derham.comm.Allreduce(
-            self._mpi_in_place, self._tmp, op=self._mpi_sum)
+        self._tmp[0] = self._alpha**2 / (2 * self.pointer['species1'].n_mks) * \
+            np.dot(self.pointer['species1'].markers_wo_holes[:, 3]**2 +
+                   self.pointer['species1'].markers_wo_holes[:, 4] ** 2 +
+                   self.pointer['species1'].markers_wo_holes[:, 5]**2,
+                   self.pointer['species1'].markers_wo_holes[:, 6])
+        if self.comm is not None:
+            self.comm.Allreduce(
+                self._mpi_in_place, self._tmp, op=self._mpi_sum)
         self.update_scalar('en_f', self._tmp[0])
 
         # en_tot = en_w + en_e + en_b
         self.update_scalar('en_tot', en_E + en_B + self._tmp[0])
 
 
 class LinearVlasovMaxwell(StruphyModel):
@@ -303,17 +616,17 @@
         from struphy.propagators.propagators_coupling import EfieldWeightsImplicit
         dct = {}
         cls.add_option(['em_fields'], ['solvers', 'maxwell'],
                        Maxwell.options()['solver'], dct)
         cls.add_option(['em_fields'], ['solvers', 'poisson'],
                        ImplicitDiffusion.options()['solver'], dct)
         cls.add_option(['kinetic', 'electrons'], ['algos', 'push_eta'],
-                        PushEta.options()['algo'], dct)
+                       PushEta.options()['algo'], dct)
         cls.add_option(['kinetic', 'electrons'], ['algos', 'push_vxb'],
-                        PushVxB.options()['algo'], dct)
+                       PushVxB.options()['algo'], dct)
         cls.add_option(['kinetic', 'electrons'], ['solver'],
                        EfieldWeightsImplicit.options()['solver'], dct)
         return dct
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm)
@@ -324,56 +637,56 @@
         # Get rank and size
         self._rank = comm.Get_rank()
 
         # prelim
         self._electron_params = params['kinetic']['electrons']
 
         # kinetic background
-        assert self._electron_params['background']['type'] == 'Maxwellian6DUniform', \
+        assert self._electron_params['background']['type'] == 'Maxwellian6D', \
             AssertionError(
                 "The background distribution function must be a uniform Maxwellian!")
 
-        self._maxwellian_params = self._electron_params['background']['Maxwellian6DUniform']
+        self._maxwellian_params = self._electron_params['background']['Maxwellian6D']
         self.pointer['electrons']._f_backgr = getattr(
-            kin_ana, 'Maxwellian6DUniform')(**self._maxwellian_params)
+            kin_ana, 'Maxwellian6D')(maxw_params=self._maxwellian_params)
         self._f0 = self.pointer['electrons'].f_backgr
 
-        assert self._f0.params['u1'] == 0., "No shifts in velocity space possible!"
-        assert self._f0.params['u2'] == 0., "No shifts in velocity space possible!"
-        assert self._f0.params['u3'] == 0., "No shifts in velocity space possible!"
-        assert self._f0.params['vth1'] == self._f0.params['vth2'] == self._f0.params['vth3'], \
+        assert self._f0.maxw_params['u1'] == 0., "No shifts in velocity space possible!"
+        assert self._f0.maxw_params['u2'] == 0., "No shifts in velocity space possible!"
+        assert self._f0.maxw_params['u3'] == 0., "No shifts in velocity space possible!"
+        assert self._f0.maxw_params['vth1'] == self._f0.maxw_params['vth2'] == self._f0.maxw_params['vth3'], \
             "Background Maxwellian must be isotropic in velocity space!"
 
         # Get coupling strength
-        self.alpha = self.equation_params['electrons']['alpha_unit']
-        self.kappa = 1. / self.equation_params['electrons']['epsilon_unit']
+        self.alpha = self.equation_params['electrons']['alpha']
+        self.kappa = 1. / self.equation_params['electrons']['epsilon']
 
         # ====================================================================================
         # Initialize background magnetic field from MHD equilibrium
         self._b_background = self.derham.P['2']([self.mhd_equil.b2_1,
                                                  self.mhd_equil.b2_2,
                                                  self.mhd_equil.b2_3])
 
-        # Create pointers to background electric potential and field
-        self._phi_background = self.derham.P['0'](self.electric_equil.phi0)
+        # TODO: must be set from model options
+        self._phi_background = self.derham.Vh['0'].zeros()
         self._e_background = self.derham.grad.dot(self._phi_background)
         # ====================================================================================
 
         # propagator params
         params_maxwell = params['em_fields']['options']['solvers']['maxwell']
         self._poisson_params = params['em_fields']['options']['solvers']['poisson']
         algo_eta = params['kinetic']['electrons']['options']['algos']['push_eta']
         algo_vxb = params['kinetic']['electrons']['options']['algos']['push_vxb']
         params_coupling = params['kinetic']['electrons']['options']['solver']
 
         # Initialize propagators/integrators used in splitting substeps
         self.add_propagator(self.prop_markers.PushEta(
             self.pointer['electrons'],
             algo=algo_eta,
-            bc_type=self._electron_params['markers']['bc']['type']))  
+            bc_type=self._electron_params['markers']['bc']['type']))
         if self._rank == 0:
             print("Added Step PushEta\n")
 
         # Only add StepVinEfield if e-field is non-zero, otherwise it is more expensive
         if np.all(self._e_background[0]._data < 1e-14) and np.all(self._e_background[1]._data < 1e-14) and np.all(self._e_background[2]._data < 1e-14):
             self.add_propagator(self.prop_markers.StepVinEfield(
                 self.pointer['electrons'],
@@ -389,15 +702,15 @@
         b_bckgr_strength = np.max(self.mhd_equil.absB0(e1, e2, e3))
         if b_bckgr_strength > 1e-6:
             self.add_propagator(self.prop_markers.PushVxB(
                 self.pointer['electrons'],
                 algo=algo_vxb,
                 scale_fac=1.,
                 b_eq=self._b_background,
-                b_tilde=None))  
+                b_tilde=None))
             if self._rank == 0:
                 print("Added Step VxB\n")
 
         self.add_propagator(self.prop_coupling.EfieldWeightsImplicit(
             self.pointer['e_field'],
             self.pointer['electrons'],
             alpha=self.alpha,
@@ -458,15 +771,15 @@
         # edges = self.kinetic['electrons']['bin_edges']['e1']
         # components = [False] * 6
         # components[0] = True
 
         # self.pointer['electrons'].show_distribution_function(components, edges, self.domain)
 
         # overwrite binning function to always bin marker data for f_1, not h
-        def new_binning(self, components, bin_edges, pforms=['0','0']):
+        def new_binning(self, components, bin_edges, pforms=['0', '0']):
             """
             Overwrite the binning method of the parent class to correctly bin data from f_1
             and not from f_1/sqrt(f_0).
 
             Parameters & Info
             -----------------
             see struphy.pic.particles.base.Particles.binning
@@ -513,16 +826,16 @@
             charge_accum._vectors[0][:] -= np.mean(charge_accum.vectors[0].toarray()[
                                                    charge_accum.vectors[0].toarray() != 0])
 
         # Instantiate Poisson solver
         _phi = StencilVector(self.derham.Vh['0'])
         poisson_solver = self.prop_fields.ImplicitDiffusion(
             _phi,
-            sigma=0.,
-            phi_n=charge_accum.vectors[0],
+            sigma_1=0.,
+            rho=charge_accum.vectors[0],
             x0=charge_accum.vectors[0],
             **self._poisson_params)
 
         # Solve with dt=1. and compute electric field
         poisson_solver(1.)
         self.derham.grad.dot(-_phi, out=self.pointer['e_field'])
 
@@ -563,17 +876,17 @@
         # # 0.5 * |b_3|^2
         # self.update_scalar('en_b3', self.pointer['b_field']._blocks[2].dot(
         #     self._en_b_tmp._blocks[2]) / 2.)
 
         # alpha^2 / (2N) * (v_th_1 * v_th_2 * v_th_3)^(2/3) * sum_p s_0 * w_p^2
         self._tmp[0] = \
             self.alpha**2 / (2 * self.pointer['electrons'].n_mks) * \
-            (self._f0.params['vth1'] *
-             self._f0.params['vth2'] *
-             self._f0.params['vth3'])**(2/3) * \
+            (self._f0.maxw_params['vth1'] *
+             self._f0.maxw_params['vth2'] *
+             self._f0.maxw_params['vth3'])**(2/3) * \
             np.dot(self.pointer['electrons'].markers_wo_holes[:, 6]**2,  # w_p^2
                    self.pointer['electrons'].markers_wo_holes[:, 7])  # s_{0,p}
 
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._tmp, op=self._mpi_sum)
 
         self.update_scalar('en_w', self._tmp[0])
@@ -678,41 +991,42 @@
         # Get rank and size
         self._rank = comm.Get_rank()
 
         # prelim
         self._electron_params = params['kinetic']['electrons']
 
         # kinetic background
-        assert self._electron_params['background']['type'] == 'Maxwellian6DUniform', \
+        assert self._electron_params['background']['type'] == 'Maxwellian6D', \
             AssertionError(
                 "The background distribution function must be a uniform Maxwellian!")
 
         self.pointer['electrons']._f_backgr = getattr(
-            kin_ana, 'Maxwellian6DUniform')(**self._electron_params['background']['Maxwellian6DUniform'])
+            kin_ana, 'Maxwellian6D')(maxw_params=self._electron_params['background']['Maxwellian6D']
+                                     )
         self._f0 = self.pointer['electrons'].f_backgr
-        self._maxwellian_params = self._f0.params
+        self._maxwellian_params = self._electron_params['background']['Maxwellian6D']
 
-        assert self._f0.params['u1'] == 0., "No shifts in velocity space possible!"
-        assert self._f0.params['u2'] == 0., "No shifts in velocity space possible!"
-        assert self._f0.params['u3'] == 0., "No shifts in velocity space possible!"
-        assert self._f0.params['vth1'] == self._f0.params['vth2'] == self._f0.params['vth3'], \
+        assert self._f0.maxw_params['u1'] == 0., "No shifts in velocity space possible!"
+        assert self._f0.maxw_params['u2'] == 0., "No shifts in velocity space possible!"
+        assert self._f0.maxw_params['u3'] == 0., "No shifts in velocity space possible!"
+        assert self._f0.maxw_params['vth1'] == self._f0.maxw_params['vth2'] == self._f0.maxw_params['vth3'], \
             "Background Maxwellian must be isotropic in velocity space!"
 
         # Get coupling strength
-        self.alpha = self.equation_params['electrons']['alpha_unit']
-        self.kappa = 1. / self.equation_params['electrons']['epsilon_unit']
+        self.alpha = self.equation_params['electrons']['alpha']
+        self.kappa = 1. / self.equation_params['electrons']['epsilon']
 
         # ====================================================================================
         # Initialize background magnetic field from MHD equilibrium
         self._b_background = self.derham.P['2']([self.mhd_equil.b2_1,
                                                  self.mhd_equil.b2_2,
                                                  self.mhd_equil.b2_3])
 
-        # Create pointers to background electric potential and field
-        self._phi_background = self.derham.P['0'](self.electric_equil.phi0)
+        # TODO: must be set from model options
+        self._phi_background = self.derham.Vh['0'].zeros()
         self._e_background = self.derham.grad.dot(self._phi_background)
         # ====================================================================================
 
         # propagator params
         params_maxwell = params['em_fields']['options']['solvers']['maxwell']
         self._poisson_params = params['em_fields']['options']['solvers']['poisson']
         algo_eta = params['kinetic']['electrons']['options']['algos']['push_eta']
@@ -720,15 +1034,15 @@
         params_analytic = params['kinetic']['electrons']['options']['solvers']['analytic']
         params_implicit = params['kinetic']['electrons']['options']['solvers']['implicit']
 
         # Initialize propagators/integrators used in splitting substeps
         self.add_propagator(self.prop_markers.PushEta(
             self.pointer['electrons'],
             algo=algo_eta,
-            bc_type=self._electron_params['markers']['bc']['type']))  
+            bc_type=self._electron_params['markers']['bc']['type']))
         if self._rank == 0:
             print("Added Step PushEta\n")
 
         self.add_propagator(self.prop_markers.StepVinEfield(
             self.pointer['electrons'],
             e_field=self._e_background + self.pointer['e_field'],
             kappa=self.kappa))
@@ -736,15 +1050,15 @@
             print("Added Step VinEfield\n")
 
         self.add_propagator(self.prop_markers.PushVxB(
             self.pointer['electrons'],
             algo=algo_vxb,
             scale_fac=1.,
             b_eq=self._b_background + self.pointer['b_field'],
-            b_tilde=None))  
+            b_tilde=None))
         if self._rank == 0:
             print("\nAdded Step VxB\n")
 
         self.add_propagator(self.prop_coupling.EfieldWeightsAnalytic(
             self.pointer['e_field'],
             self.pointer['electrons'],
             alpha=self.alpha,
@@ -806,26 +1120,28 @@
         # Initialize fields and particles
         super().initialize_from_params()
 
         f0_values = self._f0(
             *self.pointer['electrons'].markers_wo_holes[:, :6].T)
 
         # evaluate f0
-        f0_values = self._f0(self.pointer['electrons'].markers[:, 0],
-                             self.pointer['electrons'].markers[:, 1],
-                             self.pointer['electrons'].markers[:, 2],
-                             self.pointer['electrons'].markers[:, 3],
-                             self.pointer['electrons'].markers[:, 4],
-                             self.pointer['electrons'].markers[:, 5])[~self.pointer['electrons'].holes]
+        f0_values = self._f0(
+            self.pointer['electrons'].markers[:, 0],
+            self.pointer['electrons'].markers[:, 1],
+            self.pointer['electrons'].markers[:, 2],
+            self.pointer['electrons'].markers[:, 3],
+            self.pointer['electrons'].markers[:, 4],
+            self.pointer['electrons'].markers[:, 5]
+        )[~self.pointer['electrons'].holes]
         ln_f0_values = np.log(f0_values)
 
         self.pointer['electrons']._f0 = self._f0
 
         # overwrite binning function to always bin marker data for f_1, not h
-        def new_binning(self, components, bin_edges, pforms=['0','0']):
+        def new_binning(self, components, bin_edges, pforms=['0', '0']):
             """
             Overwrite the binning method of the parent class to correctly bin data from f_1
             and not from f_0 - (f_0 - f_1) ln(f_0).
 
             Parameters & Info
             -----------------
             see struphy.pic.particles.base.Particles.binning
@@ -861,20 +1177,22 @@
         self.pointer['electrons'].markers[~self.pointer['electrons'].holes, 6] -= \
             f0_values * (1 - ln_f0_values) / \
             self.pointer['electrons'].markers[~self.pointer['electrons'].holes, 7]
         self.pointer['electrons'].markers[~self.pointer['electrons'].holes,
                                           6] /= (-1) * ln_f0_values
 
         # evaluate f0
-        f0_values = self._f0(self.pointer['electrons'].markers[:, 0],
-                             self.pointer['electrons'].markers[:, 1],
-                             self.pointer['electrons'].markers[:, 2],
-                             self.pointer['electrons'].markers[:, 3],
-                             self.pointer['electrons'].markers[:, 4],
-                             self.pointer['electrons'].markers[:, 5])
+        f0_values = self._f0(
+            self.pointer['electrons'].markers[:, 0],
+            self.pointer['electrons'].markers[:, 1],
+            self.pointer['electrons'].markers[:, 2],
+            self.pointer['electrons'].markers[:, 3],
+            self.pointer['electrons'].markers[:, 4],
+            self.pointer['electrons'].markers[:, 5]
+        )
 
         # Accumulate charge density
         charge_accum = AccumulatorVector(
             self.derham, self.domain, "H1", "delta_f_vlasov_maxwell_poisson")
 
         charge_accum.accumulate(self.pointer['electrons'], f0_values,
                                 np.array(
@@ -886,16 +1204,16 @@
             charge_accum._vectors[0][:] -= np.mean(charge_accum.vectors[0].toarray()[
                                                    charge_accum.vectors[0].toarray() != 0])
 
         # Instantiate Poisson solver
         _phi = StencilVector(self.derham.Vh['0'])
         poisson_solver = self.prop_fields.ImplicitDiffusion(
             _phi,
-            sigma=1e-11,
-            phi_n=charge_accum.vectors[0],
+            sigma_1=1e-11,
+            rho=charge_accum.vectors[0],
             x0=charge_accum.vectors[0],
             **self._poisson_params)
 
         # Solve with dt=1. and compute electric field
         poisson_solver(1.)
         self.derham.grad.dot(-_phi, out=self.pointer['e_field'])
 
@@ -909,177 +1227,273 @@
         self._mass_ops.M2.dot(self.pointer['b_field'], out=self._en_b_tmp)
         en_B = self.pointer['b_field'].dot(self._en_b_tmp) / 2.
         self.update_scalar('en_b', en_B)
 
         # alpha^2 * v_th_1^2 * v_th_2^2 * v_th_3^2 * sum_p w_p
         self._tmp[0] = \
             self.alpha**2 * \
-            (self._f0.params['vth1'] *
-             self._f0.params['vth2'] *
-             self._f0.params['vth3'])**(2/3) * \
+            (self._f0.maxw_params['vth1'] *
+             self._f0.maxw_params['vth2'] *
+             self._f0.maxw_params['vth3'])**(2/3) * \
             np.sum(self.pointer['electrons'].markers_wo_holes[:, 6]) / \
             self.pointer['electrons'].n_mks
 
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._tmp, op=self._mpi_sum)
 
         self.update_scalar('en_w', self._tmp[0])
 
         # en_tot = en_w + en_e + en_b
         self.update_scalar('en_tot', self._tmp[0] + en_E + en_B)
 
 
-class VlasovMasslessElectrons(StruphyModel):
-    r'''Hybrid (kinetic ions + massless electrons) equations with quasi-neutrality condition. 
-    Unknowns: distribution function for ions, and vector potential.
+# class VlasovMasslessElectrons(StruphyModel):
+#     r'''Hybrid (kinetic ions + massless electrons) equations with quasi-neutrality condition.
+#     Unknowns: distribution function for ions, and vector potential.
+
+#     Normalization:
+
+#     .. math::
+#             t, x, p, A, f...
+
+
+#     Implemented equations:
+
+#     Hyrid model with kinetic ions and massless electrons.
+
+#     .. math::
+
+#         \begin{align}
+#         \textnormal{Vlasov}\qquad& \frac{\partial f}{\partial t} + (\mathbf{p} - \mathbf{A}) \cdot \frac{\partial f}{\partial \mathbf{x}}
+#         - \left[ T_e \frac{\nabla n}{n} - \left( \frac{\partial{\mathbf A}}{\partial {\mathbf x}} \right)^\top ({\mathbf A} - {\mathbf p} )  \right] \cdot \frac{\partial f}{\partial \mathbf{p}}
+#         = 0\,,
+#         \\
+#         \textnormal{Faraday's law}\qquad& \frac{\partial {\mathbf A}}{\partial t} = - \frac{\nabla \times \nabla \times A}{n} \times \nabla \times {\mathbf A} - \frac{\int ({\mathbf A} - {\mathbf p}f \mathrm{d}{\mathbf p})}{n} \times \nabla \times {\mathbf A}, \quad n = \int f \mathrm{d}{\mathbf p}.
+#         \end{align}
+
+#     Parameters
+#     ----------
+#         params : dict
+#             Simulation parameters, see from :ref:`params_yml`.
+#     '''
+
+#     @classmethod
+#     def bulk_species(cls):
+#         return 'ions'
+
+#     @classmethod
+#     def velocity_scale(cls):
+#         return 'cyclotron'
+
+#     def __init__(self, params, comm):
+
+#         from psydac.api.settings import PSYDAC_BACKEND_GPYCCEL
+#         from struphy.propagators.base import Propagator
+#         from struphy.propagators import propagators_fields, propagators_markers
+#         from mpi4py.MPI import SUM, IN_PLACE
+#         from struphy.pic.accumulation.particles_to_grid import Accumulator
+
+#         super().__init__(params, comm, a1='Hcurl', ions='Particles6D')
+
+#         # pointers to em-field variables
+#         self._a = self.em_fields['a1']['obj'].vector
+
+#         # pointer to kinetic variables
+#         self._ions = self.kinetic['ions']['obj']
+#         ions_params = self.kinetic['ions']['params']
+
+#         # extract necessary parameters
+#         # shape function info, degree and support size
+#         shape_params = params['kinetic']['ions']['ionsshape']
+#         # electron temperature
+#         self.thermal = params['kinetic']['electrons']['temperature']
+
+#         # extract necessary parameters
+#         solver_params_1 = params['solvers']['solver_1']
+
+#         # Project background magnetic field
+#         self._b_eq = self.derham.P['2']([self.mhd_equil.b2_1,
+#                                          self.mhd_equil.b2_2,
+#                                          self.mhd_equil.b2_3])
+
+#         # set propagators base class attributes
+#         Propagator.derham = self.derham
+#         Propagator.domain = self.domain
+#         Propagator.mass_ops = self.mass_ops
+
+#         self._accum_density = Accumulator(self.derham,
+#                                           self.domain,
+#                                           'H1',
+#                                           'hybrid_fA_density',
+#                                           add_vector=False)
+
+#         # Initialize propagators/integrators used in splitting substeps
+#         self._propagators = []
+
+#         self._propagators += [propagators_markers.StepHybridXPSymplectic(
+#                               self._ions,
+#                               a=self._a,
+#                               particle_bc=ions_params['markers']['bc']['type'],
+#                               quad_number=params['grid']['nq_el'],
+#                               shape_degree=np.array(shape_params['degree']),
+#                               shape_size=np.array(shape_params['size']),
+#                               electron_temperature=self.thermal,
+#                               accumulate_density=self._accum_density)]
+
+#         self._propagators += [propagators_markers.StepPushpxBHybrid(
+#                               self._ions,
+#                               method=ions_params['push_algos']['pxb'],
+#                               a=self._a,
+#                               b_eq=self._b_eq)]
+
+#         self._propagators += [propagators_fields.FaradayExtended(
+#                               self._a,
+#                               a_space='Hcurl',
+#                               beq=self._b_eq,
+#                               particles=self._ions,
+#                               quad_number=params['grid']['nq_el'],
+#                               shape_degree=np.array(shape_params['degree']),
+#                               shape_size=np.array(shape_params['size']),
+#                               solver_params=solver_params_1,
+#                               accumulate_density=self._accum_density)]
+
+#         # Scalar variables to be saved during simulation
+#         self._scalar_quantities = {}
+#         self._scalar_quantities['en_B'] = np.empty(1, dtype=float)
+#         self._en_f_loc = np.empty(1, dtype=float)
+#         self._scalar_quantities['en_f'] = np.empty(1, dtype=float)
+#         self._en_thermal_loc = np.empty(1, dtype=float)
+#         self._scalar_quantities['en_thermal'] = np.empty(1, dtype=float)
+#         self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+
+#         # MPI operations needed for scalar variables
+#         self._mpi_sum = SUM
+
+#     @property
+#     def propagators(self):
+#         return self._propagators
+
+#     @property
+#     def scalar_quantities(self):
+#         return self._scalar_quantities
+
+#     def update_scalar_quantities(self):
+#         import struphy.pic.utilities as pic_util
+
+#         rank = self._derham.comm.Get_rank()
+
+#         self._curla = self._derham.curl.dot(self._a)
+
+#         self._scalar_quantities['en_B'][0] = (self._curla + self._b_eq).dot(
+#             self._mass_ops.M2.dot(self._curla + self._b_eq))/2
+
+#         self._en_f_loc = pic_util.get_kinetic_energy_particles(
+#             self._a, self._derham, self._domain, self._ions)/self._ions.n_mks
+
+#         self.derham.comm.Reduce(
+#             self._en_f_loc, self._scalar_quantities['en_f'], op=self._mpi_sum, root=0)
+
+#         self._en_thermal_loc = pic_util.get_electron_thermal_energy(self._accum_density, self._derham, self._domain, int(self._derham.domain_array[int(rank), 2]), int(
+#             self._derham.domain_array[int(rank), 5]), int(self._derham.domain_array[int(rank), 8]), int(self._derham.nquads[0]+1), int(self._derham.nquads[1]+1), int(self._derham.nquads[2]+1))
+
+#         self.derham.comm.Reduce(self.thermal*self._en_thermal_loc,
+#                                 self._scalar_quantities['en_thermal'], op=self._mpi_sum, root=0)
+
+#         self._scalar_quantities['en_tot'][0] = self._scalar_quantities['en_B'][0]
+#         self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_f'][0]
+#         self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_thermal'][0]
 
-    Normalization: 
+
+class ElectrostaticGyrokAdiabatic(StruphyModel):
+    r'''Drift-kinetic equation in static background magnetic field (guiding-center motion). 
+
+    :ref:`normalization`:
 
     .. math::
-            t, x, p, A, f...
 
 
     Implemented equations:
 
-    Hyrid model with kinetic ions and massless electrons.
+    .. math::
+
+
+
+    where :math:
+
+    .. math::
+
 
     .. math::
 
-        \begin{align}
-        \textnormal{Vlasov}\qquad& \frac{\partial f}{\partial t} + (\mathbf{p} - \mathbf{A}) \cdot \frac{\partial f}{\partial \mathbf{x}}
-        - \left[ T_e \frac{\nabla n}{n} - \left( \frac{\partial{\mathbf A}}{\partial {\mathbf x}} \right)^\top ({\mathbf A} - {\mathbf p} )  \right] \cdot \frac{\partial f}{\partial \mathbf{p}}
-        = 0\,,
-        \\
-        \textnormal{Faraday's law}\qquad& \frac{\partial {\mathbf A}}{\partial t} = - \frac{\nabla \times \nabla \times A}{n} \times \nabla \times {\mathbf A} - \frac{\int ({\mathbf A} - {\mathbf p}f \mathrm{d}{\mathbf p})}{n} \times \nabla \times {\mathbf A}, \quad n = \int f \mathrm{d}{\mathbf p}.
-        \end{align}
 
     Parameters
     ----------
-        params : dict
-            Simulation parameters, see from :ref:`params_yml`.
+    params : dict
+        Simulation parameters, see from :ref:`params_yml`.
+
+    comm : mpi4py.MPI.Intracomm
+        MPI communicator used for parallelization.
     '''
 
     @classmethod
+    def species(cls):
+        dct = {'em_fields': {}, 'fluid': {}, 'kinetic': {}}
+
+        dct['em_fields']['phi'] = 'H1'
+        dct['kinetic']['ions'] = 'Particles5D'
+        return dct
+
+    @classmethod
     def bulk_species(cls):
         return 'ions'
 
     @classmethod
     def velocity_scale(cls):
-        return 'cyclotron'
-
-    def __init__(self, params, comm):
+        return 'alfvén'
 
-        from psydac.api.settings import PSYDAC_BACKEND_GPYCCEL
-        from struphy.propagators.base import Propagator
-        from struphy.propagators import propagators_fields, propagators_markers
-        from mpi4py.MPI import SUM, IN_PLACE
-        from struphy.pic.accumulation.particles_to_grid import Accumulator
+    @classmethod
+    def options(cls):
+        # import propagator options
+        from struphy.propagators.propagators_fields import ImplicitDiffusion
+        from struphy.propagators.propagators_markers import PushGuidingCenterbxEstar, PushGuidingCenterBstar
 
-        super().__init__(params, comm, a1='Hcurl', ions='Particles6D')
+        dct = {}
+        cls.add_option(species=['kinetic', 'ions'], key='push_bxEstar',
+                       option=PushGuidingCenterbxEstar.options()['algo'], dct=dct)
+        cls.add_option(species=['kinetic', 'ions'], key='push_Bstar',
+                       option=PushGuidingCenterBstar.options()['algo'], dct=dct)
+        cls.add_option(['em_fields'], ['solvers', 'poisson'],
+                       ImplicitDiffusion.options()['solver'], dct)
+        return dct
 
-        # pointers to em-field variables
-        self._a = self.em_fields['a1']['obj'].vector
+    def __init__(self, params, comm):
 
-        # pointer to kinetic variables
-        self._ions = self.kinetic['ions']['obj']
-        ions_params = self.kinetic['ions']['params']
+        super().__init__(params, comm)
 
-        # extract necessary parameters
-        # shape function info, degree and support size
-        shape_params = params['kinetic']['ions']['ionsshape']
-        # electron temperature
-        self.thermal = params['kinetic']['electrons']['temperature']
-
-        # extract necessary parameters
-        solver_params_1 = params['solvers']['solver_1']
-
-        # Project background magnetic field
-        self._b_eq = self.derham.P['2']([self.mhd_equil.b2_1,
-                                         self.mhd_equil.b2_2,
-                                         self.mhd_equil.b2_3])
-
-        # set propagators base class attributes
-        Propagator.derham = self.derham
-        Propagator.domain = self.domain
-        Propagator.mass_ops = self.mass_ops
-
-        self._accum_density = Accumulator(self.derham,
-                                          self.domain,
-                                          'H1',
-                                          'hybrid_fA_density',
-                                          add_vector=False)
+        from mpi4py.MPI import SUM, IN_PLACE
+        from struphy.feec.projectors import L2Projector
+        from struphy.fields_background.mhd_equil.base import MHDequilibrium
 
-        # Initialize propagators/integrators used in splitting substeps
-        self._propagators = []
+        # prelim
+        ions_params = self.kinetic['ions']['params']
+        solver_params = params['em_fields']['options']['solvers']['poisson']
 
-        self._propagators += [propagators_markers.StepHybridXPSymplectic(
-                              self._ions,
-                              a=self._a,
-                              particle_bc=ions_params['markers']['bc']['type'],
-                              quad_number=params['grid']['nq_el'],
-                              shape_degree=np.array(shape_params['degree']),
-                              shape_size=np.array(shape_params['size']),
-                              electron_temperature=self.thermal,
-                              accumulate_density=self._accum_density)]
-
-        self._propagators += [propagators_markers.StepPushpxBHybrid(
-                              self._ions,
-                              method=ions_params['push_algos']['pxb'],
-                              a=self._a,
-                              b_eq=self._b_eq)]
-
-        self._propagators += [propagators_fields.FaradayExtended(
-                              self._a,
-                              a_space='Hcurl',
-                              beq=self._b_eq,
-                              particles=self._ions,
-                              quad_number=params['grid']['nq_el'],
-                              shape_degree=np.array(shape_params['degree']),
-                              shape_size=np.array(shape_params['size']),
-                              solver_params=solver_params_1,
-                              accumulate_density=self._accum_density)]
+        dt = params['time']['dt']
 
-        # Scalar variables to be saved during simulation
-        self._scalar_quantities = {}
-        self._scalar_quantities['en_B'] = np.empty(1, dtype=float)
-        self._en_f_loc = np.empty(1, dtype=float)
-        self._scalar_quantities['en_f'] = np.empty(1, dtype=float)
-        self._en_thermal_loc = np.empty(1, dtype=float)
-        self._scalar_quantities['en_thermal'] = np.empty(1, dtype=float)
-        self._scalar_quantities['en_tot'] = np.empty(1, dtype=float)
+        rho = self.derham.Vh['0'].zeros()
 
-        # MPI operations needed for scalar variables
-        self._mpi_sum = SUM
+        # Initialize propagators/integrators used in splitting substeps
+        self.add_propagator(self.prop_fields.ImplicitDiffusion(
+            self.pointer['phi'],
+            sigma_1=dt,
+            sigma_2=0.,
+            sigma_3=dt,
+            A1_mat='M0ad',
+            A2_mat='M1gyro',
+            rho=rho,
+            **solver_params
+        ))
 
-    @property
-    def propagators(self):
-        return self._propagators
-
-    @property
-    def scalar_quantities(self):
-        return self._scalar_quantities
+        self.add_scalar('en_fv')
 
     def update_scalar_quantities(self):
-        import struphy.pic.utilities as pic_util
-
-        rank = self._derham.comm.Get_rank()
-
-        self._curla = self._derham.curl.dot(self._a)
-
-        self._scalar_quantities['en_B'][0] = (self._curla + self._b_eq).dot(
-            self._mass_ops.M2.dot(self._curla + self._b_eq))/2
-
-        self._en_f_loc = pic_util.get_kinetic_energy_particles(
-            self._a, self._derham, self._domain, self._ions)/self._ions.n_mks
-
-        self.derham.comm.Reduce(
-            self._en_f_loc, self._scalar_quantities['en_f'], op=self._mpi_sum, root=0)
-
-        self._en_thermal_loc = pic_util.get_electron_thermal_energy(self._accum_density, self._derham, self._domain, int(self._derham.domain_array[int(rank), 2]), int(
-            self._derham.domain_array[int(rank), 5]), int(self._derham.domain_array[int(rank), 8]), int(self._derham.nquads[0]+1), int(self._derham.nquads[1]+1), int(self._derham.nquads[2]+1))
-
-        self.derham.comm.Reduce(self.thermal*self._en_thermal_loc,
-                                self._scalar_quantities['en_thermal'], op=self._mpi_sum, root=0)
-
-        self._scalar_quantities['en_tot'][0] = self._scalar_quantities['en_B'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_f'][0]
-        self._scalar_quantities['en_tot'][0] += self._scalar_quantities['en_thermal'][0]
+        self.update_scalar('en_fv', 1.)
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `struphy-2.2.0/src/struphy/models/tests/test_fluid_models.py` & `struphy-2.3.0/src/struphy/models/tests/test_kinetic_models.py`

 * *Files 15% similar despite different names*

```diff
@@ -3,49 +3,50 @@
 from struphy.models.tests.util import call_model
 
 
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('map_and_equil', [('Cuboid', 'HomogenSlab'),
                                            ('HollowTorus', 'AdhocTorus'),
                                            ('Tokamak', 'EQDSKequilibrium')])
-def test_fluid(map_and_equil, fast, model=None, Tend=None):
-    '''Tests all models and all possible model.options (except solvers without preconditioner) in models/fluid.py.
+def test_kinetic(map_and_equil, fast, model=None, Tend=None):
+    '''Tests all models and all possible model.options (except solvers without preconditioner) in models/kinetic.py.
 
     If model is not None, tests the specified model.
 
     The argument "fast" is a pytest option that can be specified at the command line (see conftest.py).'''
 
-    from struphy.models import fluid
+    from struphy.models import kinetic
 
     if model is None:
-        for key, val in inspect.getmembers(fluid):
+        for key, val in inspect.getmembers(kinetic):
             if inspect.isclass(val) and 'StruphyModel' not in key:
 
                 # TODO: remove if-clause
-                if 'LinearExtendedMHD' in key and 'HomogenSlab' not in map_and_equil[1]:
+                if 'VlasovMasslessElectrons' in key:
                     print(
-                        f'Model {key} is currently excluded from tests with mhd_equil other than HomogenSlab.')
+                        f'Model {key} is currently excluded from tests.')
                     continue
 
                 if fast:
                     if 'Cuboid' not in map_and_equil[0]:
                         print(
                             f'Fast is enabled, mapping {map_and_equil[0]} skipped ...')
                         continue
 
                 call_model(key, val, map_and_equil, Tend=Tend)
     else:
-        val = getattr(fluid, model)
+        val = getattr(kinetic, model)
 
         # TODO: remove if-clause
-        if 'LinearExtendedMHD' in model and 'HomogenSlab' not in map_and_equil[1]:
+        if 'VlasovMasslessElectrons' in model:
             print(
-                f'Model {model} is currently excluded from tests with mhd_equil other than HomogenSlab.')
+                f'Model {model} is currently excluded from tests.')
             exit()
 
         call_model(model, val, map_and_equil, Tend=Tend)
-        
+
 if __name__ == '__main__':
     
-    test_fluid(True, ('Cuboid', 'HomogenSlab'), model=None)
-    test_fluid(True, ('HollowTorus', 'AdhocTorus'), model=None)
-    test_fluid(True, ('Tokamak', 'EQDSKequilibrium'), model=None)
+    test_kinetic(fast=True, map_and_equil=('Cuboid', 'HomogenSlab'), model=None)
+    test_kinetic(fast=True, map_and_equil=('HollowTorus', 'AdhocTorus'), model=None)
+    test_kinetic(fast=True, map_and_equil=('Tokamak', 'EQDSKequilibrium'), model=None)
+
```

### Comparing `struphy-2.2.0/src/struphy/models/tests/test_hybrid_models.py` & `struphy-2.3.0/src/struphy/models/tests/test_hybrid_models.py`

 * *Files 3% similar despite different names*

```diff
@@ -8,15 +8,15 @@
                                            ('HollowTorus', 'AdhocTorus'),
                                            ('Tokamak', 'EQDSKequilibrium')])
 def test_hybrid(map_and_equil, fast, model=None, Tend=None):
     '''Tests all models and all possible model.options (except solvers without preconditioner) in models/hybrid.py.
 
     If model is not None, tests the specified model.
 
-    The argument "fast" is a pytest option that can be specified at te command line (see conftest.py).'''
+    The argument "fast" is a pytest option that can be specified at the command line (see conftest.py).'''
 
     from struphy.models import hybrid
 
     if model is None:
         for key, val in inspect.getmembers(hybrid):
             if inspect.isclass(val) and 'StruphyModel' not in key:
```

### Comparing `struphy-2.2.0/src/struphy/models/tests/test_kinetic_models.py` & `struphy-2.3.0/src/struphy/models/tests/test_fluid_models.py`

 * *Files 13% similar despite different names*

```diff
@@ -3,50 +3,49 @@
 from struphy.models.tests.util import call_model
 
 
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('map_and_equil', [('Cuboid', 'HomogenSlab'),
                                            ('HollowTorus', 'AdhocTorus'),
                                            ('Tokamak', 'EQDSKequilibrium')])
-def test_kinetic(map_and_equil, fast, model=None, Tend=None):
-    '''Tests all models and all possible model.options (except solvers without preconditioner) in models/kinetic.py.
+def test_fluid(map_and_equil, fast, model=None, Tend=None):
+    '''Tests all models and all possible model.options (except solvers without preconditioner) in models/fluid.py.
 
     If model is not None, tests the specified model.
 
-    The argument "fast" is a pytest option that can be specified at te command line (see conftest.py).'''
+    The argument "fast" is a pytest option that can be specified at the command line (see conftest.py).'''
 
-    from struphy.models import kinetic
+    from struphy.models import fluid
 
     if model is None:
-        for key, val in inspect.getmembers(kinetic):
+        for key, val in inspect.getmembers(fluid):
             if inspect.isclass(val) and 'StruphyModel' not in key:
 
                 # TODO: remove if-clause
-                if 'VlasovMasslessElectrons' in key:
+                if 'LinearExtendedMHD' in key and 'HomogenSlab' not in map_and_equil[1]:
                     print(
-                        f'Model {key} is currently excluded from tests.')
+                        f'Model {key} is currently excluded from tests with mhd_equil other than HomogenSlab.')
                     continue
 
                 if fast:
                     if 'Cuboid' not in map_and_equil[0]:
                         print(
                             f'Fast is enabled, mapping {map_and_equil[0]} skipped ...')
                         continue
 
                 call_model(key, val, map_and_equil, Tend=Tend)
     else:
-        val = getattr(kinetic, model)
+        val = getattr(fluid, model)
 
         # TODO: remove if-clause
-        if 'VlasovMasslessElectrons' in model:
+        if 'LinearExtendedMHD' in model and 'HomogenSlab' not in map_and_equil[1]:
             print(
-                f'Model {model} is currently excluded from tests.')
+                f'Model {model} is currently excluded from tests with mhd_equil other than HomogenSlab.')
             exit()
 
         call_model(model, val, map_and_equil, Tend=Tend)
-
+        
 if __name__ == '__main__':
     
-    test_kinetic(True, ('Cuboid', 'HomogenSlab'), model=None)
-    test_kinetic(True, ('HollowTorus', 'AdhocTorus'), model=None)
-    test_kinetic(True, ('Tokamak', 'EQDSKequilibrium'), model=None)
-    
+    test_fluid(('Cuboid', 'HomogenSlab'), False, model='VariationalMHD')
+    test_fluid(('HollowTorus', 'AdhocTorus'), False, model='VariationalMHD')
+    test_fluid(('Tokamak', 'EQDSKequilibrium'), False, model='VariationalMHD')
```

### Comparing `struphy-2.2.0/src/struphy/models/tests/test_toy_models.py` & `struphy-2.3.0/src/struphy/models/tests/test_toy_models.py`

 * *Files 12% similar despite different names*

```diff
@@ -9,15 +9,15 @@
                                            ('Tokamak', 'EQDSKequilibrium')
                                            ])
 def test_toy(map_and_equil, fast, model=None, Tend=None):
     '''Tests all models and all possible model.options (except solvers without preconditioner) in models/toy.py.
 
     If model is not None, tests the specified model.
 
-    The argument "fast" is a pytest option that can be specified at te command line (see conftest.py).'''
+    The argument "fast" is a pytest option that can be specified at the command line (see conftest.py).'''
 
     from struphy.models import toy
 
     if model is None:
         for key, val in inspect.getmembers(toy):
             if inspect.isclass(val) and 'StruphyModel' not in key:
 
@@ -30,10 +30,10 @@
                 call_model(key, val, map_and_equil, Tend=Tend)
     else:
         val = getattr(toy, model)
         call_model(model, val, map_and_equil, Tend=Tend)
         
 if __name__ == '__main__':
     
-    test_toy(('Cuboid', 'HomogenSlab'), True, model=None)
-    test_toy(('HollowTorus', 'AdhocTorus'), True, model=None)
-    test_toy(('Tokamak', 'EQDSKequilibrium'), True, model=None)
+    test_toy(('Cuboid', 'HomogenSlab'), True, model='VariationalCompressibleFluid')
+    test_toy(('HollowTorus', 'AdhocTorus'), True, model='VariationalCompressibleFluid')
+    test_toy(('Tokamak', 'EQDSKequilibrium'), True, model='VariationalCompressibleFluid')
```

### Comparing `struphy-2.2.0/src/struphy/models/tests/test_xxpproc.py` & `struphy-2.3.0/src/struphy/models/tests/test_xxpproc.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 def test_pproc_codes(model=None):
     '''Tests the post processing of runs in test_codes.py'''
-    
+
     import os
     import struphy
     import inspect
     from struphy.models import fluid, kinetic, hybrid, toy
     from struphy.post_processing import pproc_struphy
     from mpi4py import MPI
-    
+
     comm = MPI.COMM_WORLD
-    
+
     libpath = struphy.__path__[0]
-    
+
     list_fluid = []
     for name, obj in inspect.getmembers(fluid):
         if inspect.isclass(obj):
             if name not in {'StruphyModel', }:
                 list_fluid += [name]
 
     list_kinetic = []
@@ -33,35 +33,34 @@
     list_toy = []
     for name, obj in inspect.getmembers(toy):
         if inspect.isclass(obj):
             if name not in {'StruphyModel', }:
                 list_toy += [name]
 
     list_models = list_fluid + list_kinetic + list_hybrid + list_toy
-    
+
     if comm.Get_rank() == 0:
         if model is None:
             for model in list_models:
-                
+
                 # TODO: remove if-clause
                 if 'VlasovMasslessElectrons' in model:
                     print(
                         f'Model {model} is currently excluded from tests.')
                     continue
-                
+
                 path_out = os.path.join(libpath, 'io/out/test_' + model)
                 pproc_struphy.main(path_out)
         else:
-            
+
             # TODO: remove if-clause
             if 'VlasovMasslessElectrons' in model:
                 print(
                     f'Model {model} is currently excluded from tests.')
                 exit()
-            
+
             path_out = os.path.join(libpath, 'io/out/test_' + model)
             pproc_struphy.main(path_out)
-        
-        
+
+
 if __name__ == '__main__':
     test_pproc_codes()
-
```

### Comparing `struphy-2.2.0/src/struphy/models/tests/util.py` & `struphy-2.3.0/src/struphy/models/tests/util.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/models/toy.py` & `struphy-2.3.0/src/struphy/models/toy.py`

 * *Files 13% similar despite different names*

```diff
@@ -182,16 +182,16 @@
 
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._tmp, op=self._mpi_sum)
 
         self.update_scalar('en_f', self._tmp[0])
 
 
-class DriftKinetic(StruphyModel):
-    r'''Drift-kinetic equation in static background magnetic field (guiding-center motion). 
+class GuidingCenter(StruphyModel):
+    r'''Guiding center equation in static background magnetic field. 
 
     :ref:`normalization`:
 
     .. math::
 
         \frac{\hat B}{\sqrt{A_\textnormal{b} m_\textnormal{H} \hat n \mu_0}} =: \hat v_\textnormal{A} = \frac{\hat \omega}{\hat k}
 
@@ -284,25 +284,25 @@
 
         self._E0T = self.derham.extraction_ops['0'].transpose()
         self._EvT = self.derham.extraction_ops['v'].transpose()
 
         # Initialize propagators/integrators used in splitting substeps
         self.add_propagator(self.prop_markers.PushGuidingCenterbxEstar(
             self.pointer['ions'],
-            epsilon=self.equation_params['ions']['epsilon_unit'],
+            epsilon=self.equation_params['ions']['epsilon'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
             abs_b=self._abs_b,
             gradB1=self._gradB1,
             curl_unit_b2=self._curl_unit_b2,
             **ions_params['options']['push_bxEstar']))
         self.add_propagator(self.prop_markers.PushGuidingCenterBstar(
             self.pointer['ions'],
-            epsilon=self.equation_params['ions']['epsilon_unit'],
+            epsilon=self.equation_params['ions']['epsilon'],
             b_eq=self._b_eq,
             unit_b1=self._unit_b1,
             unit_b2=self._unit_b2,
             abs_b=self._abs_b,
             gradB1=self._gradB1,
             curl_unit_b2=self._curl_unit_b2,
             **ions_params['options']['push_Bstar']))
@@ -322,15 +322,15 @@
         # particles' kinetic energy
         self._en_fv[0] = self.pointer['ions'].markers[~self.pointer['ions'].holes, 5].dot(
             self.pointer['ions'].markers[~self.pointer['ions'].holes, 3]**2) / (2.*self.pointer['ions'].n_mks)
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._en_fv, op=self._mpi_sum)
 
         # particles' magnetic energy
-        self.pointer['ions'].save_magnetic_energy(self._abs_b)
+        self.pointer['ions'].save_magnetic_energy(self._abs_b, self._unit_b1, self._b_eq)
 
         self._en_fB[0] = self.pointer['ions'].markers[~self.pointer['ions'].holes, 5].dot(
             self.pointer['ions'].markers[~self.pointer['ions'].holes, 8]) / self.pointer['ions'].n_mks
         self.derham.comm.Allreduce(
             self._mpi_in_place, self._en_fB, op=self._mpi_sum)
 
         self.update_scalar('en_fv', self._en_fv[0])
@@ -565,33 +565,49 @@
 
     @classmethod
     def options(cls):
         # import propagator options
         from struphy.propagators.propagators_fields import VariationalMomentumAdvection, VariationalDensityEvolve
         dct = {}
 
-        cls.add_option(species=['fluid', 'fluid'], key=['solvers'],
+        cls.add_option(species=['fluid', 'fluid'], key=['solver_momentum'],
                        option=VariationalMomentumAdvection.options()['solver'], dct=dct)
-        cls.add_option(species=['fluid', 'fluid'], key=['solvers'],
+        cls.add_option(species=['fluid', 'fluid'], key=['solver_density'],
                        option=VariationalDensityEvolve.options()['solver'], dct=dct)
+        cls.add_option(species=['fluid', 'fluid'], key=['physics'],
+                       option=VariationalDensityEvolve.options()['physics'], dct=dct)
         return dct
 
     def __init__(self, params, comm):
 
         from struphy.feec.mass import WeightedMassOperator
 
         # initialize base class
         super().__init__(params, comm)
+
         # Initialize mass matrix
-        self.WMM = WeightedMassOperator(self.derham.Vh_fem['v'], self.derham.Vh_fem['v'], matrix_free=True)        
+        self.WMM = WeightedMassOperator(
+            self.derham.Vh_fem['v'], self.derham.Vh_fem['v'])
+
         # Initialize propagators/integrators used in splitting substeps
+        solver_momentum = params['fluid']['fluid']['options']['solver_momentum']
+        solver_density = params['fluid']['fluid']['options']['solver_density']
+
+        gamma = params['fluid']['fluid']['options']['physics']['gamma']
+
         self.add_propagator(self.prop_fields.VariationalDensityEvolve(
-            self.pointer['fluid_rho3'], self.pointer['fluid_uv'], model='pressureless', mass_ops=self.WMM))
+            self.pointer['fluid_rho3'], self.pointer['fluid_uv'],
+            model='pressureless',
+            gamma=gamma,
+            mass_ops=self.WMM,
+            **solver_density))
         self.add_propagator(self.prop_fields.VariationalMomentumAdvection(
-            self.pointer['fluid_uv'], mass_ops=self.WMM))
+            self.pointer['fluid_uv'],
+            mass_ops=self.WMM,
+            **solver_momentum))
 
         # Scalar variables to be saved during simulation
         self.add_scalar('en_U')
 
         # temporary vectors for scalar quantities
         self._tmp_u1 = self.derham.Vh['v'].zeros()
 
@@ -650,34 +666,49 @@
 
     @classmethod
     def options(cls):
         # import propagator options
         from struphy.propagators.propagators_fields import VariationalMomentumAdvection, VariationalDensityEvolve
         dct = {}
 
-        cls.add_option(species=['fluid', 'fluid'], key=['solvers'],
+        cls.add_option(species=['fluid', 'fluid'], key=['solver_momentum'],
                        option=VariationalMomentumAdvection.options()['solver'], dct=dct)
-        cls.add_option(species=['fluid', 'fluid'], key=['solvers'],
+        cls.add_option(species=['fluid', 'fluid'], key=['solver_density'],
                        option=VariationalDensityEvolve.options()['solver'], dct=dct)
+        cls.add_option(species=['fluid', 'fluid'], key=['physics'],
+                       option=VariationalDensityEvolve.options()['physics'], dct=dct)
         return dct
 
     def __init__(self, params, comm):
 
         from struphy.feec.mass import WeightedMassOperator
 
         # initialize base class
         super().__init__(params, comm)
+
         # Initialize mass matrix
         self.WMM = WeightedMassOperator(
-            self.derham.Vh_fem['v'], self.derham.Vh_fem['v'], matrix_free=True)
+            self.derham.Vh_fem['v'], self.derham.Vh_fem['v'])
+
         # Initialize propagators/integrators used in splitting substeps
+        solver_momentum = params['fluid']['fluid']['options']['solver_momentum']
+        solver_density = params['fluid']['fluid']['options']['solver_density']
+
+        gamma = params['fluid']['fluid']['options']['physics']['gamma']
+
         self.add_propagator(self.prop_fields.VariationalDensityEvolve(
-            self.pointer['fluid_rho3'], self.pointer['fluid_uv'], model='barotropic', mass_ops=self.WMM))
+            self.pointer['fluid_rho3'], self.pointer['fluid_uv'],
+            model='barotropic',
+            gamma=gamma,
+            mass_ops=self.WMM,
+            **solver_density))
         self.add_propagator(self.prop_fields.VariationalMomentumAdvection(
-            self.pointer['fluid_uv'], mass_ops=self.WMM))
+            self.pointer['fluid_uv'],
+            mass_ops=self.WMM,
+            **solver_momentum))
 
         # Scalar variables to be saved during simulation
         self.add_scalar('en_U')
         self.add_scalar('en_thermo')
         self.add_scalar('en_tot')
 
         # temporary vectors for scalar quantities
@@ -750,42 +781,60 @@
 
     @classmethod
     def options(cls):
         # import propagator options
         from struphy.propagators.propagators_fields import VariationalMomentumAdvection, VariationalDensityEvolve, VariationalEntropyEvolve
         dct = {}
 
-        cls.add_option(species=['fluid', 'fluid'], key=['solvers'],
+        cls.add_option(species=['fluid', 'fluid'], key=['solver_momentum'],
                        option=VariationalMomentumAdvection.options()['solver'], dct=dct)
-        cls.add_option(species=['fluid', 'fluid'], key=['solvers'],
+        cls.add_option(species=['fluid', 'fluid'], key=['solver_density'],
                        option=VariationalDensityEvolve.options()['solver'], dct=dct)
-        cls.add_option(species=['fluid', 'fluid'], key=['solvers'],
+        cls.add_option(species=['fluid', 'fluid'], key=['solver_entropy'],
                        option=VariationalEntropyEvolve.options()['solver'], dct=dct)
+        cls.add_option(species=['fluid', 'fluid'], key=['physics'],
+                       option=VariationalDensityEvolve.options()['physics'], dct=dct)
         return dct
 
     def __init__(self, params, comm):
 
         from struphy.feec.projectors import L2Projector
         from struphy.feec.mass import WeightedMassOperator
 
         # initialize base class
         super().__init__(params, comm)
         # Initialize mass matrix
         self.WMM = WeightedMassOperator(
-            self.derham.Vh_fem['v'], self.derham.Vh_fem['v'], matrix_free=True)
+            self.derham.Vh_fem['v'], self.derham.Vh_fem['v'])
 
         # Initialize propagators/integrators used in splitting substeps
-        gamma = params['fluid']['fluid']['options']['solvers']['gamma']
+        solver_momentum = params['fluid']['fluid']['options']['solver_momentum']
+        solver_density = params['fluid']['fluid']['options']['solver_density']
+        solver_entropy = params['fluid']['fluid']['options']['solver_entropy']
+
+        gamma = params['fluid']['fluid']['options']['physics']['gamma']
 
         self.add_propagator(self.prop_fields.VariationalDensityEvolve(
-            self.pointer['fluid_rho3'], self.pointer['fluid_uv'], model='full', s=self.pointer['fluid_s3'], gamma=gamma, mass_ops=self.WMM))
+            self.pointer['fluid_rho3'], self.pointer['fluid_uv'],
+            model='full',
+            s=self.pointer['fluid_s3'],
+            gamma=gamma,
+            mass_ops=self.WMM,
+            **solver_density))
         self.add_propagator(self.prop_fields.VariationalMomentumAdvection(
-            self.pointer['fluid_uv'], mass_ops=self.WMM))
+            self.pointer['fluid_uv'],
+            mass_ops=self.WMM,
+            **solver_momentum))
         self.add_propagator(self.prop_fields.VariationalEntropyEvolve(
-            self.pointer['fluid_s3'], self.pointer['fluid_uv'], model='full', rho=self.pointer['fluid_rho3'], gamma=gamma, mass_ops=self.WMM))
+            self.pointer['fluid_s3'], self.pointer['fluid_uv'],
+            model='full',
+            rho=self.pointer['fluid_rho3'],
+            gamma=gamma,
+            mass_ops=self.WMM,
+            **solver_entropy))
 
         # Scalar variables to be saved during simulation
         self.add_scalar('en_U')
         self.add_scalar('en_thermo')
         self.add_scalar('en_tot')
 
         # temporary vectors for scalar quantities
@@ -806,106 +855,131 @@
         en_thermo = self.update_thermo_energy()
 
         en_tot = en_U + en_thermo
         self.update_scalar('en_tot', en_tot)
 
     def update_thermo_energy(self):
         '''Reuse tmp used in VariationalEntropyEvolve to compute the thermodynamical energy.
-        
+
         :meta private:
         '''
         en_prop = self._propagators[2]
         en_prop.sf.vector = self.pointer['fluid_s3']
         en_prop.rhof.vector = self.pointer['fluid_rho3']
         sf_values = en_prop.sf.eval_tp_fixed_loc(
-            en_prop.integration_grid_V3_spans, en_prop.integration_grid_V3_bd, out=en_prop._sf_values_V3)
+            en_prop.integration_grid_spans, en_prop.integration_grid_bd, out=en_prop._sf_values)
         rhof_values = en_prop.rhof.eval_tp_fixed_loc(
-            en_prop.integration_grid_V3_spans, en_prop.integration_grid_V3_bd, out=en_prop._rhof_values_V3)
-        e = en_prop._ener
-        ener_values = en_prop._proj_ener_metric_term*e(rhof_values, sf_values)
+            en_prop.integration_grid_spans, en_prop.integration_grid_bd, out=en_prop._rhof_values)
+        e = self.__ener
+        ener_values = en_prop._proj_rho2_metric_term*e(rhof_values, sf_values)
         en_prop._get_L2dofs_V3(ener_values, dofs=en_prop._linear_form_dl_ds)
         en_thermo = self._integrator.dot(en_prop._linear_form_dl_ds)
         self.update_scalar('en_thermo', en_thermo)
         return en_thermo
+    
+    def __ener(self, rho, s):
+        """Themodynamical energy as a function of rho and s, usign the perfect gaz hypothesis
+        E(rho, s) = rho^gamma*exp(s/rho)"""
+        gam = self._params['fluid']['fluid']['options']['physics']['gamma']
+        return np.power(rho, gam)*np.exp(s/rho)
 
 
 class Poisson(StruphyModel):
-    r'''Poisson's equations .
+    r'''Weak discretization of Poisson's equation with diffusion matrix, stabilization 
+    and time-depedent right-hand side.
+
+    Find :math:`\phi \in H^1` such that
 
-    .. math::   - \Delta \Phi = \rho 
+    .. math::
+
+        \int_\Omega \psi\, n_0(\mathbf x) \phi\,\textrm d \mathbf x + \int_\Omega \nabla \psi^\top D_0(\mathbf x) \nabla \phi \,\textrm d \mathbf x = \int_\Omega \psi\, \rho(t, \mathbf x)\,\textrm d \mathbf x\qquad \forall \ \psi \in H^1\,,
+
+    where :math:`n_0, \rho(t):\Omega \to \mathbb R` are real-valued functions, :math:`\rho(t)` parametrized with time :math:`t`,
+    and :math:`D_0:\Omega \to \mathbb R^{3\times 3}` is a positive diffusion matrix. 
+    Boundary terms from integration by parts are assumed to vanish.
 
     Parameters
     ----------
     params : dict
         Simulation parameters, see from :ref:`params_Poisson.yml`.
 
     comm : mpi4py.MPI.Intracomm
-
     '''
 
     @classmethod
     def species(cls):
         dct = {'em_fields': {}, 'fluid': {}, 'kinetic': {}}
 
         dct['em_fields']['phi'] = 'H1'
+        dct['em_fields']['source'] = 'H1'
         return dct
 
     @classmethod
     def bulk_species(cls):
         return None
 
     @classmethod
     def velocity_scale(cls):
         return None
 
     @classmethod
     def options(cls):
         # import propagator options
-        from struphy.propagators.propagators_fields import ImplicitDiffusion
+        from struphy.propagators.propagators_fields import ImplicitDiffusion, TimeDependentSource
 
         dct = {}
-        cls.add_option(species=['em_fields'], key=['solvers', 'poisson'],
+        cls.add_option(species=['em_fields'], key=['source', 'omega'],
+                       option=TimeDependentSource.options()['omega'], dct=dct)
+        cls.add_option(species=['em_fields'], key=['source', 'hfun'],
+                       option=TimeDependentSource.options()['hfun'], dct=dct)
+        cls.add_option(species=['em_fields'], key=['poisson', 'model'],
+                       option=ImplicitDiffusion.options()['model'], dct=dct)
+        cls.add_option(species=['em_fields'], key=['poisson', 'solver'],
                        option=ImplicitDiffusion.options()['solver'], dct=dct)
         return dct
 
     def __init__(self, params, comm):
 
         super().__init__(params, comm)
 
-        phi_n = self.derham.Vh['0'].zeros()
-        x0 = self.derham.Vh['0'].zeros()
-
         # extract necessary parameters
-        solver_params = params['em_fields']['options']['solvers']['poisson']
+        model_params = params['em_fields']['options']['poisson']['model']
+        solver_params = params['em_fields']['options']['poisson']['solver']
+        omega = params['em_fields']['options']['source']['omega']
+        hfun = params['em_fields']['options']['source']['hfun']
 
         # Initialize propagator
+        self.add_propagator(self.prop_fields.TimeDependentSource(
+            self.pointer['source'], 
+            omega=omega, 
+            hfun=hfun))
         self.add_propagator(self.prop_fields.ImplicitDiffusion(
             self.pointer['phi'],
-            A_mat='M1',
-            sigma=0.,
-            phi_n=phi_n,
-            x0=x0,
+            sigma_1=model_params['sigma_1'],
+            A1_mat=model_params['A1_mat'],
+            A2_mat=model_params['A2_mat'],
+            rho=self.pointer['source'],
             **solver_params))
 
         # assert dt=1 for implicit diffusion to solve Poisson.
-        assert params['time'][
-            'dt'] == 1., f"Time step must be 1.0 in the Poisson model, but is {params['time']['dt']}"
+        # assert params['time'][
+        #     'dt'] == 1., f"Time step must be 1.0 in the Poisson model, but is {params['time']['dt']}"
 
         # Scalar variables to be saved during simulation
-        self.add_scalar('en_E')
+        #self.add_scalar('en_E')
 
     def update_scalar_quantities(self):
         pass
 
-    # make dt=1 in parameter file
-    @classmethod
-    def generate_default_parameter_file(cls, file=None, save=True, prompt=True):
-        ''':meta private:'''
-
-        params = super(Poisson, cls).generate_default_parameter_file(
-            file=file, save=False, prompt=False)
-        params['time']['dt'] = 1.0
+    # # make dt=1 in parameter file
+    # @classmethod
+    # def generate_default_parameter_file(cls, file=None, save=True, prompt=True):
+    #     ''':meta private:'''
+
+    #     params = super(Poisson, cls).generate_default_parameter_file(
+    #         file=file, save=False, prompt=False)
+    #     params['time']['dt'] = 1.0
 
-        Poisson.write_parameters_to_file(
-            parameters=params, file=file, save=save, prompt=prompt)
+    #     Poisson.write_parameters_to_file(
+    #         parameters=params, file=file, save=save, prompt=prompt)
 
-        return params
+    #     return params
```

### Comparing `struphy-2.2.0/src/struphy/pic/accumulation/accum_kernels.py` & `struphy-2.3.0/src/struphy/pic/accumulation/accum_kernels.py`

 * *Files 1% similar despite different names*

```diff
@@ -77,42 +77,28 @@
         - ``b2_3: 'float[:,:,:]'``            # spline coefficients of b2_3
         - ``f0_params: 'float[:]'``          # parameters of equilibrium background
     '''
 
     print('This is just the docstring function.')
 
 
-def poisson(markers: 'float[:,:]', n_markers_tot: 'int',
+def charge_density_0form(markers: 'float[:,:]', n_markers_tot: 'int',
             pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
             starts: 'int[:]',
             kind_map: 'int', params_map: 'float[:]',
             p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
             ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
             cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-            vec: 'float[:,:,:]',
-            alpha: 'float',  # model specific argument
-            epsilon: 'float'):  # model specific argument
+            vec: 'float[:,:,:]'):  
     r"""
-    Kernel for :class:`struphy.pic.accumulation.particles_to_grid.AccumulatorVector` with the filling 
+    Kernel for :class:`~struphy.pic.accumulation.particles_to_grid.AccumulatorVector` into V0 with the filling 
 
     .. math::
 
-        B_p^\mu = \frac{\alpha^2}{\epsilon} w_p \,.
-
-    Parameters
-    ----------
-    alpha : float
-        Omega_c / Omega_p.
-
-    epsilon : float
-        omega / Omega_c.
-
-    Note
-    ----
-    The above parameter list contains only the model specific input arguments (`*args_add`).
+        B_p^\mu = \frac{w_p}{N} \,.
     """
 
     #$ omp parallel private (ip, eta1, eta2, eta3, f0, filling)
     #$ omp for reduction ( + :vec)
     for ip in range(shape(markers)[0]):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
@@ -120,16 +106,16 @@
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
         eta3 = markers[ip, 2]
 
-        # filling = alpha^2 / epsilon * w_p
-        filling = alpha**2 / epsilon * markers[ip, 6] / n_markers_tot
+        # filling = w_p/N
+        filling = markers[ip, 6] / n_markers_tot
 
         particle_to_mat_kernels.vec_fill_b_v0(pn, tn1, tn2, tn3, starts, eta1, eta2, eta3, vec, filling)
 
     #$ omp end parallel
 
 
 @stack_array('cell_left', 'point_left', 'point_right', 'cell_number', 'temp1', 'temp4', 'compact', 'grids_shapex', 'grids_shapey', 'grids_shapez')
@@ -623,24 +609,24 @@
 
     Note
     ----
         The above parameter list contains only the model specific input arguments.
     """
 
     # allocate for metric coeffs
-    dfm = empty((3, 3), dtype=float)
-    df_inv = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-    g_inv = empty((3, 3), dtype=float)
+    dfm = zeros((3, 3), dtype=float)
+    df_inv = zeros((3, 3), dtype=float)
+    df_inv_t = zeros((3, 3), dtype=float)
+    g_inv = zeros((3, 3), dtype=float)
 
     # allocate for filling
-    v = empty(3, dtype=float)
-    df_inv_times_v = empty(3, dtype=float)
-    filling_m = empty((3, 3), dtype=float)
-    filling_v = empty(3, dtype=float)
+    v = zeros(3, dtype=float)
+    df_inv_times_v = zeros(3, dtype=float)
+    filling_m = zeros((3, 3), dtype=float)
+    filling_v = zeros(3, dtype=float)
 
     #$ omp parallel private (ip, eta1, eta2, eta3, f0, dfm, df_inv, v, df_inv_times_v, filling_m, filling_v)
     #$ omp for reduction ( + : mat11, mat12, mat13, mat22, mat23, mat33, vec1, vec2, vec3)
     for ip in range(shape(markers)[0]):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
```

### Comparing `struphy-2.2.0/src/struphy/pic/accumulation/accum_kernels_gc.py` & `struphy-2.3.0/src/struphy/pic/accumulation/accum_kernels_gc.py`

 * *Files 2% similar despite different names*

```diff
@@ -89,35 +89,41 @@
                     p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                     ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                     cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
                     mat12: 'float[:,:,:,:,:,:]',
                     mat13: 'float[:,:,:,:,:,:]',
                     mat23: 'float[:,:,:,:,:,:]',
                     epsilon: float,           # model specific argument
-                    PB0: 'float[:,:,:]',    # model specific argument
                     b2_1: 'float[:,:,:]',   # model specific argument
                     b2_2: 'float[:,:,:]',   # model specific argument
                     b2_3: 'float[:,:,:]',   # model specific argument
                     norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',               # model specific argument
                     curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',   # model specific argument
-                    basis_u: 'int', scale_mat: 'float'):  # model specific argument
-    r"""Accumulation kernel for the propagator `CurrentCoupling5DDensity, <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_fields.CurrentCoupling5DDensity>`_ .
+                    basis_u: 'int', scale_mat: 'float', boundary_cut: float):  # model specific argument
+    r"""Accumulation kernel for the propagator :class:`~struphy.propagators.propagators_fields.CurrentCoupling5DDensity`.
 
-    Accumulates math:`\alpha` -form matrix with the filling functions
+    Accumulates :math:`\alpha`-form matrix with the filling functions (:math:`\alpha = 2`)
 
     .. math::
 
-        A_p^{\mu, \nu} = w_p * (1-\frac{B_\parallel}{B^*_\parallel}) * [ G^{-1}(\eta_p) * B2_{\times}(\eta_p) * G^{-1}(\eta_p) ]_{\mu, \nu}     
-
-    where :math:`B2_{\times} * a := B2 \times a` for :math:`a \in \mathbb R^3`. 
+        A_p^{\mu, \nu} = w_p \frac{1}{\epsilon} \left( 1-\frac{\hat B_\parallel}{\hat B^*_\parallel} \right)  g^{-1} (\mathbf B^2_\times)_{\mu, \nu} \,.
 
     Parameters
     ----------
+        epsilon : float
+            scaling factor.
+
         b2_1, b2_2, b2_3 : array[float]
             FE coefficients c_ijk of the magnetic field as a 2-form.
+        
+        norm_b11, norm_b12, norm_b12 : array[float]
+            FE coefficients c_ijk of the unit magnetic field as a 1-form.
+
+        curl_norm_b1, curl_norm_b2, curl_norm_b3 : array[float]
+            FE coefficients c_ijk of the curl of the unit magnetic field as a 2-form.
 
     Note
     ----
         The above parameter list contains only the model specific input arguments.
     """
 
     # allocate for magnetic field evaluation
@@ -146,29 +152,32 @@
     # allocate some temporary buffers for filling
     tmp1 = empty((3, 3), dtype=float)
     tmp2 = empty((3, 3), dtype=float)
 
     # get local number of markers
     n_markers_loc = shape(markers)[0]
 
-    #$ omp parallel firstprivate(b_prod) private(ip, eta1, eta2, eta3, v, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, b_para, curl_norm_b, b_star, norm_b1, b_star_para, density_const, dfm, df_inv, df_inv_t, g_inv, det_df, tmp1, tmp2, filling_m12, filling_m13, filling_m23)
+    #$ omp parallel firstprivate(b_prod) private(ip, boundary_cut, eta1, eta2, eta3, v, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, b_para, curl_norm_b, b_star, norm_b1, b_star_para, density_const, dfm, df_inv, df_inv_t, g_inv, det_df, tmp1, tmp2, filling_m12, filling_m13, filling_m23)
     #$ omp for reduction ( + : mat12, mat13, mat23)
     for ip in range(n_markers_loc):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
         eta3 = markers[ip, 2]
 
         v = markers[ip, 3]
 
+        if eta1 < boundary_cut or eta1 > 1. - boundary_cut:
+            continue
+
         # b-field evaluation
         span1 = bsplines_kernels.find_span(tn1, int(pn[0]), eta1)
         span2 = bsplines_kernels.find_span(tn2, int(pn[1]), eta2)
         span3 = bsplines_kernels.find_span(tn3, int(pn[2]), eta3)
 
         bsplines_kernels.b_d_splines_slim(tn1, int(pn[0]), eta1, span1, bn1, bd1)
         bsplines_kernels.b_d_splines_slim(tn2, int(pn[1]), eta2, span2, bn2, bd2)
@@ -177,18 +186,14 @@
         b[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
             int(pn[0]), int(pn[1]) - 1, int(pn[2]) - 1, bn1, bd2, bd3, span1, span2, span3, b2_1, starts)
         b[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
             int(pn[0]) - 1, int(pn[1]), int(pn[2]) - 1, bd1, bn2, bd3, span1, span2, span3, b2_2, starts)
         b[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
             int(pn[0]) - 1, int(pn[1]) - 1, int(pn[2]), bd1, bd2, bn3, span1, span2, span3, b2_3, starts)
 
-        # abs_b; 0form
-        b_para = evaluation_kernels_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, PB0, starts)
-
         # norm_b1; 1form
         norm_b1[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
             pn[0] - 1, pn[1], pn[2], bd1, bn2, bn3, span1, span2, span3, norm_b11, starts)
         norm_b1[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
             pn[0], pn[1] - 1, pn[2], bn1, bd2, bn3, span1, span2, span3, norm_b12, starts)
         norm_b1[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
             pn[0], pn[1], pn[2] - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts)
@@ -219,19 +224,22 @@
 
         det_df = linalg_kernels.det(dfm)
 
         # calculate Bstar and transform to H1vec
         b_star[:] = b + epsilon*v*curl_norm_b
         b_star /= det_df
 
-        # calculate abs_b_star_para
+        # calculate b_para and b_star_para
+        b_para = linalg_kernels.scalar_dot(norm_b1, b)
+        b_para /= det_df
+
         b_star_para = linalg_kernels.scalar_dot(norm_b1, b_star)
 
         # calculate scaling constant
-        density_const = 1 - b_para/b_star_para
+        density_const = (1 - b_para/b_star_para)/epsilon
 
         # marker weight
         weight = markers[ip, 5]
 
         if basis_u == 0:
 
             # filling functions
@@ -302,38 +310,39 @@
                      mat13: 'float[:,:,:,:,:,:]',
                      mat22: 'float[:,:,:,:,:,:]',
                      mat23: 'float[:,:,:,:,:,:]',
                      mat33: 'float[:,:,:,:,:,:]',
                      vec1: 'float[:,:,:]',
                      vec2: 'float[:,:,:]',
                      vec3: 'float[:,:,:]',
-                     epsilon: float,                  # model specific argument
+                     epsilon: float,                # model specific argument
                      b1: 'float[:,:,:]',            # model specific argument
                      b2: 'float[:,:,:]',            # model specific argument
                      b3: 'float[:,:,:]',            # model specific argument
                      norm_b11: 'float[:,:,:]',      # model specific argument
                      norm_b12: 'float[:,:,:]',      # model specific argument
                      norm_b13: 'float[:,:,:]',      # model specific argument
                      curl_norm_b1: 'float[:,:,:]',  # model specific argument
                      curl_norm_b2: 'float[:,:,:]',  # model specific argument
                      curl_norm_b3: 'float[:,:,:]',  # model specific argument
-                     basis_u: 'int',               # model specific argument
-                     scale_mat: 'float',           # model specific argument
-                     scale_vec: 'float'):          # model specific argument
-    r"""Accumulation kernel for the propagator `CurrentCoupling5DCurlb, <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_coupling.CurrentCoupling5DCurlb>`_ .
+                     basis_u: 'int',                # model specific argument
+                     scale_mat: 'float',            # model specific argument
+                     scale_vec: 'float',            # model specific argument
+                     boundary_cut: 'float'):        # model specific argument
+    r"""Accumulation kernel for the propagator :class:`~struphy.propagators.propagators_coupling.CurrentCoupling5DCurlb`.
 
-    Accumulates :math:`\alpha` -form matrix and vector with the filling functions
+    Accumulates :math:`\alpha`-form matrix and vector with the filling functions (:math:`\alpha = 2`)
 
     .. math::
 
-        A_p^{\mu, \nu} &= w_p * [G^{-1}(\eta_p) * B2_{\times}(\eta_p) * B2_{\times}(\eta_p)^\top * G^{-1}(\eta_p) * v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)^2 * |1/\sqrt{g} \hat \nabla \times \hat b^1_0|_p^2]_{\mu, \nu}
+        A_p^{\mu, \nu} &= w_p \left[\left( \frac{v_{\parallel,p}}{g\hat B^*_\parallel}\right)^2  \mathbf B^2_{\times} \left| \hat \nabla \times \hat{\mathbf b}^1_0 \right|^2 (\mathbf B^2_{\times})^\top \right]_{\mu, \nu}\,,
 
-        B_p^\mu &= w_p *[ G^{-1}(\eta_p) * B2_{\times}(\eta_p)* v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)]_\mu
+        B_p^\mu &= w_p \left( \frac{v^2_{\parallel,p}}{g\hat B^*_\parallel} \mathbf B^2_{\times} \right)_\mu \,,
 
-    where :math:`B2_{\times} * a := B2 \times a` for :math:`a \in \mathbb R^3`.
+    where :math:`\mathbf B^2_{\times} \mathbf a := \hat{\mathbf B}^2 \times \mathbf a` for :math:`a \in \mathbb R^3`.
 
     Parameters
     ----------
         b1, b2, b3 : array[float]
             FE coefficients c_ijk of the magnetic field as a 2-form.
 
         norm_b11, norm_b12, norm_b13 : array[float]
@@ -379,15 +388,15 @@
     tmp_m = empty((3, 3), dtype=float)
 
     tmp_v = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
 
-    #$ omp parallel firstprivate(b_prod) private(ip, eta1, eta2, eta3, v, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, b_star, b_prod_neg, norm_b1, curl_norm_b, abs_b_star_para, dfm, df_inv, df_inv_t, g_inv, det_df, tmp, tmp1, tmp2, tmp_m, tmp_v, filling_m, filling_v)
+    #$ omp parallel firstprivate(b_prod) private(ip, boundary_cut, eta1, eta2, eta3, v, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, b_star, b_prod_neg, norm_b1, curl_norm_b, abs_b_star_para, dfm, df_inv, df_inv_t, g_inv, det_df, tmp, tmp1, tmp2, tmp_m, tmp_v, filling_m, filling_v)
     #$ omp for reduction ( + : mat11, mat12, mat13, mat22, mat23, mat33, vec1, vec2, vec3)
     for ip in range(n_markers_loc):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
@@ -396,14 +405,17 @@
         eta2 = markers[ip, 1]
         eta3 = markers[ip, 2]
 
         # marker weight and velocity
         weight = markers[ip, 5]
         v = markers[ip, 3]
 
+        if eta1 < boundary_cut or eta1 > 1. - boundary_cut:
+            continue
+
         # b-field evaluation
         span1 = bsplines_kernels.find_span(tn1, int(pn[0]), eta1)
         span2 = bsplines_kernels.find_span(tn2, int(pn[1]), eta2)
         span3 = bsplines_kernels.find_span(tn3, int(pn[2]), eta3)
 
         bsplines_kernels.b_d_splines_slim(tn1, int(pn[0]), eta1, span1, bn1, bd1)
         bsplines_kernels.b_d_splines_slim(tn2, int(pn[1]), eta2, span2, bn2, bd2)
@@ -553,160 +565,79 @@
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
     #$ omp end parallel
 
 
-@stack_array('bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
-def cc_lin_mhd_5d_mu(markers: 'float[:,:]', n_markers_tot: 'int',
-                     pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                     starts: 'int[:]',
-                     kind_map: 'int', params_map: 'float[:]',
-                     p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                     ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                     cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                     mat: 'float[:,:,:,:,:,:]',
-                     vec: 'float[:,:,:]',
-                     coupling_const: 'float'):
-    r"""Accumulation kernel for the propagator `ShearAlfvénCurrentCoupling5D, <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_fields.ShearAlfvénCurrentCoupling5D>`_ .
-
-    Accumulates 0-form scalar with the filling functions:
-
-    .. math::
-
-        C_p = \omega_p * \mu_p \,.
-
-    """
-    bn1 = empty(int(pn[0]) + 1, dtype=float)
-    bn2 = empty(int(pn[1]) + 1, dtype=float)
-    bn3 = empty(int(pn[2]) + 1, dtype=float)
-
-    bd1 = empty(int(pn[0]), dtype=float)
-    bd2 = empty(int(pn[1]), dtype=float)
-    bd3 = empty(int(pn[2]), dtype=float)
-
-    # get number of markers
-    n_markers_loc = shape(markers)[0]
-
-    #$ omp parallel private(ip, eta1, eta2, eta3, mu, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, filling)
-    #$ omp for reduction ( + : vec)
-
-    for ip in range(n_markers_loc):
-
-        # only do something if particle is a "true" particle (i.e. not a hole)
-        if markers[ip, 0] == -1.:
-            continue
-
-        # marker positions
-        eta1 = markers[ip, 0]
-        eta2 = markers[ip, 1]
-        eta3 = markers[ip, 2]
-
-        # marker weight and velocity
-        weight = markers[ip, 5]
-        mu = markers[ip, 4]
-
-        # b-field evaluation
-        span1 = bsplines_kernels.find_span(tn1, int(pn[0]), eta1)
-        span2 = bsplines_kernels.find_span(tn2, int(pn[1]), eta2)
-        span3 = bsplines_kernels.find_span(tn3, int(pn[2]), eta3)
-
-        bsplines_kernels.b_d_splines_slim(tn1, int(pn[0]), eta1, span1, bn1, bd1)
-        bsplines_kernels.b_d_splines_slim(tn2, int(pn[1]), eta2, span2, bn2, bd2)
-        bsplines_kernels.b_d_splines_slim(tn3, int(pn[2]), eta3, span3, bn3, bd3)
-
-        filling = weight * mu * coupling_const
-
-        # call the appropriate matvec filler
-        particle_to_mat_kernels.vec_fill_v0(pn, span1, span2, span3, bn1,
-                           bn2, bn3, starts, vec, filling)
-
-    vec /= n_markers_tot
-
-    #$ omp end parallel
-
+@stack_array('dfm', 'norm_b1', 'filling_v', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
+def cc_lin_mhd_5d_M(markers: 'float[:,:]', n_markers_tot: 'int',
+                    pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                    starts: 'int[:]',
+                    kind_map: 'int', params_map: 'float[:]',
+                    p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                    ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                    cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                    mat11: 'float[:,:,:,:,:,:]',
+                    mat12: 'float[:,:,:,:,:,:]',
+                    mat13: 'float[:,:,:,:,:,:]',
+                    mat22: 'float[:,:,:,:,:,:]',
+                    mat23: 'float[:,:,:,:,:,:]',
+                    mat33: 'float[:,:,:,:,:,:]',
+                    vec1: 'float[:,:,:]',
+                    vec2: 'float[:,:,:]',
+                    vec3: 'float[:,:,:]',
+                    norm_b11: 'float[:,:,:]',  # model specific argument
+                    norm_b12: 'float[:,:,:]',  # model specific argument
+                    norm_b13: 'float[:,:,:]',  # model specific argument
+                    scale_vec: 'float',        # model specific argument
+                    boundary_cut: 'float'):    # model specific argument
 
-@stack_array('dfm', 'df_inv', 'df_inv_t', 'g_inv', 'filling_v', 'tmp_v1', 'tmp_v2', 'b', 'curl_norm_b', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
-def cc_lin_mhd_5d_curlMxB(markers: 'float[:,:]', n_markers_tot: 'int',
-                          pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
-                          starts: 'int[:]',
-                          kind_map: 'int', params_map: 'float[:]',
-                          p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
-                          ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
-                          cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
-                          mat11: 'float[:,:,:,:,:,:]',
-                          mat12: 'float[:,:,:,:,:,:]',
-                          mat13: 'float[:,:,:,:,:,:]',
-                          mat21: 'float[:,:,:,:,:,:]',
-                          mat22: 'float[:,:,:,:,:,:]',
-                          mat23: 'float[:,:,:,:,:,:]',
-                          mat31: 'float[:,:,:,:,:,:]',
-                          mat32: 'float[:,:,:,:,:,:]',
-                          mat33: 'float[:,:,:,:,:,:]',
-                          vec1: 'float[:,:,:]',
-                          vec2: 'float[:,:,:]',
-                          vec3: 'float[:,:,:]',
-                          b1: 'float[:,:,:]',           # model specific argument
-                          b2: 'float[:,:,:]',           # model specific argument
-                          b3: 'float[:,:,:]',           # model specific argument
-                          curl_norm_b1: 'float[:,:,:]', # model specific argument
-                          curl_norm_b2: 'float[:,:,:]', # model specific argument
-                          curl_norm_b3: 'float[:,:,:]', # model specific argument
-                          basis_u: 'int', scale_vec: 'float'):  # model specific argument
-    r"""Accumulation kernel for the propagator `MagnetosonicCurrentCoupling5D, <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_fields.MagnetosonicCurrentCoupling5D>`_ .
+    r"""Accumulation kernel for the propagator :class:`~struphy.propagators.propagators_fields.ShearAlfvénCurrentCoupling5D` and :class:`~struphy.propagators.propagators_fields.MagnetosonicCurrentCoupling5D`.
 
-    Accumulates :math:`\alpha` -form vector with the filling functions:
+    Accumulates 2-form vector with the filling functions:
 
     .. math::
 
-        B^\mu_p = \omega_p * \mu_p * [(\hat \nabla \times \hat{\mathbf b}^1_0)(\boldsymbol \eta_k) \times \hat{\mathbf B}^2 (\boldsymbol \eta_k)]_\mu \,.
+        B^\mu_p = \omega_p \mu_p\left(\sqrt{g}^{-1} \hat{\mathbf{b}}¹_0\right)_\mu \,.
 
     Parameters
     ----------
-        b2_1, b2_2, b2_3 : array[float]
-            FE coefficients c_ijk of the magnetic field as a 2-form.
 
-        curl_norm_b1, curl_norm_b2, curl_norm_b3 : array[float]
-            FE coefficients c_ijk of the curl of the unit magnetic field as a 1-form.
+        norm_b11, norm_b12, norm_b13 : array[float]
+            FE coefficients c_ijk of the normalized magnetic field as a 1-form.
 
     Note
     ----
         The above parameter list contains only the model specific input arguments.
     """
 
-    # allocate for magnetic field evaluation
-    b = empty(3, dtype=float)
-    curl_norm_b = empty(3, dtype=float)
+    # allocate for a field evaluation
+    norm_b1 = empty(3, dtype=float)
 
     bn1 = empty(int(pn[0]) + 1, dtype=float)
     bn2 = empty(int(pn[1]) + 1, dtype=float)
     bn3 = empty(int(pn[2]) + 1, dtype=float)
 
     bd1 = empty(int(pn[0]), dtype=float)
     bd2 = empty(int(pn[1]), dtype=float)
     bd3 = empty(int(pn[2]), dtype=float)
 
     # allocate for metric coeffs
     dfm = empty((3, 3), dtype=float)
-    df_inv = empty((3, 3), dtype=float)
-    df_inv_t = empty((3, 3), dtype=float)
-    g_inv = empty((3, 3), dtype=float)
 
     # allocate for filling
     filling_v = empty(3, dtype=float)
 
-    tmp_v1 = empty(3, dtype=float)
-    tmp_v2 = empty(3, dtype=float)
-
     # get number of markers
     n_markers_loc = shape(markers)[0]
 
-    #$ omp parallel private(ip, eta1, eta2, eta3, mu, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, curl_norm_b, dfm, df_inv, df_inv_t, g_inv, det_df, tmp_v1, tmp_v2, filling_v)
+    #$ omp parallel private(ip, boundary_cut, eta1, eta2, eta3, mu, weight, norm_b1, dfm, det_df, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, filling_v)
     #$ omp for reduction ( + : vec1, vec2, vec3)
+
     for ip in range(n_markers_loc):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
@@ -714,14 +645,17 @@
         eta2 = markers[ip, 1]
         eta3 = markers[ip, 2]
 
         # marker weight and velocity
         weight = markers[ip, 5]
         mu = markers[ip, 4]
 
+        if eta1 < boundary_cut or eta1 > 1. - boundary_cut:
+            continue
+
         # b-field evaluation
         span1 = bsplines_kernels.find_span(tn1, int(pn[0]), eta1)
         span2 = bsplines_kernels.find_span(tn2, int(pn[1]), eta2)
         span3 = bsplines_kernels.find_span(tn3, int(pn[2]), eta3)
 
         bsplines_kernels.b_d_splines_slim(tn1, int(pn[0]), eta1, span1, bn1, bd1)
         bsplines_kernels.b_d_splines_slim(tn2, int(pn[1]), eta2, span2, bn2, bd2)
@@ -733,69 +667,30 @@
                               t1_map, t2_map, t3_map, p_map,
                               ind1_map, ind2_map, ind3_map,
                               cx, cy, cz,
                               dfm)
 
         det_df = linalg_kernels.det(dfm)
 
-        # needed metric coefficients
-        linalg_kernels.matrix_inv_with_det(dfm, det_df, df_inv)
-        linalg_kernels.transpose(df_inv, df_inv_t)
-        linalg_kernels.matrix_matrix(df_inv, df_inv_t, g_inv)
-
-        # b; 2form
-        b[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
-            int(pn[0]), int(pn[1]) - 1, int(pn[2]) - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts)
-        b[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
-            int(pn[0]) - 1, int(pn[1]), int(pn[2]) - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts)
-        b[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
-            int(pn[0]) - 1, int(pn[1]) - 1, int(pn[2]), bd1, bd2, bn3, span1, span2, span3, b3, starts)
-
-        # curl_norm_b; 2form
-        curl_norm_b[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
-            int(pn[0]), int(pn[1]) - 1, int(pn[2]) - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts)
-        curl_norm_b[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
-            int(pn[0]) - 1, int(pn[1]), int(pn[2]) - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts)
-        curl_norm_b[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
-            int(pn[0]) - 1, int(pn[1]) - 1, int(pn[2]), bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts)
-
-        linalg_kernels.cross(curl_norm_b, b, tmp_v1)
-        tmp_v1 /= det_df
-
-        if basis_u == 0:
-
-            filling_v[:] = weight * mu * tmp_v1 * scale_vec
-
-            particle_to_mat_kernels.vec_fill_v0vec(pn, span1, span2, span3,
-                            bn1, bn2, bn3,
-                            starts,
-                            vec1, vec2, vec3,
-                            filling_v[0], filling_v[1], filling_v[2])
-
-        elif basis_u == 1:
-
-            linalg_kernels.matrix_vector(g_inv, tmp_v1, tmp_v2)
-
-            filling_v[:] = weight * mu * tmp_v2 * scale_vec
-
-            particle_to_mat_kernels.vec_fill_v1(pn, span1, span2, span3,
-                            bn1, bn2, bn3, bd1, bd2, bd3,
-                            starts,
-                            vec1, vec2, vec3,
-                            filling_v[0], filling_v[1], filling_v[2])
-
-        elif basis_u == 2:
+        # norm_b1; 1form
+        norm_b1[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]) - 1, int(pn[1]), int(pn[2]), bd1, bn2, bn3, span1, span2, span3, norm_b11, starts)
+        norm_b1[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]), int(pn[1]) - 1, int(pn[2]), bn1, bd2, bn3, span1, span2, span3, norm_b12, starts)
+        norm_b1[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]), int(pn[1]), int(pn[2]) - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts)
 
-            filling_v[:] = weight * mu * tmp_v1 / det_df * scale_vec
+        filling_v[:] = weight * mu / det_df * scale_vec * norm_b1
 
-            particle_to_mat_kernels.vec_fill_v2(pn, span1, span2, span3,
-                            bn1, bn2, bn3, bd1, bd2, bd3,
-                            starts,
-                            vec1, vec2, vec3,
-                            filling_v[0], filling_v[1], filling_v[2])
+        particle_to_mat_kernels.vec_fill_v2(pn, span1, span2, span3,
+                                            bn1, bn2, bn3,
+                                            bd1, bd2, bd3,
+                                            starts,
+                                            vec1, vec2, vec3,
+                                            filling_v[0], filling_v[1], filling_v[2])
 
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
     #$ omp end parallel
 
@@ -829,24 +724,25 @@
                      norm_b23: 'float[:,:,:]',       # model specific argument
                      curl_norm_b1: 'float[:,:,:]',  # model specific argument
                      curl_norm_b2: 'float[:,:,:]',  # model specific argument
                      curl_norm_b3: 'float[:,:,:]',  # model specific argument
                      grad_PB1: 'float[:,:,:]',  # model specific argument
                      grad_PB2: 'float[:,:,:]',  # model specific argument
                      grad_PB3: 'float[:,:,:]',  # model specific argument
-                     basis_u: 'int', scale_mat: 'float', scale_vec: 'float'):  # model specific argument
-    r"""Accumulation kernel for the propagator `CurrentCoupling5DGradBxB, <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_coupling.CurrentCoupling5DGradBxB>`_ .
+                     basis_u: 'int', scale_mat: 'float', scale_vec: 'float',
+                     boundary_cut: float):  # model specific argument
+    r"""Accumulation kernel for the propagator :class:`~struphy.propagators.propagators_coupling.CurrentCoupling5DGradB`.
 
     Accumulates math:`\alpha` -form matrix and vector with the filling functions
 
     .. math::
 
-        A_p^{\mu, \nu} &= w_p * [G^{-1}(\eta_p) * B2_{\times}(\eta_p) * B2_{\times}(\eta_p)^\top * G^{-1}(\eta_p) * v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)^2 * |1/\sqrt{g} \hat \nabla \times \hat b^1_0|_p^2]_{\mu, \nu}
+        A_p^{\mu, \nu} &= \omega_p \left[\left(\frac{\mu_p}{g\hat B^{*2}_\parallel}\right) \mathbf B^2_{\times} G^{-1} \mathbf b^2_{0 \times} G^{-1} \nabla B_\parallel¹G^{-\top} (\mathbf b^2_{0 \times})^\top G^{-\top} (\mathbf B^2_{\times})^\top \right]_{\mu, \nu} \,,
 
-        B_p^\mu &= w_p *[ G^{-1}(\eta_p) * B2_{\times}(\eta_p)* v^2_{\parallel,p} * \left( 1/B^*_\parallel \right)]_\mu
+        B_p^\mu &= \omega_p \left[\left(\frac{\mu_p}{\sqrt{g}\hat B^*_\parallel}\right) \mathbf B^2_{\times} G^{-1} \mathbf b^2_{0 \times} G^{-1} \nabla B_\parallel¹\right]_\mu \,,
 
     where :math:`B2_{\times} * a := B2 \times a` for :math:`a \in \mathbb R^3`.
 
     Parameters
     ----------
         b1, b2, b3 : array[float]
             FE coefficients c_ijk of the magnetic field as a 2-form.
@@ -903,27 +799,30 @@
     tmp_m = empty((3, 3), dtype=float)
 
     tmp_v = empty(3, dtype=float)
 
     # get number of markers
     n_markers_loc = shape(markers)[0]
 
-    #$ omp parallel firstprivate(b_prod) private(ip, eta1, eta2, eta3, v, mu, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, b_star, norm_b1, norm_b2, norm_b2_prod, curl_norm_b, grad_PB, grad_PB_mat, abs_b_star_para, dfm, df_inv, df_inv_t, g_inv, det_df, tmp_t, tmp1, tmp2, tmp_m, tmp_v, filling_m, filling_v)
+    #$ omp parallel firstprivate(b_prod) private(ip, boundary_cut, eta1, eta2, eta3, v, mu, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, b_star, norm_b1, norm_b2, norm_b2_prod, curl_norm_b, grad_PB, grad_PB_mat, abs_b_star_para, dfm, df_inv, df_inv_t, g_inv, det_df, tmp_t, tmp1, tmp2, tmp_m, tmp_v, filling_m, filling_v)
     #$ omp for reduction ( + : mat11, mat12, mat13, mat22, mat23, mat33, vec1, vec2, vec3)
     for ip in range(n_markers_loc):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         # marker positions
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
         eta3 = markers[ip, 2]
 
+        if eta1 < boundary_cut or eta1 > 1. - boundary_cut:
+            continue
+
         # marker weight and velocity
         weight = markers[ip, 5]
         v = markers[ip, 3]
         mu = markers[ip, 4]
 
         # b-field evaluation
         span1 = bsplines_kernels.find_span(tn1, int(pn[0]), eta1)
@@ -1118,14 +1017,257 @@
     vec1 /= n_markers_tot
     vec2 /= n_markers_tot
     vec3 /= n_markers_tot
 
     #$ omp end parallel
 
 
+# @stack_array('dfm', 'df_inv', 'df_inv_t', 'g_inv', 'filling_v', 'tmp_v1', 'tmp_v2', 'b', 'curl_norm_b', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
+# def cc_lin_mhd_5d_curlMxB(markers: 'float[:,:]', n_markers_tot: 'int',
+#                           pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+#                           starts: 'int[:]',
+#                           kind_map: 'int', params_map: 'float[:]',
+#                           p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+#                           ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+#                           cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+#                           mat11: 'float[:,:,:,:,:,:]',
+#                           mat12: 'float[:,:,:,:,:,:]',
+#                           mat13: 'float[:,:,:,:,:,:]',
+#                           mat21: 'float[:,:,:,:,:,:]',
+#                           mat22: 'float[:,:,:,:,:,:]',
+#                           mat23: 'float[:,:,:,:,:,:]',
+#                           mat31: 'float[:,:,:,:,:,:]',
+#                           mat32: 'float[:,:,:,:,:,:]',
+#                           mat33: 'float[:,:,:,:,:,:]',
+#                           vec1: 'float[:,:,:]',
+#                           vec2: 'float[:,:,:]',
+#                           vec3: 'float[:,:,:]',
+#                           b1: 'float[:,:,:]',           # model specific argument
+#                           b2: 'float[:,:,:]',           # model specific argument
+#                           b3: 'float[:,:,:]',           # model specific argument
+#                           curl_norm_b1: 'float[:,:,:]', # model specific argument
+#                           curl_norm_b2: 'float[:,:,:]', # model specific argument
+#                           curl_norm_b3: 'float[:,:,:]', # model specific argument
+#                           basis_u: 'int', scale_vec: 'float'):  # model specific argument
+#     r"""Accumulation kernel for the propagator `MagnetosonicCurrentCoupling5D, <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_fields.MagnetosonicCurrentCoupling5D>`_ .
+
+#     Accumulates :math:`\alpha` -form vector with the filling functions:
+
+#     .. math::
+
+#         B^\mu_p = \omega_p * \mu_p * [(\hat \nabla \times \hat{\mathbf b}^1_0)(\boldsymbol \eta_k) \times \hat{\mathbf B}^2 (\boldsymbol \eta_k)]_\mu \,.
+
+#     Parameters
+#     ----------
+#         b2_1, b2_2, b2_3 : array[float]
+#             FE coefficients c_ijk of the magnetic field as a 2-form.
+
+#         curl_norm_b1, curl_norm_b2, curl_norm_b3 : array[float]
+#             FE coefficients c_ijk of the curl of the unit magnetic field as a 1-form.
+
+#     Note
+#     ----
+#         The above parameter list contains only the model specific input arguments.
+#     """
+
+#     # allocate for magnetic field evaluation
+#     b = empty(3, dtype=float)
+#     curl_norm_b = empty(3, dtype=float)
+
+#     bn1 = empty(int(pn[0]) + 1, dtype=float)
+#     bn2 = empty(int(pn[1]) + 1, dtype=float)
+#     bn3 = empty(int(pn[2]) + 1, dtype=float)
+
+#     bd1 = empty(int(pn[0]), dtype=float)
+#     bd2 = empty(int(pn[1]), dtype=float)
+#     bd3 = empty(int(pn[2]), dtype=float)
+
+#     # allocate for metric coeffs
+#     dfm = empty((3, 3), dtype=float)
+#     df_inv = empty((3, 3), dtype=float)
+#     df_inv_t = empty((3, 3), dtype=float)
+#     g_inv = empty((3, 3), dtype=float)
+
+#     # allocate for filling
+#     filling_v = empty(3, dtype=float)
+
+#     tmp_v1 = empty(3, dtype=float)
+#     tmp_v2 = empty(3, dtype=float)
+
+#     # get number of markers
+#     n_markers_loc = shape(markers)[0]
+
+#     #$ omp parallel private(ip, eta1, eta2, eta3, mu, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, curl_norm_b, dfm, df_inv, df_inv_t, g_inv, det_df, tmp_v1, tmp_v2, filling_v)
+#     #$ omp for reduction ( + : vec1, vec2, vec3)
+#     for ip in range(n_markers_loc):
+
+#         # only do something if particle is a "true" particle (i.e. not a hole)
+#         if markers[ip, 0] == -1.:
+#             continue
+
+#         # marker positions
+#         eta1 = markers[ip, 0]
+#         eta2 = markers[ip, 1]
+#         eta3 = markers[ip, 2]
+
+#         # marker weight and velocity
+#         weight = markers[ip, 5]
+#         mu = markers[ip, 4]
+
+#         # b-field evaluation
+#         span1 = bsplines_kernels.find_span(tn1, int(pn[0]), eta1)
+#         span2 = bsplines_kernels.find_span(tn2, int(pn[1]), eta2)
+#         span3 = bsplines_kernels.find_span(tn3, int(pn[2]), eta3)
+
+#         bsplines_kernels.b_d_splines_slim(tn1, int(pn[0]), eta1, span1, bn1, bd1)
+#         bsplines_kernels.b_d_splines_slim(tn2, int(pn[1]), eta2, span2, bn2, bd2)
+#         bsplines_kernels.b_d_splines_slim(tn3, int(pn[2]), eta3, span3, bn3, bd3)
+
+#         # evaluate Jacobian, result in dfm
+#         evaluation_kernels.df(eta1, eta2, eta3,
+#                               kind_map, params_map,
+#                               t1_map, t2_map, t3_map, p_map,
+#                               ind1_map, ind2_map, ind3_map,
+#                               cx, cy, cz,
+#                               dfm)
+
+#         det_df = linalg_kernels.det(dfm)
+
+#         # needed metric coefficients
+#         linalg_kernels.matrix_inv_with_det(dfm, det_df, df_inv)
+#         linalg_kernels.transpose(df_inv, df_inv_t)
+#         linalg_kernels.matrix_matrix(df_inv, df_inv_t, g_inv)
+
+#         # b; 2form
+#         b[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+#             int(pn[0]), int(pn[1]) - 1, int(pn[2]) - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts)
+#         b[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+#             int(pn[0]) - 1, int(pn[1]), int(pn[2]) - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts)
+#         b[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+#             int(pn[0]) - 1, int(pn[1]) - 1, int(pn[2]), bd1, bd2, bn3, span1, span2, span3, b3, starts)
+
+#         # curl_norm_b; 2form
+#         curl_norm_b[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+#             int(pn[0]), int(pn[1]) - 1, int(pn[2]) - 1, bn1, bd2, bd3, span1, span2, span3, curl_norm_b1, starts)
+#         curl_norm_b[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+#             int(pn[0]) - 1, int(pn[1]), int(pn[2]) - 1, bd1, bn2, bd3, span1, span2, span3, curl_norm_b2, starts)
+#         curl_norm_b[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+#             int(pn[0]) - 1, int(pn[1]) - 1, int(pn[2]), bd1, bd2, bn3, span1, span2, span3, curl_norm_b3, starts)
+
+#         linalg_kernels.cross(curl_norm_b, b, tmp_v1)
+#         tmp_v1 /= det_df
+
+#         if basis_u == 0:
+
+#             filling_v[:] = weight * mu * tmp_v1 * scale_vec
+
+#             particle_to_mat_kernels.vec_fill_v0vec(pn, span1, span2, span3,
+#                             bn1, bn2, bn3,
+#                             starts,
+#                             vec1, vec2, vec3,
+#                             filling_v[0], filling_v[1], filling_v[2])
+
+#         elif basis_u == 1:
+
+#             linalg_kernels.matrix_vector(g_inv, tmp_v1, tmp_v2)
+
+#             filling_v[:] = weight * mu * tmp_v2 * scale_vec
+
+#             particle_to_mat_kernels.vec_fill_v1(pn, span1, span2, span3,
+#                             bn1, bn2, bn3, bd1, bd2, bd3,
+#                             starts,
+#                             vec1, vec2, vec3,
+#                             filling_v[0], filling_v[1], filling_v[2])
+
+#         elif basis_u == 2:
+
+#             filling_v[:] = weight * mu * tmp_v1 / det_df * scale_vec
+
+#             particle_to_mat_kernels.vec_fill_v2(pn, span1, span2, span3,
+#                             bn1, bn2, bn3, bd1, bd2, bd3,
+#                             starts,
+#                             vec1, vec2, vec3,
+#                             filling_v[0], filling_v[1], filling_v[2])
+
+#     vec1 /= n_markers_tot
+#     vec2 /= n_markers_tot
+#     vec3 /= n_markers_tot
+
+#     #$ omp end parallel
+
+
+# @stack_array('bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
+# def cc_lin_mhd_5d_mu(markers: 'float[:,:]', n_markers_tot: 'int',
+#                      pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+#                      starts: 'int[:]',
+#                      kind_map: 'int', params_map: 'float[:]',
+#                      p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+#                      ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+#                      cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+#                      mat: 'float[:,:,:,:,:,:]',
+#                      vec: 'float[:,:,:]',
+#                      coupling_const: 'float'):
+#     r"""Accumulation kernel for the propagator `ShearAlfvénCurrentCoupling5D, <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_fields.ShearAlfvénCurrentCoupling5D>`_ .
+
+#     Accumulates 0-form scalar with the filling functions:
+
+#     .. math::
+
+#         C_p = \omega_p * \mu_p \,.
+
+#     """
+#     bn1 = empty(int(pn[0]) + 1, dtype=float)
+#     bn2 = empty(int(pn[1]) + 1, dtype=float)
+#     bn3 = empty(int(pn[2]) + 1, dtype=float)
+
+#     bd1 = empty(int(pn[0]), dtype=float)
+#     bd2 = empty(int(pn[1]), dtype=float)
+#     bd3 = empty(int(pn[2]), dtype=float)
+
+#     # get number of markers
+#     n_markers_loc = shape(markers)[0]
+
+#     #$ omp parallel private(ip, eta1, eta2, eta3, mu, weight, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, filling)
+#     #$ omp for reduction ( + : vec)
+
+#     for ip in range(n_markers_loc):
+
+#         # only do something if particle is a "true" particle (i.e. not a hole)
+#         if markers[ip, 0] == -1.:
+#             continue
+
+#         # marker positions
+#         eta1 = markers[ip, 0]
+#         eta2 = markers[ip, 1]
+#         eta3 = markers[ip, 2]
+
+#         # marker weight and velocity
+#         weight = markers[ip, 5]
+#         mu = markers[ip, 4]
+
+#         # b-field evaluation
+#         span1 = bsplines_kernels.find_span(tn1, int(pn[0]), eta1)
+#         span2 = bsplines_kernels.find_span(tn2, int(pn[1]), eta2)
+#         span3 = bsplines_kernels.find_span(tn3, int(pn[2]), eta3)
+
+#         bsplines_kernels.b_d_splines_slim(tn1, int(pn[0]), eta1, span1, bn1, bd1)
+#         bsplines_kernels.b_d_splines_slim(tn2, int(pn[1]), eta2, span2, bn2, bd2)
+#         bsplines_kernels.b_d_splines_slim(tn3, int(pn[2]), eta3, span3, bn3, bd3)
+
+#         filling = weight * mu * coupling_const
+
+#         # call the appropriate matvec filler
+#         particle_to_mat_kernels.vec_fill_v0(pn, span1, span2, span3, bn1,
+#                            bn2, bn3, starts, vec, filling)
+
+#     vec /= n_markers_tot
+
+#     #$ omp end parallel
+
+
 # def cc_lin_mhd_5d_J2_dg(markers: 'float[:,:]', n_markers_tot: 'int',
 #                         pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
 #                         starts: 'int[:]',
 #                         kind_map: 'int', params_map: 'float[:]',
 #                         p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
 #                         ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
 #                         cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
```

### Comparing `struphy-2.2.0/src/struphy/pic/accumulation/filler_kernels.py` & `struphy-2.3.0/src/struphy/pic/accumulation/filler_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/accumulation/particle_to_mat_kernels.py` & `struphy-2.3.0/src/struphy/pic/accumulation/particle_to_mat_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/accumulation/particles_to_grid.py` & `struphy-2.3.0/src/struphy/pic/accumulation/particles_to_grid.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,28 +15,28 @@
     r"""
     Struphy accumulation matrices and vectors of the form
 
     .. math::
 
         M^{\mu,\nu}_{ijk,mno} &= \sum_p \Lambda^\mu_{ijk}(\eta_p) * A^{\mu,\nu}_p * (\Lambda^\nu_{mno})^\top(\eta_p)  \qquad  (\mu,\nu = 1,2,3)
 
-        S^\mu_{ijk} &= \sum_p \Lambda^\mu_{ijk}(\eta_p) * B^\mu_p
+        V^\mu_{ijk} &= \sum_p \Lambda^\mu_{ijk}(\eta_p) * B^\mu_p
 
     where :math:`p` runs over the particles, :math:`\Lambda^\mu_{ijk}(\eta_p)` denotes the :math:`ijk`-th basis function
-    of the :math:`\mu`-th component of a Derham space (V0, V1, V2, V3) evaluated at the particle position :math:`\eta_p`.
+    of the :math:`\mu`-th component of a Derham space (V0, V1, V2, V3, V0vec) evaluated at the particle position :math:`\eta_p`.
 
     :math:`A^{\mu,\nu}_p` and :math:`B^\mu_p` are particle-dependent "filling functions",
-    to be defined in the module **struphy.pic.accumulation.accum_kernels**.
+    to be defined in the module :mod:`~struphy.pic.accumulation.accum_kernels`.
 
     Parameters
     ----------
-    derham : struphy.feec.psydac_derham.Derham
+    derham : Derham
         Discrete Derham complex.
 
-    domain : struphy.geometry.domains
+    domain : Domain
         Mapping info for evaluating metric coefficients.
 
     space_id : str
         Space identifier for the matrix/vector (H1, Hcurl, Hdiv, L2 or H1vec) to be accumulated into.
 
     kernel_name : str
         Name of accumulation kernel.
@@ -304,27 +304,27 @@
 
 class AccumulatorVector:
     r"""
     Struphy accumulation for only a vector of the form
 
     .. math::
 
-        S^\mu_{ijk} = \sum_p \Lambda^\mu_{ijk}(\eta_p) * B^\mu_p
+        V^\mu_{ijk} = \sum_p \Lambda^\mu_{ijk}(\eta_p) * B^\mu_p
 
     where :math:`p` runs over the particles, :math:`\Lambda^\mu_{ijk}(\eta_p)` denotes the :math:`ijk`-th basis function
-    of the :math:`\mu`-th component of a Derham space (V0, V1, V2, V3) evaluated at the particle position :math:`\eta_p`.
+    of the :math:`\mu`-th component of a Derham space (V0, V1, V2, V3, V0vec) evaluated at the particle position :math:`\eta_p`.
 
-    :math:`B^\mu_p` is a particle-dependent "filling function", to be defined in the module **struphy.pic.accumulation.accum_kernels**.
+    :math:`B^\mu_p` is a particle-dependent "filling function", to be defined in the module :mod:`~struphy.pic.accumulation.accum_kernels`.
 
     Parameters
     ----------
-    derham : struphy.feec.psydac_derham.Derham
+    derham : Derham
         Discrete Derham complex.
 
-    domain : struphy.geometry.domains
+    domain : Domain
         Mapping info for evaluating metric coefficients.
 
     space_id : str
         Space identifier for the matrix/vector (H1, Hcurl, Hdiv, L2 or H1vec) to be accumulated into.
 
     kernel_name : str
         Name of accumulation kernel.
@@ -436,29 +436,32 @@
         from struphy.feec.projectors import L2Projector
         
         # L2 projector for dofs
         self._get_L2dofs = L2Projector(self.space_id, mass_ops).get_dofs
 
     def accumulate(self, particles, *args_add, **args_control):
         """
-        Performs the accumulation into the vector by calling the chosen accumulation kernel and additional analytical contributions (control variate, optional).
+        Performs the accumulation into the vector by calling the chosen accumulation kernel 
+        and additional analytical contributions (control variate, optional).
 
         Parameters
         ----------
-        particles : struphy.pic.particles.Particles
-            Particles object holding the markers information in format particles.markers.shape == (n_markers, :).
+        particles : Particles
+            Particles object holding the markers information.
 
         *args_add
             Additional arguments to be passed to the accumulator kernel, besides the mandatory arguments
             which are prepared automatically (spline bases info, mapping info, data arrays).
             Examples would be parameters for a background kinetic distribution or spline coefficients of a background magnetic field.
             Entries must be pyccel-conform types.
 
         **args_control
-            Keyword arguments for an analytical control variate correction in the accumulation step. Possible keywords are 'control_vec' for a vector correction or 'control_mat' for a matrix correction. Values are a 1d (vector) or 2d (matrix) list with callables or np.ndarrays used for the correction.
+            Keyword arguments for an analytical control variate correction in the accumulation step. 
+            Possible keywords are 'control_vec' for a vector correction or 'control_mat' for a matrix correction. 
+            Values are a 1d (vector) or 2d (matrix) list with callables or np.ndarrays used for the correction.
         """
 
         # flags for break
         vec_finished = False
 
         # reset data
         for dat in self._args_data:
@@ -479,7 +482,44 @@
             vec_finished = True
 
         # finish vector: accumulate ghost regions and update ghost regions
         if not vec_finished:
             for vec in self._vectors:
                 vec.exchange_assembly_data()
                 vec.update_ghost_regions()
+
+    def show_accumulated_spline_field(self, mass_ops, eta_direction=0):
+        r'''1D plot of the spline field corresponding to the accumulated vector.
+        The latter can be viewed as the rhs of an L2-projection:
+        
+        .. math::
+        
+            \mathbb M \mathbf a = \sum_p \boldsymbol \Lambda(\boldsymbol \eta_p) * B_p\,.
+            
+        The FE coefficients :math:`\mathbf a` determine a FE :class:`~struphy.feec.psydac_derham.Derham.Field`.
+        '''
+        from struphy.feec.projectors import L2Projector
+        from matplotlib import pyplot as plt
+        
+        # L2 projection
+        proj = L2Projector(self.space_id, mass_ops)
+        a = proj.solve(self.vectors[0])
+        
+        # create field and assign coeffs
+        field = self.derham.create_field('accum_field', self.space_id)
+        field.vector = a
+        
+        # plot field
+        eta = np.linspace(0, 1, 100)
+        if eta_direction == 0:
+            args = (eta, .5, .5)
+        elif eta_direction == 1:
+            args = (.5, eta, .5)
+        else:
+            args = (.5, .5, eta)
+            
+        plt.plot(eta, field(*args, squeeze_output=True))
+        plt.title(f'Spline field accumulated with the kernel "{self.kernel_name}"')
+        plt.xlabel(f'$\eta_{eta_direction + 1}$')
+        plt.ylabel('field amplitude')
+        plt.show()
+
```

### Comparing `struphy-2.2.0/src/struphy/pic/base.py` & `struphy-2.3.0/src/struphy/pic/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,137 +5,192 @@
 import yaml
 import numpy as np
 import h5py
 import scipy.special as sp
 
 from struphy.pic import sampling_kernels, sobol_seq
 from struphy.pic.pushing.pusher_utilities_kernels import reflect
-from struphy.pic.utilities_kernels import eval_magnetic_energy
 from struphy.kinetic_background import maxwellians
 from struphy.fields_background.mhd_equil.equils import set_defaults
 from struphy.io.output_handling import DataContainer
 
 
 class Particles(metaclass=ABCMeta):
     """
-    Base class for a particle based kinetic species.
+    Base class for particle species.
 
-    Loading and compute initial particles and save the values at the corresponding column of markers array:
-
-    ===== ============== ======================= ======= ====== ====== ========== === ===
-    index  | 0 | 1 | 2 | | 3 | ... | 3+(vdim-1)|  3+vdim 4+vdim 5+vdim >=6+vdim   ... -1
-    ===== ============== ======================= ======= ====== ====== ========== === ===
-    value position (eta)    velocities           weight   s0     w0      other    ... ID
-    ===== ============== ======================= ======= ====== ====== ========== === ===
+    The marker information is stored in a 2D numpy array, 
+    see `Tutorial on PIC data structures <https://struphy.pages.mpcdf.de/struphy/tutorials/tutorial_08_data_structures.html#PIC-data-structures>`_.
 
     Parameters
     ----------
     name : str
         Name of particle species.
 
-    **params : dict
-        Marker parameters.
-    """
+    derham : Derham
+        Struphy Derham object. 
+
+    domain : Domain
+        Struphy domain object.
+
+    mhd_equil : MHDequilibrium
+        Struphy MHD equilibrium object
+
+    bckgr_params : dict
+        Kinetic background parameters.
 
-    def __init__(self, name: str, **params):
+    pert_params : dict
+        Kinetic perturbation parameters.
 
-        params_default = {'type': 'full_f',
-                          'ppc': None,
-                          'Np': 4,
-                          'eps': .25,
-                          'bc': {'type': ['periodic', 'periodic', 'periodic']},
-                          'loading': {'type': 'pseudo:random', 'seed': 1234, 'dir_particles': None, 'moments': [0., 0., 0., 1., 1., 1.]},
-                          'derham': None,
-                          'domain': None,
-                          'f0_params': None}
+    marker_params : dict
+        Marker parameters for loading.
+    """
+
+    def __init__(self,
+                 name,
+                 derham=None,
+                 domain=None,
+                 mhd_equil=None,
+                 bckgr_params=None,
+                 pert_params=None,
+                 **marker_params):
+
+        if bckgr_params is None:
+            bckgr_params = {'type': 'Maxwellian6D'}
+
+        self._bckgr_params = bckgr_params
+        self._pert_params = pert_params
+
+        marker_params_default = {
+            'type': 'full_f',
+            'ppc': None,
+            'Np': 4,
+            'eps': .25,
+            'bc': {'type': ['periodic', 'periodic', 'periodic']},
+            'loading': {'type': 'pseudo:random',
+                        'seed': 1234,
+                        'dir_particles': None,
+                        'moments': [0., 0., 0., 1., 1., 1.]},
+        }
 
-        self._params = set_defaults(params, params_default)
+        self._marker_params = set_defaults(
+            marker_params, marker_params_default)
 
         self._name = name
-        self._derham = params['derham']
-        self._domain = params['domain']
-        self._domain_decomp = params['derham'].domain_array
-        f0_params = params['f0_params']
-
-        assert params['derham'].comm is not None
-        self._mpi_comm = params['derham'].comm
-        self._mpi_size = params['derham'].comm.Get_size()
-        self._mpi_rank = params['derham'].comm.Get_rank()
+        self._derham = derham
+        self._domain = domain
+        self._mhd_equil = mhd_equil
+
+        self._domain_decomp = derham.domain_array
+
+        if 'pforms' in bckgr_params:
+            assert len(bckgr_params['pforms']) == 2, \
+                'Only two form degrees can be given!'
+            self._pforms = bckgr_params['pforms']
+        else:
+            self._pforms = [None, None]
+
+        if derham is not None:
+            self._mpi_comm = derham.comm
+            self._mpi_size = derham.comm.Get_size()
+            self._mpi_rank = derham.comm.Get_rank()
+        else:
+            raise NotImplementedError('We need an MPI comm for the moment.')
 
         # create marker array
         self.create_marker_array()
 
-        # Assume full-f if type is not in parameters
-        if params['type'] not in 'full_f':
-
-            self._control_variate = True
-
-            assert f0_params is not None, \
-                'When control variate is used, background parameters must be given!'
-            fun_name = f0_params['type']
-
-            if fun_name in f0_params:
-                self._f_backgr = getattr(maxwellians, fun_name)(
-                    **f0_params[fun_name])
-            else:
-                self._f_backgr = getattr(maxwellians, fun_name)()
+        # Check if control variate
+        self._control_variate = (
+            self.marker_params['type'] == 'control_variate')
+
+        # set background function
+        bckgr_fun = bckgr_params['type']
+
+        if bckgr_fun in bckgr_params:
+            self._f_backgr = getattr(maxwellians, bckgr_fun)(
+                maxw_params=bckgr_params[bckgr_fun],
+                mhd_equil=mhd_equil
+            )
         else:
+            self._f_backgr = getattr(maxwellians, bckgr_fun)()
+            print(
+                f'\n{bckgr_fun} is not in bckgr_params; default background parameters are used.')
+
+    @classmethod
+    @abstractmethod
+    def default_bckgr_params(cls):
+        """ Dictionary holding the minimal information of the default background.
 
-            self._control_variate = False
-            self._f_backgr = None
+        Must contain at least a keyword 'type' with corresponding value a valid choice of background.
+        """
+        pass
 
     @abstractmethod
     def velocity_jacobian_det(self, eta1, eta2, eta3, *v):
-        """ Jacobian determinant of the velocity coordinate transformation.
+        """ Jacobian determinant of the velocity coordinate transformation 
+        (e.g. :math:`B^*_\parallel` in gyrokinetics).
         """
         pass
 
     @abstractmethod
     def svol(self, eta1, eta2, eta3, *v):
-        """ Sampling density function as volume form.
+        r""" Marker sampling distribution function :math:`s^\textrm{vol}` as a volume form, see :ref:`monte_carlo`.
         """
         pass
 
     @abstractmethod
     def s0(self, eta1, eta2, eta3, *v, remove_holes=True):
-        """ Sampling density function as 0 form.
+        r""" Marker sampling distribution function :math:`s^0` as 0-form, see :ref:`monte_carlo`.
         """
         pass
 
     @property
     @abstractmethod
     def n_cols(self):
-        """Number of the columns at each markers.
+        """Number of columns in the :attr:`~struphy.pic.base.Particles.markers` array.
         """
         pass
 
     @property
     @abstractmethod
     def vdim(self):
         """Dimension of the velocity space.
         """
         pass
 
     @property
     def kinds(self):
-        """ Name of the class
+        """ Name of the class.
         """
         return self.__class__.__name__
 
     @property
     def name(self):
         """ Name of the kinetic species in DATA container.
         """
         return self._name
 
     @property
-    def params(self):
+    def bckgr_params(self):
+        """ Kinetic background parameters.
+        """
+        return self._bckgr_params
+
+    @property
+    def pert_params(self):
+        """ Kinetic perturbation parameters.
+        """
+        return self._pert_params
+
+    @property
+    def marker_params(self):
         """ Parameters for markers.
         """
-        return self._params
+        return self._marker_params
 
     @property
     def f_init(self):
         assert hasattr(self, '_f_init'), AttributeError(
             'The method "initialize_weights" has not yet been called.')
         return self._f_init
 
@@ -143,15 +198,15 @@
     def f_backgr(self):
         assert hasattr(self, '_f_backgr'), AttributeError(
             'No background distribution available, maybe this is a full-f model?')
         return self._f_backgr
 
     @property
     def control_variate(self):
-        '''Boolean for whether to use the `<https://struphy.pages.mpcdf.de/struphy/sections/discretization.html#control-variate-method>`_.'''
+        '''Boolean for whether to use the :ref:`control_var` during time stepping.'''
         return self._control_variate
 
     @property
     def domain_decomp(self):
         """ Array containing domain decomposition information.
         """
         return self._domain_decomp
@@ -190,21 +245,25 @@
     def n_mks_load(self):
         """ Array of number of markers on each process at loading stage
         """
         return self._n_mks_load
 
     @property
     def markers(self):
-        """ Numpy array holding the marker information, including holes. The i-th row holds the i-th marker info.
+        """ 2D numpy array holding the marker information, including holes. 
+        The i-th row holds the i-th marker info.
 
         ===== ============== ======================= ======= ====== ====== ========== === ===
         index  | 0 | 1 | 2 | | 3 | ... | 3+(vdim-1)|  3+vdim 4+vdim 5+vdim >=6+vdim   ... -1
         ===== ============== ======================= ======= ====== ====== ========== === ===
         value position (eta)    velocities           weight   s0     w0      other    ... ID
         ===== ============== ======================= ======= ====== ====== ========== === ===
+
+        The column indices referring to different attributes can be obtained from
+        :attr:`~struphy.pic.base.Particles.index`.
         """
         return self._markers
 
     @property
     def holes(self):
         """ Array of booleans stating if an entry in the markers array is a hole or not. 
         """
@@ -220,25 +279,31 @@
     def markers_wo_holes(self):
         """ Array holding the marker information, excluding holes. The i-th row holds the i-th marker info.
         """
         return self.markers[~self.holes]
 
     @property
     def derham(self):
-        """ struphy.feec.psydac_derham.Derham
+        """ :class:`~struphy.feec.psydac_derham.Derham`
         """
         return self._derham
 
     @property
     def domain(self):
-        """ struphy.geometry.domains
+        """ From :mod:`struphy.geometry.domains`.
         """
         return self._domain
 
     @property
+    def mhd_equil(self):
+        """ From :mod:`struphy.fields_background.mhd_equil.equils`.
+        """
+        return self._mhd_equil
+
+    @property
     def lost_markers(self):
         """ Array containing the last infos of removed markers
         """
         return self._lost_markers
 
     @property
     def n_lost_markers(self):
@@ -354,32 +419,32 @@
     @property
     def spatial(self):
         """ Drawing particles uniformly on the unit cube('uniform') or on the disc('disc')
         """
         return self._spatial
 
     def create_marker_array(self):
-        """ Create marker array (self.markers).
+        """ Create marker array :attr:`~struphy.pic.base.Particles.markers`.
         """
 
         # number of cells on current process
         n_cells_loc = np.prod(
             self._domain_decomp[self._mpi_rank, 2::3], dtype=int)
 
         # total number of cells
         n_cells = np.sum(
             np.prod(self._domain_decomp[:, 2::3], axis=1, dtype=int))
 
         # number of markers to load on each process (depending on relative domain size)
-        if self.params['ppc'] is not None:
-            assert isinstance(self.params['ppc'], int)
-            ppc = self.params['ppc']
+        if self.marker_params['ppc'] is not None:
+            assert isinstance(self.marker_params['ppc'], int)
+            ppc = self.marker_params['ppc']
             Np = ppc*n_cells
         else:
-            Np = self.params['Np']
+            Np = self.marker_params['Np']
             assert isinstance(Np, int)
             ppc = Np/n_cells
 
         Np = int(Np)
         assert Np >= self._mpi_size
 
         # array of number of markers on each process at loading stage
@@ -395,29 +460,29 @@
         self._n_mks = Np
 
         # number of markers on the local process at loading stage
         n_mks_load_loc = self._n_mks_load[self._mpi_rank]
 
         # create markers array (3 x positions, vdim x velocities, weight, s0, w0, ..., ID) with eps send/receive buffer
         markers_size = round(n_mks_load_loc *
-                             (1 + 1/np.sqrt(n_mks_load_loc) + self.params['eps']))
+                             (1 + 1/np.sqrt(n_mks_load_loc) + self.marker_params['eps']))
         self._markers = np.zeros((markers_size, self.n_cols), dtype=float)
 
         # create array container (3 x positions, vdim x velocities, weight, s0, w0, ID) for removed markers
         self._n_lost_markers = 0
         self._lost_markers = np.zeros((int(markers_size*0.5), 10), dtype=float)
 
     def draw_markers(self):
         r""" 
-        Drawing markers according to the volume density :math:`s^n_{\textnormal{in}}`.
-        In Struphy, the initial marker distribution :math:`s^n_{\textnormal{in}}` is always of the form
+        Drawing markers according to the volume density :math:`s^\textrm{vol}_{\textnormal{in}}`.
+        In Struphy, the initial marker distribution :math:`s^\textrm{vol}_{\textnormal{in}}` is always of the form
 
         .. math::
 
-            s^n_{\textnormal{in}}(\eta,v) = n^3(\eta)\, \mathcal M(v)\,,
+            s^\textrm{vol}_{\textnormal{in}}(\eta,v) = n^3(\eta)\, \mathcal M(v)\,,
 
         with :math:`\mathcal M(v)` a multi-variate Gaussian:
 
         .. math:: 
 
             \mathcal M(v) = \prod_{i=1}^{d_v} \frac{1}{\sqrt{2\pi}\,v_{\mathrm{th},i}}
                 \exp\left[-\frac{(v_i-u_i)^2}{2 v_{\mathrm{th},i}^2}\right]\,,
@@ -468,15 +533,15 @@
 
         So then,
 
         .. math::
 
             v_\perp = \sqrt{- \ln(1-r)}\sqrt{2}v_\mathrm{th} + u \,.
 
-        All needed parameters can be set in the parameter file, in the section ``kinetic/<species>/markers/loading``.
+        All needed parameters can be set in the parameter file, see :ref:`params_yml`.
         """
 
         # number of markers on the local process at loading stage
         n_mks_load_loc = self.n_mks_load[self.mpi_rank]
 
         # fill holes in markers array with -1 (all holes are at end of array at loading stage)
         self._markers[n_mks_load_loc:] = -1.
@@ -487,23 +552,24 @@
         self._n_mks_loc = self.markers.shape[0] - self._n_holes_loc
 
         # cumulative sum of number of markers on each process at loading stage.
         n_mks_load_cum_sum = np.cumsum(self.n_mks_load)
 
         if self.mpi_rank == 0:
             print('\nMARKERS:')
-            for key, val in self.params.items():
+            for key, val in self.marker_params.items():
                 if 'loading' not in key and 'derham' not in key and 'domain' not in key:
                     print((key + ' :').ljust(25), val)
 
         # load markers from external .hdf5 file
-        if self.params['loading']['type'] == 'external':
+        if self.marker_params['loading']['type'] == 'external':
 
             if self.mpi_rank == 0:
-                file = h5py.File(self.params['loading']['dir_markers'], 'r')
+                file = h5py.File(
+                    self.marker_params['loading']['dir_markers'], 'r')
                 print('Loading markers from file: '.ljust(25), file)
 
                 self._markers[:n_mks_load_cum_sum[0], :
                               ] = file['markers'][:n_mks_load_cum_sum[0], :]
 
                 for i in range(1, self._mpi_size):
                     self._mpi_comm.Send(
@@ -513,66 +579,66 @@
             else:
                 recvbuf = np.zeros(
                     (n_mks_load_loc, self.markers.shape[1]), dtype=float)
                 self._mpi_comm.Recv(recvbuf, source=0, tag=123)
                 self._markers[:n_mks_load_loc, :] = recvbuf
 
         # load markers from restart .hdf5 file
-        elif self.params['loading']['type'] == 'restart':
+        elif self.marker_params['loading']['type'] == 'restart':
 
             libpath = struphy.__path__[0]
 
             with open(os.path.join(libpath, 'state.yml')) as f:
                 state = yaml.load(f, Loader=yaml.FullLoader)
 
             o_path = state['o_path']
 
-            if self.params['loading']['dir_particles_abs'] is None:
+            if self.marker_params['loading']['dir_particles_abs'] is None:
                 data_path = os.path.join(
-                    o_path, self.params['loading']['dir_particles'])
+                    o_path, self.marker_params['loading']['dir_particles'])
             else:
-                data_path = self.params['loading']['dir_particles_abs']
+                data_path = self.marker_params['loading']['dir_particles_abs']
 
             data = DataContainer(data_path, comm=self.comm)
 
             self.markers[:, :] = data.file['restart/' +
-                                           self.params['loading']['key']][-1, :, :]
+                                           self.marker_params['loading']['key']][-1, :, :]
 
         # load fresh markers
         else:
 
             if self.mpi_rank == 0:
                 print('\nLoading fresh markers:')
-                for key, val in self.params['loading'].items():
+                for key, val in self.marker_params['loading'].items():
                     print((key + ' :').ljust(25), val)
 
             # 1. standard random number generator (pseudo-random)
-            if self.params['loading']['type'] == 'pseudo_random':
+            if self.marker_params['loading']['type'] == 'pseudo_random':
 
-                _seed = self.params['loading']['seed']
+                _seed = self.marker_params['loading']['seed']
                 if _seed is not None:
                     np.random.seed(_seed)
 
                 for i in range(self._mpi_size):
                     temp = np.random.rand(self.n_mks_load[i], 3 + self.vdim)
 
                     if i == self._mpi_rank:
                         self.phasespace_coords = temp
                         break
 
                 del temp
 
             # 2. plain sobol numbers with skip of first 1000 numbers
-            elif self.params['loading']['type'] == 'sobol_standard':
+            elif self.marker_params['loading']['type'] == 'sobol_standard':
 
                 self.phasespace_coords = sobol_seq.i4_sobol_generate(
                     3 + self.vdim, n_mks_load_loc, 1000 + (n_mks_load_cum_sum - self.n_mks_load)[self._mpi_rank])
 
             # 3. symmetric sobol numbers in all 6 dimensions with skip of first 1000 numbers
-            elif self.params['loading']['type'] == 'sobol_antithetic':
+            elif self.marker_params['loading']['type'] == 'sobol_antithetic':
 
                 assert self.vdim == 3, NotImplementedError(
                     '"sobol_antithetic" requires vdim=3 at the moment.')
 
                 temp_markers = sobol_seq.i4_sobol_generate(
                     3 + self.vdim, n_mks_load_loc//64, 1000 + (n_mks_load_cum_sum - self.n_mks_load)[self._mpi_rank]//64)
 
@@ -581,16 +647,18 @@
 
             # 4. Wrong specification
             else:
                 raise ValueError(
                     'Specified particle loading method does not exist!')
 
             # inverse transform sampling in velocity space
-            u_mean = np.array(self.params['loading']['moments'][:self.vdim])
-            v_th = np.array(self.params['loading']['moments'][self.vdim:])
+            u_mean = np.array(
+                self.marker_params['loading']['moments'][:self.vdim])
+            v_th = np.array(
+                self.marker_params['loading']['moments'][self.vdim:])
 
             # Particles6D: (1d Maxwellian, 1d Maxwellian, 1d Maxwellian)
             if self.vdim == 3:
                 self.velocities = sp.erfinv(
                     2*self.velocities - 1)*np.sqrt(2)*v_th + u_mean
 
             # Particles5D: (1d Maxwellian, 2d Maxwellian)
@@ -601,28 +669,28 @@
                     -1*np.log(1-self.velocities[:, 1]))*np.sqrt(2)*v_th[1] + u_mean[1]
 
             else:
                 raise NotImplementedError(
                     'Inverse transform sampling of given vdim is not implemented!')
 
             # inversion method for drawing uniformly on the disc
-            self._spatial = self.params['loading']['spatial']
+            self._spatial = self.marker_params['loading']['spatial']
             if self._spatial == 'disc':
                 self._markers[:n_mks_load_loc, 0] = np.sqrt(
                     self.markers[:n_mks_load_loc, 0])
             else:
                 assert self._spatial == 'uniform', f'Spatial drawing must be "uniform" or "disc", is {self._spatial}.'
 
             # set markers ID in last column
             self.marker_ids = (n_mks_load_cum_sum - self.n_mks_load)[
                 self._mpi_rank] + np.arange(n_mks_load_loc, dtype=float)
 
             # set specific initial condition for some particles
-            if 'initial' in self.params['loading']:
-                specific_markers = self.params['loading']['initial']
+            if 'initial' in self.marker_params['loading']:
+                specific_markers = self.marker_params['loading']['initial']
 
                 counter = 0
                 for i in range(len(specific_markers)):
                     if i == int(self.markers[counter, -1]):
 
                         for j in range(3+self.vdim):
                             if specific_markers[i][j] is not None:
@@ -635,15 +703,15 @@
             n_mks_load_loc = self._n_mks_load[self._mpi_rank]
 
             assert np.all(~self._holes[:n_mks_load_loc]) and np.all(
                 self._holes[n_mks_load_loc:])
 
     def mpi_sort_markers(self, do_test=False):
         """ 
-        Sorts markers according to domain decomposition.
+        Sorts markers according to MPI domain decomposition.
 
         Parameters
         ----------
         do_test : bool
             Check if all markers are on the right process after sorting.
         """
 
@@ -678,60 +746,56 @@
                 self.positions > self.domain_decomp[self.mpi_rank, 0::3],
                 self.positions < self.domain_decomp[self.mpi_rank, 1::3]))
 
             assert all_on_right_proc
 
         self.comm.Barrier()
 
-    def initialize_weights(self, fun_params, bckgr_params=None):
+    def initialize_weights(self):
         r"""
         Computes the initial weights
 
         .. math::
 
             w_{k0} := \frac{f^0(t, q_k(t)) }{s^0(t, q_k(t)) } = \frac{f^0(0, q_k(0)) }{s^0(0, q_k(0)) } = \frac{f^0_{\textnormal{in}}(q_{k0}) }{s^0_{\textnormal{in}}(q_{k0}) }
 
         from the initial distribution function :math:`f^0_{\textnormal{in}}` specified in the parmeter file
-        and from the initial volume density :math:`s^n_{\textnormal{in}}` specified in :meth:`struphy.pic.particles.Particles.draw_markers`.
+        and from the initial volume density :math:`s^n_{\textnormal{vol}}` specified in :meth:`~struphy.pic.base.Particles.draw_markers`.
         Moreover, it sets the corresponding columns for "w0", "s0" and "weights" in the markers array.
-        For the control variate method, the background is subtracted.
-
-        Parameters
-        ----------
-        fun_params : dict
-            Dictionary of the form {type : class_name, pforms : differential forms, class_name : params_dict} defining the initial condition.
-
-        bckgr_params : dict (optional)
-            Dictionary of the form {type : class_name, class_name : params_dict} defining the background.
+        If :attr:`~struphy.pic.base.Particles.control_variate` is True, the background :attr:`~struphy.pic.base.Particles.f_backgr` is subtracted.
         """
 
         assert self.domain is not None, 'A domain is needed to initialize weights.'
 
         # compute s0 and save at vdim + 4
         self.sampling_density = self.s0(*self.phasespace_coords.T)
 
         # load distribution function (with given parameters or default parameters)
-        fun_name = fun_params['type']
+        bckgr_fun = self.bckgr_params['type']
+        bp_copy = self._bckgr_params.copy()
 
-        if fun_name in fun_params:
-            self._f_init = getattr(maxwellians, fun_name)(
-                **fun_params[fun_name])
-        else:
-            self._f_init = getattr(maxwellians, fun_name)()
+        # For delta-f set markers only as perturbation
+        if self.marker_params['type'] == 'delta_f':
+            # Take out background by setting its density to zero
+            if bckgr_fun in bp_copy:
+                bp_copy[bckgr_fun]['n'] = 0.
+            else:
+                bp_copy[bckgr_fun] = {'n': 0.}
 
-        f_init = self.f_init(*self.phasespace_coords.T)
+        # Get the initialization function and pass the correct arguments
+        print(f'{bp_copy = }')
+        self._f_init = getattr(maxwellians, bckgr_fun)(
+            maxw_params=bp_copy[bckgr_fun],
+            pert_params=self.pert_params,
+            mhd_equil=self.mhd_equil
+        )
 
-        # if diffential forms of f_init is not specified, consider it as 0-form
-        if 'pforms' in fun_params:
-            assert len(fun_params['pforms']) == 2
-            self._pforms = fun_params['pforms']
-        else:
-            self._pforms = (None, None)
+        f_init = self.f_init(*self.phasespace_coords.T)
 
-        # if f_init is vol-form, tramsform to 0-form
+        # if f_init is vol-form, transform to 0-form
         if self.pforms[0] == 'vol':
             f_init /= self.domain.jacobian_det(self.markers_wo_holes)
 
         if self.pforms[1] == 'vol':
             f_init /= self.velocity_jacobian_det(*self.phasespace_coords.T)
 
         # compute w0 and save at vdim + 5
@@ -741,18 +805,17 @@
         if self._control_variate:
             self.update_weights()
         else:
             self.weights = self.weights0
 
     def update_weights(self):
         """
-        Applies the control variate method.
-
-        Updates the time-dependent marker weights according to the algorithm in the 
-        `Struphy documentation <https://struphy.pages.mpcdf.de/struphy/sections/discretization.html#control-variate-method>`_.
+        Applies the control variate method, i.e. updates the time-dependent marker weights 
+        according to the algorithm in :ref:`control_var`.
+        The background :attr:`~struphy.pic.base.Particles.f_backgr` is used for this.
         """
 
         f_backgr = self.f_backgr(*self.phasespace_coords.T)
 
         # if f_init is vol-form, transform to 0-form
         if self.pforms[0] == 'vol':
             f_backgr /= self.domain.jacobian_det(self.markers_wo_holes)
@@ -760,17 +823,17 @@
         if self.pforms[1] == 'vol':
             f_backgr /= self.velocity_jacobian_det(
                 *self.phasespace_coords.T)
 
         self.weights = self.weights0 - f_backgr/self.sampling_density
 
     def binning(self, components, bin_edges, pforms=['0', '0']):
-        r"""
-        Computes the distribution function via marker binning in logical space using numpy's histogramdd,
-        following the algorithm outlined in the `Struphy documentation <https://struphy.pages.mpcdf.de/struphy/sections/discretization.html#particle-binning>`_.
+        r""" Computes the distribution function via marker binning in logical space.
+        For this, numpy's histogramdd is used, following the algorithm outlined in the `Struphy documentation
+        <https://struphy.pages.mpcdf.de/struphy/sections/discretization.html#particle-binning>`_.
         If pforms=['vol','vol'], approximations of the volume density :math:`f^n(t)` are computed (of :math:`f^0(t)` by default). 
 
         Parameters
         ----------
         components : list[bool]
             List of length n (dim. of phase space) giving the directions in phase space in which to bin.
 
@@ -807,15 +870,15 @@
         if pforms[1] == '0':
             _weights /= self.velocity_jacobian_det(*self.phasespace_coords.T)
 
         f_slice = np.histogramdd(self.markers_wo_holes[:, slicing],
                                  bins=bin_edges,
                                  weights=_weights)[0]
 
-        return f_slice/(self._n_mks*bin_vol)
+        return f_slice / (self.n_mks * bin_vol)
 
     def show_distribution_function(self, components, bin_edges, pforms=['0', '0']):
         """
         1D and 2D plots of slices of the distribution function via marker binning.
         This routine is mainly for de-bugging.
 
         Parameters
@@ -836,16 +899,18 @@
 
         assert n_dim == 1 or n_dim == 2, f'Distribution function can only be shown in 1D or 2D slices, not {n_dim}.'
 
         f_slice = self.binning(components, bin_edges, pforms)
 
         bin_centers = [bi[:-1] + (bi[1] - bi[0])/2 for bi in bin_edges]
 
-        labels = {0: '$\eta_1$', 1: '$\eta_2$',
-                  2: '$\eta_3$', 3: '$v_1$', 4: '$v_2$', 5: '$v_3$'}
+        labels = {
+            0: r'$\eta_1$', 1: r'$\eta_2$', 2: r'$\eta_3$',
+            3: '$v_1$', 4: '$v_2$', 5: '$v_3$'
+        }
         indices = np.nonzero(components)[0]
 
         if n_dim == 1:
             plt.plot(bin_centers[0], f_slice)
             plt.xlabel(labels[indices[0]])
         else:
             plt.contourf(bin_centers[0], bin_centers[1], f_slice, levels=20)
@@ -860,34 +925,34 @@
         """
         Apply boundary conditions to markers that are outside of the logical unit cube.
 
         Parameters
         ----------
         """
 
-        for axis, bc in enumerate(self.params['bc']['type']):
+        for axis, bc in enumerate(self.marker_params['bc']['type']):
 
             # sorting out particles outside of the logical unit cube
             is_outside_cube = np.logical_or(self.markers[:, axis] > 1.,
                                             self.markers[:, axis] < 0.)
 
             # exclude holes
             is_outside_cube[self.holes] = False
 
             # indices or particles that are outside of the logical unit cube
             outside_inds = np.nonzero(is_outside_cube)[0]
 
             # apply boundary conditions
             if bc == 'remove':
 
-                if self.params['bc']['remove']['boundary_transfer']:
+                if self.marker_params['bc']['remove']['boundary_transfer']:
                     # boundary transfer
                     outside_inds = self.boundary_transfer(is_outside_cube)
 
-                if self.params['bc']['remove']['save']:
+                if self.marker_params['bc']['remove']['save']:
                     # save the positions and velocities just before the pushing step
                     if self.vdim == 3:
                         self.lost_markers[self.n_lost_markers:self.n_lost_markers +
                                           len(outside_inds), 0:3] = self.markers[outside_inds, 9:12]
                         self.lost_markers[self.n_lost_markers:self.n_lost_markers +
                                           len(outside_inds), 3:9] = self.markers[outside_inds, 3:9]
                         self.lost_markers[self.n_lost_markers:self.n_lost_markers +
```

### Comparing `struphy-2.2.0/src/struphy/pic/particles.py` & `struphy-2.3.0/src/struphy/pic/particles.py`

 * *Files 10% similar despite different names*

```diff
@@ -19,47 +19,44 @@
 
     Parameters
     ----------
     name : str
         Name of the particle species.
 
     **params : dict
-        Parameters for markers.
+        Parameters for markers, see :class:`~struphy.pic.base.Particles`.
     """
 
-    def __init__(self, name, **params):
+    @classmethod
+    def default_bckgr_params(cls):
+        return {'type': 'Maxwellian6D',
+                'Maxwellian6D': {}}
 
-        # base class params
-        base_params = {}
+    def __init__(self, name, **params):
 
-        list_base_params = ['type', 'ppc', 'Np', 'eps',
-                            'bc', 'loading', 'derham', 'domain',
-                            'f0_params']
-
-        for key, val in params.items():
-            if key in list_base_params:
-                base_params[key] = val
+        assert 'bckgr_params' in params
+        if params['bckgr_params'] is None:
+            params['bckgr_params'] = self.default_bckgr_params()
 
-        super().__init__(name, **base_params)
+        super().__init__(name, **params)
 
     @property
     def n_cols(self):
-        """Number of the columns at each markers.
+        """ Number of the columns at each markers.
         """
         return 16
 
     @property
     def vdim(self):
-        """Dimension of the velocity space.
+        """ Dimension of the velocity space.
         """
         return 3
 
     def velocity_jacobian_det(self, eta1, eta2, eta3, *v):
-        """
-        Jacobian determinant of the velocity coordinate transformation.
+        """ Jacobian determinant of the velocity coordinate transformation.
 
         Input parameters should be slice of 2d numpy marker array. (i.e. *self.phasespace_coords.T)
 
         Parameters
         ----------
         eta1, eta2, eta3 : array_like
             Logical evaluation points.
@@ -78,16 +75,15 @@
         assert eta2.ndim == 1
         assert eta3.ndim == 1
         assert len(v) == self.vdim
 
         return 1. + 0*eta1
 
     def svol(self, eta1, eta2, eta3, *v):
-        """ 
-        Sampling density function as volume form.
+        """ Sampling density function as volume form.
 
         Parameters
         ----------
         eta1, eta2, eta3 : array_like
             Logical evaluation points.
 
         *v : array_like
@@ -95,38 +91,39 @@
 
         Returns
         -------
         out : array-like
             The volume-form sampling density.
         -------
         """
-        # load sampling density svol = s6 = s3 (normalized to 1 in logical space!)
-        Maxwellian6DUniform = getattr(maxwellians, 'Maxwellian6DUniform')
+        # load sampling density svol (normalized to 1 in logical space)
+        maxwellian6D = getattr(maxwellians, 'Maxwellian6D')
 
-        s3 = Maxwellian6DUniform(n=1.,
-                                 u1=self._params['loading']['moments'][0],
-                                 u2=self._params['loading']['moments'][1],
-                                 u3=self._params['loading']['moments'][2],
-                                 vth1=self._params['loading']['moments'][3],
-                                 vth2=self._params['loading']['moments'][4],
-                                 vth3=self._params['loading']['moments'][5])
+        maxw_params = {'n': 1.,
+                       'u1': self.marker_params['loading']['moments'][0],
+                       'u2': self.marker_params['loading']['moments'][1],
+                       'u3': self.marker_params['loading']['moments'][2],
+                       'vth1': self.marker_params['loading']['moments'][3],
+                       'vth2': self.marker_params['loading']['moments'][4],
+                       'vth3': self.marker_params['loading']['moments'][5]}
+
+        fun = maxwellian6D(maxw_params=maxw_params)
 
         if self.spatial == 'uniform':
-            return s3(eta1, eta2, eta3, *v)
+            return fun(eta1, eta2, eta3, *v)
 
         elif self.spatial == 'disc':
-            return s3(eta1, eta2, eta3, *v)*2*eta1
+            return fun(eta1, eta2, eta3, *v)*2*eta1
 
         else:
             raise NotImplementedError(
                 f'Spatial drawing must be "uniform" or "disc", is {self._spatial}.')
 
     def s0(self, eta1, eta2, eta3, *v, remove_holes=True):
-        """ 
-        Sampling density function as 0 form.
+        """ Sampling density function as 0 form.
 
         Parameters
         ----------
         eta1, eta2, eta3 : array_like
             Logical evaluation points.
 
         *v : array_like
@@ -159,73 +156,42 @@
 
     Parameters
     ----------
     name : str
         Name of the particle species.
 
     **params : dict
-        Parameters for markers.
+        Parameters for markers, see :class:`~struphy.pic.base.Particles`.
     """
 
-    def __init__(self, name, **params):
-
-        # base class params
-        base_params = {}
-
-        list_base_params = ['type', 'ppc', 'Np', 'eps',
-                            'bc', 'loading', 'derham', 'domain']
-
-        for key, val in params.items():
-            if key in list_base_params:
-                base_params[key] = val
-
-        super().__init__(name, **base_params)
+    @classmethod
+    def default_bckgr_params():
+        return {'type': 'Maxwellian5D',
+                'Maxwellian5D': {}}
 
-        # child class params
-        child_params = {}
-
-        list_child_params = ['mhd_equil', 'epsilon']
-
-        for key, val in params.items():
-            if key in list_child_params:
-                child_params[key] = val
-
-        params_default = {'mhd_equil': None,
-                          'epsilon': 1.
-                          }
+    def __init__(self, name, **params):
 
-        child_params = set_defaults(child_params, params_default)
+        assert 'bckgr_params' in params
+        if params['bckgr_params'] is None:
+            params['bckgr_params'] = self.default_bckgr_params()
 
-        self._mhd_equil = params['mhd_equil']
-        self._epsilon = child_params['epsilon']
+        super().__init__(name, **params)
 
     @property
     def n_cols(self):
         """Number of the columns at each markers.
         """
         return 23
 
     @property
     def vdim(self):
         """Dimension of the velocity space.
         """
         return 2
 
-    @property
-    def mhd_equil(self):
-        """Class of MHD equilibrium
-        """
-        return self._mhd_equil
-
-    @property
-    def epsilon(self):
-        """Epsilon unit, 1 / (cyclotron freq * time_unit)
-        """
-        return self._epsilon
-
     def velocity_jacobian_det(self, eta1, eta2, eta3, *v):
         """
         Jacobian determinant of the velocity coordinate transformation.
 
         Input parameters should be slice of 2d numpy marker array. (i.e. *self.phasespace_coords.T)
 
         Parameters
@@ -272,28 +238,30 @@
 
         Returns
         -------
         out : array-like
             The volume-form sampling density.
         -------
         """
-        # load sampling density svol = s5 (normalized to 1 in logical space!)
-        Maxwellian5DUniform = getattr(maxwellians, 'Maxwellian5DUniform')
+        # load sampling density svol (normalized to 1 in logical space)
+        maxwellian5D = getattr(maxwellians, 'Maxwellian5D')
 
-        s5 = Maxwellian5DUniform(n=1.,
-                                 u_parallel=self.params['loading']['moments'][0],
-                                 u_perp=self.params['loading']['moments'][1],
-                                 vth_parallel=self.params['loading']['moments'][2],
-                                 vth_perp=self.params['loading']['moments'][3])
+        maxw_params = {'n': 1.,
+                       'u_para': self.marker_params['loading']['moments'][0],
+                       'u_perp': self.marker_params['loading']['moments'][1],
+                       'vth_para': self.marker_params['loading']['moments'][2],
+                       'vth_perp': self.marker_params['loading']['moments'][3]}
+
+        fun = maxwellian5D(maxw_params=maxw_params)
 
         if self.spatial == 'uniform':
-            return s5(eta1, eta2, eta3, *v)
+            return fun(eta1, eta2, eta3, *v)
 
         elif self.spatial == 'disc':
-            return s5(eta1, eta2, eta3, *v)*2*eta1
+            return fun(eta1, eta2, eta3, *v)*2*eta1
 
         else:
             raise NotImplementedError(
                 f'Spatial drawing must be "uniform" or "disc", is {self._spatial}.')
 
     def s3(self, eta1, eta2, eta3, *v):
         """
@@ -353,21 +321,32 @@
         absB = E0T.dot(absB)
 
         eval_magnetic_moment_5d(self.markers,
                                 np.array(self.derham.p), T1, T2, T3,
                                 np.array(self.derham.Vh['0'].starts),
                                 absB._data)
 
-    def save_magnetic_energy(self, PB):
+    def save_magnetic_energy(self, abs_B0, unit_b1, b):
         r"""
         Calculate magnetic field energy at each particles' position and asign it into markers[:,8].
         """
-        T1, T2, T3 = self.derham.Vh_fem['0'].knots
+
+        # fixed FEM arguments for the accumulator kernel
+        self._args_fem = (np.array(self.derham.p),
+                          self.derham.Vh_fem['0'].knots[0],
+                          self.derham.Vh_fem['0'].knots[1],
+                          self.derham.Vh_fem['0'].knots[2],
+                          np.array(self.derham.Vh['0'].starts))
 
         E0T = self.derham.extraction_ops['0'].transpose()
+        E1T = self.derham.extraction_ops['1'].transpose()
+        E2T = self.derham.extraction_ops['2'].transpose()
 
-        PB = E0T.dot(PB)
+        abs_B0 = E0T.dot(abs_B0)
+        unit_b1 = E1T.dot(unit_b1)
+        b = E2T.dot(b)
 
         eval_magnetic_energy(self.markers,
-                             np.array(self.derham.p), T1, T2, T3,
-                             np.array(self.derham.Vh['0'].starts),
-                             PB._data)
+                             *self._args_fem, *self._domain.args_map,
+                             abs_B0._data,
+                             unit_b1[0]._data, unit_b1[1]._data, unit_b1[2]._data,
+                             b[0]._data, b[1]._data, b[2]._data)
```

### Comparing `struphy-2.2.0/src/struphy/pic/pushing/eval_kernels_gc.py` & `struphy-2.3.0/src/struphy/pic/pushing/eval_kernels_gc.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/pushing/pusher.py` & `struphy-2.3.0/src/struphy/pic/pushing/pusher.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/pushing/pusher_kernels.py` & `struphy-2.3.0/src/struphy/pic/pushing/pusher_kernels.py`

 * *Files 0% similar despite different names*

```diff
@@ -74,22 +74,22 @@
                        starts: 'int[:]',
                        kind_map: int, params_map: 'float[:]',
                        p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                        ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                        cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
                        e1_1: 'float[:,:,:]', e1_2: 'float[:,:,:]', e1_3: 'float[:,:,:]',
                        const: 'float'):
-    r'''Updates
+    r'''Updates particle velocities as
 
     .. math::
 
-        \frac{\mathbf v^{n+1}_k - \mathbf v^n_k}{\Delta t} = C * DF^{-\top}(\boldsymbol \eta^n_k) \hat{\mathbf E}^1_h(\boldsymbol \eta^n_k)
+        \frac{\mathbf v^{n+1} - \mathbf v^n}{\Delta t} = c * \bar{DF}^{-\top}  (\mathbb L^1)^\top \mathbf e
 
-    for each marker :math:`k` in markers array, where :math:`\hat{\mathbf E}^1_h \in V_h^1 \subset H(\textnormal{curl})`,
-    and :math:`C \in \mathbb R` some constant.
+    where :math:`\mathbf e \in \mathbb R^{N_1}` are given FE coefficients of the 1-form spline field
+    and :math:`c \in \mathbb R` is some constant.
 
     Parameters
     ----------
         e1_1, e1_2, e1_3 : ndarray[float]
             3d array of FE coeffs of E-field as 1-form.
             
         const : float
```

### Comparing `struphy-2.2.0/src/struphy/pic/pushing/pusher_kernels_gc.py` & `struphy-2.3.0/src/struphy/pic/pushing/pusher_kernels_gc.py`

 * *Files 0% similar despite different names*

```diff
@@ -1907,15 +1907,16 @@
                        p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
                        ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
                        cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
                        epsilon: float,
                        b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                        norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                        curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
-                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]'):
+                       u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]',
+                       boundary_cut: float):
     r'''Velocity update step for the `CurrentCoupling5DCurlb <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_coupling.CurrentCoupling5DCurlb>`_
 
     Marker update:
 
     .. math::
 
         v_{\parallel,p}^{n+1} =  v_{\parallel,p}^n - \frac{\Delta t}{2} \hat B^{*,-1}_\parallel(\mathbf X_p, v^n_{\parallel,p}) \frac{1}{\sqrt{g(\mathbf X_p)}} \frac{1}{\sqrt{g(\mathbf X_p)}} v_{\parallel,p}^n \hat{\mathbf B}^2(\mathbf X_p) \times(\hat \nabla \times \hat{\mathbf b}_0)(\mathbf X_p) \Lambda^2 (\mathbf u^{n+1} + \mathbf u^n ) (\mathbf X_p) \,,
@@ -1945,25 +1946,28 @@
 
     # marker position eta
     eta = empty(3, dtype=float)
 
     # get number of markers
     n_markers = shape(markers)[0]
 
-    #$ omp parallel private(ip, eta, v, det_df, dfm, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, u, e, curl_norm_b, norm_b1, b_star, tmp, abs_b_star_para)
+    #$ omp parallel private(ip, boundary_cut, eta, v, det_df, dfm, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, u, e, curl_norm_b, norm_b1, b_star, tmp, abs_b_star_para)
     #$ omp for
     for ip in range(n_markers):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         eta[:] = markers[ip, 0:3]
         v = markers[ip, 3]
 
+        if eta[0] < boundary_cut or eta[0] > 1. - boundary_cut:
+            continue
+
         # evaluate Jacobian, result in dfm
         evaluation_kernels.df(eta[0], eta[1], eta[2],
                               kind_map, params_map,
                               t1_map, t2_map, t3_map, p_map,
                               ind1_map, ind2_map, ind3_map,
                               cx, cy, cz,
                               dfm)
@@ -2044,15 +2048,15 @@
                               epsilon: float,
                               b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                               norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                               norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                               curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                               u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]',
                               a: 'float[:]', b: 'float[:]', c: 'float[:]'):
-    r'''Single stage of a s-stage explicit pushing step for the `CurrentCoupling5DGradBxB <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_coupling.CurrentCoupling5DGradBxB>`_
+    r'''Single stage of a s-stage explicit pushing step for the `CurrentCoupling5DGradB <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_coupling.CurrentCoupling5DGradB>`_
 
     Marker update:
 
     .. math::
 
         \mathbf X^{n+1} = \mathbf X^n - \frac{\Delta t}{2} \hat B^{*,-1}_\parallel(\mathbf X_p, v^n_{\parallel,p}) G^{-1}(\mathbf X_p) \hat{\mathbf b}_0^2(\mathbf X_p) \times G^{-1}(\mathbf X_p) \hat{\mathbf B}^2(\mathbf X_p) \times \Lambda^v (\mathbf u^{n+1} + \mathbf u^n ) (\mathbf X_p) \,,
 
@@ -2223,16 +2227,16 @@
                              cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
                              epsilon: float,
                              b1: 'float[:,:,:]', b2: 'float[:,:,:]', b3: 'float[:,:,:]',
                              norm_b11: 'float[:,:,:]', norm_b12: 'float[:,:,:]', norm_b13: 'float[:,:,:]',
                              norm_b21: 'float[:,:,:]', norm_b22: 'float[:,:,:]', norm_b23: 'float[:,:,:]',
                              curl_norm_b1: 'float[:,:,:]', curl_norm_b2: 'float[:,:,:]', curl_norm_b3: 'float[:,:,:]',
                              u1: 'float[:,:,:]', u2: 'float[:,:,:]', u3: 'float[:,:,:]',
-                             a: 'float[:]', b: 'float[:]', c: 'float[:]'):
-    r'''Single stage of a s-stage explicit pushing step for the `CurrentCoupling5DGradBxB <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_coupling.CurrentCoupling5DGradBxB>`_
+                             a: 'float[:]', b: 'float[:]', c: 'float[:]', boundary_cut: float):
+    r'''Single stage of a s-stage explicit pushing step for the `CurrentCoupling5DGradB <https://struphy.pages.mpcdf.de/struphy/sections/propagators.html#struphy.propagators.propagators_coupling.CurrentCoupling5DGradB>`_
 
     Marker update:
 
     .. math::
 
         \mathbf X^{n+1} = \mathbf X^n - \frac{\Delta t}{2} \hat B^{*,-1}_\parallel(\mathbf X_p, v^n_{\parallel,p}) \frac{1}{\sqrt{g(\mathbf X_p)}} G^{-1}(\mathbf X_p) \hat{\mathbf b}_0^2(\mathbf X_p) \times G^{-1}(\mathbf X_p) \hat{\mathbf B}^2(\mathbf X_p) \times \Lambda^2 (\mathbf u^{n+1} + \mathbf u^n ) (\mathbf X_p) \,,
 
@@ -2277,28 +2281,31 @@
     n_stages = shape(b)[0]
 
     if stage == n_stages - 1:
         last = 1.
     else:
         last = 0.
 
-    #$ omp parallel firstprivate(b_prod, norm_b2_prod) private(ip, eta, v, det_df, dfm, df_inv, df_inv_t, g_inv, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, bb, u, e, curl_norm_b, norm_b1, norm_b2, b_star, temp1, temp2, abs_b_star_para)
+    #$ omp parallel firstprivate(b_prod, norm_b2_prod) private(ip, boundary_cut, eta, v, det_df, dfm, df_inv, df_inv_t, g_inv, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, bb, u, e, curl_norm_b, norm_b1, norm_b2, b_star, temp1, temp2, abs_b_star_para)
     #$ omp for
     for ip in range(n_markers):
 
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         if markers[ip, 9] == -1.:
             continue
 
         eta[:] = markers[ip, 0:3]
         v = markers[ip, 3]
 
+        if eta[0] < boundary_cut or eta[0] > 1. - boundary_cut:
+            continue
+
         # evaluate Jacobian, result in dfm
         evaluation_kernels.df(eta[0], eta[1], eta[2],
                               kind_map, params_map,
                               t1_map, t2_map, t3_map, p_map,
                               ind1_map, ind2_map, ind3_map,
                               cx, cy, cz,
                               dfm)
```

### Comparing `struphy-2.2.0/src/struphy/pic/pushing/pusher_utilities_kernels.py` & `struphy-2.3.0/src/struphy/pic/pushing/pusher_utilities_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/sampling_kernels.py` & `struphy-2.3.0/src/struphy/pic/sampling_kernels.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/sobol_seq.py` & `struphy-2.3.0/src/struphy/pic/sobol_seq.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_accum_vec_H1.py` & `struphy-2.3.0/src/struphy/pic/tests/test_accum_vec_H1.py`

 * *Files 5% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 @pytest.mark.parametrize('spl_kind', [[False, False, True], [False, True, True], [True, False, True], [True, True, True]])
 @pytest.mark.parametrize('mapping', [
     ['Cuboid', {
         'l1': 0., 'r1': 1., 'l2': 0., 'r2': 1., 'l3': 0., 'r3': 1.}],
     ['Cuboid', {
         'l1': 0., 'r1': 2., 'l2': 0., 'r2': 3., 'l3': 0., 'r3': 4.}],
 ])
-def test_accum_poisson(Nel, p, spl_kind, mapping, Np=1000, verbose=False):
+def test_accum_poisson(Nel, p, spl_kind, mapping, Np=1000):
     '''DRAFT: test the accumulation of the rhs (H1-space) in Poisson's equation .
 
     Tests:
 
         * Whether all weights are initialized as \sqrt(g) = const. (Cuboid mappings).
         * Whether the sum oaver all MC integrals is 1.
     '''
@@ -50,42 +50,41 @@
                       'loading': {'type': 'pseudo_random',
                                   'seed': 1607,
                                   'moments': [0., 0., 0., 1., 1., 1.],
                                   'spatial': 'uniform'},
                       'domain': domain,
                       'derham': derham
                       }
-    init_params = {'type': 'Maxwellian6DUniform', 'Maxwellian6DUniform': {}}
 
-    particles = Particles6D('test_particles', **params_markers)
+    particles = Particles6D('test_particles', **params_markers, bckgr_params=None)
     particles.draw_markers()
     particles.mpi_sort_markers()
-    particles.initialize_weights(init_params)
+    particles.initialize_weights()
 
     _vdim = particles.vdim
     _w0 = particles.weights
 
     print('Test weights:')
     print(f'rank {mpi_rank}:', _w0.shape, np.min(_w0), np.max(_w0))
 
     _sqrtg = domain.jacobian_det(0.5, 0.5, 0.5)
 
     assert np.isclose(np.min(_w0), _sqrtg)
     assert np.isclose(np.max(_w0), _sqrtg)
 
     # instance of the accumulator
-    acc = AccumulatorVector(derham, domain, 'H1', 'poisson')
-    acc.accumulate(particles, 1., 1.)
+    acc = AccumulatorVector(derham, domain, 'H1', 'charge_density_0form')
+    acc.accumulate(particles)
 
     # sum all MC integrals
     _sum = np.empty(1, dtype=float)
     _sum[0] = np.sum(acc.vectors[0].toarray())
     mpi_comm.Allreduce(MPI.IN_PLACE, _sum, op=MPI.SUM)
 
     print(f'rank {mpi_rank}:', _sum)
 
     assert np.isclose(_sum, _sqrtg)
 
 
 if __name__ == '__main__':
     test_accum_poisson([8, 5, 6], [2, 2, 3], [True]*3, ['Cuboid', {
-        'l1': 0., 'r1': 1., 'l2': 0., 'r2': 2., 'l3': 0., 'r3': 1.}], Np=1000, verbose=False)
+        'l1': 0., 'r1': 1., 'l2': 0., 'r2': 2., 'l3': 0., 'r3': 1.}], Np=1000)
```

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_accumulation.py` & `struphy-2.3.0/src/struphy/pic/tests/test_accumulation.py`

 * *Files 0% similar despite different names*

```diff
@@ -62,15 +62,15 @@
 
     # load distributed markers first and use Send/Receive to make global marker copies for the legacy routines
     params_markers = {'Np': Np, 'eps': .25,
                       'loading': {'type': 'pseudo_random', 'seed': 1607, 'moments': [0., 0., 0., 1., 2., 3.], 'spatial': 'uniform'}
                       }
 
     particles = Particles6D(
-        'test_particles', **params_markers, derham=derham)
+        'test_particles', **params_markers, derham=derham, bckgr_params=None)
     particles.draw_markers()
 
     # set random weights on each process
     particles.markers[~particles.holes,
                       6] = np.random.rand(particles.n_mks_loc)
 
     # gather all particles for legacy kernel
```

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_draw_parallel.py` & `struphy-2.3.0/src/struphy/pic/tests/test_draw_parallel.py`

 * *Files 6% similar despite different names*

```diff
@@ -3,17 +3,19 @@
 
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[8, 9, 10]])
 @pytest.mark.parametrize('p', [[1, 2, 3]])
 @pytest.mark.parametrize('spl_kind', [[False, False, True], [False, True, False], [True, False, False]])
 @pytest.mark.parametrize('mapping', [
     ['Cuboid', {
-        'l1': 1., 'r1': 2., 'l2': 10., 'r2': 20., 'l3': 100., 'r3': 200.}],
+        'l1': 1., 'r1': 2., 'l2': 10., 'r2': 20., 'l3': 100., 'r3': 200.
+    }],
     ['ShafranovDshapedCylinder', {
-        'R0': 4., 'Lz': 5., 'delta_x': 0.06, 'delta_y': 0.07, 'delta_gs': 0.08, 'epsilon_gs': 9., 'kappa_gs': 10.}]
+        'R0': 4., 'Lz': 5., 'delta_x': 0.06, 'delta_y': 0.07, 'delta_gs': 0.08, 'epsilon_gs': 9., 'kappa_gs': 10.
+    }]
 ])
 def test_draw(Nel, p, spl_kind, mapping, ppc=10):
     '''Asserts whether all particles are on the correct process after `particles.mpi_sort_markers()`.'''
 
     from mpi4py import MPI
     import numpy as np
 
@@ -38,32 +40,34 @@
 
     if rank == 0:
         print()
         print('Domain decomposition according to : ')
         print(derham.domain_array)
 
     # create particles
-    loading_params = {'type': 'pseudo_random',
-                      'seed': seed,
-                      'moments': [0., 0., 0., 1., 1., 1.],
-                      'spatial': 'uniform'}
-    bc_params = {'type' : ['periodic', 'periodic', 'periodic']}
-    marker_params = {'ppc': ppc,
-                     'eps': .25,
-                     'loading': loading_params,
-                     'bc': bc_params,
-                     'domain': domain}
-    init_params = {'type': 'Maxwellian6DUniform', 'Maxwellian6DUniform': {}}
+    loading_params = {
+        'type': 'pseudo_random',
+        'seed': seed,
+        'moments': [0., 0., 0., 1., 1., 1.],
+        'spatial': 'uniform'
+    }
+    bc_params = {'type': ['periodic', 'periodic', 'periodic']}
+    marker_params = {
+        'ppc': ppc,
+        'eps': .25,
+        'loading': loading_params,
+        'bc': bc_params,
+        'domain': domain
+    }
 
-    particles = Particles6D('energetic_ions', **marker_params, derham=derham)
+    particles = Particles6D('energetic_ions', **marker_params, derham=derham, bckgr_params=None)
     particles.draw_markers()
 
     # test weights
-    particles.initialize_weights(init_params)
-    _vdim = particles.vdim
+    particles.initialize_weights()
     _w0 = particles.weights
     print('Test weights:')
     print(f'rank {rank}:', _w0.shape, np.min(_w0), np.max(_w0))
 
     comm.Barrier()
     print('Number of particles w/wo holes on each process before sorting : ')
     print('Rank', rank, ':', particles.n_mks_loc,
@@ -71,29 +75,28 @@
 
     # sort particles according to domain decomposition
     comm.Barrier()
     particles.mpi_sort_markers(do_test=True)
 
     comm.Barrier()
     print('Number of particles w/wo holes on each process after sorting : ')
-    print('Rank', rank, ':', particles.n_mks_loc,
-          particles.markers.shape[0])
+    print('Rank', rank, ':', particles.n_mks_loc, particles.markers.shape[0])
 
     # are all markers in the correct domain?
-    conds = np.logical_and(particles.markers[:, :3] > derham.domain_array[rank, 0::3],
-                           particles.markers[:, :3] < derham.domain_array[rank, 1::3])
+    conds = np.logical_and(
+        particles.markers[:, :3] > derham.domain_array[rank, 0::3],
+        particles.markers[:, :3] < derham.domain_array[rank, 1::3]
+    )
     holes = particles.markers[:, 0] == -1.
     stay = np.all(conds, axis=1)
 
     error_mks = particles.markers[np.logical_and(~stay, ~holes)]
 
-    print(
-        f'rank {rank} | markers not on correct process: {np.nonzero(np.logical_and(~stay, ~holes))} \n corresponding positions:\n {error_mks[:, :3]}')
-
-    assert error_mks.size == 0
+    assert error_mks.size == 0, \
+        f'rank {rank} | markers not on correct process: {np.nonzero(np.logical_and(~stay, ~holes))} \n corresponding positions:\n {error_mks[:, :3]}'
 
 
 if __name__ == '__main__':
     # test_draw([8, 9, 10], [2, 3, 4], [False, False, True], ['Cuboid', {
     #     'l1': 1., 'r1': 2., 'l2': 10., 'r2': 20., 'l3': 100., 'r3': 200.}])
     test_draw([8, 9, 10], [2, 3, 4], [False, False, True], ['Cuboid', {
         'l1': 0., 'r1': 1., 'l2': 0., 'r2': 1., 'l3': 0., 'r3': 1.}])
```

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_mat_vec_filler.py` & `struphy-2.3.0/src/struphy/pic/tests/test_mat_vec_filler.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/accumulation.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/accumulation.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/accumulation_kernels_3d.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/accumulation_kernels_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/mappings_3d.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/mappings_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/mappings_3d_fast.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/mappings_3d_fast.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/pusher.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/pusher.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_pos.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_pos.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_vel_2d.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_vel_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_vel_3d.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/pusher_vel_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/spline_evaluation_2d.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/spline_evaluation_2d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pic_legacy_files/spline_evaluation_3d.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pic_legacy_files/spline_evaluation_3d.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/tests/test_pushers.py` & `struphy-2.3.0/src/struphy/pic/tests/test_pushers.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,23 +1,19 @@
 import pytest
 
-# ==================================================================================
-
-
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[8, 9, 5], [7, 8, 9]])
 @pytest.mark.parametrize('p',   [[2, 3, 1], [1, 2, 3]])
 @pytest.mark.parametrize('spl_kind', [[False, True, True], [True, False, True], [False, False, True], [True, True, True]])
 @pytest.mark.parametrize('mapping', [
     ['Colella', {
         'Lx': 2., 'Ly': 3., 'alpha': .1, 'Lz': 4.}]])
 def test_push_vxb_analytic(Nel, p, spl_kind, mapping, show_plots=False):
 
     from mpi4py import MPI
-
     import numpy as np
 
     from struphy.eigenvalue_solvers.spline_space import Spline_space_1d, Tensor_spline_space
     from struphy.geometry import domains
     from struphy.feec.psydac_derham import Derham
     from struphy.pic.particles import Particles6D
     from struphy.pic.pushing.pusher import Pusher as Pusher_psy
@@ -31,37 +27,32 @@
     # domain object
     domain_class = getattr(domains, mapping[0])
     domain = domain_class(**mapping[1])
 
     # discrete Derham sequence (psydac and legacy struphy)
     derham = Derham(Nel, p, spl_kind, comm=comm)
 
-    starts0 = np.array(derham.Vh['0'].starts)
-    starts1 = np.array(derham.Vh['1'].starts)
-    starts2 = np.array(derham.Vh['2'].starts)
-    starts3 = np.array(derham.Vh['3'].starts)
-
     if rank == 0:
         print('Domain decomposition : \n', derham.domain_array)
 
     spaces = [Spline_space_1d(Nel, p, spl_kind)
               for Nel, p, spl_kind in zip(Nel, p, spl_kind)]
 
     space = Tensor_spline_space(spaces)
 
     # particle loading and sorting
     seed = int(np.random.rand()*1000)
     loader_params = {'type': 'pseudo_random',
                      'seed': seed, 'moments': [0., 0., 0., 1., 1., 1.], 'spatial': 'uniform'}
-    bc_params = {'type' : ['periodic', 'periodic', 'periodic']}
+    bc_params = {'type': ['periodic', 'periodic', 'periodic']}
     marker_params = {'ppc': 2, 'eps': .25, 'loading': loader_params,
                      'bc': bc_params}
 
     particles = Particles6D(
-        'energetic_ions', **marker_params, derham=derham)
+        'energetic_ions', **marker_params, derham=derham, bckgr_params=None)
     particles.draw_markers()
 
     if show_plots:
         particles.show_physical()
     comm.Barrier()
     particles.mpi_sort_markers()
     comm.Barrier()
@@ -99,26 +90,24 @@
                b2_eq_psy[1]._data + b2_psy[1]._data,
                b2_eq_psy[2]._data + b2_psy[2]._data)
 
     # compare if markers are the same AFTER push
     assert np.allclose(particles.markers, markers_str.T)
 
 
-# ==================================================================================
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[8, 9, 5], [7, 8, 9]])
 @pytest.mark.parametrize('p',   [[2, 3, 1], [1, 2, 3]])
 @pytest.mark.parametrize('spl_kind', [[False, True, True], [True, False, True], [False, False, True], [True, True, True]])
 @pytest.mark.parametrize('mapping', [
     ['Colella', {
         'Lx': 2., 'Ly': 3., 'alpha': .1, 'Lz': 4.}]])
 def test_push_bxu_Hdiv(Nel, p, spl_kind, mapping, show_plots=False):
 
     from mpi4py import MPI
-
     import numpy as np
 
     from struphy.eigenvalue_solvers.spline_space import Spline_space_1d, Tensor_spline_space
     from struphy.geometry import domains
     from struphy.feec.psydac_derham import Derham
     from struphy.pic.particles import Particles6D
     from struphy.pic.pushing.pusher import Pusher as Pusher_psy
@@ -144,20 +133,20 @@
 
     space = Tensor_spline_space(spaces)
 
     # particle loading and sorting
     seed = int(np.random.rand()*1000)
     loader_params = {'type': 'pseudo_random',
                      'seed': seed, 'moments': [0., 0., 0., 1., 1., 1.], 'spatial': 'uniform'}
-    bc_params = {'type' : ['periodic', 'periodic', 'periodic']}
+    bc_params = {'type': ['periodic', 'periodic', 'periodic']}
     marker_params = {'ppc': 2, 'eps': .25, 'loading': loader_params,
                      'bc': bc_params}
 
     particles = Particles6D(
-        'energetic_ions', **marker_params, derham=derham)
+        'energetic_ions', **marker_params, derham=derham, bckgr_params=None)
     particles.draw_markers()
 
     if show_plots:
         particles.show_physical()
     comm.Barrier()
     particles.mpi_sort_markers()
     comm.Barrier()
@@ -202,26 +191,24 @@
                u2_psy[1]._data,
                u2_psy[2]._data)
 
     # compare if markers are the same AFTER push
     assert np.allclose(particles.markers, markers_str.T)
 
 
-# ==================================================================================
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[8, 9, 5], [7, 8, 9]])
 @pytest.mark.parametrize('p',   [[2, 3, 1], [1, 2, 3]])
 @pytest.mark.parametrize('spl_kind', [[False, True, True], [True, False, True], [False, False, True], [True, True, True]])
 @pytest.mark.parametrize('mapping', [
     ['Colella', {
         'Lx': 2., 'Ly': 3., 'alpha': .1, 'Lz': 4.}]])
 def test_push_bxu_Hcurl(Nel, p, spl_kind, mapping, show_plots=False):
 
     from mpi4py import MPI
-
     import numpy as np
 
     from struphy.eigenvalue_solvers.spline_space import Spline_space_1d, Tensor_spline_space
     from struphy.geometry import domains
     from struphy.feec.psydac_derham import Derham
     from struphy.pic.particles import Particles6D
     from struphy.pic.pushing.pusher import Pusher as Pusher_psy
@@ -247,20 +234,20 @@
 
     space = Tensor_spline_space(spaces)
 
     # particle loading and sorting
     seed = int(np.random.rand()*1000)
     loader_params = {'type': 'pseudo_random',
                      'seed': seed, 'moments': [0., 0., 0., 1., 1., 1.], 'spatial': 'uniform'}
-    bc_params = {'type' : ['periodic', 'periodic', 'periodic']}
+    bc_params = {'type': ['periodic', 'periodic', 'periodic']}
     marker_params = {'ppc': 2, 'eps': .25, 'loading': loader_params,
                      'bc': bc_params}
 
     particles = Particles6D(
-        'energetic_ions', **marker_params, derham=derham)
+        'energetic_ions', **marker_params, derham=derham, bckgr_params=None)
     particles.draw_markers()
 
     if show_plots:
         particles.show_physical()
     comm.Barrier()
     particles.mpi_sort_markers()
     comm.Barrier()
@@ -305,26 +292,24 @@
                u1_psy[1]._data,
                u1_psy[2]._data)
 
     # compare if markers are the same AFTER push
     assert np.allclose(particles.markers, markers_str.T)
 
 
-# ==================================================================================
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[8, 9, 5], [7, 8, 9]])
 @pytest.mark.parametrize('p',   [[2, 3, 1], [1, 2, 3]])
 @pytest.mark.parametrize('spl_kind', [[False, True, True], [True, False, True], [False, False, True], [True, True, True]])
 @pytest.mark.parametrize('mapping', [
     ['Colella', {
         'Lx': 2., 'Ly': 3., 'alpha': .1, 'Lz': 4.}]])
 def test_push_bxu_H1vec(Nel, p, spl_kind, mapping, show_plots=False):
 
     from mpi4py import MPI
-
     import numpy as np
 
     from struphy.eigenvalue_solvers.spline_space import Spline_space_1d, Tensor_spline_space
     from struphy.geometry import domains
     from struphy.feec.psydac_derham import Derham
     from struphy.pic.particles import Particles6D
     from struphy.pic.pushing.pusher import Pusher as Pusher_psy
@@ -350,20 +335,20 @@
 
     space = Tensor_spline_space(spaces)
 
     # particle loading and sorting
     seed = int(np.random.rand()*1000)
     loader_params = {'type': 'pseudo_random',
                      'seed': seed, 'moments': [0., 0., 0., 1., 1., 1.], 'spatial': 'uniform'}
-    bc_params = {'type' : ['periodic', 'periodic', 'periodic']}
+    bc_params = {'type': ['periodic', 'periodic', 'periodic']}
     marker_params = {'ppc': 2, 'eps': .25, 'loading': loader_params,
                      'bc': bc_params}
 
     particles = Particles6D(
-        'energetic_ions', **marker_params, derham=derham)
+        'energetic_ions', **marker_params, derham=derham, bckgr_params=None)
     particles.draw_markers()
 
     if show_plots:
         particles.show_physical()
     comm.Barrier()
     particles.mpi_sort_markers()
     comm.Barrier()
@@ -408,26 +393,24 @@
                uv_psy[1]._data,
                uv_psy[2]._data)
 
     # compare if markers are the same AFTER push
     assert np.allclose(particles.markers, markers_str.T)
 
 
-# ==================================================================================
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[8, 9, 5], [7, 8, 9]])
 @pytest.mark.parametrize('p',   [[2, 3, 1], [1, 2, 3]])
 @pytest.mark.parametrize('spl_kind', [[False, True, True], [True, False, True], [False, False, True], [True, True, True]])
 @pytest.mark.parametrize('mapping', [
     ['Colella', {
         'Lx': 2., 'Ly': 3., 'alpha': .1, 'Lz': 4.}]])
 def test_push_bxu_Hdiv_pauli(Nel, p, spl_kind, mapping, show_plots=False):
 
     from mpi4py import MPI
-
     import numpy as np
 
     from struphy.eigenvalue_solvers.spline_space import Spline_space_1d, Tensor_spline_space
     from struphy.geometry import domains
     from struphy.feec.psydac_derham import Derham
     from struphy.pic.particles import Particles6D
     from struphy.pic.pushing.pusher import Pusher as Pusher_psy
@@ -453,20 +436,20 @@
 
     space = Tensor_spline_space(spaces)
 
     # particle loading and sorting
     seed = int(np.random.rand()*1000)
     loader_params = {'type': 'pseudo_random',
                      'seed': seed, 'moments': [0., 0., 0., 1., 1., 1.], 'spatial': 'uniform'}
-    bc_params = {'type' : ['periodic', 'periodic', 'periodic']}
+    bc_params = {'type': ['periodic', 'periodic', 'periodic']}
     marker_params = {'ppc': 2, 'eps': .25, 'loading': loader_params,
                      'bc': bc_params}
 
     particles = Particles6D(
-        'energetic_ions', **marker_params, derham=derham)
+        'energetic_ions', **marker_params, derham=derham, bckgr_params=None)
     particles.draw_markers()
 
     if show_plots:
         particles.show_physical()
     comm.Barrier()
     particles.mpi_sort_markers()
     comm.Barrier()
@@ -513,26 +496,24 @@
                b0_eq_psy._data,
                mu0_str)
 
     # compare if markers are the same AFTER push
     assert np.allclose(particles.markers, markers_str.T)
 
 
-# ==================================================================================
 @pytest.mark.mpi(min_size=2)
 @pytest.mark.parametrize('Nel', [[8, 9, 5], [7, 8, 9]])
 @pytest.mark.parametrize('p',   [[2, 3, 1], [1, 2, 3]])
 @pytest.mark.parametrize('spl_kind', [[False, True, True], [True, False, True], [False, False, True], [True, True, True]])
 @pytest.mark.parametrize('mapping', [
     ['Colella', {
         'Lx': 2., 'Ly': 3., 'alpha': .1, 'Lz': 4.}]])
 def test_push_eta_rk4(Nel, p, spl_kind, mapping, show_plots=False):
 
     from mpi4py import MPI
-
     import numpy as np
 
     from struphy.eigenvalue_solvers.spline_space import Spline_space_1d, Tensor_spline_space
     from struphy.geometry import domains
     from struphy.feec.psydac_derham import Derham
     from struphy.pic.particles import Particles6D
     from struphy.pic.pushing.pusher import Pusher as Pusher_psy
@@ -559,20 +540,20 @@
 
     space = Tensor_spline_space(spaces)
 
     # particle loading and sorting
     seed = int(np.random.rand()*1000)
     loader_params = {'type': 'pseudo_random',
                      'seed': seed, 'moments': [0., 0., 0., 1., 1., 1.], 'spatial': 'uniform'}
-    bc_params = {'type' : ['periodic', 'periodic', 'periodic']}
+    bc_params = {'type': ['periodic', 'periodic', 'periodic']}
     marker_params = {'ppc': 2, 'eps': .25, 'loading': loader_params,
                      'bc': bc_params}
 
     particles = Particles6D(
-        'energetic_ions', **marker_params, derham=derham)
+        'energetic_ions', **marker_params, derham=derham, bckgr_params=None)
     particles.draw_markers()
 
     if show_plots:
         particles.show_physical()
     comm.Barrier()
     particles.mpi_sort_markers()
     comm.Barrier()
@@ -593,15 +574,16 @@
         b0_eq_str), space.extract_2(b2_eq_str), basis_u=0, bc_pos=0)
 
     a = [1/2, 1/2, 1.]
     b = [1/6, 1/3, 1/3, 1/6]
     c = [0., 1/2, 1/2, 1.]
     butcher = ButcherTableau(a, b, c)
 
-    pusher_psy = Pusher_psy(derham, domain, 'push_eta_stage', n_stages=butcher.n_stages)
+    pusher_psy = Pusher_psy(
+        derham, domain, 'push_eta_stage', n_stages=butcher.n_stages)
 
     # compare if markers are the same BEFORE push
     assert np.allclose(particles.markers, markers_str.T)
 
     # push markers
     dt = 0.1
 
@@ -609,15 +591,14 @@
     pusher_psy(particles, dt,
                butcher.a, butcher.b, butcher.c)
 
     # compare if markers are the same AFTER push
     assert np.allclose(particles.markers, markers_str.T)
 
 
-# ==================================================================================
 # @pytest.mark.mpi(min_size=2)
 # @pytest.mark.parametrize('Nel', [[8, 9, 5], [7, 8, 9]])
 # @pytest.mark.parametrize('p',   [[2, 3, 1], [1, 2, 3]])
 # @pytest.mark.parametrize('spl_kind', [[False, True, True], [True, False, True], [False, False, True], [True, True, True]])
 # @pytest.mark.parametrize('mapping', [
 #     ['Colella', {
 #         'Lx' : 2., 'Ly' : 3., 'alpha' : .1, 'Lz' : 4.}]])
@@ -697,15 +678,14 @@
 #                V_2_psy[0]._data, V_2_psy[1]._data, V_2_psy[2]._data,
 #                V_3_psy[0]._data, V_3_psy[1]._data, V_3_psy[2]._data)
 
 #     # compare if markers are the same AFTER push
 #     assert np.allclose(particles.markers, markers_str.T)
 
 
-# ==================================================================================
 # @pytest.mark.mpi(min_size=2)
 # @pytest.mark.parametrize('Nel', [[8, 9, 5], [7, 8, 9]])
 # @pytest.mark.parametrize('p',   [[2, 3, 1], [1, 2, 3]])
 # @pytest.mark.parametrize('spl_kind', [[False, True, True], [True, False, True], [False, False, True], [True, True, True]])
 # @pytest.mark.parametrize('mapping', [
 #     ['Colella', {
 #         'Lx' : 2., 'Ly' : 3., 'alpha' : .1, 'Lz' : 4.}]])
```

### Comparing `struphy-2.2.0/src/struphy/pic/utilities.py` & `struphy-2.3.0/src/struphy/pic/utilities.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/pic/utilities_kernels.py` & `struphy-2.3.0/src/struphy/pic/utilities_kernels.py`

 * *Files 2% similar despite different names*

```diff
@@ -495,20 +495,29 @@
         B0 = evaluation_kernels_3d.eval_spline_mpi_kernel(
             pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, absB, starts)
 
         # magnetic moment
         markers[ip, 4] = 1/2 * v_perp**2 / abs(B0)
 
 
-@stack_array('bn1', 'bn2', 'bn3')
+@stack_array('dfm', 'norm_b1', 'b', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3')
 def eval_magnetic_energy(markers: 'float[:,:]',
-                         pn: 'int[:]',
-                         tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
+                         pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                          starts: 'int[:]',
-                         PB: 'float[:,:,:]'):
+                         kind_map: 'int', params_map: 'float[:]',
+                         p_map: 'int[:]', t1_map: 'float[:]', t2_map: 'float[:]', t3_map: 'float[:]',
+                         ind1_map: 'int[:,:]', ind2_map: 'int[:,:]', ind3_map: 'int[:,:]',
+                         cx: 'float[:,:,:]', cy: 'float[:,:,:]', cz: 'float[:,:,:]',
+                         abs_B0: 'float[:,:,:]',
+                         norm_b11: 'float[:,:,:]',
+                         norm_b12: 'float[:,:,:]',
+                         norm_b13: 'float[:,:,:]',
+                         b1: 'float[:,:,:]',
+                         b2: 'float[:,:,:]',
+                         b3: 'float[:,:,:]'):
     """
     Evaluate magnetic field energy of each particles
 
     Parameters
     ----------
         markers : array[float]
             .markers attribute of a struphy.pic.particles.Particles object
@@ -521,47 +530,87 @@
 
         starts : array[int]
             starts of the stencil objects (0-form)
 
         b0 : array[float]
             3d array of FE coeffs of the absolute value of static magnetic field (0-form).
     """
-    # allocate spline values
-    bn1 = empty(pn[0] + 1, dtype=float)
-    bn2 = empty(pn[1] + 1, dtype=float)
-    bn3 = empty(pn[2] + 1, dtype=float)
+    norm_b1 = empty(3, dtype=float)
+    b = empty(3, dtype=float)
+
+    bn1 = empty(int(pn[0]) + 1, dtype=float)
+    bn2 = empty(int(pn[1]) + 1, dtype=float)
+    bn3 = empty(int(pn[2]) + 1, dtype=float)
+
+    bd1 = empty(int(pn[0]), dtype=float)
+    bd2 = empty(int(pn[1]), dtype=float)
+    bd3 = empty(int(pn[2]), dtype=float)
+
+    dfm = empty((3, 3), dtype=float)
 
     # get number of markers
     n_markers = shape(markers)[0]
 
+    #$ omp parallel private(ip, eta1, eta2, eta3, mu, span1, span2, span3, bn1, bn2, bn3, bd1, bd2, bd3, b, b_para, abs_B, norm_b1, dfm, det_df)
     for ip in range(n_markers):
         # only do something if particle is a "true" particle (i.e. not a hole)
         if markers[ip, 0] == -1.:
             continue
 
         eta1 = markers[ip, 0]
         eta2 = markers[ip, 1]
         eta3 = markers[ip, 2]
 
+        mu = markers[ip, 4]
+
         # spline evaluation
         span1 = bsplines_kernels.find_span(tn1, pn[0], eta1)
         span2 = bsplines_kernels.find_span(tn2, pn[1], eta2)
         span3 = bsplines_kernels.find_span(tn3, pn[2], eta3)
 
-        bsplines_kernels.b_splines_slim(tn1, pn[0], eta1, span1, bn1)
-        bsplines_kernels.b_splines_slim(tn2, pn[1], eta2, span2, bn2)
-        bsplines_kernels.b_splines_slim(tn3, pn[2], eta3, span3, bn3)
+        bsplines_kernels.b_d_splines_slim(tn1, int(pn[0]), eta1, span1, bn1, bd1)
+        bsplines_kernels.b_d_splines_slim(tn2, int(pn[1]), eta2, span2, bn2, bd2)
+        bsplines_kernels.b_d_splines_slim(tn3, int(pn[2]), eta3, span3, bn3, bd3)
+
+        # evaluate Jacobian, result in dfm
+        evaluation_kernels.df(eta1, eta2, eta3,
+                              kind_map, params_map,
+                              t1_map, t2_map, t3_map, p_map,
+                              ind1_map, ind2_map, ind3_map,
+                              cx, cy, cz,
+                              dfm)
+
+        det_df = linalg_kernels.det(dfm)
+
+        # abs_B0; 0form
+        abs_B = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, abs_B0, starts)
+
+        # b; 2form
+        b[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]), int(pn[1]) - 1, int(pn[2]) - 1, bn1, bd2, bd3, span1, span2, span3, b1, starts)
+        b[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]) - 1, int(pn[1]), int(pn[2]) - 1, bd1, bn2, bd3, span1, span2, span3, b2, starts)
+        b[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]) - 1, int(pn[1]) - 1, int(pn[2]), bd1, bd2, bn3, span1, span2, span3, b3, starts)
+
+        # norm_b1; 1form
+        norm_b1[0] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]) - 1, int(pn[1]), int(pn[2]), bd1, bn2, bn3, span1, span2, span3, norm_b11, starts)
+        norm_b1[1] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]), int(pn[1]) - 1, int(pn[2]), bn1, bd2, bn3, span1, span2, span3, norm_b12, starts)
+        norm_b1[2] = evaluation_kernels_3d.eval_spline_mpi_kernel(
+            int(pn[0]), int(pn[1]), int(pn[2]) - 1, bn1, bn2, bd3, span1, span2, span3, norm_b13, starts)
 
-        B0 = evaluation_kernels_3d.eval_spline_mpi_kernel(
-            pn[0], pn[1], pn[2], bn1, bn2, bn3, span1, span2, span3, PB, starts)
+        b_para = linalg_kernels.scalar_dot(norm_b1, b)
+        b_para /= det_df
 
-        # if B0 < 0:
-        #     print('minus', B0)
+        markers[ip, 8] = mu*(abs_B + b_para)
 
-        markers[ip, 8] = B0*markers[ip, 4]
+    #$ omp end parallel
 
 
 @stack_array('grad_PB', 'bn1', 'bn2', 'bn3', 'bd1', 'bd2', 'bd3', 'tmp')
 def accum_gradI_const(markers: 'float[:,:]', n_markers_tot: 'int',
                       pn: 'int[:]', tn1: 'float[:]', tn2: 'float[:]', tn3: 'float[:]',
                       starts: 'int[:]',
                       grad_PB1: 'float[:,:,:]', grad_PB2: 'float[:,:,:]', grad_PB3: 'float[:,:,:]',
```

### Comparing `struphy-2.2.0/src/struphy/polar/basic.py` & `struphy-2.3.0/src/struphy/polar/basic.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/polar/extraction_operators.py` & `struphy-2.3.0/src/struphy/polar/extraction_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/polar/linear_operators.py` & `struphy-2.3.0/src/struphy/polar/linear_operators.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/polar/tests/test_legacy_polar_splines.py` & `struphy-2.3.0/src/struphy/polar/tests/test_legacy_polar_splines.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/polar/tests/test_polar.py` & `struphy-2.3.0/src/struphy/polar/tests/test_polar.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/post_processing/cprofile_analyser.py` & `struphy-2.3.0/src/struphy/post_processing/cprofile_analyser.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/post_processing/post_processing_tools.py` & `struphy-2.3.0/src/struphy/post_processing/post_processing_tools.py`

 * *Files 0% similar despite different names*

```diff
@@ -501,19 +501,19 @@
         else:
             fun_name = params['kinetic'][species]['background']['type']
             bckgr_params = params['kinetic'][species]['background']
 
             # Get background function
             if fun_name in bckgr_params.keys():
                 f_bckgr = getattr(maxwellians, fun_name)(
-                    **bckgr_params[fun_name])
+                    maxw_params=bckgr_params[fun_name])
             else:
                 f_bckgr = getattr(maxwellians, fun_name)()
 
-            assert fun_name == 'Maxwellian6DUniform', \
+            assert fun_name == 'Maxwellian6D', \
                 f'Post-processing is not yet implemented for a background distribution function of type {fun_name}'
 
             # load all grids of the variables of f
             grid_tot = []
             factor = 1.
             for coord in ['e', 'v']:
                 for comp in range(1, 4):
```

### Comparing `struphy-2.2.0/src/struphy/post_processing/pproc_struphy.py` & `struphy-2.3.0/src/struphy/post_processing/pproc_struphy.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/post_processing/profile_struphy.py` & `struphy-2.3.0/src/struphy/post_processing/profile_struphy.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/propagators/base.py` & `struphy-2.3.0/src/struphy/propagators/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -113,14 +113,30 @@
         assert hasattr(self, '_basis_ops'), \
             'Basis projection operators not set. Please do obj.basis_ops = ...'
         return self._basis_ops
 
     @basis_ops.setter
     def basis_ops(self, basis_ops):
         self._basis_ops = basis_ops
+        
+    @property
+    def time_state(self):
+        '''A pointer to the time variable of the dynamics ('t').'''
+        return self._time_state
+    
+    def add_time_state(self, time_state):
+        '''Add a pointer to the time variable of the dynamics ('t').
+
+        Parameters
+        ----------
+        time_state : ndarray
+            Of size 1, holds the current physical time 't'.
+        '''
+        assert time_state.size == 1
+        self._time_state = time_state
 
     def feec_vars_update(self, *variables_new):
         """ Writes new entries into the FEEC variables in ``Propagator.feec_vars``.
 
         Parameters
         ----------
         variables_new : list
```

### Comparing `struphy-2.2.0/src/struphy/propagators/propagators_coupling.py` & `struphy-2.3.0/src/struphy/propagators/propagators_coupling.py`

 * *Files 5% similar despite different names*

```diff
@@ -6,98 +6,97 @@
 from psydac.linalg.solvers import inverse
 from psydac.linalg.block import BlockVector
 
 from struphy.propagators.base import Propagator
 from struphy.linear_algebra.schur_solver import SchurSolver
 from struphy.pic.accumulation.particles_to_grid import Accumulator, AccumulatorVector
 from struphy.pic.pushing.pusher import Pusher
-import struphy.pic.utilities_kernels as utilities
 from struphy.polar.basic import PolarVector
 from struphy.kinetic_background.base import Maxwellian
-from struphy.kinetic_background.maxwellians import Maxwellian6DUniform, Maxwellian5DUniform
+from struphy.kinetic_background.maxwellians import Maxwellian6D, Maxwellian5D
 from struphy.fields_background.mhd_equil.equils import set_defaults
 
 from struphy.feec import preconditioner
 from struphy.feec.linear_operators import LinOpWithTransp
 from struphy.feec.mass import WeightedMassOperator
 
 
-class VlasovMaxwell(Propagator):
+class VlasovAmpere(Propagator):
     r'''Solve the following Crank-Nicolson step
 
     .. math::
 
         \begin{bmatrix}
             \mathbb{M}_1 \left( \mathbf{e}^{n+1} - \mathbf{e}^n \right) \\
             \mathbf{V}^{n+1} - \mathbf{V}^n
         \end{bmatrix}
         =
         \frac{\Delta t}{2}
         \begin{bmatrix}
-            0 & - c_1 \left(\mathbb{\Lambda}^1\right)^\top \overline{DF^{-1}} \mathbb{W} \\
-            c_2 \overline{DF^{-\top}} \mathbb{\Lambda}^1 & 0
+            0 & - c_1 \mathbb L^1 \bar{DF^{-1}} \bar{\mathbf w} \\
+            c_2 \bar{DF^{-\top}} \left(\mathbb L^1\right)^\top & 0
         \end{bmatrix}
         \begin{bmatrix}
             \mathbf{e}^{n+1} + \mathbf{e}^n \\
             \mathbf{V}^{n+1} + \mathbf{V}^n
         \end{bmatrix}
 
-    based on the :ref:`Schur complement <schur_solver>` where
+    based on the :class:`~struphy.linear_algebra.schur_solver.SchurSolver` with
 
     .. math::
-        \begin{align}
-        \mathbb{W} & = \text{diag}(w_p) \,,
-        \end{align}
+    
+        A = \mathbb M^1\,,\qquad B = \frac{c_1}{2} \mathbb L^1 \bar{DF^{-1}} \bar{\mathbf w}\,,\qquad C = - \frac{c_2}{2} \bar{DF^{-\top}} \left(\mathbb L^1\right)^\top \,.
 
-    and the accumulation matrix writes
+    The accumulation matrix and vector assembled in :class:`~struphy.pic.accumulation.particles_to_grid.Accumulator` are
 
     .. math::
-        \mathbb{A} = -\frac{{\Delta t}^2}{4} c_1 c_2 \, \left( \mathbb{\Lambda}^1 \right)^\top \overline{G^{-1}} \mathbb{W} \mathbb{\Lambda}^1 \,.
+    
+        M = BC  \,,\qquad V = B \mathbf v \,.
 
     Parameters
     ---------- 
-    e : psydac.linalg.block.BlockVector
+    e : BlockVector
         FE coefficients of a 1-form.
 
-    particles : struphy.pic.particles.Particles6D
+    particles : Particles6D
         Particles object.
 
-    **params : dict
-        Solver- and/or other parameters for this splitting step.
-
     Note
     ----------
-    For VlasovMaxwell :math:`c_1 = \alpha^2/\varepsilon \,, \, c_2 = 1/\varepsilon`
+    * For :class:`~struphy.models.kinetic.VlasovAmpereOneSpecies`: :math:`c_1 = \kappa^2 \,, \, c_2 = 1`
+    * For :class:`~struphy.models.kinetic.VlasovMaxwellOneSpecies`: :math:`c_1 = \alpha^2/\varepsilon \,, \, c_2 = 1/\varepsilon`
     '''
 
     def __init__(self, e, particles, **params):
 
         super().__init__(e, particles)
 
         # parameters
-        params_default = {'c1': 1.,
-                          'c2': 1.,
-                          'type': ('pcg', 'MassMatrixPreconditioner'),
-                          'tol': 1e-8,
-                          'maxiter': 3000,
-                          'info': False,
-                          'verbose': False, }
+        params_default = {
+            'c1': 1.,
+            'c2': 1.,
+            'type': ('pcg', 'MassMatrixPreconditioner'),
+            'tol': 1e-8,
+            'maxiter': 3000,
+            'info': False,
+            'verbose': False,
+        }
 
         params = set_defaults(params, params_default)
 
         self._c1 = params['c1']
         self._c2 = params['c2']
         self._info = params['info']
 
         # Initialize Accumulator object
         self._accum = Accumulator(self.derham, self.domain, 'Hcurl', 'vlasov_maxwell',
                                   add_vector=True, symmetry='symm')
 
         # Create buffers to store temporarily _e and its sum with old e
-        self._e_temp = e.space.zeros()
+        self._e_tmp = e.space.zeros()
         self._e_sum = e.space.zeros()
 
         # store old weights to compute difference
         self._old_v_sq = np.empty(particles.markers.shape[0], dtype=float)
         self._new_v_sq = np.empty(particles.markers.shape[0], dtype=float)
 
         # ================================
@@ -109,15 +108,15 @@
             pc = None
         else:
             pc_class = getattr(preconditioner, params['type'][1])
             pc = pc_class(self.mass_ops.M1)
 
         # Define block matrix [[A B], [C I]] (without time step size dt in the diagonals)
         _A = self.mass_ops.M1
-        _BC = - self._accum.operators[0].matrix / 4.
+        _BC = - self._accum.operators[0].matrix
 
         # Instantiate Schur solver
         self._schur_solver = SchurSolver(_A, _BC,
                                          params['type'][0],
                                          pc=pc,
                                          tol=params['tol'],
                                          maxiter=params['maxiter'],
@@ -136,15 +135,15 @@
 
         # Update Schur solver
         self._schur_solver.BC = - self._c1 * self._c2 / \
             4. * self._accum.operators[0].matrix
 
         # new e coeffs
         en1, info = self._schur_solver(
-            en, self._c1 / 2. * self._accum.vectors[0], dt, out=self._e_temp)
+            en, self._c1 / 2. * self._accum.vectors[0], dt, out=self._e_tmp)
 
         # Store old velocity magnitudes
         self._old_v_sq[~self.particles[0].holes] = np.sqrt(self.particles[0].markers[~self.particles[0].holes, 3]**2 +
                                                            self.particles[0].markers[~self.particles[0].holes, 4]**2 +
                                                            self.particles[0].markers[~self.particles[0].holes, 5]**2)
 
         # mid-point e-field (no tmps created here)
@@ -153,15 +152,16 @@
         _e *= 0.5
 
         # Update velocities
         self._pusher(self.particles[0], dt,
                      _e.blocks[0]._data,
                      _e.blocks[1]._data,
                      _e.blocks[2]._data,
-                     self._c2)
+                     self._c2,
+                     mpi_sort='last')
 
         # Store new velocity magnitudes
         self._new_v_sq[~self.particles[0].holes] = np.sqrt(self.particles[0].markers[~self.particles[0].holes, 3]**2 +
                                                            self.particles[0].markers[~self.particles[0].holes, 4]**2 +
                                                            self.particles[0].markers[~self.particles[0].holes, 5]**2)
 
         # update_weights
@@ -245,45 +245,48 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, e, particles, **params):
 
-        from struphy.kinetic_background.maxwellians import Maxwellian6DUniform
-
+        from struphy.kinetic_background.maxwellians import Maxwellian6D
         super().__init__(e, particles)
 
         # parameters
-        params_default = {'alpha': 1.,
-                          'kappa': 1.,
-                          'f0': Maxwellian6DUniform(),
-                          'model': 'linear_vlasov_maxwell',
-                          'type': ('pcg', 'MassMatrixPreconditioner'),
-                          'tol': 1e-8,
-                          'maxiter': 3000,
-                          'info': False,
-                          'verbose': False}
+        params_default = {
+            'alpha': 1.,
+            'kappa': 1.,
+            'f0': Maxwellian6D(),
+            'model': 'linear_vlasov_maxwell',
+            'type': ('pcg', 'MassMatrixPreconditioner'),
+            'tol': 1e-8,
+            'maxiter': 3000,
+            'info': False,
+            'verbose': False
+        }
 
         params = set_defaults(params, params_default)
 
-        assert isinstance(params['f0'], Maxwellian6DUniform)
+        assert isinstance(params['f0'], Maxwellian6D)
         assert params['model'] in (
             'linear_vlasov_maxwell', 'delta_f_vlasov_maxwell')
 
         self._alpha = params['alpha']
         self._kappa = params['kappa']
         self._f0 = params['f0']
-        self._f0_params = np.array([self._f0.params['n'],
-                                    self._f0.params['u1'],
-                                    self._f0.params['u2'],
-                                    self._f0.params['u3'],
-                                    self._f0.params['vth1'],
-                                    self._f0.params['vth2'],
-                                    self._f0.params['vth3']])
+        self._f0_params = np.array(
+            [self._f0.maxw_params['n'],
+             self._f0.maxw_params['u1'],
+             self._f0.maxw_params['u2'],
+             self._f0.maxw_params['u3'],
+             self._f0.maxw_params['vth1'],
+             self._f0.maxw_params['vth2'],
+             self._f0.maxw_params['vth3']]
+        )
         self._model = params['model']
 
         self._info = params['info']
 
         # Initialize Accumulator object
         if params['model'] == 'linear_vlasov_maxwell':
             self._accum = Accumulator(self.derham, self.domain, 'Hcurl', 'linear_vlasov_maxwell',
@@ -291,15 +294,15 @@
         elif params['model'] == 'delta_f_vlasov_maxwell':
             self._accum = Accumulator(self.derham, self.domain, 'Hcurl', 'delta_f_vlasov_maxwell_scn',
                                       add_vector=True, symmetry='symm')
         else:
             raise NotImplementedError(f"Unknown model : {params['model']}")
 
         # Create buffers to store temporarily _e and its sum with old e
-        self._e_temp = e.space.zeros()
+        self._e_tmp = e.space.zeros()
         self._e_sum = e.space.zeros()
 
         # store old weights to compute difference
         self._old_weights = np.empty(particles.markers.shape[0], dtype=float)
 
         # ================================
         # ========= Schur Solver =========
@@ -352,15 +355,15 @@
 
         # Update Schur solver
         self._schur_solver.BC = - self._accum.operators[0].matrix / 4
 
         # new e-field (no tmps created here)
         en1, info = self._schur_solver(
             en, self._accum.vectors[0] / 2., dt,
-            out=self._e_temp)
+            out=self._e_tmp)
 
         # Store old weights
         self._old_weights[~self.particles[0].holes] = self.particles[0].markers[~self.particles[0].holes, 6]
 
         # Compute (e^{n+1} + e^n) / 2 (no tmps created here)
         _e = en.copy(out=self._e_sum)
         _e += en1
@@ -436,45 +439,49 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, e, particles, **params):
 
-        from struphy.kinetic_background.maxwellians import Maxwellian6DUniform
+        from struphy.kinetic_background.maxwellians import Maxwellian6D
 
         super().__init__(e, particles)
 
         # parameters
-        params_default = {'alpha': 1e2,
-                          'kappa': 1.,
-                          'f0': Maxwellian6DUniform(),
-                          'type': 'pcg',
-                          'pc': 'MassMatrixPreconditioner',
-                          'tol': 1e-8,
-                          'maxiter': 3000,
-                          'info': False,
-                          'verbose': False}
+        params_default = {
+            'alpha': 1e2,
+            'kappa': 1.,
+            'f0': Maxwellian6D(),
+            'type': 'pcg',
+            'pc': 'MassMatrixPreconditioner',
+            'tol': 1e-8,
+            'maxiter': 3000,
+            'info': False,
+            'verbose': False
+        }
 
         params = set_defaults(params, params_default)
 
         self._params = params
 
-        assert isinstance(params['f0'], Maxwellian6DUniform)
+        assert isinstance(params['f0'], Maxwellian6D)
 
         self._alpha = params['alpha']
         self._kappa = params['kappa']
         self._f0 = params['f0']
-        self._f0_params = np.array([self._f0.params['n'],
-                                    self._f0.params['u1'],
-                                    self._f0.params['u2'],
-                                    self._f0.params['u3'],
-                                    self._f0.params['vth1'],
-                                    self._f0.params['vth2'],
-                                    self._f0.params['vth3']])
+        self._f0_params = np.array(
+            [self._f0.maxw_params['n'],
+             self._f0.maxw_params['u1'],
+             self._f0.maxw_params['u2'],
+             self._f0.maxw_params['u3'],
+             self._f0.maxw_params['vth1'],
+             self._f0.maxw_params['vth2'],
+             self._f0.maxw_params['vth3']]
+        )
 
         self._info = params['info']
 
         # Initialize Accumulator object
         self._accum = AccumulatorVector(
             self.derham, self.domain, 'Hcurl', 'delta_f_vlasov_maxwell')
 
@@ -489,29 +496,29 @@
         if params['type'][1] == None:
             pc = None
         else:
             pc_class = getattr(preconditioner, params['type'][1])
             pc = pc_class(self.mass_ops.M1)
 
         # solver
-        self.solver = inverse(self.mass_ops.M1, 
-                              params['type'][0], 
+        self.solver = inverse(self.mass_ops.M1,
+                              params['type'][0],
                               pc=pc,
                               x0=self.feec_vars[0],
                               tol=self._params['tol'],
                               maxiter=self._params['maxiter'],
                               verbose=self._params['verbose'])
 
         self._pusher = Pusher(self.derham, self.domain,
                               'push_weights_with_efield_delta_f_vm')
 
     def __call__(self, dt):
         # current e-field
         en = self.feec_vars[0]
-        
+
         # evaluate f0 and accumulate
         f0_values = self._f0(self.particles[0].markers[:, 0],
                              self.particles[0].markers[:, 1],
                              self.particles[0].markers[:, 2],
                              self.particles[0].markers[:, 3],
                              self.particles[0].markers[:, 4],
                              self.particles[0].markers[:, 5])
@@ -580,44 +587,46 @@
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     """
 
     def __init__(self, e, particles, **params):
 
-        from struphy.kinetic_background.maxwellians import Maxwellian6DUniform
+        from struphy.kinetic_background.maxwellians import Maxwellian6D
 
         super().__init__(e, particles)
 
         # parameters
         params_default = {'alpha': 1e2,
                           'kappa': 1.,
-                          'f0': Maxwellian6DUniform(),
+                          'f0': Maxwellian6D(),
                           'type': ('pcg', 'MassMatrixPreconditioner'),
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False}
 
         params = set_defaults(params, params_default)
 
         self._params = params
 
-        assert isinstance(params['f0'], Maxwellian6DUniform)
+        assert isinstance(params['f0'], Maxwellian6D)
 
         self._alpha = params['alpha']
         self._kappa = params['kappa']
         self._f0 = params['f0']
-        self._f0_params = np.array([self._f0.params['n'],
-                                    self._f0.params['u1'],
-                                    self._f0.params['u2'],
-                                    self._f0.params['u3'],
-                                    self._f0.params['vth1'],
-                                    self._f0.params['vth2'],
-                                    self._f0.params['vth3']])
+        self._f0_params = np.array(
+            [self._f0.maxw_params['n'],
+             self._f0.maxw_params['u1'],
+             self._f0.maxw_params['u2'],
+             self._f0.maxw_params['u3'],
+             self._f0.maxw_params['vth1'],
+             self._f0.maxw_params['vth2'],
+             self._f0.maxw_params['vth3']]
+        )
 
         self._info = params['info']
 
         # Initialize Accumulator object
         self._accum = AccumulatorVector(
             self.derham, self.domain, 'Hcurl', 'delta_f_vlasov_maxwell')
 
@@ -632,21 +641,23 @@
         if params['type'][1] == None:
             self._pc = None
         else:
             pc_class = getattr(preconditioner, params['type'][1])
             self._pc = pc_class(self.mass_ops.M1)
 
         # solver
-        self.solver = inverse(self.mass_ops.M1, 
-                              params['type'][0], 
-                              pc=self._pc,
-                              x0=self.feec_vars[0],
-                              tol=self._params['tol'],
-                              maxiter=self._params['maxiter'],
-                              verbose=self._params['verbose'])
+        self.solver = inverse(
+            self.mass_ops.M1,
+            params['type'][0],
+            pc=self._pc,
+            x0=self.feec_vars[0],
+            tol=self._params['tol'],
+            maxiter=self._params['maxiter'],
+            verbose=self._params['verbose']
+        )
 
         self._pusher = Pusher(self.derham, self.domain,
                               'push_weights_with_efield_delta_f_vm')
 
     def __call__(self, dt):
         # evaluate f0 and accumulate
         f0_values = self._f0(self.particles[0].markers[:, 0],
@@ -749,15 +760,15 @@
     def __init__(self, particles, u, **params):
 
         super().__init__(particles, u)
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'use_perp_model': True,
-                          'f0': Maxwellian6DUniform(),
+                          'f0': Maxwellian6D(),
                           'type': ('pcg', 'MassMatrixPreconditioner'),
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False,
                           'nuh': 5.,
                           'Ab': 1,
@@ -1216,92 +1227,59 @@
                          'maxiter': 3000,
                          'info': False,
                          'verbose': False}
         return dct
 
 
 class CurrentCoupling5DCurlb(Propagator):
-    r'''Crank-Nicolson step for the current coupling part (:math:`v_\parallel \nabla \times \mathbf b_0`) in `LinearMHDDriftkineticCC <https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.hybrid.LinearMHDDriftkineticCC>`_ model,
+    r'''Crank-Nicolson scheme for the CC-Curlb step in :class:`~struphy.models.hybrid.LinearMHDDriftkineticCC`,
 
-    Equation:
+    Equation: 
 
     .. math::
 
         \left\{ 
             \begin{aligned} 
-                n_0 &\frac{\partial \tilde{\mathbf U}}{\partial t} = - \frac{A_h}{A_b} \iint f_{\textnormal{h}} \frac{1}{B^*_\parallel} v_\parallel^2 \nabla \times \mathbf b_0 \textnormal{d} v_\parallel \textnormal{d} \mu \times \mathbf B \,,
+                \int n_{0} &\frac{\partial \tilde{\mathbf U}}{\partial t} \cdot \tilde{\mathbf V}\, \textnormal{d} \mathbf x = - \frac{A_\textnormal{h}}{A_b} \iint \frac{f^\text{vol}}{B^*_\parallel} v_\parallel^2 (\nabla \times \mathbf b_0)  \times \mathbf B \cdot \tilde{\mathbf V}\, \textnormal{d} \mathbf x \textnormal{d} v_\parallel \textnormal{d} \mu \quad \forall \ \tilde{\mathbf V} \,,
                 \\
                 &\frac{\partial v_\parallel}{\partial t} = - \frac{1}{B^*_\parallel} v_\parallel (\nabla \times \mathbf b_0) \cdot (\mathbf B \times \tilde{\mathbf U}) \,.
             \end{aligned}
         \right.
 
     FE coefficients and marker update (:math:`\alpha = 2`):
 
     .. math::
 
         \begin{bmatrix} 
             \mathbf u^{n+1} - \mathbf u^n \\ V_\parallel^{n+1} - V_\parallel^n
         \end{bmatrix} 
-        = \frac{\Delta t}{2} \,.
+        = \frac{\Delta t}{2} 
         \begin{bmatrix} 
-            0 & (\mathbb M^\rho_\alpha)^{-1} {\mathbb{P}^2}^\top \mathbb B^{*,-1}_\parallel \mathbb{V}_\parallel \sqrt{\mathbb g}^{-1} \sqrt{\mathbb g}^{-1} \mathbb{B}^\times \mathbb b_0^{\nabla \times}
+            0 & - (\mathbb{M}^{2,n})^{-1} \left\{ \mathbb{L}^2 \frac{1}{\bar{\sqrt{g}}} \right\}\cdot_\text{vector} \left\{\bar{b}^{\nabla \times}_0 (\bar{B}^\times_f)^\top \bar{V}_\parallel \frac{1}{\bar{\sqrt{g}}}\right\} \frac{1}{\bar B^{*0}_\parallel})
             \\  
-            - {\mathbb b_0^{\nabla \times}}^\top \mathbb{B}^\times \sqrt{\mathbb g}^{-1} \sqrt{\mathbb g}^{-1} \mathbb{V}_\parallel \mathbb B^{*,-1}_\parallel \mathbb{P}^2 (\mathbb M^\rho_\alpha)^{-1} & 0 
+            \frac{1}{\bar B^{*0}_\parallel} \left\{\bar{b}^{\nabla \times}_0 (\bar{B}^\times_f)^\top \bar{V}_\parallel \frac{1}{\bar{\sqrt{g}}}\right\}\, \cdot_\text{vector} \left\{\frac{1}{\bar{\sqrt{g}}}(\mathbb{L}²)^\top\right\} (\mathbb{M}^{2,n})^{-1} & 0 
         \end{bmatrix} 
         \begin{bmatrix}
-            \mathbb M^\rho_\alpha (\mathbf u^{n+1} + \mathbf u^n)
+            (\mathbb{M}^{2,n})^{-1} (\mathbf u^{n+1} + \mathbf u^n)
             \\
-            \mathbb W (\bar{V}_\parallel^{n+1} + \bar{V}_\parallel^n)
+            \frac{A_\textnormal{h}}{A_b} W (V_\parallel^{n+1} + V_\parallel^n)
         \end{bmatrix} \,,
 
     where 
-    :math:`\mathbb M^\rho_\alpha` is a :ref:`weighted_mass` being weighted with :math:`\rho_0`, the MHD equilibirum density. 
-    :math:`\alpha \in \{1, 2, v\}` denotes the :math:`\alpha`-form space where the operators correspond to.
-    Moreover, :math:`\mathbb B^\times, \, \mathbb b_0^{\nabla \times}, \, \mathbb P^2` and notations with over-bar are the block matrices which are diagonally stacked collocation vectors.    Note that following matrices are not assembled but only for representing the accumulation and pushing of particles compactly:
+    :math:`\mathbb{M}^{\alpha,n}` is a :class:`~struphy.feec.mass.WeightedMassOperators` being weighted with :math:`n_{0}`, the MHD equilibirum density. 
+    Moreover, :math:`\bar{B}^\times_f, \, \bar{b}_0^{\nabla \times}, \, \mathbb L^2` and notations with over-bar are the block matrices which are diagonally stacked collocation vectors.
 
-    .. math::
-
-        \begin{alignat}{2}
-            &\mathbb{V}_\parallel := \mathbb{I}_3 \otimes \text{diag}(V_\parallel) && 
-            \bar{V}_\parallel := (V_\parallel, V_\parallel, V_\parallel) \qquad \qquad V_\parallel := (v_{\parallel,1}, \, \dots, v_{\parallel,N_p})^\top
-            \\
-            &\mathbb W_\parallel := \mathbb{I}_3 \otimes \text{diag}(W) && 
-            W := (\omega_1, \, \dots, \omega_{N_p})^\top 
-            \\
-            &\mathbb B^{*,-1}_\parallel := \mathbb{I}_3 \otimes \mathbb{B}^{*, -1}_\parallel && 
-            \bar B^{*,-1}_\parallel := \text{diag}(B^{*, -1}_{\parallel}(\boldsymbol{\eta}_1, v_{\parallel,1}), \, \dots, B^{*, -1}_{\parallel}(\boldsymbol{\eta}_{N_p}, v_{\parallel,N_p}))
-            \\
-            &\sqrt{\mathbb g}^{-1} := \mathbb{I}_3 \otimes  \bar{\sqrt{g}}^{-1} && 
-            \bar{\sqrt{g}}^{-1} := \text{diag}(\sqrt{g(\boldsymbol{\eta}_{1})}^{-1}, \, \dots, \sqrt{g(\boldsymbol{\eta}_{N_p})}^{-1})
-            \\
-            &\mathbb{P}^n := \text{diag}(\mathbb{P}^n_1, \mathbb{P}^n_2, \mathbb{P}^n_3) && 
-            \mathbb{P}^n_\mu := (\Lambda^n_{\mu,i}(\boldsymbol{\eta}_k))_{0\leq i \leq N^n_\mu, \,  1\leq k \leq N_p, \, n \in \{v,1,2\}, \, \mu \in \{ 1,2,3\}}
-            \\
-            &\mathbb{b}^{\nabla \times}_0 := (\mathbb{b}^{\nabla \times}_{0,1}, \mathbb{b}^{\nabla \times}_{0,2}, \mathbb{b}^{\nabla \times}_{0,3}) &&
-            \mathbb{b}^{\nabla\times}_{0,\mu} := ((\widehat \nabla \times \widehat{\mathbf b}^1_{0})_\mu(\boldsymbol{\eta}_k))_{1 \leq k \leq N_p, \mu \in \{1,2,3\}}
-            \\
-            &\mathbb{B}^\times := 
-            \begin{pmatrix}
-                0 & - \mathbb{B}^2_3 & \mathbb{B}^2_2
-                \\
-                \mathbb{B}^2_3 & 0 & -\mathbb{B}^2_1
-                \\
-                - \mathbb{B}^2_2 & \mathbb{B}^2_1 & 0
-            \end{pmatrix} \qquad && 
-            \mathbb{B}^2_\mu = \mathbf b^\top \mathbb{P}^2_\mu + (\widehat{\mathbf B}^2_{0,\mu}(\boldsymbol{\eta}_k))_{1 \leq k \leq N_p, \mu \in \{1,2,3\}}
-        \end{alignat}
-
-    The solution of the above system is based on the :ref:`Schur complement <schur_solver>`.
+    For the detail explanation of the notations, see `2022_DriftKineticCurrentCoupling <https://gitlab.mpcdf.mpg.de/struphy/struphy-projects/-/blob/main/running-projects/2022_DriftKineticCurrentCoupling.md?ref_type=heads>`_.
 
     Parameters
     ---------- 
-    particles : struphy.pic.particles.Particles6D
+    particles : Particles5D
         Particles object.
 
-    u : psydac.linalg.block.BlockVector
+    u : BlockVector
         FE coefficients of MHD velocity.
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, particles, u, **params):
@@ -1310,15 +1288,15 @@
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'b': None,
                           'b_eq': None,
                           'unit_b1': None,
                           'curl_unit_b2': None,
-                          'f0': Maxwellian5DUniform(),
+                          'f0': Maxwellian5D(),
                           'type': ('pcg', 'MassMatrixPreconditioner'),
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False,
                           'Ab': 1,
                           'Ah': 1,
@@ -1345,14 +1323,15 @@
         self._rank = self.derham.comm.Get_rank()
 
         self._coupling_mat = params['Ah'] / params['Ab']
         self._coupling_vec = params['Ah'] / params['Ab']
         self._scale_push = 1
 
         u_id = self.derham.space_to_form[params['u_space']]
+        self._E0T = self.derham.extraction_ops['0'].transpose()
         self._EuT = self.derham.extraction_ops[u_id].transpose()
         self._E2T = self.derham.extraction_ops['2'].transpose()
         self._E1T = self.derham.extraction_ops['1'].transpose()
 
         self._unit_b1 = self._E1T.dot(self._unit_b1)
         self._curl_norm_b = self._E2T.dot(self._curl_norm_b)
         self._curl_norm_b.update_ghost_regions()
@@ -1373,18 +1352,18 @@
         self._pusher = Pusher(self.derham, self.domain,
                               'push_gc_cc_J1_' + params['u_space'])
 
         # define BC and B dot V of the Schur block matrix [[A, B], [C, I]]
         _BC = -1/4 * self._ACC.operators[0]
 
         # call SchurSolver class
-        self._schur_solver = SchurSolver(_A, _BC, 
+        self._schur_solver = SchurSolver(_A, _BC,
                                          params['type'][0],
                                          pc=pc,
-                                         tol=params['tol'], 
+                                         tol=params['tol'],
                                          maxiter=params['maxiter'],
                                          verbose=params['verbose'])
 
         # temporary vectors to avoid memory allocation
         self._b_full1 = self._b_eq.space.zeros()
         self._b_full2 = self._E2T.codomain.zeros()
         self._u_new = u.space.zeros()
@@ -1408,15 +1387,15 @@
         Eb_full.update_ghost_regions()
 
         # acuumulate MAT and VEC
         self._ACC.accumulate(self.particles[0], self._epsilon,
                              Eb_full[0]._data, Eb_full[1]._data, Eb_full[2]._data,
                              self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                              self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
-                             self._space_key_int, self._coupling_mat, self._coupling_vec)
+                             self._space_key_int, self._coupling_mat, self._coupling_vec, 0.1)
 
         # update u coefficients
         un1, info = self._schur_solver(
             un, -self._ACC.vectors[0]/2, dt, out=self._u_new)
 
         # call pusher kernel with average field (u_new + u_old)/2 and update ghost regions because of non-local access in kernel
         _u = un.copy(out=self._u_avg1)
@@ -1428,15 +1407,15 @@
         _Eu.update_ghost_regions()
 
         self._pusher(self.particles[0], self._scale_push*dt,
                      self._epsilon,
                      Eb_full[0]._data, Eb_full[1]._data, Eb_full[2]._data,
                      self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                      self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
-                     _Eu[0]._data, _Eu[1]._data, _Eu[2]._data)
+                     _Eu[0]._data, _Eu[1]._data, _Eu[2]._data, 0.1)
 
         # write new coeffs into Propagator.variables
         max_du, = self.feec_vars_update(un1)
 
         if self._info and self._rank == 0:
             print('Status     for CurrentCoupling5DCurlb:', info['success'])
             print('Iterations for CurrentCoupling5DCurlb:', info['niter'])
@@ -1452,94 +1431,60 @@
                          'tol': 1.e-8,
                          'maxiter': 3000,
                          'info': False,
                          'verbose': False}
         return dct
 
 
-class CurrentCoupling5DGradBxB(Propagator):
-    r'''Crank-Nicolson step for the current coupling part (:math:`\mu \nabla B_\parallel \times \mathbf b_0`) in `LinearMHDDriftkineticCC <https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.hybrid.LinearMHDDriftkineticCC>`_ model,
+class CurrentCoupling5DGradB(Propagator):
+    r'''Crank-Nicolson scheme for the CC-GradB step in :class:`~struphy.models.hybrid.LinearMHDDriftkineticCC`.
 
     Equation:
 
     .. math::
 
         \left\{ 
             \begin{aligned} 
-                n_0 &\frac{\partial \tilde{\mathbf U}}{\partial t} = \frac{A_h}{A_b} \iint f_{\textnormal{h}} \frac{1}{B^*_\parallel} \mathbf b_0 \times (\mu \nabla B_\parallel) \textnormal{d} v_\parallel \textnormal{d} \mu \times \mathbf B \,,
+                \int n_{0} &\frac{\partial \tilde{\mathbf U}}{\partial t} \cdot \tilde{\mathbf V}\, \textnormal{d} \mathbf x = - \frac{A_\textnormal{h}}{A_b} \iint \mu \frac{f^\text{vol}}{B^*_\parallel} (\mathbf b_0 \times \nabla B_\parallel) \times \mathbf B \cdot \tilde{\mathbf V} \,\textnormal{d} \mathbf x \textnormal{d} v_\parallel \textnormal{d} \mu \quad \forall \ \tilde{\mathbf V} \,,
                 \\
-                &\frac{\partial \mathbf X}{\partial t} = \frac{1}{B^*_\parallel} \mathbf b_0 \times \tilde{\mathbf U} \times \mathbf B \,.
+                &\frac{\partial \boldsymbol \eta}{\partial t} = \frac{1}{B^*_\parallel} \mathbf b_0 \times (\tilde{\mathbf U} \times \mathbf B) \,.
             \end{aligned}
         \right.
 
     FE coefficients and marker update (:math:`\alpha = 2`):
 
     .. math::
 
         \begin{bmatrix} 
             \mathbf u^{n+1} - \mathbf u^n \\ \mathbf H^{n+1} - \mathbf H^n
         \end{bmatrix} 
-        = \frac{\Delta t}{2} \,.
+        = \frac{\Delta t}{2}
         \begin{bmatrix} 
-            0 & (\mathbb M^\rho_\alpha)^{-1} {\mathbb{P}^2}^\top \mathbb B^{*,-1}_\parallel \sqrt{\mathbb g}^{-1}\mathbb{B}^\times \bar G^{-1} \mathbb b_0^\times \bar G^{-1}
+            0 & (\mathbb{M}^{2,n})^{-1} \mathbb{L}² \frac{1}{\bar{\sqrt{g}}} \frac{1}{\bar B^{*0}_\parallel}\bar{B}^\times_f \bar{G}^{-1} \bar{b}^\times_0 \bar{G}^{-1} 
             \\  
-            - \bar G^{-1} \mathbb b_0^\times \bar G^{-1} \mathbb{B}^\times \sqrt{\mathbb g}^{-1} \mathbb B^{*,-1}_\parallel \mathbb{P}^2 (\mathbb M^\rho_\alpha)^{-1} & 0 
+            -\bar{G}^{-1} \bar{b}^\times_0 \bar{G}^{-1}  \bar{B}^\times_f \frac{1}{\bar B^{*0}_\parallel} \frac{1}{\bar{\sqrt{g}}} (\mathbb{L}²)^\top (\mathbb{M}^{2,n})^{-1} & 0 
         \end{bmatrix} 
         \begin{bmatrix}
-            \mathbb M^\rho_\alpha (\mathbf u^{n+1} + \mathbf u^n)
+            \mathbb M^{2,n} (\mathbf u^{n+1} + \mathbf u^n)
             \\
-            \mathbb{W} \bar \mu \mathbb P^2 \mathbb G \mathcal{P}_b (\mathbf b^{n+1} + \mathbf b^n)
+            \frac{A_\textnormal{h}}{A_b} \bar M \bar W \overline{\nabla B}_\parallel 
         \end{bmatrix} \,,
 
     where 
-    :math:`\mathbb M^\rho_\alpha` is a :ref:`weighted_mass` being weighted with :math:`\rho_0`, the MHD equilibirum density. 
+    :math:`\mathbb M^\rho_\alpha` is a :class:`~struphy.feec.mass.WeightedMassOperators` being weighted with :math:`\rho_0`, the MHD equilibirum density. 
     :math:`\alpha \in \{1, 2, v\}` denotes the :math:`\alpha`-form space where the operators correspond to.
-    Moreover, :math:`\mathbb B^\times, \, \mathbb b_0^{\times}, \, \mathbb P^2` and notations with over-bar are the block matrices which are diagonally stacked collocation vectors.    Note that following matrices are not assembled but only for representing the accumulation and pushing of particles compactly:
-
-    .. math::
-
-        \begin{alignat}{2}
-            \\
-            &\mathbf H := (\eta_{1,1}, \dots, \eta_{N_p,1}, \eta_{1,2}, \dots, \eta_{N_p,2}, \eta_{1,3}, \dots, \eta_{N_p,3})^\top
-            \\
-            &\bar \mu := \mathbb{I}_3 \otimes \text{diag}((\mu_1, \, \dots, \mu_{N_p})^\top )
-            \\
-            &\mathbb W_\parallel := \mathbb{I}_3 \otimes \text{diag}(W) && 
-            W := (\omega_1, \, \dots, \omega_{N_p})^\top 
-            \\
-            &\mathbb B^{*,-1}_\parallel := \mathbb{I}_3 \otimes \mathbb{B}^{*, -1}_\parallel && 
-            \bar B^{*,-1}_\parallel := \text{diag}(B^{*, -1}_{\parallel}(\boldsymbol{\eta}_1, v_{\parallel,1}), \, \dots, B^{*, -1}_{\parallel}(\boldsymbol{\eta}_{N_p}, v_{\parallel,N_p}))
-            \\
-            &\bar{G}^{-1} := \text{diag}(G^{-1}(\boldsymbol{\eta}_{1}), \dots, G^{-1}(\boldsymbol{\eta}_{N_p}))
-            \\
-            &\sqrt{\mathbb g}^{-1} := \mathbb{I}_3 \otimes  \bar{\sqrt{g}}^{-1} && 
-            \bar{\sqrt{g}}^{-1} := \text{diag}(\sqrt{g(\boldsymbol{\eta}_{1})}^{-1}, \, \dots, \sqrt{g(\boldsymbol{\eta}_{N_p})}^{-1})
-            \\
-            &\mathbb{P}^n := \text{diag}(\mathbb{P}^n_1, \mathbb{P}^n_2, \mathbb{P}^n_3) && 
-            \mathbb{P}^n_\mu := (\Lambda^n_{\mu,i}(\boldsymbol{\eta}_k))_{0\leq i \leq N^n_\mu, \,  1\leq k \leq N_p, \, n \in \{v,1,2\}, \, \mu \in \{ 1,2,3\}}
-            \\
-            &\mathbb{b}_0^\times := 
-            \begin{pmatrix}
-                0 & - \mathbb{b}^2_{0,3} & \mathbb{b}^2_{0,2}
-                \\
-                \mathbb{b}^2_{0,3} & 0 & -\mathbb{b}^2_{0,1}
-                \\
-                - \mathbb{b}^2_{0,2} & \mathbb{b}^2_{0,1} & 0
-            \end{pmatrix} \qquad && 
-            \mathbb{b}^2_{0,\mu} = (\widehat{\mathbf b}^2_{0,\mu}(\boldsymbol{\eta}_k))_{1 \leq k \leq N_p, \mu \in \{1,2,3\}}
-        \end{alignat}
 
-    The solution of the above system is based on the :ref:`Schur complement <schur_solver>`.
+    For the detail explanation of the notations, see `2022_DriftKineticCurrentCoupling <https://gitlab.mpcdf.mpg.de/struphy/struphy-projects/-/blob/main/running-projects/2022_DriftKineticCurrentCoupling.md?ref_type=heads>`_.
 
     Parameters
     ---------- 
-    particles : struphy.pic.particles.Particles6D
+    particles : Particles5D
         Particles object.
 
-    u : psydac.linalg.block.BlockVector
+    u : BlockVector
         FE coefficients of MHD velocity.
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, particles, u, **params):
@@ -1550,18 +1495,17 @@
 
         # parameters
         params_default = {'u_space': 'Hdiv',
                           'b': None,
                           'b_eq': None,
                           'unit_b1': None,
                           'unit_b2': None,
-                          'abs_b': None,
                           'gradB1': None,
                           'curl_unit_b2': None,
-                          'f0': Maxwellian5DUniform(),
+                          'f0': Maxwellian5D(),
                           'type': ('pcg', 'MassMatrixPreconditioner'),
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False,
                           'Ab': 1,
                           'Ah': 1,
@@ -1580,16 +1524,15 @@
 
         self._epsilon = params['epsilon']
         self._f0 = params['f0']
         self._b = params['b']
         self._b_eq = params['b_eq']
         self._unit_b1 = params['unit_b1']
         self._unit_b2 = params['unit_b2']
-        self._abs_b = params['abs_b']
-        self._grad_abs_b = params['gradB1']
+        self._gradB1 = params['gradB1']
         self._curl_norm_b = params['curl_unit_b2']
         self._info = params['info']
         self._rank = self.derham.comm.Get_rank()
 
         self._coupling_mat = params['Ah'] / params['Ab']
         self._coupling_vec = params['Ah'] / params['Ab']
         self._scale_push = 1
@@ -1659,46 +1602,46 @@
 
         # temporary vectors to avoid memory allocation
         self._b_full1 = self._b_eq.space.zeros()
         self._b_full2 = self._E2T.codomain.zeros()
         self._u_new = u.space.zeros()
         self._u_avg1 = u.space.zeros()
         self._u_avg2 = self._EuT.codomain.zeros()
-        self._tmp1 = self._abs_b.space.zeros()
-        self._tmp2 = self._grad_abs_b.space.zeros()
+        self._tmp1 = self._E0T.codomain.zeros()
+        self._tmp2 = self._gradB1.space.zeros()
         self._tmp3 = self._E1T.codomain.zeros()
 
     def __call__(self, dt):
 
         un = self.feec_vars[0]
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         b_full = self._b_eq.copy(out=self._b_full1)
 
         if self._b is not None:
             self._b_full1 += self._b
 
         PBb = self._PB.dot(self._b, out=self._tmp1)
         grad_PBb = self.derham.grad.dot(PBb, out=self._tmp2)
-        grad_PBb += self._grad_abs_b
+        grad_PBb += self._gradB1
 
         Eb_full = self._E2T.dot(b_full, out=self._b_full2)
         Eb_full.update_ghost_regions()
 
         Egrad_PBb = self._E1T.dot(grad_PBb, out=self._tmp3)
         Egrad_PBb.update_ghost_regions()
 
         # accumulate MAT and VEC
         self._ACC.accumulate(self.particles[0], self._epsilon,
                              Eb_full[0]._data, Eb_full[1]._data, Eb_full[2]._data,
                              self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                              self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                              self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                              Egrad_PBb[0]._data, Egrad_PBb[1]._data, Egrad_PBb[2]._data,
-                             self._space_key_int, self._coupling_mat, self._coupling_vec)
+                             self._space_key_int, self._coupling_mat, self._coupling_vec, 0.1)
 
         # solve linear system for updated u coefficients
         un1, info = self._schur_solver(
             un, -self._ACC.vectors[0]/2, dt, out=self._u_new)
 
         # call pusher kernel with average field (u_new + u_old)/2 and update ghost regions because of non-local access in kernel
         _u = un.copy(out=self._u_avg1)
@@ -1711,24 +1654,24 @@
         self._pusher(self.particles[0], dt,
                      self._epsilon,
                      Eb_full[0]._data, Eb_full[1]._data, Eb_full[2]._data,
                      self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                      self._unit_b2[0]._data, self._unit_b2[1]._data, self._unit_b2[2]._data,
                      self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
                      Eu[0]._data, Eu[1]._data, Eu[2]._data,
-                     self._butcher.a, self._butcher.b, self._butcher.c,
+                     self._butcher.a, self._butcher.b, self._butcher.c, 0.1,
                      mpi_sort='each')
 
         # write new coeffs into Propagator.variables
         max_du, = self.feec_vars_update(un1)
 
         if self._info and self._rank == 0:
-            print('Status     for CurrentCoupling5DGradBxB:', info['success'])
-            print('Iterations for CurrentCoupling5DGradBxB:', info['niter'])
-            print('Maxdiff up for CurrentCoupling5DGradBxB:', max_du)
+            print('Status     for CurrentCoupling5DGradB:', info['success'])
+            print('Iterations for CurrentCoupling5DGradB:', info['niter'])
+            print('Maxdiff up for CurrentCoupling5DGradB:', max_du)
             print()
 
     @classmethod
     def options(cls):
         dct = {}
         dct['u_space'] = ['Hcurl', 'Hdiv', 'H1vec']
         dct['solver'] = {'type': [('pcg', 'MassMatrixPreconditioner'),
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `struphy-2.2.0/src/struphy/propagators/propagators_fields.py` & `struphy-2.3.0/src/struphy/propagators/propagators_fields.py`

 * *Files 15% similar despite different names*

```diff
@@ -5,24 +5,26 @@
 from numpy import zeros
 
 from struphy.propagators.base import Propagator
 from struphy.linear_algebra.schur_solver import SchurSolver
 from struphy.pic.accumulation.particles_to_grid import Accumulator
 from struphy.polar.basic import PolarVector
 from struphy.kinetic_background.base import Maxwellian
-from struphy.kinetic_background.maxwellians import Maxwellian6DUniform, Maxwellian5DUniform
+from struphy.kinetic_background.maxwellians import Maxwellian6D, Maxwellian5D
 from struphy.fields_background.mhd_equil.equils import set_defaults
 from struphy.feec import preconditioner
 from struphy.feec.mass import WeightedMassOperator
 from struphy.feec.basis_projection_ops import BasisProjectionOperator, CoordinateProjector
+from struphy.feec.variational_utilities import BracketOperator
+
 
 from psydac.linalg.solvers import inverse
 from psydac.linalg.basic import IdentityOperator
 from psydac.linalg.stencil import StencilVector
-from psydac.linalg.block import BlockVector
+from psydac.linalg.block import BlockVector, BlockLinearOperator, BlockVectorSpace
 import struphy.feec.utilities as util
 from mpi4py import MPI
 
 from copy import deepcopy
 
 
 class Maxwell(Propagator):
@@ -1343,15 +1345,15 @@
         super().__init__(u)
 
         # parameters
         params_default = {'particles': None,
                           'u_space': 'Hdiv',
                           'b_eq': None,
                           'b_tilde': None,
-                          'f0': Maxwellian6DUniform(),
+                          'f0': Maxwellian6D(),
                           'type': ('pbicgstab', 'MassMatrixPreconditioner'),
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False,
                           'Ab': 1,
                           'Ah': 1,
@@ -1527,56 +1529,56 @@
                          'maxiter': 3000,
                          'info': False,
                          'verbose': False}
         return dct
 
 
 class ShearAlfvénCurrentCoupling5D(Propagator):
-    r'''Crank-Nicolson step for the shear Alfvén part in `LinearMHDDriftkineticCC <https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.hybrid.LinearMHDDriftkineticCC>`_ model,
+    r'''Crank-Nicolson scheme for the shear Alfvén step in :class:`~struphy.models.hybrid.LinearMHDDriftkineticCC`,
 
     Equation:
 
     .. math::
 
         \left\{ 
             \begin{aligned} 
-                n_0 &\frac{\partial \tilde{\mathbf U}}{\partial t} = \nabla \times \left(\mathbf B + \frac{A_h}{A_b} \iint f_{\textnormal{h}} \mu \mathbf b_0 \textnormal{d} v_\parallel \textnormal{d} \mu \right) \times \mathbf B_0 \,,
+                \int n_0 &\frac{\partial \tilde{\mathbf U}}{\partial t} \cdot \tilde{\mathbf V} \, \textnormal{d} \mathbf{x} = \int \left(\tilde{\mathbf B} - \frac{A_\textnormal{h}}{A_b} \iint f^\text{vol} \mu \mathbf{b}_0\textnormal{d} \mu \textnormal{d} v_\parallel \right) \cdot \nabla \times (\mathbf B_0 \times \tilde{\mathbf V}) \, \textnormal{d} \mathbf{x} \quad \forall \ \tilde{\mathbf V} \,,
                 \\
                 &\frac{\partial \tilde{\mathbf B}}{\partial t} = - \nabla \times (\mathbf B_0 \times \tilde{\mathbf U}) \,.
             \end{aligned}
         \right.
 
     FE coefficients update:
 
     .. math::
 
         \begin{bmatrix} 
-            \mathbf u^{n+1} - \mathbf u^n \\ \mathbf b^{n+1} - \mathbf b^n \,,
+            \mathbf u^{n+1} - \mathbf u^n \\ \mathbf b^{n+1} - \mathbf b^n
         \end{bmatrix} 
         = \frac{\Delta t}{2} \,.
         \begin{bmatrix} 
-            0 & (\mathbb M^\rho_\alpha)^{-1} \mathcal {T^\alpha}^\top \mathbb C^\top \\ - \mathbb C \mathcal {T^\alpha} (\mathbb M^\rho_\alpha)^{-1} & 0 
+            0 & (\mathbb M^{\alpha,n})^{-1} \mathcal {T^\alpha}^\top \mathbb C^\top \\ - \mathbb C \mathcal {T^\alpha} (\mathbb M^{\alpha,n})^{-1} & 0 
         \end{bmatrix} 
         \begin{bmatrix}
-            {\mathbb M^\rho_\alpha}(\mathbf u^{n+1} + \mathbf u^n) \\ \mathbb M_2(\mathbf b^{n+1} + \mathbf b^n) + \mathcal{P}_b^{\top} \sum_k^{N_p} \omega_k \mu_k \Lambda^0(\boldsymbol \eta_k) 
+            {\mathbb M^{\alpha,n}}(\mathbf u^{n+1} + \mathbf u^n) \\ \mathbb M_2(\mathbf b^{n+1} + \mathbf b^n) + \sum_k^{N_p} \omega_k \mu_k \hat{\mathbf b}¹_0 (\boldsymbol \eta_k) \cdot \left(\frac{1}{\sqrt{g(\boldsymbol \eta_k)}} \vec \Lambda² (\boldsymbol \eta_k) \right)
         \end{bmatrix} \,,
 
     where 
-    :math:`\mathcal{T}^\alpha` and :math:`\mathcal{P}_b` are :ref:`basis_ops` and
-    :math:`\mathbb M^\rho_\alpha` is a :ref:`weighted_mass` being weighted with :math:`\rho_0`, the MHD equilibirum density. 
+    :math:`\mathcal{T}^\alpha` is a :class:`~struphy.feec.basis_projection_ops.BasisProjectionOperators` and
+    :math:`\mathbb M^{\alpha,n}` is a :class:`~struphy.feec.mass.WeightedMassOperators` being weighted with :math:`\rho_\text{eq}`, the MHD equilibirum density. 
     :math:`\alpha \in \{1, 2, v\}` denotes the :math:`\alpha`-form space where the operators correspond to.
-    Moreover, :math:`\sum_k^{N_p} \omega_k \mu_k \Lambda^0(\boldsymbol \eta_k)` is accumulated by the kernel `cc_lin_mhd_5d_mu <https://struphy.pages.mpcdf.de/struphy/sections/accumulators.html#struphy.pic.accumulation.accum_kernels_gc.cc_lin_mhd_5d_mu>`_ .
-    The solution of the above system is based on the :ref:`Schur complement <schur_solver>`.
+    Moreover, :math:`\sum_k^{N_p} \omega_k \mu_k \hat{\mathbf b}¹_0 (\boldsymbol \eta_k) \cdot \left(\frac{1}{\sqrt{g(\boldsymbol \eta_k)}} \vec \Lambda² (\boldsymbol \eta_k)\right)` is accumulated by the kernel :class:`~struphy.pic.accumulation.accum_kernels_gc.cc_lin_mhd_5d_M`.
+    The solution of the above system is based on the :class:`struphy.linear_algebra.schur_solver.SchurSolver`.
 
     Parameters
     ---------- 
-    u : psydac.linalg.block.BlockVector
+    u : BlockVector
         FE coefficients of MHD velocity.
 
-    b : psydac.linalg.block.BlockVector
+    b : BlockVector
         FE coefficients of magnetic field as 2-form.
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, u, b, **params):
@@ -1584,58 +1586,54 @@
         from struphy.pic.particles import Particles5D
 
         super().__init__(u, b)
 
         # parameters
         params_default = {'particles': Particles5D,
                           'u_space': 'Hdiv',
-                          'b_eq': None,
-                          'f0': Maxwellian5DUniform(),
+                          'unit_b1': None,
+                          'f0': Maxwellian5D(),
                           'type': ('pcg', 'MassMatrixPreconditioner'),
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False,
                           'Ab': 1,
                           'Ah': 1}
 
         params = set_defaults(params, params_default)
 
-        assert isinstance(params['particles'], Particles5D)
         self._particles = params['particles']
-
-        assert params['u_space'] in {'Hcurl', 'Hdiv', 'H1vec'}
-
         self._f0 = params['f0']
-        assert isinstance(params['b_eq'], (BlockVector, PolarVector))
-        self._b_eq = params['b_eq']
-
         self._type = params['type'][0]
         self._tol = params['tol']
         self._maxiter = params['maxiter']
         self._info = params['info']
         self._verbose = params['verbose']
         self._rank = self.derham.comm.Get_rank()
+        self._scale_vec = params['Ah'] / params['Ab']
 
-        self._coupling_const = params['Ah'] / params['Ab']
+        self._unit_b1 = params['unit_b1']
+
+        self._E1T = self.derham.extraction_ops['1'].transpose()
+        self._unit_b1 = self._E1T.dot(self._unit_b1)
 
-        self._PB = getattr(self.basis_ops, 'PB')
         self._ACC = Accumulator(self.derham, self.domain,
-                                'H1', 'cc_lin_mhd_5d_mu', add_vector=True)
+                                'Hdiv', 'cc_lin_mhd_5d_M', add_vector=True, symmetry='symm')
 
         # define block matrix [[A B], [C I]] (without time step size dt in the diagonals)
         id_M = 'M' + self.derham.space_to_form[params['u_space']] + 'n'
         id_T = 'T' + self.derham.space_to_form[params['u_space']]
 
         _A = getattr(self.mass_ops, id_M)
         _T = getattr(self.basis_ops, id_T)
 
         self._B = -1/2 * _T.T @ self.derham.curl.T @ self.mass_ops.M2
         self._C = 1/2 * self.derham.curl @ _T
-        self._B2 = -1/2. * _T.T @ self.derham.curl.T @ self._PB.T
+        self._B2 = -1/2 * _T.T @ self.derham.curl.T
 
         # Preconditioner
         if params['type'][1] is None:
             pc = None
         else:
             pc_class = getattr(preconditioner, params['type'][1])
             pc = pc_class(getattr(self.mass_ops, id_M))
@@ -1660,16 +1658,18 @@
 
     def __call__(self, dt):
 
         # current variables
         un = self.feec_vars[0]
         bn = self.feec_vars[1]
 
-        # accumulate scalar
-        self._ACC.accumulate(self._particles, self._coupling_const)
+        # accumulate vector
+        self._ACC.accumulate(self._particles, 
+                             self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
+                             self._scale_vec, 0.1)
 
         # solve for new u coeffs (no tmps created here)
         byn = self._B.dot(bn, out=self._byn)
         b2acc = self._B2.dot(self._ACC.vectors[0], out=self._tmp_acc)
         byn += b2acc
 
         un1, info = self._schur_solver(un, byn, dt, out=self._u_tmp1)
@@ -1701,68 +1701,74 @@
                          'maxiter': 3000,
                          'info': False,
                          'verbose': False}
         return dct
 
 
 class MagnetosonicCurrentCoupling5D(Propagator):
-    r'''Crank-Nicolson step for Magnetosonic part in `LinearMHDDriftkineticCC <https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.hybrid.LinearMHDDriftkineticCC>`_ model,
+    r'''Crank-Nicolson scheme for Magnetosonic step in :class:`~struphy.models.hybrid.LinearMHDDriftkineticCC`,
 
     Equation:
 
     .. math::
 
         \left\{
             \begin{aligned}
                 &\frac{\partial \tilde n}{\partial t} = - \nabla \cdot (n_0 \tilde{\mathbf U}) \,,
                 \\
-                n_0 &\frac{\partial \tilde{\mathbf U}}{\partial t} = \nabla \times \left(\mathbf B_0 + \frac{A_\textnormal{h}}{A_b}\iint f_{\textnormal{h}} \mu \mathbf b_0 \textnormal{d} v_\parallel \textnormal{d} \mu \right) \times \tilde{\mathbf B} - \nabla \tilde p \,,
+                \int n_0 &\frac{\partial \tilde{\mathbf U}}{\partial t} \cdot \tilde{\mathbf V} \, \textnormal{d} \mathbf{x} = \int (\nabla \times \mathbf B_0) \times \tilde{\mathbf B} \cdot \tilde{\mathbf V} \, \textnormal{d} \mathbf x + \frac{A_\textnormal{h}}{A_b}\iint f^\text{vol} \mu \mathbf b_0 \cdot \nabla \times (\tilde{\mathbf B} \times \tilde{\mathbf V}) \, \textnormal{d} \mathbf x \textnormal{d} v_\parallel \textnormal{d} \mu + \int \tilde p \nabla \cdot \tilde{\mathbf V} \, \textnormal{d} \mathbf x \qquad \forall \ \tilde{\mathbf V}\,,
                 \\
-                &\frac{\partial \tilde p}{\partial t} = - \nabla \cdot (p_0 \tilde{\mathbf U}) \,.
+                &\frac{\partial \tilde p}{\partial t} = - \nabla \cdot (p_0 \tilde{\mathbf U}) - (\gamma - 1) p_0 \nabla \cdot \tilde{\mathbf U} \,.
             \end{aligned} 
         \right.
 
     FE coefficients update:
 
     .. math::
 
-        \boldsymbol{\rho}^{n+1} - \boldsymbol{\rho}^n = - \frac{\Delta t}{2} \mathbb D \mathcal Q^\alpha (\mathbf u^{n+1} + \mathbf u^n) \,,
+        \boldsymbol{n}^{n+1} - \boldsymbol{n}^n = - \frac{\Delta t}{2} \mathbb D \mathcal Q^\alpha (\mathbf u^{n+1} + \mathbf u^n) \,,
 
     .. math::
 
         \begin{bmatrix} 
             \mathbf u^{n+1} - \mathbf u^n \\ \mathbf p^{n+1} - \mathbf p^n 
         \end{bmatrix} 
         = \frac{\Delta t}{2} 
         \begin{bmatrix} 
-            0 & (\mathbb M^\rho_\alpha)^{-1} {\mathcal U^\alpha}^\top \mathbb D^\top \mathbb M_3 \\ - \mathbb D \mathcal S^\alpha - (\gamma - 1) \mathcal K^\alpha \mathbb D \mathcal U^\alpha & 0 
+            0 & (\mathbb M^{\alpha,n})^{-1} {\mathcal U^\alpha}^\top \mathbb D^\top \mathbb M_3 \\ - \mathbb D \mathcal S^\alpha - (\gamma - 1) \mathcal K^\alpha \mathbb D \mathcal U^\alpha & 0 
         \end{bmatrix} 
         \begin{bmatrix} 
             (\mathbf u^{n+1} + \mathbf u^n) \\ (\mathbf p^{n+1} + \mathbf p^n) 
         \end{bmatrix} + 
         \begin{bmatrix} 
-            \Delta t (\mathbb M^\rho_\alpha)^{-1}\left[\mathbb M^J_\alpha \mathbf b^n + \sum_k^{N_p} \omega_k \mu_k \left\{(\hat \nabla \times \hat{\mathbf b}_0^1) \times \hat{\mathbf B}^2\right\}(\boldsymbol \eta_k)\right] \\ 0 
+            \Delta t (\mathbb M^{\alpha,n})^{-1}\left[\mathbb M^{\alpha,J} \mathbf b^n + \frac{A_\textnormal{h}}{A_b}{\mathcal{T}^B}^\top \mathbb{C}^\top \sum_k^{N_p} \omega_k \mu_k \hat{\mathbf b}¹_0 (\boldsymbol \eta_k) \cdot \left(\frac{1}{\sqrt{g(\boldsymbol \eta_k)}} \vec \Lambda² (\boldsymbol \eta_k) \right)\right] \\ 0 
         \end{bmatrix} \,,
 
     where 
-    :math:`\mathcal U^\alpha`, :math:`\mathcal S^\alpha`, :math:`\mathcal K^\alpha` and :math:`\mathcal Q^\alpha` are :ref:`basis_ops` and
-    :math:`\mathbb M^\rho_\alpha` and :math:`\mathbb M^J_\alpha` are :ref:`weighted_mass` being weighted with :math:`\rho_0` and :math:`\mathbf J_0 = \nabla \times \mathbf B_0`, the MHD equilibrium density and current density. 
+    :math:`\mathcal U^\alpha`, :math:`\mathcal S^\alpha`, :math:`\mathcal K^\alpha` and :math:`\mathcal Q^\alpha` are :class:`~struphy.feec.basis_projection_ops.BasisProjectionOperators` and
+    :math:`\mathbb M^{\alpha,n}` and :math:`\mathbb M^{\alpha,J}` are :class:`~struphy.feec.mass.WeightedMassOperators` being weighted with :math:`n_0` the MHD equilibrium density. 
     :math:`\alpha \in \{1, 2, v\}` denotes the :math:`\alpha`-form space where the operators correspond to.
-    Moreover, :math:`\sum_k^{N_p} \omega_k \mu_k \left\{(\hat \nabla \times \hat{\mathbf b}_0^1) \times \hat{\mathbf B}^2\right\}(\boldsymbol \eta_k)` is accumulated by by the kernel `cc_lin_mhd_5d_curlMxB <https://struphy.pages.mpcdf.de/struphy/sections/accumulators.html#struphy.pic.accumulation.accum_kernels_gc.cc_lin_mhd_5d_curlMxB>`_.
-    The solution of the above system is based on the :ref:`Schur complement <schur_solver>`.
+    Moreover, :math:`\sum_k^{N_p} \omega_k \mu_k \hat{\mathbf b}¹_0 (\boldsymbol \eta_k) \cdot \left(\frac{1}{\sqrt{g(\boldsymbol \eta_k)}} \vec \Lambda² (\boldsymbol \eta_k)\right)` is accumulated by the kernel :class:`~struphy.pic.accumulation.accum_kernels_gc.cc_lin_mhd_5d_M` and
+    the time-varying projection operator :math:`\mathcal{T}^B` is defined as
+
+    .. math::
+
+        \mathcal{T}^B_{(\mu,ijk),(\nu,mno)} := \hat \Pi¹_{(\mu,ijk)} \left[ \epsilon_{\mu \alpha \nu} \frac{\tilde{B}^2_\alpha}{\sqrt{g}} \Lambda²_{\nu,mno} \right] \,.
+
+    The solution of the above system is based on the :class:`struphy.linear_algebra.schur_solver.SchurSolver`.
 
     Parameters
     ---------- 
-    n : psydac.linalg.stencil.StencilVector
+    n : StencilVector
         FE coefficients of a discrete 3-form.
 
-    u : psydac.linalg.block.BlockVector
+    u : BlockVector
         FE coefficients of MHD velocity.
 
-    p : psydac.linalg.stencil.StencilVector
+    p : StencilVector
         FE coefficients of a discrete 3-form.
 
     **params : dict
         Solver- and/or other parameters for this splitting step.
     '''
 
     def __init__(self, n, u, p, **params):
@@ -1772,80 +1778,85 @@
         super().__init__(n, u, p)
 
         # parameters
         params_default = {'b': self.derham.Vh['2'].zeros(),
                           'particles': Particles5D,
                           'u_space': 'Hdiv',
                           'unit_b1': None,
-                          'curl_unit_b2': None,
-                          'f0': Maxwellian5DUniform(),
+                          'f0': Maxwellian5D(),
                           'type': ('pbicgstab', 'MassMatrixPreconditioner'),
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False,
                           'Ab': 1,
                           'Ah': 1}
 
         params = set_defaults(params, params_default)
 
         assert isinstance(params['particles'], Particles5D)
         self._particles = params['particles']
 
         assert params['u_space'] in {'Hcurl', 'Hdiv', 'H1vec'}
-        if params['u_space'] == 'H1vec':
+        self._u_id=  self.derham.space_to_form[params['u_space']]
+        if self._u_id == 'v':
             self._space_key_int = 0
         else:
-            self._space_key_int = int(
-                self.derham.space_to_form[params['u_space']])
+            self._space_key_int = int(self._u_id)
 
         self._f0 = params['f0']
         self._b = params['b']
-        self._unit_b1 = params['unit_b1']
-        self._curl_norm_b = params['curl_unit_b2']
-        self._curl_norm_b.update_ghost_regions()
         self._bc = self.derham.dirichlet_bc
         self._info = params['info']
         self._rank = self.derham.comm.Get_rank()
+        self._scale_vec = params['Ah'] / params['Ab']
 
-        self._coupling_const = params['Ah'] / params['Ab']
+        self._unit_b1 = params['unit_b1']
+
+        self._E1T = self.derham.extraction_ops['1'].transpose()
+        self._unit_b1 = self._E1T.dot(self._unit_b1)
 
         self._ACC = Accumulator(self.derham, self.domain,
-                                params['u_space'], 'cc_lin_mhd_5d_curlMxB', add_vector=True)
+                                'Hdiv', 'cc_lin_mhd_5d_M', add_vector=True, symmetry='symm')
 
         # define block matrix [[A B], [C I]] (without time step size dt in the diagonals)
-        id_Mn = 'M' + self.derham.space_to_form[params['u_space']] + 'n'
-        id_MJ = 'M' + self.derham.space_to_form[params['u_space']] + 'J'
+        id_Mn = 'M' + self._u_id + 'n'
+        id_MJ = 'M' + self._u_id + 'J'
 
-        if params['u_space'] == 'Hcurl':
+        if self._u_id == '1':
             id_S, id_U, id_K, id_Q = 'S1', 'U1', 'K3', 'Q1'
-        elif params['u_space'] == 'Hdiv':
+        elif self._u_id == '2':
             id_S, id_U, id_K, id_Q = 'S2', None, 'K3', 'Q2'
-        elif params['u_space'] == 'H1vec':
+        elif self._u_id == 'v':
             id_S, id_U, id_K, id_Q = 'Sv', 'Uv', 'K3', 'Qv'
 
         self._E2T = self.derham.extraction_ops['2'].transpose()
 
         _A = getattr(self.mass_ops, id_Mn)
         _S = getattr(self.basis_ops, id_S)
         _K = getattr(self.basis_ops, id_K)
 
+        # initialize projection operator TB
+        self._initialize_projection_operator_TB()
+
         if id_U is None:
             _U, _UT = IdentityOperator(u.space), IdentityOperator(u.space)
         else:
             _U = getattr(self.basis_ops, id_U)
             _UT = _U.T
 
         self._B = -1/2. * _UT @ self.derham.div.T @ self.mass_ops.M3
         self._C = 1/2. * (self.derham.div @ _S + 2 /
                           3. * _K @ self.derham.div @ _U)
 
         self._MJ = getattr(self.mass_ops, id_MJ)
         self._DQ = self.derham.div @ getattr(self.basis_ops, id_Q)
 
+        self._TC = self._TB.T @ self.derham.curl.T
+
         # preconditioner
         if params['type'][1] is None:
             pc = None
         else:
             pc_class = getattr(preconditioner, params['type'][1])
             pc = pc_class(getattr(self.mass_ops, id_Mn))
 
@@ -1860,37 +1871,40 @@
                                          verbose=params['verbose'])
 
         # allocate dummy vectors to avoid temporary array allocations
         self._u_tmp1 = u.space.zeros()
         self._u_tmp2 = u.space.zeros()
         self._p_tmp1 = p.space.zeros()
         self._n_tmp1 = n.space.zeros()
-        self._b_tmp = self._E2T.codomain.zeros()
         self._byn1 = self._B.codomain.zeros()
         self._byn2 = self._B.codomain.zeros()
+        self._tmp_acc = self._TC.codomain.zeros()
 
     def __call__(self, dt):
 
         # current variables
         nn = self.feec_vars[0]
         un = self.feec_vars[1]
         pn = self.feec_vars[2]
 
-        Eb = self._E2T.dot(self._b, out=self._b_tmp)
+        # accumulate vector
+        self._ACC.accumulate(self._particles, 
+                             self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
+                             self._scale_vec, 0.1)
 
-        # accumulate
-        self._ACC.accumulate(self._particles,
-                             Eb[0]._data, Eb[1]._data, Eb[2]._data,
-                             self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
-                             self._space_key_int, self._coupling_const)
+
+        # update time-dependent operator
+        self._b.update_ghost_regions()
+        self._update_weights_TB()
 
         # solve for new u coeffs (no tmps created here)
         byn1 = self._B.dot(pn, out=self._byn1)
         byn2 = self._MJ.dot(self._b, out=self._byn2)
-        byn2 -= self._ACC.vectors[0]
+        b2acc = self._TC.dot(self._ACC.vectors[0], out=self._tmp_acc)
+        byn2 += b2acc
         byn2 *= 1/2
         byn1 -= byn2
 
         un1, info = self._schur_solver(un, byn1, dt, out=self._u_tmp1)
 
         # new p, n, b coeffs (no tmps created here)
         _u = un.copy(out=self._u_tmp2)
@@ -1924,35 +1938,120 @@
                                   ('bicgstab', None)],
                          'tol': 1.e-8,
                          'maxiter': 3000,
                          'info': False,
                          'verbose': False}
         return dct
 
+    def _initialize_projection_operator_TB(self):
+        """Initialize BasisProjectionOperator TB with the time-varying weight.
+
+        .. math::
+
+            \mathcal{T}^B_{(\mu,ijk),(\nu,mno)} := \hat \Pi¹_{(\mu,ijk)} \left[ \epsilon_{\mu \alpha \nu} \frac{\tilde{B}²_\alpha}{\sqrt{g}} \Lambda²_{\nu,mno} \right] \,.
+
+        """
+
+        # Call the projector and the space
+        P1 = self.derham.P['1']
+        Vh = self.derham.Vh_fem[self._u_id]
+
+        # Femfield for the field evaluation
+        self._bf = self.derham.create_field("bf", "Hdiv")
+
+        # define temp callable
+        def tmp(x,y,z): return 0*x
+
+        # Initialize BasisProjectionOperator
+        self._TB = BasisProjectionOperator(P1, Vh, [[tmp, tmp, tmp]])
+
+    def _update_weights_TB(self):
+        """Updats time-dependent weights of the BasisProjectionOperator TB
+        """
+
+        # Update Femfield
+        self._bf.vector = self._b
+        self._bf.vector.update_ghost_regions()
+
+        # define callable weights
+        def bf1(x,y,z): return self._bf(x,y,z,local=True)[0]
+        def bf2(x,y,z): return self._bf(x,y,z,local=True)[1]
+        def bf3(x,y,z): return self._bf(x,y,z,local=True)[2]
+
+        from struphy.feec.utilities import RotationMatrix
+
+        rot_B = RotationMatrix(bf1, bf2, bf3)
+
+        fun = []
+
+        if self._u_id == 'v':
+            for m in range(3):
+                fun += [[]]
+                for n in range(3):
+                    fun[-1] += [lambda e1, e2, e3, m=m, n=n:
+                                rot_B(e1, e2, e3)[:, :, :, m, n]]
+
+        elif self._u_id == '1':
+            for m in range(3):
+                fun += [[]]
+                for n in range(3):
+                    fun[-1] += [lambda e1, e2, e3, m=m, n=n:
+                                (rot_B(e1, e2, e3) @ self.domain.metric_inv(e1, e2, e3, change_out_order=True, squeeze_out=False))[:, :, :, m, n]]
+
+        else:
+            for m in range(3):
+                fun += [[]]
+                for n in range(3):
+                    fun[-1] += [lambda e1, e2, e3, m=m, n=n:
+                                rot_B(e1, e2, e3)[:, :, :, m, n] / abs(self.domain.jacobian_det(e1, e2, e3, squeeze_out=False))]
+
+        # Initialize BasisProjectionOperator
+        self._TB.update_weights(fun)
+
 
 class CurrentCoupling5DDensity(Propagator):
-    """Draft
-    """
+    r'''Crank-Nicolson scheme for the CC-Density step in :class:`~struphy.models.hybrid.LinearMHDDriftkineticCC`,
+
+    Equation:
+
+    .. math::
+
+        \int n_0 \frac{\partial \tilde{\mathbf U}}{\partial t} \cdot \tilde{\mathbf V} \, \textnormal{d} \mathbf{x} = \frac{A_\textnormal{h}}{A_b} \frac{1}{\epsilon} \iiint f^\text{vol} \left(1 - \frac{B_\parallel}{B^*_\parallel}\right) \tilde{\mathbf U} \times \mathbf B_f \cdot \tilde{\mathbf V} \, \textnormal{d} \mathbf{x} \textnormal{d} v_\parallel \textnormal{d} \mu \quad \forall \ \tilde{\mathbf V} \,,
+
+    FE coefficients update:
+
+    .. math::
+
+        \mathbf u^{n+1} - \mathbf u^n = -\frac{A_\textnormal{h}}{A_b} \frac{1}{\epsilon} \mathbb{L}²{\mathbb{B}}^\times_f \mathbb{N}(1/g) \mathbb{W} \mathbb{N}\left(1- \frac{\hat B^0_\parallel}{\hat B^{*0} _\parallel}\right) (\mathbb{L}²)^\top \frac{\Delta t}{2} \cdot (\mathbf u^{n+1} + \mathbf u^n) \,.
+
+    For the detail explanation of the notations, see `2022_DriftKineticCurrentCoupling <https://gitlab.mpcdf.mpg.de/struphy/struphy-projects/-/blob/main/running-projects/2022_DriftKineticCurrentCoupling.md?ref_type=heads>`_.
+
+    Parameters
+    ---------- 
+    u : BlockVector
+        FE coefficients of MHD velocity.
+
+    **params : dict
+        Solver- and/or other parameters for this splitting step.
+    '''
 
     def __init__(self, u, **params):
 
         from struphy.pic.particles import Particles5D
 
         super().__init__(u)
 
         # parameters
         params_default = {'particles': None,
                           'u_space': 'Hdiv',
                           'b_eq': None,
                           'b_tilde': None,
                           'unit_b1': None,
-                          'abs_b': None,
-                          'gradB1': None,
                           'curl_unit_b2': None,
-                          'f0': Maxwellian5DUniform(),
+                          'f0': Maxwellian5D(),
                           'type': 'pbicgstab',
                           'pc': 'MassMatrixPreconditioner',
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False,
                           'Ab': 1,
@@ -1971,28 +2070,26 @@
             self._space_key_int = int(
                 self.derham.space_to_form[params['u_space']])
 
         self._particles = params['particles']
         self._b_eq = params['b_eq']
         self._b_tilde = params['b_tilde']
         self._unit_b1 = params['unit_b1']
-        self._abs_b = params['abs_b']
-        self._grad_abs_b = params['gradB1']
         self._curl_norm_b = params['curl_unit_b2']
         self._epsilon = params['epsilon']
         self._f0 = params['f0']
 
         self._type = params['type'][0]
         self._tol = params['tol']
         self._maxiter = params['maxiter']
         self._info = params['info']
         self._verbose = params['verbose']
         self._rank = self.derham.comm.Get_rank()
 
-        self._coupling_const = params['Ah'] / params['Ab']
+        self._scale_mat = params['Ah'] / params['Ab']
         self._accumulator = Accumulator(
             self.derham, self.domain, params['u_space'], 'cc_lin_mhd_5d_D', add_vector=False, symmetry='asym')
 
         u_id = self.derham.space_to_form[params['u_space']]
         self._M = getattr(self.mass_ops, 'M' + u_id + 'n')
 
         self._E0T = self.derham.extraction_ops['0'].transpose()
@@ -2018,51 +2115,39 @@
                                tol=self._tol,
                                maxiter=self._maxiter,
                                verbose=self._verbose)
 
         # temporary vectors to avoid memory allocation
         self._b_full1 = self._b_eq.space.zeros()
         self._b_full2 = self._E2T.codomain.zeros()
-        self._tmp1 = self._abs_b.space.zeros()
-        self._tmp2 = self._E0T.codomain.zeros()
         self._rhs_v = u.space.zeros()
         self._u_new = u.space.zeros()
 
     @property
     def variables(self):
         return [self._u]
 
     def __call__(self, dt):
-        """TODO
-        """
-
         # pointer to old coefficients
         un = self.feec_vars[0]
 
         # sum up total magnetic field b_full1 = b_eq + b_tilde (in-place)
         b_full = self._b_eq.copy(out=self._b_full1)
 
         if self._b_tilde is not None:
             b_full += self._b_tilde
 
-        PBb = self._PB.dot(self._b_tilde, out=self._tmp1)
-        PBb += self._abs_b
-
         Eb_full = self._E2T.dot(b_full, out=self._b_full2)
         Eb_full.update_ghost_regions()
 
-        EPBb = self._E0T.dot(PBb, out=self._tmp2)
-        EPBb.update_ghost_regions()
-
         self._accumulator.accumulate(self._particles, self._epsilon,
-                                     EPBb._data,
                                      Eb_full[0]._data, Eb_full[1]._data, Eb_full[2]._data,
                                      self._unit_b1[0]._data, self._unit_b1[1]._data, self._unit_b1[2]._data,
                                      self._curl_norm_b[0]._data, self._curl_norm_b[1]._data, self._curl_norm_b[2]._data,
-                                     self._space_key_int, self._coupling_const)
+                                     self._space_key_int, self._scale_mat, 0.1)
 
         # define system (M - dt/2 * A)*u^(n + 1) = (M + dt/2 * A)*u^n
         lhs = self._M - dt/2 * self._accumulator.operators[0]
         rhs = self._M + dt/2 * self._accumulator.operators[0]
 
         # solve linear system for updated u coefficients (in-place)
         rhs = rhs.dot(un, out=self._rhs_v)
@@ -2090,171 +2175,212 @@
                          'info': False,
                          'verbose': False}
         return dct
 
 
 class ImplicitDiffusion(Propagator):
     r"""
-    Weak, implicit discretization of the diffusion (or heat) equation (can be used as a Poisson solver too),
+    Weak, implicit discretization of the diffusion (or heat) equation (can be used as a Poisson solver too).
+
+    Find :math:`\phi \in H^1` such that
 
     .. math::
 
-        \frac{\partial \phi}{\partial t} - \Delta \phi = 0\,,
+        \int_\Omega \psi\, n_0(\mathbf x)\frac{\partial \phi}{\partial t}\,\textrm d \mathbf x + \int_\Omega \nabla \psi^\top D_0(\mathbf x) \nabla \phi \,\textrm d \mathbf x = \int_\Omega \psi\, \rho(\mathbf x)\,\textrm d \mathbf x \qquad \forall \ \psi \in H^1\,,
 
-    which is discretized as
+    where :math:`n_0, \rho:\Omega \to \mathbb R` are real-valued functions and 
+    :math:`D_0:\Omega \to \mathbb R^{3\times 3}`
+    is a positive diffusion matrix. 
+    Boundary terms from integration by parts are assumed to vanish.
+    The equation is discretized as
 
     .. math::
 
-        (\sigma \mathbb M_0 + \Delta t\,\mathbb G^\top \mathbb M_1 \mathbb G)\, \phi^{n+1} = \int_{(0,1)^3} \Lambda^0 \phi^n\, \textnormal d\eta\,,
+        \left( \frac{\sigma_1}{\Delta t} \mathbb M^0_{n_0} + \mathbb G^\top \mathbb M^1_{D_0} \mathbb G \right)\, \boldsymbol\phi^{n+1} = \frac{\sigma_2}{\Delta t} ( \Lambda^0, n_0 \phi^n )_{L^2} + \frac{\sigma_3}{\Delta t}(\Lambda^0, \rho  )_{L^2}\,,
 
-    where :math:`\Lambda^0 \in H^1` are the FEEC basis functions and :math:`\sigma \in \mathbb R` is a parameter.
-    The solution is :math:`\phi^{n+1}\,\in H^1` and the right-hand side is :math:`\phi^n\,\in H^1`.
-    For the choice :math:`\sigma=0` and :math:`\Delta t = 1` this is a Poisson solver,
-    where :math:`\phi^n` corresponds to the charge density.
-    Boundary terms are assumed to vanish.
+    where :math:`M^0_{n_0}` and :math:`M^1_{D_0}` are :class:`WeightedMassOperators <struphy.feec.mass.WeightedMassOperators>`
+    and :math:`\sigma_1, \sigma_2, \sigma_3 \in \mathbb R` are artificial parameters that can be tuned to
+    change the model (see Notes).
+
+    Notes
+    -----
+
+    * :math:`\sigma_1=\sigma_2=0` and :math:`\sigma_3 = 1`: **Poisson solver** with a given charge density :math:`\rho/\Delta t`. 
+    * :math:`\sigma_2=0` and :math:`\sigma_1 = \sigma_3 = \Delta t` : Poisson with **adiabatic electrons**.
+    * :math:`\sigma_1=\sigma_2=1` and :math:`\sigma_3 = 0`: **Implicit heat equation**. 
 
     Parameters
     ----------
-    phi : psydac.linalg.stencil.StencilVector
-        FE coefficients of a discrete 0-form, the solution.
+    phi : StencilVector
+        FE coefficients of the solution as a discrete 0-form.
 
     sigma : float
         Stabilization parameter: :math:`\sigma=1` for the heat equation and :math:`\sigma=0` for the Poisson equation.
 
-    phi_n : psydac.linalg.stencil.StencilVector
-        FE coefficients of a 0-form (optional, can be set with a setter later).
+    rho : StencilVector
+        Right-hand side FE coefficients of a 0-form (optional, can be set with a setter later).
 
-    x0 : psydac.linalg.stencil.StencilVector
+    x0 : StencilVector
         Initial guess for the iterative solver (optional, can be set with a setter later).
 
     **params : dict
         Parameters for the iteravtive solver.
     """
 
-    def __init__(self, phi, sigma=1., A_mat='M1', phi_n=None, x0=None, **params):
+    def __init__(self, phi: StencilVector,
+                 sigma_1=0., sigma_2=1., sigma_3=0.,
+                 A1_mat='M0', A2_mat='M1',
+                 rho=None,
+                 x0=None,
+                 **params):
+
+        assert phi.space == self.derham.Vh['0']
 
         super().__init__(phi)
 
-        # parameters
+        # model parameters
+        self._sigma_1 = sigma_1
+        self._sigma_2 = sigma_2
+        self._sigma_3 = sigma_3
+
+        # solver parameters
         params_default = {'type': ('pcg', 'MassMatrixPreconditioner'),
                           'tol': 1e-8,
                           'maxiter': 3000,
                           'info': False,
                           'verbose': False}
 
         params = set_defaults(params, params_default)
 
-        # allocate memory for solution and rhs
-        self._phi_n = StencilVector(self.derham.Vh['0'])
-
         # check the rhs
-        if phi_n is not None:
+        if rho is not None:
+            assert rho.space == phi.space
+            self._rho = rho
+        else:
+            self._rho = phi.space.zeros()
 
-            assert type(phi_n) == type(self._phi_n)
-            self._phi_n[:] = phi_n[:]
-            self._phi_n.update_ghost_regions()
-
-            # check solvability condition
-            if np.abs(sigma) < 1e-14:
-                sigma = 1e-14
-                self.check_rhs(phi_n)
+        # check solvability condition
+        if np.abs(self._sigma_1) < 1e-14:
+            self._sigma_1 = 1e-14
+            #self.check_rhs(self._rho)
 
         # initial guess and solver params
         self._x0 = x0
         self._params = params
-        A_mat = getattr(self.mass_ops, A_mat)
-
-        # Set lhs matrices
-    
-        self._A1 = sigma * self.mass_ops.M0
-        self._A2 = self.derham.grad.T @ A_mat @ self.derham.grad
+        A1_mat = getattr(self.mass_ops, A1_mat)
+        A2_mat = getattr(self.mass_ops, A2_mat)
+        # Set lhs matrices (without dt)
+        self._A1 = A1_mat
+        self._A2 = self.derham.grad.T @ A2_mat @ self.derham.grad
 
         # preconditioner and solver for Ax=b
         if params['type'][1] is None:
             pc = None
         else:
             pc_class = getattr(preconditioner, params['type'][1])
-            pc = pc_class(self.mass_ops.M0)
+            pc = pc_class(A1_mat)
 
-        # solver for Ax=b with A=const.
+        # solver just with A_2, but will be set during call with dt
         self.solver = inverse(self._A2,
                               params['type'][0],
                               pc=pc,
                               x0=self._x0,
                               tol=self._params['tol'],
                               maxiter=self._params['maxiter'],
                               verbose=self._params['verbose'])
 
+        # allocate memory for solution
         self._tmp = phi.space.zeros()
+        self._rhs = phi.space.zeros()
+        self._rhs2 = phi.space.zeros()
 
-    def check_rhs(self, phi_n):
+    def check_rhs(self, rho):
         '''Checks space of rhs and, for periodic boundary conditions and sigma=0,
-        checks whether the integral over phi_n is zero.
+        checks whether the integral over rho is zero.
 
         Parameters
         ----------
-        phi_n : psydac.linalg.stencil.StencilVector
+        rho : StencilVector
             FE coefficients of a 0-form.'''
 
-        assert type(phi_n) == type(self._phi_n)
+        assert type(rho) == type(self._rho)
 
-        if np.all(phi_n.space.periods):
+        if np.all(rho.space.periods):
             solvability = np.zeros(1)
             self.derham.comm.Allreduce(
-                np.sum(phi_n.toarray()), solvability, op=MPI.SUM)
+                np.sum(rho.toarray()), solvability, op=MPI.SUM)
             assert np.abs(
                 solvability[0]) <= 1e-10, f'Solvability condition not met: {solvability[0]}'
 
     @property
-    def phi_n(self):
+    def rho(self):
         """
         psydac.linalg.stencil.StencilVector or struphy.polar.basic.PolarVector.
         """
-        return self._phi_n
+        return self._rho
 
-    @phi_n.setter
-    def phi_n(self, value):
+    @rho.setter
+    def rho(self, value):
         """ In-place setter for StencilVector/PolarVector.
         """
         self.check_rhs(value)
-        self._phi_n[:] = value[:]
+        self._rho[:] = value[:]
 
     @property
     def x0(self):
         """
         psydac.linalg.stencil.StencilVector or struphy.polar.basic.PolarVector. First guess of the iterative solver.
         """
         return self._x0
 
     @x0.setter
     def x0(self, value):
         """ In-place setter for StencilVector/PolarVector. First guess of the iterative solver.
         """
-        assert type(value) == type(self._phi_n)
+        assert type(value) == type(self._rho)
         assert value.space.symbolic_space == 'H1', f'Right-hand side must be in H1, but is in {value.space.symbolic_space}.'
 
         if self._x0 is None:
             self._x0 = value
         else:
             self._x0[:] = value[:]
 
     def __call__(self, dt):
 
-        self.solver.linop = self._A1 + dt * self._A2
-        out = self.solver.solve(self._phi_n, out=self._tmp)
+        # current variables
+        phin = self.feec_vars[0]
+
+        # compute rhs
+        rhs = self._A1.dot(phin, out=self._rhs)
+        rhs *= self._sigma_2 / dt
+
+        self._rhs2 = self._sigma_3 / dt * self._rho
+
+        rhs += self._rhs2
+
+        # compute lhs
+        self.solver.linop = self._sigma_1/dt * self._A1 + self._A2
+
+        # solve
+        out = self.solver.solve(rhs, out=self._tmp)
         info = self.solver._info
 
         if self._params['info']:
             print(info)
 
         self.feec_vars_update(out)
 
     @classmethod
     def options(cls):
         dct = {}
+        dct['model'] = {'sigma_1': 0.,
+                        'sigma_2': 0.,
+                        'sigma_3': 1.,
+                        'A1_mat': ['M0', 'M0ad'],
+                        'A2_mat': ['M1', 'M1perp']}
         dct['solver'] = {'type': [('pcg', 'MassMatrixPreconditioner'),
                                   ('cg', None)],
                          'tol': 1.e-8,
                          'maxiter': 3000,
                          'info': False,
                          'verbose': False}
         return dct
@@ -2467,134 +2593,164 @@
 
 
 class VariationalMomentumAdvection(Propagator):
     r'''Crank-Nicolson step for self-advection term in fluids model,
 
     .. math::
 
-        \int_{\Omega} \partial_t ( \rho \mathbf u ) \cdot \mathbf v \, \textnormal d^3 \mathbf x - \int_{\Omega}( \rho \mathbf u ) \cdot [\mathbf u, \mathbf v] \, \textnormal d^3 \mathbf x = 0 ~ ,
+        \int_{\hat{\Omega}} \partial_t ( \hat{\rho}^3  \hat{\mathbf{u}}) \cdot G \hat{\mathbf{v}} \,\textrm d \boldsymbol \eta - 
+        \int_{\hat{\Omega}}( \hat{\rho}^3 \hat{\mathbf{u}}) \cdot G [\hat{\mathbf{u}}, \hat{\mathbf{v}}] \, \textrm d \boldsymbol \eta = 0 ~ ,
 
     which is discretized as
 
     .. math::
 
-        \mathbb M_v[\rho^n] \frac{\mathbf u^{n+1}- \mathbf u^n}{\Delta t} - (\sum_i (\hat{\Pi}^{1->0}[\mathbf u^{n+1/2}] \mathbb G P_i - \hat{\Pi}^{X->0}[\nabla\mathbf u^{n+1/2}_i])^\top P_i) \mathbb M_v[\rho^n] \mathbf u^{n+1/2} = 0 ~ .
+        \mathbb M^v[\hat{\rho}_h^n] \frac{\mathbf u^{n+1}- \mathbf u^n}{\Delta t} - (\sum_{\mu} (\hat{\Pi}^{0}[\hat{\mathbf u}_h^{n+1/2} \cdot \vec{\boldsymbol \Lambda}^1] \mathbb G P_{\mu} - \hat{\Pi}^0[\hat{\mathbf A}^1_{\mu,h} \cdot \vec{\boldsymbol \Lambda}^v])^\top P_i) \mathbb M^v[\hat{\rho}_h^n] \mathbf u^{n} = 0 ~ .
+
+    where :math:`P_\mu` stand for the :class:`~struphy.feec.basis_projection_ops.CoordinateProjector` and the weights
+    in the the two :class:`~struphy.feec.basis_projection_ops.BasisProjectionOperator` and the :class:`~struphy.feec.mass.WeightedMassOperator` are given by
 
+    .. math::
+
+        \hat{\mathbf{u}}_h^{n+1/2} = (\mathbf{u}^{n+1/2})^\top \vec{\boldsymbol \Lambda}^v \in (V_h^0)^3 \,, \qquad \hat{\mathbf A}^1_{\mu,h} = \nabla P_\mu((\mathbf u^{n+1/2})^\top \vec{\boldsymbol \Lambda}^v)] \in V_h^1\,, \qquad \hat{\rho}_h^{n} = (\rho^{n})^\top \vec{\boldsymbol \Lambda}^3 \in V_h^3.
     Parameters
     ----------
     rho : psydac.linalg.stencil.Vector
         FE coefficients of a discrete field, density of the solution.
 
     u : psydac.linalg.stencil.BlockVector
         FE coefficients of a discrete vector field,velocity of the solution.
 
     **params : dict
-        Parameters for the iterative solver.
+        Parameters for the iterative solvers.
 
     '''
 
     def __init__(self, u, **params):
 
         super().__init__(u)
 
         # parameters
-        params_default = {'tol': 1e-8,
-                          'maxiter': 100,
-                          'type_linear_solver': ('pcg', 'MassMatrixPreconditioner'),
+        params_default = {'linear_tol': 1e-12,
+                          'non_linear_tol': 1e-8,
+                          'linear_maxiter': 500,
+                          'non_linear_maxiter': 100,
+                          'type_linear_solver': ('pcg', 'MassMatrixDiagonalPreconditioner'),
+                          'non_linear_solver': 'Newton',
                           'info': False,
                           'verbose': False,
-                          'mass_ops' : None}
+                          'mass_ops': None}
 
         assert 'mass_ops' in params
 
         params = set_defaults(params, params_default)
 
         self._params = params
 
         self.WMM = params['mass_ops']
 
-        # Femfields for the projectors
-        self.uf = self.derham.create_field("uf", "H1vec")
-        self.gu1f = self.derham.create_field("gu1f", "Hcurl")  # grad(u[0])
-        self.gu2f = self.derham.create_field("gu2f", "Hcurl")  # grad(u[1])
-        self.gu3f = self.derham.create_field("gu3f", "Hcurl")  # grad(u[2])
-
-        self._initialize_projectors_and_mass()
-
-        # gradient of the component of the vector field
-        grad = self.derham.grad
-        self.gp1 = grad @ self.Pcoord1
-        self.gp2 = grad @ self.Pcoord2
-        self.gp3 = grad @ self.Pcoord3
-
-        # v-> int(Pi(grad v_i . u)m_i)
-        m1ugv1 = self.gp1.T @ self.PiuT @ self.Pcoord1
-        m2ugv2 = self.gp2.T @ self.PiuT @ self.Pcoord2
-        m3ugv3 = self.gp3.T @ self.PiuT @ self.Pcoord3
-
-        # v-> int(Pi(grad u_i . v)m_i)
-        m1vgu1 = self.PiguT_1 @ self.Pcoord1
-        m2vgu2 = self.PiguT_2 @ self.Pcoord2
-        m3vgu3 = self.PiguT_3 @ self.Pcoord3
-
-        # v-> int(Pi([u,v]) . m)
-        self.mbrackuv = (m1vgu1 + m2vgu2 + m3vgu3 - m1ugv1 - m2ugv2 - m3ugv3)
+        self._initialize_mass()
 
         # bunch of temporaries to avoid allocating in the loop
         self._tmp_un1 = u.space.zeros()
         self._tmp_un12 = u.space.zeros()
         self._tmp_diff = u.space.zeros()
+        self._tmp__pc_diff = u.space.zeros()
+        self._tmp_update = u.space.zeros()
         self._tmp_weak_diff = u.space.zeros()
         self._tmp_mn = u.space.zeros()
         self._tmp_mn1 = u.space.zeros()
-        self._tmp_mn12 = u.space.zeros()
         self._tmp_advection = u.space.zeros()
-        self.gp1u = self.gp1.dot(u)
-        self.gp2u = self.gp2.dot(u)
-        self.gp3u = self.gp3.dot(u)
+
+        self.brack = BracketOperator(self.derham, self._tmp_mn)
+        self._dt2_brack = 2.*self.brack
+        self.derivative = self.WMM + self._dt2_brack
+        self.inv_derivative = inverse(self.pc@self.derivative,
+                                 'gmres',
+                                 tol=self._params['linear_tol'],
+                                 maxiter=self._params['linear_maxiter'],
+                                 verbose=self._params['verbose'],
+                                 recycle=True)
 
     def __call__(self, dt):
+        if self._params['non_linear_solver'] == 'Newton':
+            self.__call_newton(dt)
+        elif self._params['non_linear_solver'] == 'Picard':
+            self.__call_picard(dt)
+
+    def __call_newton(self, dt):
+
+        # Initialize variable for Newton iteration
+        un = self.feec_vars[0]
+        mn = self._Mrho.dot(un, out=self._tmp_mn)
+        mn1 = mn.copy(out=self._tmp_mn1)
+        un1 = un.copy(out=self._tmp_un1)
+        tol = self._params['non_linear_tol']
+        err = tol+1
+        self.pc.update_mass_operator(self._Mrho)
+        # Jacobian matrix for Newton solve
+        self._dt2_brack._scalar = dt/2
+
+        for it in range(self._params['non_linear_maxiter']):
+
+            un12 = un.copy(out=self._tmp_un12)
+            un12 += un1
+            un12 *= 0.5
+
+            # Compute the advection term
+            advection = self.brack.dot(un12, out=self._tmp_advection)
+            advection *= dt
+
+            # Difference with the previous approximation :
+            # diff = m^{n+1,r}-m^{n+1,r+1} = m^{n+1,r}-m^{n}+advection
+            diff = mn1.copy(out=self._tmp_diff)
+            diff -= mn
+            diff += advection
+
+            # Get error and stop if small enough
+            err = self._get_error_newton(diff)
+
+            if err < tol**2:
+                break
+
+            # Newton step
+            pc_diff = self.pc.dot(diff, out=self._tmp__pc_diff)
+            update = self.inv_derivative.dot(pc_diff, out=self._tmp_update)
+            un1 -= update
+            mn1 = self._Mrho.dot(un1, out=self._tmp_mn1)
+
+        if it == self._params['non_linear_maxiter']-1:
+            print(
+                f'!!!WARNING: Maximum iteration in VariationalMomentumAdvection reached - not converged \n {err = } \n {tol**2 = }')
+
+        self.feec_vars_update(un1)
+
+    def __call_picard(self, dt):
 
         # Initialize variable for Picard iteration
         un = self.feec_vars[0]
         mn = self._Mrho.dot(un, out=self._tmp_mn)
         mn1 = mn.copy(out=self._tmp_mn1)
         un1 = un.copy(out=self._tmp_un1)
-        tol = self._params['tol']
+        tol = self._params['non_linear_tol']
         err = tol+1
-        for it in range(self._params['maxiter']):
+        # Jacobian matrix for Newton solve
+        
+        for it in range(self._params['non_linear_maxiter']):
 
             # Picard iteration
             if err < tol**2:
                 break
             # half time step approximation
-            mn12 = mn.copy(out=self._tmp_mn12)
-            mn12 += mn1
-            mn12 *= 0.5
-
             un12 = un.copy(out=self._tmp_un12)
             un12 += un1
             un12 *= 0.5
 
-            # gradients of un12 components
-            grad_1_u = self.gp1.dot(un12, out=self.gp1u)
-            grad_2_u = self.gp2.dot(un12, out=self.gp2u)
-            grad_3_u = self.gp3.dot(un12, out=self.gp3u)
-
-            # To avoid tmp we need to update the fields we created.
-            self.gu1f.vector = grad_1_u
-            self.gu2f.vector = grad_2_u
-            self.gu3f.vector = grad_3_u
-            self.uf.vector = un12
-
-            # Update the BasisProjectionOperators
-            self._update_all_weights()
-
             # Compute the advection term
-            advection = self.mbrackuv.dot(mn12, out=self._tmp_advection)
+            advection = self.brack.dot(un12, out=self._tmp_advection)
             advection *= dt
 
             # Difference with the previous approximation :
             # diff = m^{n+1,r}-m^{n+1,r+1} = m^{n+1,r}-m^{n}+advection
             diff = mn1.copy(out=self._tmp_diff)
             diff -= mn
             diff += advection
@@ -2607,142 +2763,96 @@
             # Update : m^{n+1,r+1} = m^n-advection
             mn1 = mn.copy(out=self._tmp_mn1)
             mn1 -= advection
 
             # Inverse the mass matrix to get the velocity
             un1 = self._Mrhoinv.dot(mn1, out=self._tmp_un1)
 
-        if it == self._params['maxiter']-1:
-            raise(ValueError, 'maximum iteration in VariationalMomentumAdvection')
+        if it == self._params['non_linear_maxiter']-1:
+            print(f'!!!WARNING: Maximum iteration in VariationalMomentumAdvection reached - not converged \n {err = } \n {tol**2 = }')
 
         self.feec_vars_update(un1)
 
     @classmethod
     def options(cls):
         dct = {}
-        dct['solver'] = {'tol': 1e-8,
-                         'maxiter': 3000,
-                         'type_linear_solver': [('pcg', 'MassMatrixPreconditioner'),
+        dct['solver'] = {'linear_tol': 1e-12,
+                         'non_linear_tol': 1e-8,
+                         'linear_maxiter': 500,
+                         'non_linear_maxiter': 100,
+                         'type_linear_solver': [('pcg', 'MassMatrixDiagonalPreconditioner'),
                                                 ('cg', None)],
+                         'non_linear_solver': ['Newton', 'Picard'],
                          'info': False,
                          'verbose': False}
         return dct
 
-    def _initialize_projectors_and_mass(self):
-        """Initialization of all the `BasisProjectionOperator` and `CoordinateProjector` needed to compute the bracket term"""
-
-        # Get the projector and the spaces
-        P0 = self.derham.P['0']
-
-        Xh = self.derham.Vh_fem['v']
-        V0h = self.derham.Vh_fem['0']
-        V1h = self.derham.Vh_fem['1']
-
-        # Initialize the CoordinateProjectors
-        self.Pcoord1 = CoordinateProjector(0, Xh, V0h)
-        self.Pcoord2 = CoordinateProjector(1, Xh, V0h)
-        self.Pcoord3 = CoordinateProjector(2, Xh, V0h)
-
-        # Initialize the BasisProjectionOperators
-        self.PiuT = BasisProjectionOperator(
-            P0, V1h, [[None, None, None]], transposed=True, use_cache=True)
-
-        self.PiguT_1 = BasisProjectionOperator(
-            P0,  Xh, [[None, None, None]], transposed=True, use_cache=True)
-        self.PiguT_2 = BasisProjectionOperator(
-            P0,  Xh, [[None, None, None]], transposed=True, use_cache=True)
-        self.PiguT_3 = BasisProjectionOperator(
-            P0,  Xh, [[None, None, None]], transposed=True, use_cache=True)
-
-        # Store the interpolation grid for later use in _update_all_weights
-        interpolation_grid = [pts.flatten()
-                                    for pts in self.derham.proj_grid_pts['0']]
-
-        self.interpolation_grid_spans, self.interpolation_grid_bn, self.interpolation_grid_bd = self.derham.prepare_eval_tp_fixed(interpolation_grid)
-
-        self.interpolation_grid_gradient = [[self.interpolation_grid_bd[0], self.interpolation_grid_bn[1], self.interpolation_grid_bn[2]],
-                                            [self.interpolation_grid_bn[0], self.interpolation_grid_bd[1], self.interpolation_grid_bn[2]],
-                                            [self.interpolation_grid_bn[0], self.interpolation_grid_bn[1], self.interpolation_grid_bd[2]]]
-
-        # Create tmps for later use in evaluating on the grid
-        grid_shape = tuple([len(loc_grid)
-                           for loc_grid in interpolation_grid])
-        self._uf_values = [np.zeros(grid_shape, dtype=float) for i in range(3)]
-        self._guf1_values = [np.zeros(grid_shape, dtype=float)
-                             for i in range(3)]
-        self._guf2_values = [np.zeros(grid_shape, dtype=float)
-                             for i in range(3)]
-        self._guf3_values = [np.zeros(grid_shape, dtype=float)
-                             for i in range(3)]
-
+    def _initialize_mass(self):
+        """Initialization of the mass matrix solver"""
         # weighted mass matrix to go from m to u
         self._Mrho = self.WMM
 
         # Inverse weighted mass matrix
         if self._params['type_linear_solver'][1] is None:
-            pc = None
+            self.pc = None
         else:
             pc_class = getattr(
                 preconditioner, self._params['type_linear_solver'][1])
-            pc = pc_class(self.mass_ops.Mv)
+            self.pc = pc_class(self.mass_ops.Mv)
 
         self._Mrhoinv = inverse(self._Mrho,
                                 self._params['type_linear_solver'][0],
-                                pc=pc,
-                                tol=1e-30,
-                                maxiter=self._params['maxiter'],
-                                verbose=self._params['verbose'])
-
-    def _update_all_weights(self,):
-        """Update the weights of all the `BasisProjectionOperators` appearing in the bracket term"""
-
-        uf_values = self.uf.eval_tp_fixed_loc(
-            self.interpolation_grid_spans, [self.interpolation_grid_bn]*3, out=self._uf_values)
-
-        guf1_values = self.gu1f.eval_tp_fixed_loc(self.interpolation_grid_spans,
-                                                  self.interpolation_grid_gradient, out=self._guf1_values)
-        
-        guf2_values = self.gu2f.eval_tp_fixed_loc(self.interpolation_grid_spans,
-                                                  self.interpolation_grid_gradient, out=self._guf2_values)
-        
-        guf3_values = self.gu3f.eval_tp_fixed_loc(self.interpolation_grid_spans,
-                                                  self.interpolation_grid_gradient, out=self._guf3_values)
-        
-        self.PiuT.update_weights([[uf_values[0], uf_values[1], uf_values[2]]])
+                                pc=self.pc,
+                                tol=self._params['linear_tol'],
+                                maxiter=self._params['linear_maxiter'],
+                                verbose=self._params['verbose'],
+                                recycle = True)
         
-        self.PiguT_1.update_weights(
-            [[guf1_values[0], guf1_values[1], guf1_values[2]]])
-        self.PiguT_2.update_weights(
-            [[guf2_values[0], guf2_values[1], guf2_values[2]]])
-        self.PiguT_3.update_weights(
-            [[guf3_values[0], guf3_values[1], guf3_values[2]]])
+    def _get_error_newton(self, mn_diff):
+        inv_Mv = inverse(self.mass_ops.Mv, 'cg', tol=1e-16, maxiter = 1000)
+        weak_un_diff = inv_Mv.dot(
+            mn_diff, out=self._tmp_weak_diff)
+        err_u = weak_un_diff.dot(mn_diff)
+        return err_u
 
 
 class VariationalDensityEvolve(Propagator):
     r'''Crank-Nicolson step for the evolution of the density terms in fluids models,
 
     .. math::
 
-        \int_{\Omega} \partial_t \rho \mathbf u \cdot \mathbf v \, \textnormal d^3 \mathbf x 
-        + \int_{\Omega} \big( \frac{| \mathbf u |^2}{2} - \frac{\partial \rho e}{\partial \rho} \big) \nabla \cdot (\rho \mathbf v) \, \textnormal d^3 \mathbf x = 0 ~ ,
+        \begin{align}
+        &\int_{\hat{\Omega}} \partial_t ( \hat{\rho}^3  \hat{\mathbf{u}}) \cdot G \hat{\mathbf{v}} \, \textrm d \boldsymbol \eta  
+        + \int_{\hat{\Omega}} \big( \frac{| DF \hat{\mathbf{u}} |^2}{2} - \frac{\partial \hat{\rho}^3 \hat{e}}{\partial \hat{\rho}^3} \big) \nabla \cdot (\hat{\rho}^3 \hat{\mathbf{v}}) \, \textrm d \boldsymbol \eta = 0 ~ ,
+        \\[2mm]
+        &\partial_t \hat{\rho}^3 + \nabla \cdot ( \hat{\rho}^3 \hat{\mathbf{u}} ) = 0 ~ ,
+        \end{align}
 
-        \partial_t \rho + \nabla \cdot ( \rho \mathbf u ) = 0 ~ ,
+    where :math:`\hat{e}` depends on the chosen model. It is discretized as
 
-    where $e$ depends on the chosen model.
+    .. math::
 
-    It is discretized as
+        \begin{align}
+        &\frac{\mathbb M^v[\hat{\rho}_h^{n+1}] \mathbf u^{n+1}- \mathbb M^v[\hat{\rho}_h^n] \mathbf u^n}{\Delta t} 
+        + (\mathbb D \hat{\Pi}^{2}[\hat{\rho}_h^{n+1/2} \vec{\boldsymbol \Lambda}^v])^\top \hat{l}^3\Big( \big(\frac{DF \hat{\mathbf{u}}_h^{n+1} \cdot DF \hat{\mathbf{u}}_h^{n}}{2} 
+        - \frac{\hat{\rho}_h^{n+1}\hat{e}(\hat{\rho}_h^{n+1})-\hat{\rho}_h^{n}\hat{e}(\hat{\rho}_h^{n})}{\hat{\rho}_h^{n+1}-\hat{\rho}_h^n} \big)\Big) = 0 ~ ,
+        \\[2mm]
+        &\frac{\boldsymbol \rho^{n+1}- \boldsymbol \rho^n}{\Delta t} + \mathbb D \hat{\Pi}^{2}[\hat{\rho}_h^{n+1/2} \vec{\boldsymbol \Lambda}^v] \mathbf u^{n+1/2} = 0 ~ ,
+        \end{align}
+
+    where :math:`\hat{l}^3(f)` denotes the vector representing the linear form :math:`v_h \mapsto \int_{\hat{\Omega}} f(\boldsymbol \eta) v_h(\boldsymbol \eta) d \boldsymbol \eta`, that is the vector with components
 
     .. math::
+        \hat{l}^3(f)_{ijk}=\int_{\hat{\Omega}} f \Lambda^3_{ijk} \textrm d \boldsymbol \eta
 
-        \frac{\mathbb M_v[\rho^{n+1}] \mathbf u^{n+1}- \mathbb M_v[\rho^{n}] \mathbf u^n}{\Delta t} + 
-        (\mathbb D \hat{\Pi}^{X->2}[\rho^{n+1/2}])^\top l^3\big( \frac{u^{n+1} \cdot u^{n}}{2} - \frac{\rho^{n+1}e(\rho^{n+1})-\rho^{n}e(\rho^{n})}{\rho^{n+1}-\rho^n} \big) = 0 ~ ,
+    and the weights in the the :class:`~struphy.feec.basis_projection_ops.BasisProjectionOperator` and the :class:`~struphy.feec.mass.WeightedMassOperator` are given by
 
-        \frac{\mathbf \rho^{n+1}- \mathbf \rho^n}{\Delta t} + \mathbb D \hat{\Pi}^{X->2}[\rho^{n+1/2}] \mathbf u^{n+1/2} = 0 ~ ,
+    .. math::
 
-    where :math:`l^3(f)` denotes the vector representing the linear form :math:`v \mapsto \int_{\Omega} f(\mathbf x) v(\mathbf x) d \mathbf x` .
+        \hat{\mathbf{u}}_h^{k} = (\mathbf{u}^{k})^\top \vec{\boldsymbol \Lambda}^v \in (V_h^0)^3 \, \text{for k in} \{n, n+1/2, n+1\}, \qquad \hat{\rho}_h^{k} = (\rho^{k})^\top \vec{\boldsymbol \Lambda}^3 \in V_h^3 \, \text{for k in} \{n, n+1/2, n+1\} .
 
     Parameters
     ----------
     rho : psydac.linalg.stencil.Vector
         FE coefficients of a discrete field, density of the solution.
 
     u : psydac.linalg.stencil.BlockVector
@@ -2754,23 +2864,26 @@
     '''
 
     def __init__(self, rho, u, **params):
 
         super().__init__(rho, u)
 
         # parameters
-        params_default = {'tol': 1e-8,
-                          'maxiter': 100,
-                          'type_linear_solver': ('pcg', 'MassMatrixPreconditioner'),
+        params_default = {'linear_tol': 1e-12,
+                          'non_linear_tol': 1e-8,
+                          'linear_maxiter': 500,
+                          'non_linear_maxiter': 100,
+                          'type_linear_solver': ('pcg', 'MassMatrixDiagonalPreconditioner'),
+                          'non_linear_solver': 'Newton',
                           'info': False,
                           'verbose': False,
                           'model': None,
                           'gamma': 5/3,
                           's': None,
-                          'mass_ops' : None}
+                          'mass_ops': None}
 
         assert 'model' in params, 'model must be provided for VariationalDensityEvolve'
         assert params['model'] in ['pressureless', 'barotropic', 'full']
         if params['model'] == 'full':
             assert 's' in params
         assert 'mass_ops' in params
         params = set_defaults(params, params_default)
@@ -2787,74 +2900,155 @@
         self.uf1 = self.derham.create_field("uf1", "H1vec")
 
         # Projector
         self._initialize_projectors_and_mass()
         self.rhof1.vector = rho
         self._update_weighted_MM()
 
-        # gradient of the component of the vector field
-        self.div = self.derham.div
-
-        # Initialize the transport operator and transposed
-        self.divPirho = self.div @ self.Pirho
-        self.divPirhoT = self.PirhoT @ self.div.T
-
         # bunch of temporaries to avoid allocating in the loop
         self._tmp_un1 = u.space.zeros()
         self._tmp_un2 = u.space.zeros()
         self._tmp_un12 = u.space.zeros()
         self._tmp_rhon1 = rho.space.zeros()
-        self._tmp_rhon12 = rho.space.zeros()
         self._tmp_un_diff = u.space.zeros()
         self._tmp_rhon_diff = rho.space.zeros()
         self._tmp_un_weak_diff = u.space.zeros()
+        self._tmp_mn_diff = u.space.zeros()
         self._tmp_rhon_weak_diff = rho.space.zeros()
         self._tmp_mn = u.space.zeros()
         self._tmp_mn1 = u.space.zeros()
-        self._tmp_mn12 = u.space.zeros()
         self._tmp_advection = u.space.zeros()
         self._tmp_rho_advection = rho.space.zeros()
         self._linear_form_dl_drho = rho.space.zeros()
 
     def __call__(self, dt):
+        if self._params['non_linear_solver'] == 'Newton':
+            self.__call_newton(dt)
+        elif self._params['non_linear_solver'] == 'Picard':
+            self.__call_picard(dt)
+
+    def __call_newton(self, dt):
+        """Solve the non linear system for updating the variables using Newton iteration method"""
+        # Initialize variable for Newton iteration
+        if self._params['model'] == 'full':
+            s = self._params['s']
+            self.sf.vector = s
+        rhon = self.feec_vars[0]
+        rhon1 = rhon.copy(out=self._tmp_rhon1)
+        self.rhof.vector = rhon
+        self.rhof1.vector = rhon1
+        self._update_all_weights()
+        self._update_weighted_MM()
+        un = self.feec_vars[1]
+        self.uf.vector = un
+        mn = self._Mrho.dot(un, out=self._tmp_mn)
+        un1 = un.copy(out=self._tmp_un1)
+        mn1 = mn.copy(out=self._tmp_mn1)
+        tol = self._params['non_linear_tol']
+        err = tol+1
+
+        inv_derivative = inverse(self._Jacobian,
+                                 'gmres',
+                                 tol=self._params['linear_tol'],
+                                 maxiter=self._params['linear_maxiter'],
+                                 verbose=self._params['verbose'],
+                                 recycle = True,)
+                                 #verbose = True)
+
+        for it in range(self._params['non_linear_maxiter']):
+
+            # Newton iteration
+            
+            un12 = un.copy(out=self._tmp_un12)
+            un12 += un1
+            un12 *= 0.5
+
+            # Update the linear form
+            self.uf1.vector = un1
+            self._update_linear_form_u2()
+
+            # Compute the advection terms
+            advection = self.divPirhoT.dot(
+                self._linear_form_dl_drho, out=self._tmp_advection)
+            advection *= dt
+
+            rho_advection = self.divPirho.dot(
+                un12, out=self._tmp_rho_advection)
+            rho_advection *= dt
+
+            # Get diff 
+            rhon_diff = rhon1.copy(out=self._tmp_rhon_diff)
+            rhon_diff -= rhon
+            rhon_diff += rho_advection
+
+            mn_diff = mn1.copy(out=self._tmp_mn_diff)
+            mn_diff -= mn
+            mn_diff += advection
+
+            # Get error
+            err = self._get_error_newton(mn_diff, rhon_diff)
+
+            if err < tol**2:
+                break
+
+            # Derivative for Newton
+            self._get_jacobian(dt)
+
+            # Newton step
+            self.pc.update_mass_operator(self._Mrho)
+            f0 = self.pc.dot(mn_diff, out = self._tmp_f[0])
+            self._tmp_f[1] = rhon_diff
+
+            incr = inv_derivative.dot(self._tmp_f, out = self._tmp_incr)
+
+            un1 -= incr[0]
+            rhon1 -= incr[1]
+
+            # Multiply by the mass matrix to get the momentum
+            self.rhof1.vector = rhon1
+            self._update_weighted_MM()
+            mn1 = self._Mrho.dot(un1, out = self._tmp_mn1)
+
+
+        if it == self._params['non_linear_maxiter']-1:
+            print(
+                f'!!!Warning: Maximum iteration in VariationalDensityEvolve reached - not converged:\n {err = } \n {tol**2 = }')
+
+        self.feec_vars_update(rhon1, un1)
+
+    def __call_picard(self, dt):
+        """Solve the non linear system for updating the variables using Picard iteration method"""
 
         # Initialize variable for Picard iteration
         if self._params['model'] == 'full':
             s = self._params['s']
             self.sf.vector = s
         rhon = self.feec_vars[0]
         rhon1 = rhon.copy(out=self._tmp_rhon1)
         self.rhof.vector = rhon
         self.rhof1.vector = rhon1
         self._update_weighted_MM()
+        self._update_all_weights()
         un = self.feec_vars[1]
         mn = self._Mrho.dot(un, out=self._tmp_mn)
         un1 = un.copy(out=self._tmp_un1)
         un2 = un1.copy(out=self._tmp_un2)
         mn1 = mn.copy(out=self._tmp_mn1)
-        tol = self._params['tol']
+        tol = self._params['non_linear_tol']
         err = tol+1
-        for it in range(self._params['maxiter']):
+        for it in range(self._params['non_linear_maxiter']):
 
             # Picard iteration
             if err < tol**2:
                 break
             # half time step approximation
-            rhon12 = rhon.copy(out=self._tmp_rhon12)
-            rhon12 += rhon1
-            rhon12 *= 0.5
-
             un12 = un.copy(out=self._tmp_un12)
             un12 += un1
             un12 *= 0.5
 
-            # Update the BasisProjectionOperators
-            self.rhof.vector = rhon12
-            self._update_all_weights()
-
             # Update the linear form
             self.uf.vector = un
             self.uf1.vector = un1
             self.rhof.vector = rhon
             self._update_linear_form_u2()
 
             # Compute the advection terms
@@ -2878,73 +3072,85 @@
             # Update : rho^{n+1,r+1} = rho^n-rho_avection
             rhon1 = rhon.copy(out=self._tmp_rhon1)
             rhon1 -= rho_advection
 
             # Inverse the mass matrix to get the velocity
             self.rhof1.vector = rhon1
             self._update_weighted_MM()
-            self._Mrhoinv._options['x0'] = un1
+            self.pc.update_mass_operator(self._Mrho)
             un1 = self._Mrhoinv.dot(mn1, out=self._tmp_un1)
 
             # get the error
             un_diff = un1.copy(out=self._tmp_un_diff)
             un_diff -= un2
             un2 = un1.copy(out=self._tmp_un2)
 
-            err = self._get_error(un_diff, rhon_diff)
+            err = self._get_error_picard(un_diff, rhon_diff)
 
-        if it == self._params['maxiter']-1:
-            raise(ValueError('maximum iteration in VariationalDensityEvolve'))
+        if it == self._params['non_linear_maxiter']-1:
+            print(f'!!!Warning: Maximum iteration in VariationalDensityEvolve reached - not converged:\n {err = } \n {tol**2 = }')
 
         self.feec_vars_update(rhon1, un1)
 
     @classmethod
     def options(cls):
         dct = {}
-        dct['solver'] = {'tol': 1e-8,
-                         'maxiter': 3000,
-                         'type_linear_solver': [('pcg', 'MassMatrixPreconditioner'),
+        dct['solver'] = {'linear_tol': 1e-12,
+                         'non_linear_tol': 1e-8,
+                         'linear_maxiter': 500,
+                         'non_linear_maxiter': 100,
+                         'type_linear_solver': [('pcg', 'MassMatrixDiagonalPreconditioner'),
                                                 ('cg', None)],
+                        'non_linear_solver': ['Newton', 'Picard'],
                          'info': False,
-                         'verbose': False,
-                         'gamma': 5/3}
+                         'verbose': False}
+        dct['physics'] = {'gamma': 5/3}
         return dct
 
     def _initialize_projectors_and_mass(self):
         """Initialization of all the `BasisProjectionOperator` and `CoordinateProjector` needed to compute the bracket term"""
 
         from struphy.feec.projectors import L2Projector
 
         # Get the projector and the spaces
         P2 = self.derham.P['2']
 
         Xh = self.derham.Vh_fem['v']
-        V3h = self.derham.Vh_fem['3']
 
         # Initialize the BasisProjectionOperators
         self.Pirho = BasisProjectionOperator(
             P2, Xh, [[None, None, None],
                      [None, None, None],
                      [None, None, None]],
             transposed=False, use_cache=True)
 
         self.PirhoT = self.Pirho.T
 
+        # divergence
+        self.div = self.derham.div
+
+        # Initialize the transport operator and transposed
+        self.divPirho = self.div @ self.Pirho
+        self.divPirhoT = self.PirhoT @ self.div.T
+
         hist_grid = self.derham.proj_grid_pts['2']
 
         hist_grid_0 = [pts.flatten()
-                                    for pts in hist_grid[0]]
+                       for pts in hist_grid[0]]
         hist_grid_1 = [pts.flatten()
-                                    for pts in hist_grid[1]]
+                       for pts in hist_grid[1]]
         hist_grid_2 = [pts.flatten()
-                                    for pts in hist_grid[2]]
-        
-        self.hist_grid_0_spans, self.hist_grid_0_bn, self.hist_grid_0_bd = self.derham.prepare_eval_tp_fixed(hist_grid_0)
-        self.hist_grid_1_spans, self.hist_grid_1_bn, self.hist_grid_1_bd = self.derham.prepare_eval_tp_fixed(hist_grid_1)
-        self.hist_grid_2_spans, self.hist_grid_2_bn, self.hist_grid_2_bd = self.derham.prepare_eval_tp_fixed(hist_grid_2)
+                       for pts in hist_grid[2]]
+
+        self.hist_grid_0_spans, self.hist_grid_0_bn, self.hist_grid_0_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_0)
+        self.hist_grid_1_spans, self.hist_grid_1_bn, self.hist_grid_1_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_1)
+        self.hist_grid_2_spans, self.hist_grid_2_bn, self.hist_grid_2_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_2)
 
         grid_shape = tuple([len(loc_grid)
                            for loc_grid in hist_grid_0])
         self._rhof_0_values = np.zeros(grid_shape, dtype=float)
 
         grid_shape = tuple([len(loc_grid)
                            for loc_grid in hist_grid_1])
@@ -2955,181 +3161,471 @@
         self._rhof_2_values = np.zeros(grid_shape, dtype=float)
 
         # weighted mass matrix to go from m to u
         self._Mrho = self.WMM
 
         # Inverse weighted mass matrix
         if self._params['type_linear_solver'][1] is None:
-            pc = None
+            self.pc = None
         else:
             pc_class = getattr(
                 preconditioner, self._params['type_linear_solver'][1])
-            pc = pc_class(self.mass_ops.Mv)
+            self.pc = pc_class(self.mass_ops.Mv)
 
         self._Mrhoinv = inverse(self._Mrho,
                                 self._params['type_linear_solver'][0],
-                                pc=pc,
-                                tol=1e-30,
-                                maxiter=self._params['maxiter'],
-                                verbose=self._params['verbose'])
+                                pc=self.pc,
+                                tol=self._params['linear_tol'],
+                                maxiter=self._params['linear_maxiter'],
+                                verbose=self._params['verbose'],
+                                recycle = True)
 
-        integration_grid_X = [grid_1d.flatten() for grid_1d in self.derham.quad_grid_pts['0']]
+        integration_grid = [grid_1d.flatten()
+                              for grid_1d in self.derham.quad_grid_pts['0']]
 
-        self.integration_grid_X_spans, self.integration_grid_X_bn, self.integration_grid_X_bd = self.derham.prepare_eval_tp_fixed(integration_grid_X)
+        self.integration_grid_spans, self.integration_grid_bn, self.integration_grid_bd = self.derham.prepare_eval_tp_fixed(
+            integration_grid)
 
-        metric = self.domain.metric(*integration_grid_X)
+        metric = self.domain.metric(*integration_grid)
         self._mass_metric_term = deepcopy(metric)
 
         # tmps
         grid_shape = tuple([len(loc_grid)
-                           for loc_grid in integration_grid_X])
+                           for loc_grid in integration_grid])
         self._rhof_values = np.zeros(grid_shape, dtype=float)
 
         self._full_term_mass = deepcopy(metric)
 
         # prepare for integration of linear form
-        integration_grid_V3 = [grid_1d.flatten() for grid_1d in self.derham.quad_grid_pts['3']]
 
-        self.integration_grid_V3_spans, self.integration_grid_V3_bn, self.integration_grid_V3_bd = self.derham.prepare_eval_tp_fixed(integration_grid_V3)
-
-        metric = self.domain.metric(*integration_grid_V3)*self.domain.jacobian_det(*integration_grid_V3)
+        metric = self.domain.metric(
+            *integration_grid)*self.domain.jacobian_det(*integration_grid)
         self._proj_u2_metric_term = deepcopy(metric)
 
+        # Other mass matrices for newton solve
+        self._M_un = WeightedMassOperator(
+            self.derham.Vh_fem['v'], self.derham.Vh_fem['3'])
+
+        self._M_un1 = WeightedMassOperator(
+            self.derham.Vh_fem['3'], self.derham.Vh_fem['v'])
+
+        self._M_drho = WeightedMassOperator(
+            self.derham.Vh_fem['3'], self.derham.Vh_fem['3'])
+
+        grid_shape = tuple([len(loc_grid)
+                           for loc_grid in integration_grid])
+
+        self._Guf_values = [np.zeros(grid_shape, dtype=float)
+                            for i in range(3)]
+
+        self._Guf1_values = [np.zeros(grid_shape, dtype=float)
+                             for i in range(3)]
+
+        metric = self.domain.metric(*integration_grid)
+        self._mass_u_metric_term = deepcopy(metric)
+
+        Jacs = BlockVectorSpace(self.derham.Vh['v'],self.derham.Vh['3'])
+
+        self._tmp_f = Jacs.zeros()
+        self._tmp_incr = Jacs.zeros()
+
+        self._Jacobian = BlockLinearOperator(Jacs, Jacs)
+        
+        self._I3 = IdentityOperator(self.derham.Vh['3'])
+
+        #local version to avoid creating new version of LinearOperator every time
+        self._dt_pc_divPirhoT = 2 * (self.pc @ self.divPirhoT)
+        self._dt2_pc_divPirhoT = 2 * (self.pc @ self.divPirhoT)
+        self._dt2_divPirho = 2 * self.divPirho
+
+        self._Jacobian[0,0] = self.pc @ self._Mrho + self._dt2_pc_divPirhoT@self._M_un
+        self._Jacobian[0,1] = self.pc @ self._M_un1 + self._dt_pc_divPirhoT@self._M_drho
+        self._Jacobian[1,0] = self._dt2_divPirho
+        self._Jacobian[1,1] = self._I3
+
         # L2-projector for V3
         self._get_L2dofs_V3 = L2Projector('L2', self.mass_ops).get_dofs
 
         grid_shape = tuple([len(loc_grid)
-                           for loc_grid in integration_grid_V3])
-        
+                           for loc_grid in integration_grid])
+
         # tmps
         self._eval_dl_drho = np.zeros(grid_shape, dtype=float)
 
         self._uf_values = [np.zeros(grid_shape, dtype=float) for i in range(3)]
         self._uf1_values = [np.zeros(grid_shape, dtype=float)
                             for i in range(3)]
+        
+        grid_shape = tuple([len(loc_grid)
+                           for loc_grid in integration_grid])
+        
+        self._tmp_int_grid = np.zeros(grid_shape, dtype=float)
+        self._tmp_int_grid2 = np.zeros(grid_shape, dtype=float)
+        self._rhof_values = np.zeros(grid_shape, dtype=float)
+        self._rhof1_values = np.zeros(grid_shape, dtype=float)
 
-        if self._params['model'] == 'barotropic':
-            self._rhof_values_V3 = np.zeros(grid_shape, dtype=float)
-            self._rhof1_values_V3 = np.zeros(grid_shape, dtype=float)
-
-        elif self._params['model'] == 'full':
-            self._rhof_values_V3 = np.zeros(grid_shape, dtype=float)
-            self._rhof1_values_V3 = np.zeros(grid_shape, dtype=float)
+        if self._params['model'] == 'full':
             self._sf_values_V3 = np.zeros(grid_shape, dtype=float)
+            self._delta_rhof_values = np.zeros(grid_shape, dtype=float)
+            self._rhof_mid_values = np.zeros(grid_shape, dtype=float)
+            self._eta_values = np.zeros(grid_shape, dtype=float)
+            self._e_rho1_s_values = np.zeros(grid_shape, dtype=float)
+            self._e_rho_s_values = np.zeros(grid_shape, dtype=float)
+            self._de_rhom_s_values = np.zeros(grid_shape, dtype=float)
+            self._d2e_rho1_s_values = np.zeros(grid_shape, dtype=float)
+            self._DG_values = np.zeros(grid_shape, dtype=float)
+            
             gam = self._params['gamma']
-
-            self._ener = lambda rho, s: np.power(rho, gam)*np.exp(s/rho)
-            self._dener_drho = lambda rho, s: gam*np.power(rho, gam-1)*np.exp(s/rho)-s*np.power(rho, gam-2)*np.exp(s/rho)
-            self.eta = lambda delta_x: 1.-np.exp(-(delta_x/1e-5)**2)
-
-            metric = np.power(self.domain.jacobian_det(*integration_grid_V3),2-gam)
+            metric = np.power(self.domain.jacobian_det(
+                *integration_grid), 2-gam)
             self._proj_rho2_metric_term = deepcopy(metric)
 
+            metric = np.power(self.domain.jacobian_det(
+                *integration_grid), 1-gam)
+            self._proj_drho_metric_term = deepcopy(metric)
+
+    def __ener(self, rho, s, out=None):
+        """Themodynamical energy as a function of rho and s, usign the perfect gaz hypothesis
+        E(rho, s) = rho^gamma*exp(s/rho)"""
+        gam = self._params['gamma']
+        if out is None:
+            out = np.power(rho, gam)*np.exp(s/rho)
+        else :
+            out *= 0.
+            out += s
+            out /= rho
+            np.exp(out, out=out)
+            np.power(rho, gam, out = self._tmp_int_grid)
+            out *= self._tmp_int_grid
+        return out
+    
+    def __dener_drho(self, rho, s, out = None):
+        """Derivative with respect to rho of the thermodynamical energy as a function of rho and s, usign the perfect gaz hypothesis
+        dE(rho, s)/drho = (gamma*rho^{gamma-1} - s*rho^{gamma-2})*exp(s/rho)"""
+        gam = self._params['gamma']
+        if out is None:
+            out = (gam *np.power(rho, gam-1)-
+                s * np.power(rho, gam-2))*np.exp(s/rho)
+        else:
+            out *= 0.
+            out += s
+            out /= rho
+            np.exp(out, out=out)
+
+            np.power(rho, gam-1, out = self._tmp_int_grid)
+            self._tmp_int_grid *= gam
+
+            np.power(rho, gam-2, out = self._tmp_int_grid2)
+            self._tmp_int_grid2 *= s
+
+            self._tmp_int_grid -= self._tmp_int_grid2
+            out *= self._tmp_int_grid
+        return out
+    
+    def __d2ener_drho2(self, rho, s, out=None):
+        """Second derivative with respect to (rho, rho) of the thermodynamical energy as a function of rho and s, usign the perfect gaz hypothesis
+        d^2E(rho, s)/drho^2 = (gamma*(gamma-1) rho^{gamma-2}- 2*s*(gamma-1)*rho^{gamma-3}+ s^2*rho^{gamma-4})*exp(s/rho)"""
+        gam = self._params['gamma']
+        if out is None:
+            out = (gam * (gam-1) * np.power(rho, gam-2)
+                - s * 2 * (gam-1) * np.power(rho, gam-3)
+                + s**2 * np.power(rho, gam-4))*np.exp(s/rho)
+        else : 
+            out *= 0.
+            out += s
+            out /= rho
+            np.exp(out, out=out)
+
+            np.power(rho, gam-2, out = self._tmp_int_grid)
+            self._tmp_int_grid *= gam*(gam-1)
+
+            np.power(rho, gam-3, out = self._tmp_int_grid2)
+            self._tmp_int_grid2 *= s
+            self._tmp_int_grid2 *= 2*(gam-1)
+            self._tmp_int_grid -=self._tmp_int_grid2
+
+            np.power(rho, gam-4, out = self._tmp_int_grid2)
+            self._tmp_int_grid2 *= s
+            self._tmp_int_grid2 *= s
+            self._tmp_int_grid +=self._tmp_int_grid2
+            out *= self._tmp_int_grid
+        return out
+
+    def __eta(self, delta_x, out=None):
+        if out is None :
+            out = 1.-np.exp(-(delta_x/1e-5)**2)
+        else :
+            out *=0.
+            out += delta_x
+            out /= 1e-5
+            out **= 2
+            out *= -1
+            np.exp(out, out=out)
+            out *= -1
+            out +=1.
+        return out
 
     def _update_all_weights(self,):
         """Update the weights of the `BasisProjectionOperator` appearing in the equations"""
 
-        rhof0_values = self.rhof.eval_tp_fixed_loc(self.hist_grid_0_spans, self.hist_grid_0_bd, out=self._rhof_0_values)
-        rhof1_values = self.rhof.eval_tp_fixed_loc(self.hist_grid_1_spans, self.hist_grid_1_bd, out=self._rhof_1_values)
-        rhof2_values = self.rhof.eval_tp_fixed_loc(self.hist_grid_2_spans, self.hist_grid_2_bd, out=self._rhof_2_values)
+        rhof0_values = self.rhof.eval_tp_fixed_loc(
+            self.hist_grid_0_spans, self.hist_grid_0_bd, out=self._rhof_0_values)
+        rhof1_values = self.rhof.eval_tp_fixed_loc(
+            self.hist_grid_1_spans, self.hist_grid_1_bd, out=self._rhof_1_values)
+        rhof2_values = self.rhof.eval_tp_fixed_loc(
+            self.hist_grid_2_spans, self.hist_grid_2_bd, out=self._rhof_2_values)
 
         self.Pirho.update_weights([[rhof0_values, None, None],
                                    [None, rhof1_values, None],
                                    [None, None, rhof2_values]])
-        
+
         self.PirhoT.update_weights([[rhof0_values, None, None],
                                     [None, rhof1_values, None],
                                     [None, None, rhof2_values]])
 
     def _update_weighted_MM(self,):
         """update the weighted mass matrix operator"""
 
-        rhof_values = self.rhof1.eval_tp_fixed_loc(self.integration_grid_X_spans, self.integration_grid_X_bd, out=self._rhof_values)
+        rhof_values = self.rhof1.eval_tp_fixed_loc(
+            self.integration_grid_spans, self.integration_grid_bd, out=self._rhof_values)
         for i in range(3):
             for j in range(3):
-                self._full_term_mass[i, j] = rhof_values*self._mass_metric_term[i, j]
+                self._full_term_mass[i, j] = rhof_values * \
+                    self._mass_metric_term[i, j]
 
         self.WMM.assemble([[self._full_term_mass[0, 0], self._full_term_mass[0, 1], self._full_term_mass[0, 2]],
                            [self._full_term_mass[1, 0], self._full_term_mass[1,
                                                                              1], self._full_term_mass[1, 2]],
                            [self._full_term_mass[2, 0], self._full_term_mass[2, 1], self._full_term_mass[2, 2]]],
                           verbose=False)
 
     def _update_linear_form_u2(self,):
         """Update the linearform representing integration in V3 against kynetic energy"""
 
-        uf_values = self.uf.eval_tp_fixed_loc(self.integration_grid_V3_spans, [self.integration_grid_V3_bn]*3, out=self._uf_values)
-        uf1_values = self.uf1.eval_tp_fixed_loc(self.integration_grid_V3_spans, [self.integration_grid_V3_bn]*3, out=self._uf1_values)
+        uf_values = self.uf.eval_tp_fixed_loc(self.integration_grid_spans, [
+                                              self.integration_grid_bn]*3, out=self._uf_values)
+        uf1_values = self.uf1.eval_tp_fixed_loc(self.integration_grid_spans, [
+                                                self.integration_grid_bn]*3, out=self._uf1_values)
 
-        # TODO : probably could be faster, tmp (mabe use a kernel?)
         self._eval_dl_drho *= 0.
         for i in range(3):
             for j in range(3):
-                self._eval_dl_drho += uf_values[i]*self._proj_u2_metric_term[i, j]*uf1_values[j]
+                self._tmp_int_grid *= 0
+                self._tmp_int_grid += uf_values[i]
+                self._tmp_int_grid *= self._proj_u2_metric_term[i, j]
+                self._tmp_int_grid *= uf1_values[j]
+                self._eval_dl_drho += self._tmp_int_grid
 
         self._eval_dl_drho *= 0.5
 
         if self._params['model'] == 'barotropic':
-            
-            rhof_values = self.rhof.eval_tp_fixed_loc(self.integration_grid_V3_spans, self.integration_grid_V3_bd, out=self._rhof_values_V3)
-            rhof1_values = self.rhof1.eval_tp_fixed_loc(self.integration_grid_V3_spans, self.integration_grid_V3_bd, out=self._rhof1_values_V3)
 
-            self._eval_dl_drho -= (rhof_values + rhof1_values)/2
-            
+            rhof_values = self.rhof.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._rhof_values)
+            rhof1_values = self.rhof1.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._rhof1_values)
+
+            #self._eval_dl_drho -= (rhof_values + rhof1_values)/2
+            rhof_values /= 2
+            rhof1_values /=2
+
+            self._eval_dl_drho -= rhof_values
+            self._eval_dl_drho -= rhof1_values
+
         if self._params['model'] == 'full':
-            rhof_values = self.rhof.eval_tp_fixed_loc(self.integration_grid_V3_spans, self.integration_grid_V3_bd, out=self._rhof_values_V3)
-            rhof1_values = self.rhof1.eval_tp_fixed_loc(self.integration_grid_V3_spans, self.integration_grid_V3_bd, out=self._rhof1_values_V3)
+            rhof_values = self.rhof.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._rhof_values)
+            rhof1_values = self.rhof1.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._rhof1_values)
+
+            sf_values = self.sf.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._sf_values_V3)
+
+            #delta_rho_values = rhof1_values-rhof_values
+            self._delta_rhof_values *= 0.
+            self._delta_rhof_values += rhof1_values
+            self._delta_rhof_values -= rhof_values
+            delta_rho_values = self._delta_rhof_values
+
+            #rho_mid_values = (rhof1_values+rhof_values)/2
+            self._rhof_mid_values *= 0
+            self._rhof_mid_values += rhof1_values
+            self._rhof_mid_values += rhof_values
+            self._rhof_mid_values /=2
+            rho_mid_values = self._rhof_mid_values
+
+            eta = self.__eta(delta_rho_values, out=self._eta_values)
+
+            e_rho1_s = self.__ener(rhof1_values, sf_values, out=self._e_rho1_s_values)
+            e_rho_s  = self.__ener(rhof_values, sf_values, out=self._e_rho_s_values)
+
+            de_rhom_s = self.__dener_drho(rho_mid_values, sf_values, out=self._de_rhom_s_values)
+
+            # eta*delta_rho_values*(e_rho1_s-e_rho_s)*delta_rho_values/(delta_rho_values**2+1e-40)
+            self._DG_values *=0.
+            self._DG_values += e_rho1_s
+            self._DG_values -= e_rho_s
+            self._DG_values *= delta_rho_values
+            delta_rho_values **=2
+            delta_rho_values += 1e-40 
+            self._DG_values /= delta_rho_values
+            self._DG_values *=eta
+
+            #(1-eta)*de_rhom_s
+            eta -= 1.
+            eta *= -1.
+            de_rhom_s *= eta
+
+            #metric_term * (DG_values + de_rhom_s)
+            self._tmp_int_grid *= 0.
+            self._tmp_int_grid += self._DG_values
+            self._tmp_int_grid += de_rhom_s
+            self._tmp_int_grid *= self._proj_rho2_metric_term
 
-            sf_values = self.sf.eval_tp_fixed_loc(self.integration_grid_V3_spans, self.integration_grid_V3_bd, out=self._sf_values_V3)
-            
+            #self._eval_dl_drho -= self._proj_rho2_metric_term * (self._DG_values + de_rhom_s)
+            self._eval_dl_drho -= self._tmp_int_grid
+
+        self._get_L2dofs_V3(self._eval_dl_drho, dofs=self._linear_form_dl_drho)
+
+    def _get_jacobian(self,dt):
+        uf_values = self.uf.eval_tp_fixed_loc(self.integration_grid_spans, [
+                                              self.integration_grid_bn]*3, out=self._uf_values)
+        uf1_values = self.uf1.eval_tp_fixed_loc(self.integration_grid_spans, [
+                                                self.integration_grid_bn]*3, out=self._uf1_values)
+
+        # Guf = metric @ uf
+        for i in range(3):
+            self._Guf_values[i] *= 0.
+            self._Guf1_values[i] *= 0.
+            for j in range(3):
+                self._tmp_int_grid *= 0.
+                self._tmp_int_grid += self._mass_u_metric_term[i,j]
+                self._tmp_int_grid *= uf_values[j]
+                self._Guf_values[i] += self._tmp_int_grid
+
+                self._tmp_int_grid *= 0.
+                self._tmp_int_grid += self._mass_u_metric_term[i,j]
+                self._tmp_int_grid *= uf1_values[j]
+                self._Guf1_values[i] += self._tmp_int_grid
+
+        if self._params['model'] == 'barotropic':
+            self._M_drho = -self.mass_ops.M3/2.
+
+        if self._params['model'] == 'full':
+            rhof_values = self.rhof.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._rhof_values)
+            rhof1_values = self.rhof1.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._rhof1_values)
+            sf_values = self.sf.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._sf_values_V3)
             
-            delta_rho_values = rhof1_values-rhof_values
-            rho_mid_values = (rhof1_values+rhof_values)/2
-            e = self._ener
-            de = self._dener_drho
-            eta = self.eta(delta_rho_values)
-            self._eval_dl_drho -= self._proj_rho2_metric_term*(eta*delta_rho_values*(e(rhof1_values, sf_values)-e(rhof_values, sf_values)) / \
-                (delta_rho_values**2+1e-40)+(1-eta)*de(rho_mid_values, sf_values))
+            #delta_rho_values = rhof1_values-rhof_values
+            self._delta_rhof_values *= 0.
+            self._delta_rhof_values += rhof1_values
+            self._delta_rhof_values -= rhof_values
+            delta_rho_values = self._delta_rhof_values  
 
+            eta = self.__eta(delta_rho_values)
 
+            e_rho1_s = self.__ener(rhof1_values, sf_values, out=self._e_rho1_s_values)
+            e_rho_s  = self.__ener(rhof_values, sf_values, out=self._e_rho_s_values)
+            
+            de_rho1_s = self.__dener_drho(rhof1_values, sf_values, out=self._de_rhom_s_values)
 
-        self._get_L2dofs_V3(self._eval_dl_drho, dofs=self._linear_form_dl_drho)
+            d2e_rho1_s = self.__d2ener_drho2(rhof1_values, sf_values, out=self._d2e_rho1_s_values)
 
-    def _get_error(self, un_diff, rhon_diff):
+            #eta*(de_rho1_s*delta_rho_values-e_rho1_s+e_rho_s)/(delta_rho_values**2+1e-40)
+            self._DG_values *=0.
+            self._DG_values += de_rho1_s
+            self._DG_values *= delta_rho_values
+            self._DG_values -= e_rho1_s
+            self._DG_values += e_rho_s
+            delta_rho_values **=2
+            delta_rho_values += 1e-40 
+            self._DG_values /= delta_rho_values
+            self._DG_values *=eta
+
+            #(1-eta)*d2e_rho1_s
+            eta -= 1.
+            eta *= -1.
+            d2e_rho1_s *= eta
+
+            #-metric_term * (DG_values + d2e_rho1_s)
+            self._tmp_int_grid *= 0.
+            self._tmp_int_grid -= self._DG_values
+            self._tmp_int_grid -= d2e_rho1_s
+            self._tmp_int_grid *= self._proj_drho_metric_term
+
+            self._M_drho.assemble([[self._tmp_int_grid]], verbose=False)
+
+        self._M_un.assemble(
+            [[self._Guf_values[0],   self._Guf_values[1],   self._Guf_values[2]]], verbose=False)
+        self._M_un1.assemble(
+            [[self._Guf1_values[0]],[self._Guf1_values[1]],[self._Guf1_values[2]]], verbose=False)
+        
+        # This way we can update only the scalar multiplying the operator and avoid creating multiple operators
+        self._dt_pc_divPirhoT._scalar = dt
+        self._dt2_pc_divPirhoT._scalar = dt/2
+        self._dt2_divPirho._scalar = dt/2
+
+    def _get_error_newton(self, mn_diff, rhon_diff):
+        """Error for the newton method : max(|f(0)|,|f(1)|) where f is the function we're trying to nullify"""
+        inv_Mv = inverse(self.mass_ops.Mv, 'cg', tol=1e-16, maxiter = 1000)
+        weak_un_diff = inv_Mv.dot(
+            mn_diff, out=self._tmp_un_weak_diff)
+        weak_rhon_diff = self.mass_ops.M3.dot(
+            rhon_diff, out=self._tmp_rhon_weak_diff)
+        err_rho = weak_rhon_diff.dot(rhon_diff)
+        err_u = weak_un_diff.dot(mn_diff)
+        return max(err_rho, err_u)
+    
+    def _get_error_picard(self, un_diff, rhon_diff):
+        """Error for the picard method : difference between the two last iterations"""
         weak_un_diff = self.mass_ops.Mv.dot(
             un_diff, out=self._tmp_un_weak_diff)
         weak_rhon_diff = self.mass_ops.M3.dot(
             rhon_diff, out=self._tmp_rhon_weak_diff)
         err_rho = weak_rhon_diff.dot(rhon_diff)
         err_u = weak_un_diff.dot(un_diff)
         return max(err_rho, err_u)
 
 
 class VariationalEntropyEvolve(Propagator):
     r'''Crank-Nicolson step for the evolution of the entropy terms in fluids models,
 
     .. math::
 
-        \int_{\Omega} \partial_t \rho \mathbf u \cdot \mathbf v \, \textnormal d^3 \mathbf x 
-        - \int_{\Omega} \big(\frac{\partial \rho e}{\partial s} \big) \nabla \cdot (s \mathbf v) \, \textnormal d^3 \mathbf x = 0 ~ ,
+        \begin{align}
+        &\int_{\hat{\Omega}} \partial_t ( \hat{\rho}^3  \hat{\mathbf{u}}) \cdot G \hat{\mathbf{v}} \, \textrm d \boldsymbol \eta  
+        - \int_{\hat{\Omega}} \big(\frac{\partial \hat{\rho}^3 \hat{e}}{\partial \hat{s}} \big) \nabla \cdot (\hat{s} \hat{\mathbf{v}}) \, \textrm d \boldsymbol \eta = 0 ~ ,
+        \\[2mm]
+        &\partial_t \hat{s} + \nabla \cdot ( \hat{s} \hat{\mathbf{u}} ) = 0 ~ ,
+        \end{align}
 
-        \partial_t s + \nabla \cdot (s \mathbf u ) = 0 ~ ,
+    where :math:`\hat{e}` depends on the chosen model. It is discretized as
 
-    where $e$ depends on the chosen model.
+    .. math::
 
-    It is discretized as
+        \begin{align}
+        &\mathbb M^v[\hat{\rho}_h^{n}] \frac{ \mathbf u^{n+1}-\mathbf u^n}{\Delta t} - 
+        (\mathbb D \hat{\Pi}^{2}[\hat{s}_h^{n} \vec{\boldsymbol \Lambda}^v])^\top \hat{l}^3\Big( \big(\frac{\hat{\rho}_h^{n}\hat{e}(\hat{\rho}_h^{n},\hat{s}_h^{n+1})-\hat{\rho}_h^{n}\hat{e}(\hat{\rho}_h^{n},\hat{s}_h^{n})}{\hat{s}_h^{n+1}-\hat{s}_h^n} \big)\Big) = 0 ~ ,
+        \\[2mm]
+        &\frac{\mathbf s^{n+1}- \mathbf s^n}{\Delta t} + \mathbb D \hat{\Pi}^{2}[\hat{s}_h^{n} \vec{\boldsymbol \Lambda}^v] \mathbf u^{n+1/2} = 0 ~ ,
+        \end{align}
+
+    where :math:`\hat{l}^3(f)` denotes the vector representing the linear form :math:`v_h \mapsto \int_{\hat{\Omega}} f(\boldsymbol \eta) v_h(\boldsymbol \eta) d \boldsymbol \eta`, that is the vector with components
 
     .. math::
+        \hat{l}^3(f)_{ijk}=\int_{\hat{\Omega}} f \Lambda^3_{ijk} \textrm d \boldsymbol \eta
 
-        \frac{\mathbb M_v[\rho^{n}] \mathbf u^{n+1}- \mathbb M_v[\rho^{n}] \mathbf u^n}{\Delta t} -
-        (\mathbb D \hat{\Pi}^{X->2}[s^{n+1/2}])^\top l^3\big(\frac{\rho^{n}e(s^{n+1})-\rho^{n}e(s^{n})}{s^{n+1}-s^n} \big) = 0 ~ ,
+    and the weights in the the :class:`~struphy.feec.basis_projection_ops.BasisProjectionOperator` and the :class:`~struphy.feec.mass.WeightedMassOperator` are given by
 
-        \frac{s^{n+1}- s^n}{\Delta t} + \mathbb D \hat{\Pi}^{X->2}[s^{n+1/2}] \mathbf u^{n+1/2} = 0 ~ ,
+    .. math::
 
-    where :math:`l^3(f)` denotes the vector representing the linear form :math:`v \mapsto \int_{\Omega} f(\mathbf x) v(\mathbf x) d \mathbf x` .
+        \hat{\mathbf{u}}_h^{k} = (\mathbf{u}^{k})^\top \vec{\boldsymbol \Lambda}^v \in (V_h^0)^3 \, \text{for k in} \{n, n+1/2, n+1\}, \qquad \hat{s}_h^{k} = (s^{k})^\top \vec{\boldsymbol \Lambda}^3 \in V_h^3 \, \text{for k in} \{n, n+1/2, n+1\} \qquad \hat{\rho}_h^{n} = (\rho^{n})^\top \vec{\boldsymbol \Lambda}^3 \in V_h^3 \.
 
     Parameters
     ----------
     s : psydac.linalg.stencil.Vector
         FE coefficients of a discrete field, entropy of the solution.
 
     u : psydac.linalg.stencil.BlockVector
@@ -3141,23 +3637,26 @@
     '''
 
     def __init__(self, s, u, **params):
 
         super().__init__(s, u)
 
         # parameters
-        params_default = {'tol': 1e-8,
-                          'maxiter': 100,
-                          'type_linear_solver': ('pcg', 'MassMatrixPreconditioner'),
+        params_default = {'linear_tol': 1e-12,
+                          'non_linear_tol': 1e-8,
+                          'linear_maxiter': 500,
+                          'non_linear_maxiter': 100,
+                          'type_linear_solver': ('pcg', 'MassMatrixDiagonalPreconditioner'),
+                          'non_linear_solver': 'Newton',
                           'info': False,
                           'verbose': False,
                           'model': None,
                           'rho': None,
                           'gamma': 5/3,
-                          'mass_ops' : None}
+                          'mass_ops': None}
 
         assert 'model' in params, 'model must be provided for VariationalDensityEvolve'
         assert params['model'] in ['full']
         assert 'rho' in params
         assert 'mass_ops' in params
 
         params = set_defaults(params, params_default)
@@ -3172,77 +3671,161 @@
         self.sf1 = self.derham.create_field("sf1", "L2")
         self.uf = self.derham.create_field("uf", "H1vec")
         self.uf1 = self.derham.create_field("uf1", "H1vec")
 
         # Projector
         self._initialize_projectors_and_mass()
 
-        # gradient of the component of the vector field
-        self.div = self.derham.div
-
-        # Initialize the transport operator and transposed
-        self.divPis = self.div @ self.Pis
-        self.divPisT = self.PisT @ self.div.T
-
         # bunch of temporaries to avoid allocating in the loop
         self._tmp_un1 = u.space.zeros()
         self._tmp_un2 = u.space.zeros()
         self._tmp_un12 = u.space.zeros()
         self._tmp_sn1 = s.space.zeros()
         self._tmp_sn12 = s.space.zeros()
         self._tmp_un_diff = u.space.zeros()
         self._tmp_sn_diff = s.space.zeros()
+        self._tmp_mn_diff = u.space.zeros()
         self._tmp_un_weak_diff = u.space.zeros()
         self._tmp_sn_weak_diff = s.space.zeros()
         self._tmp_mn = u.space.zeros()
         self._tmp_mn1 = u.space.zeros()
         self._tmp_mn12 = u.space.zeros()
         self._tmp_advection = u.space.zeros()
         self._tmp_s_advection = s.space.zeros()
         self._linear_form_dl_ds = s.space.zeros()
 
     def __call__(self, dt):
+        if self._params['non_linear_solver'] == 'Newton':
+            self.__call_newton(dt)
+        elif self._params['non_linear_solver'] == 'Picard':
+            self.__call_picard(dt)
+
+    def __call_newton(self, dt):
+        """Solve the non linear system for updating the variables using Newton iteration method"""
+        # Initialize variable for Newton iteration
+        rho = self._params['rho']
+        self.rhof.vector = rho
+
+        sn = self.feec_vars[0]
+        sn1 = sn.copy(out=self._tmp_sn1)
+        self.sf.vector = sn
+        self.sf1.vector = sn1
+
+        self._update_all_weights()
+        self.pc.update_mass_operator(self._Mrho)
+
+        un = self.feec_vars[1]
+        self.uf.vector = un
+        mn = self._Mrho.dot(un, out=self._tmp_mn)
+        un1 = un.copy(out=self._tmp_un1)
+        mn1 = mn.copy(out=self._tmp_mn1)
+        tol = self._params['non_linear_tol']
+        err = tol+1
+
+        inv_derivative = inverse(self._Jacobian,
+                                 'gmres',
+                                 tol=self._params['linear_tol'],
+                                 maxiter=self._params['linear_maxiter'],
+                                 verbose=self._params['verbose'],
+                                 recycle = True)
+
+        for it in range(self._params['non_linear_maxiter']):
+
+            # Newton iteration
+            
+            un12 = un.copy(out=self._tmp_un12)
+            un12 += un1
+            un12 *= 0.5
+
+            # Update the linear form
+            self.uf1.vector = un1
+            self._update_linear_form_u2()
+
+            # Compute the advection terms
+            advection = self.divPisT.dot(
+                self._linear_form_dl_ds, out=self._tmp_advection)
+            advection *= dt
+
+            s_advection = self.divPis.dot(
+                un12, out=self._tmp_s_advection)
+            s_advection *= dt
+
+            # Get diff 
+            sn_diff = sn1.copy(out=self._tmp_sn_diff)
+            sn_diff -= sn
+            sn_diff += s_advection
+
+            mn_diff = mn1.copy(out=self._tmp_mn_diff)
+            mn_diff -= mn
+            mn_diff += advection
+
+            # Get error
+            err = self._get_error_newton(mn_diff, sn_diff)
+
+            if err < tol**2:
+                break
+
+            # Derivative for Newton
+            self._get_jacobian(dt)
+
+            # Newton step
+            f0 = self.pc.dot(mn_diff, out = self._tmp_f[0])
+            self._tmp_f[1] = sn_diff
+
+            incr = inv_derivative.dot(self._tmp_f, out = self._tmp_incr)
+
+            un1 -= incr[0]
+            sn1 -= incr[1]
+
+            # Multiply by the mass matrix to get the momentum
+            self.sf1.vector = sn1
+            mn1 = self._Mrho.dot(un1, out = self._tmp_mn1)
+
+
+        if it == self._params['non_linear_maxiter']-1:
+            print(
+                f'!!!Warning: Maximum iteration in VariationalDensityEvolve reached - not converged:\n {err = } \n {tol**2 = }')
+
+        self.feec_vars_update(sn1, un1)
+
+    def __call_picard(self, dt):
 
         # Initialize variable for Picard iteration
         rho = self._params['rho']
         self.rhof.vector = rho
 
         sn = self.feec_vars[0]
         sn1 = sn.copy(out=self._tmp_sn1)
         self.sf.vector = sn
         self.sf1.vector = sn1
 
+        self._update_all_weights()
+
         un = self.feec_vars[1]
         un1 = un.copy(out=self._tmp_un1)
         un2 = un1.copy(out=self._tmp_un2)
         self.uf.vector = un
 
         mn = self._Mrho.dot(un, out=self._tmp_mn)
         mn1 = mn.copy(out=self._tmp_mn1)
 
-        tol = self._params['tol']
+        self.pc.update_mass_operator(self._Mrho)
+
+        tol = self._params['non_linear_tol']
         err = tol+1
-        for it in range(self._params['maxiter']):
+        for it in range(self._params['non_linear_maxiter']):
 
             # Picard iteration
             if err < tol**2:
                 break
             # half time step approximation
-            sn12 = sn.copy(out=self._tmp_sn12)
-            sn12 += sn1
-            sn12 *= 0.5
-
             un12 = un.copy(out=self._tmp_un12)
             un12 += un1
             un12 *= 0.5
 
-            # Update the BasisProjectionOperators
-            self.sf.vector = sn12
-            self._update_all_weights()
-
             # Update the linear form
             self.sf.vector = sn
             self.sf1.vector = sn1
 
             self._update_linear_form_u2()
 
             # Compute the advection terms
@@ -3264,69 +3847,84 @@
             mn1 -= advection
 
             # Update : rho^{n+1,r+1} = rho^n-rho_avection
             sn1 = sn.copy(out=self._tmp_sn1)
             sn1 -= s_advection
 
             # Inverse the mass matrix to get the velocity
-            self._Mrhoinv._options['x0'] = un1
             un1 = self._Mrhoinv.dot(mn1, out=self._tmp_un1)
 
             # get the error
             un_diff = un1.copy(out=self._tmp_un_diff)
             un_diff -= un2
             un2 = un1.copy(out=self._tmp_un2)
 
-            err = self._get_error(un_diff, sn_diff)
+            err = self._get_error_picard(un_diff, sn_diff)
+
+            if it == self._params['non_linear_maxiter']-1:
+                print(
+                    f'!!!Warning: Maximum iteration in VariationalEntropyEvolve reached - not converged:\n {err = } \n {tol**2 = }')
 
         self.feec_vars_update(sn1, un1)
 
     @classmethod
     def options(cls):
         dct = {}
-        dct['solver'] = {'tol': 1e-8,
-                         'maxiter': 3000,
-                         'type_linear_solver': [('pcg', 'MassMatrixPreconditioner'),
+        dct['solver'] = {'linear_tol': 1e-12,
+                         'non_linear_tol': 1e-8,
+                         'linear_maxiter': 500,
+                         'non_linear_maxiter': 100,
+                         'type_linear_solver': [('pcg', 'MassMatrixDiagonalPreconditioner'),
                                                 ('cg', None)],
+                         'non_linear_solver': ['Newton', 'Picard'],
                          'info': False,
-                         'verbose': False,
-                         'gamma': 5/3}
+                         'verbose': False}
+        dct['physics'] = {'gamma': 5/3}
         return dct
 
     def _initialize_projectors_and_mass(self):
         """Initialization of all the `BasisProjectionOperator` and `CoordinateProjector` needed to compute the bracket term"""
 
         from struphy.feec.projectors import L2Projector
-        
+
         # Get the projector and the spaces
         P2 = self.derham.P['2']
 
         Xh = self.derham.Vh_fem['v']
 
         # Initialize the BasisProjectionOperators
         self.Pis = BasisProjectionOperator(
             P2, Xh, [[None, None, None],
                      [None, None, None],
                      [None, None, None]],
             transposed=False, use_cache=True)
 
         self.PisT = self.Pis.T
 
+        self.div = self.derham.div
+
+        # Initialize the transport operator and transposed
+        self.divPis = self.div @ self.Pis
+        self.divPisT = self.PisT @ self.div.T
+
         hist_grid = self.derham.proj_grid_pts['2']
 
         hist_grid_0 = [pts.flatten()
-                                    for pts in hist_grid[0]]
+                       for pts in hist_grid[0]]
         hist_grid_1 = [pts.flatten()
-                                    for pts in hist_grid[1]]
+                       for pts in hist_grid[1]]
         hist_grid_2 = [pts.flatten()
-                                    for pts in hist_grid[2]]
-        
-        self.hist_grid_0_spans, self.hist_grid_0_bn, self.hist_grid_0_bd = self.derham.prepare_eval_tp_fixed(hist_grid_0)
-        self.hist_grid_1_spans, self.hist_grid_1_bn, self.hist_grid_1_bd = self.derham.prepare_eval_tp_fixed(hist_grid_1)
-        self.hist_grid_2_spans, self.hist_grid_2_bn, self.hist_grid_2_bd = self.derham.prepare_eval_tp_fixed(hist_grid_2)
+                       for pts in hist_grid[2]]
+
+        self.hist_grid_0_spans, self.hist_grid_0_bn, self.hist_grid_0_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_0)
+        self.hist_grid_1_spans, self.hist_grid_1_bn, self.hist_grid_1_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_1)
+        self.hist_grid_2_spans, self.hist_grid_2_bn, self.hist_grid_2_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_2)
 
         grid_shape = tuple([len(loc_grid)
                            for loc_grid in hist_grid_0])
         self._sf_0_values = np.zeros(grid_shape, dtype=float)
 
         grid_shape = tuple([len(loc_grid)
                            for loc_grid in hist_grid_1])
@@ -3337,115 +3935,325 @@
         self._sf_2_values = np.zeros(grid_shape, dtype=float)
 
         # weighted mass matrix to go from m to u
         self._Mrho = self.WMM
 
         # Inverse weighted mass matrix
         if self._params['type_linear_solver'][1] is None:
-            pc = None
+            self.pc = None
         else:
             pc_class = getattr(
                 preconditioner, self._params['type_linear_solver'][1])
-            pc = pc_class(self.mass_ops.Mv)
+            self.pc = pc_class(self.mass_ops.Mv)
 
         self._Mrhoinv = inverse(self._Mrho,
                                 self._params['type_linear_solver'][0],
-                                pc=pc,
-                                tol=1e-30,
-                                maxiter=self._params['maxiter'],
-                                verbose=self._params['verbose'])
+                                pc=self.pc,
+                                tol=self._params['linear_tol'],
+                                maxiter=self._params['linear_maxiter'],
+                                verbose=self._params['verbose'],
+                                recycle = True)
+        
+        # For Newton solve
+        self._M_ds = WeightedMassOperator(
+            self.derham.Vh_fem['3'], self.derham.Vh_fem['3'])
+
+        Jacs = BlockVectorSpace(self.derham.Vh['v'],self.derham.Vh['3'])
+
+        self._tmp_f = Jacs.zeros()
+        self._tmp_incr = Jacs.zeros()
+
+        self._Jacobian = BlockLinearOperator(Jacs, Jacs)
+        
+        self._I3 = IdentityOperator(self.derham.Vh['3'])
+
+        #local version to avoid creating new version of LinearOperator every time
+        self._dt_pc_divPisT = 2 * (self.pc @ self.divPisT)
+        self._dt2_divPis = 2 * self.divPis
+
+        self._Jacobian[0,0] = self.pc@self._Mrho
+        self._Jacobian[0,1] = self._dt_pc_divPisT@self._M_ds
+        self._Jacobian[1,0] = self._dt2_divPis
+        self._Jacobian[1,1] = self._I3
 
         # prepare for integration of linear form
         # L2-projector for V3
         self._get_L2dofs_V3 = L2Projector('L2', self.mass_ops).get_dofs
 
-        integration_grid_V3 = [grid_1d.flatten() for grid_1d in self.derham.quad_grid_pts['3']]
+        integration_grid = [grid_1d.flatten()
+                               for grid_1d in self.derham.quad_grid_pts['3']]
 
-        self.integration_grid_V3_spans, self.integration_grid_V3_bn, self.integration_grid_V3_bd = self.derham.prepare_eval_tp_fixed(integration_grid_V3)
+        self.integration_grid_spans, self.integration_grid_bn, self.integration_grid_bd = self.derham.prepare_eval_tp_fixed(
+            integration_grid)
 
         if self._params['model'] == 'full':
             grid_shape = tuple([len(loc_grid)
-                           for loc_grid in integration_grid_V3])
-            self._sf_values_V3 = np.zeros(grid_shape, dtype=float)
-            self._sf1_values_V3 = np.zeros(grid_shape, dtype=float)
-            self._rhof_values_V3 = np.zeros(grid_shape, dtype=float)
-            gam = self._params['gamma']
-
-            self._ener = lambda rho, s: np.power(rho, gam)*np.exp(s/rho)
-            self._dener_ds = lambda rho, s: np.power(rho, gam-1)*np.exp(s/rho)
-            self.eta = lambda delta_x: 1.-np.exp(-(delta_x/1e-5)**2)
+                           for loc_grid in integration_grid])
+            self._sf_values = np.zeros(grid_shape, dtype=float)
+            self._sf1_values = np.zeros(grid_shape, dtype=float)
+            self._rhof_values = np.zeros(grid_shape, dtype=float)
+            self._tmp_int_grid = np.zeros(grid_shape, dtype=float)
+            self._delta_sf_values = np.zeros(grid_shape, dtype=float)
+            self._sf_mid_values = np.zeros(grid_shape, dtype=float)
+            self._eta_values = np.zeros(grid_shape, dtype=float)
+            self._e_rho_s1_values = np.zeros(grid_shape, dtype=float)
+            self._e_rho_s_values = np.zeros(grid_shape, dtype=float)
+            self._de_rho_sm_values = np.zeros(grid_shape, dtype=float)
+            self._d2e_rho_s1_values = np.zeros(grid_shape, dtype=float)
 
-            metric = np.power(self.domain.jacobian_det(*integration_grid_V3),2-gam)
+            gam = self._params['gamma']
+            metric = np.power(self.domain.jacobian_det(
+                *integration_grid), 2-gam)
             self._proj_rho2_metric_term = deepcopy(metric)
-            metric = np.power(self.domain.jacobian_det(*integration_grid_V3),2-gam)
-            self._proj_ener_metric_term = deepcopy(metric)
+
+            metric = np.power(self.domain.jacobian_det(
+                *integration_grid), 1-gam)
+            self._proj_ds_metric_term = deepcopy(metric)
+
+    def __ener(self, rho, s, out=None):
+        """Themodynamical energy as a function of rho and s, usign the perfect gaz hypothesis
+        E(rho, s) = rho^gamma*exp(s/rho)"""
+        gam = self._params['gamma']
+        if out is None:
+            out = np.power(rho, gam)*np.exp(s/rho)
+        else :
+            out *= 0.
+            out += s
+            out /= rho
+            np.exp(out, out=out)
+            np.power(rho, gam, out = self._tmp_int_grid)
+            out *= self._tmp_int_grid
+        return out
+    
+    def __dener_ds(self, rho, s, out=None):
+        """Derivative with respect to s of the thermodynamical energy as a function of rho and s, usign the perfect gaz hypothesis
+        dE(rho, s)/ds = (rho^{gamma-1})*exp(s/rho)"""
+        gam = self._params['gamma']
+        if out is None:
+            out = np.power(rho, gam-1)*np.exp(s/rho)
+        else :
+            out *= 0.
+            out += s
+            out /= rho
+            np.exp(out, out=out)
+            np.power(rho, gam-1, out = self._tmp_int_grid)
+            out *= self._tmp_int_grid
+        return out
+    
+    def __d2ener_ds2(self, rho, s, out=None):
+        """Second derivative with respect to (s, s) of the thermodynamical energy as a function of rho and s, usign the perfect gaz hypothesis
+        d^2E(rho, s)/ds^2 = (rho^{gamma-2})*exp(s/rho)"""
+        gam = self._params['gamma']
+        if out is None:
+            out = np.power(rho, gam-2)*np.exp(s/rho)
+        else :
+            out *= 0.
+            out += s
+            out /= rho
+            np.exp(out, out=out)
+            np.power(rho, gam-2, out = self._tmp_int_grid)
+            out *= self._tmp_int_grid
+        return out
+    
+    def __eta(self, delta_x, out=None):
+        if out is None :
+            out = 1.-np.exp(-(delta_x/1e-5)**2)
+        else :
+            out *=0.
+            out += delta_x
+            out /= 1e-5
+            out **= 2
+            out *= -1
+            np.exp(out, out=out)
+            out *= -1
+            out +=1.
+        return out
 
     def _update_all_weights(self,):
         """Update the weights of the `BasisProjectionOperator` appearing in the equations"""
 
-        sf0_values = self.sf.eval_tp_fixed_loc(self.hist_grid_0_spans, self.hist_grid_0_bd, out=self._sf_0_values)
-        sf1_values = self.sf.eval_tp_fixed_loc(self.hist_grid_1_spans, self.hist_grid_1_bd, out=self._sf_1_values)
-        sf2_values = self.sf.eval_tp_fixed_loc(self.hist_grid_2_spans, self.hist_grid_2_bd, out=self._sf_2_values)
+        sf0_values = self.sf.eval_tp_fixed_loc(
+            self.hist_grid_0_spans, self.hist_grid_0_bd, out=self._sf_0_values)
+        sf1_values = self.sf.eval_tp_fixed_loc(
+            self.hist_grid_1_spans, self.hist_grid_1_bd, out=self._sf_1_values)
+        sf2_values = self.sf.eval_tp_fixed_loc(
+            self.hist_grid_2_spans, self.hist_grid_2_bd, out=self._sf_2_values)
 
         self.Pis.update_weights([[sf0_values, None, None],
                                  [None, sf1_values, None],
                                  [None, None, sf2_values]])
-        
+
         self.PisT.update_weights([[sf0_values, None, None],
                                   [None, sf1_values, None],
                                   [None, None, sf2_values]])
 
     def _update_linear_form_u2(self,):
         """Update the linearform representing integration in V3 against kynetic energy"""
-        V3h = self.derham.Vh_fem['3']
 
         if self._params['model'] == 'full':
-            sf_values = self.sf.eval_tp_fixed_loc(self.integration_grid_V3_spans, self.integration_grid_V3_bd, out=self._sf_values_V3)
-            sf1_values = self.sf1.eval_tp_fixed_loc(self.integration_grid_V3_spans, self.integration_grid_V3_bd, out=self._sf1_values_V3)
+            sf_values = self.sf.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._sf_values)
+            sf1_values = self.sf1.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._sf1_values)
+
+            rhof_values = self.rhof.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._rhof_values)
+
+            #delta_s_values = s1_values-sf_values
+            self._delta_sf_values *= 0.
+            self._delta_sf_values += sf1_values
+            self._delta_sf_values -= sf_values
+            delta_s_values = self._delta_sf_values
+
+            #rho_mid_values = (rhof1_values+rhof_values)/2
+            self._sf_mid_values *= 0.
+            self._sf_mid_values += sf1_values
+            self._sf_mid_values += sf_values
+            self._sf_mid_values /=2.
+            s_mid_values = self._sf_mid_values
+
+            eta = self.__eta(delta_s_values, out=self._eta_values)
 
-            rhof_values = self.rhof.eval_tp_fixed_loc(self.integration_grid_V3_spans, self.integration_grid_V3_bd, out=self._rhof_values_V3)
+            e_rho_s1 = self.__ener(rhof_values, sf1_values, out=self._e_rho_s1_values)
+            e_rho_s  = self.__ener(rhof_values, sf_values, out=self._e_rho_s_values)
+
+            de_rho_sm = self.__dener_ds(rhof_values, s_mid_values, out=self._de_rho_sm_values)
+
+            # metric_term * (eta*delta_s_values*(e_rho_s1-e_rho_s) / (delta_s_values**2+1e-40)+(1-eta)*de_rho_sm)
             
-            delta_s_values = sf1_values-sf_values
-            s_mid_values = (sf1_values+sf_values)/2
-            e = self._ener
-            de = self._dener_ds
-            eta = self.eta(delta_s_values)
-            eval_dl_ds = -self._proj_rho2_metric_term *(eta*delta_s_values*(e(rhof_values, sf1_values)-e(rhof_values, sf_values)) / \
-                (delta_s_values**2+1e-40)+(1-eta)*de(rhof_values, s_mid_values))
+            # eta*delta_s_values*(e_rho_s1-e_rho_s) /(delta_s_values**2+1e-40)
+            self._tmp_int_grid *= 0.
+            self._tmp_int_grid += e_rho_s1
+            self._tmp_int_grid -= e_rho_s
+            self._tmp_int_grid *= delta_s_values
+            self._tmp_int_grid *= eta
+
+            # delta_s_values**2+1e-40
+            delta_s_values **=2
+            delta_s_values += 1e-40
+            self._tmp_int_grid/= delta_s_values
+
+            #(1-eta)
+            eta -=1.
+            eta *=-1.
+
+            #(1-eta)*de_rho_sm
+            de_rho_sm *= eta
+
+            self._tmp_int_grid += de_rho_sm
+            self._tmp_int_grid *= self._proj_rho2_metric_term
+            self._tmp_int_grid *= -1.
+
+        self._get_L2dofs_V3(self._tmp_int_grid, dofs=self._linear_form_dl_ds)
 
-        self._get_L2dofs_V3(eval_dl_ds, dofs=self._linear_form_dl_ds)
+    def _get_jacobian(self,dt):
+
+        if self._params['model'] == 'full':
+            rhof_values = self.rhof.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._rhof_values)
+            sf_values = self.sf.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._sf_values)
+            sf1_values = self.sf1.eval_tp_fixed_loc(
+                self.integration_grid_spans, self.integration_grid_bd, out=self._sf1_values)
+            
+            #delta_s_values = s1_values-sf_values
+            self._delta_sf_values *= 0.
+            self._delta_sf_values += sf1_values
+            self._delta_sf_values -= sf_values
+            delta_s_values = self._delta_sf_values
+
+            eta = self.__eta(delta_s_values, out=self._eta_values)
+
+            e_rho_s1 = self.__ener(rhof_values, sf1_values, out=self._e_rho_s1_values)
+            e_rho_s  = self.__ener(rhof_values, sf_values, out=self._e_rho_s_values)
+
+            de_rho_s1 = self.__dener_ds(rhof_values, sf1_values, out=self._de_rho_sm_values)
+
+            d2e_rho_s1 = self.__d2ener_ds2(rhof_values, sf1_values, out=self._d2e_rho_s1_values)
+
+            # de_rho_s1*delta_s_values-e_rho_s1+e_rho_s
+            self._tmp_int_grid *= 0.
+            self._tmp_int_grid += de_rho_s1
+            self._tmp_int_grid *= delta_s_values
+            self._tmp_int_grid -= e_rho_s1
+            self._tmp_int_grid += e_rho_s
+
+            #(delta_s_values**2+1e-40)
+            delta_s_values **= 2
+            delta_s_values += 1e-40
+
+            #eta*(de_rho_s1*delta_s_values-e_rho_s1+e_rho_s)/(delta_s_values**2+1e-40)
+            self._tmp_int_grid /= delta_s_values
+            self._tmp_int_grid *= eta
+
+            #(1-eta)*d2e_rho_s1
+            eta -= 1.
+            eta *= -1.
+            d2e_rho_s1 *= eta 
+
+            #-metric *(eta*(de_rho_s1*delta_s_values-e_rho_s1+e_rho_s)/(delta_s_values**2+1e-40) + (1-eta)*d2e_rho_s1)
+            self._tmp_int_grid += d2e_rho_s1
+            self._tmp_int_grid *= self._proj_ds_metric_term
+            self._tmp_int_grid *= -1.
+
+            self._M_ds.assemble([[self._tmp_int_grid]], verbose=False)
+
+        # This way we can update only the scalar multiplying the operator and avoid creating multiple operators
+        self._dt_pc_divPisT._scalar = dt
+        self._dt2_divPis._scalar = dt/2
+
+    def _get_error_newton(self, mn_diff, sn_diff):
+        inv_Mv = inverse(self.mass_ops.Mv, 'cg', tol=1e-16, maxiter = 1000)
+        weak_un_diff = inv_Mv.dot(
+            mn_diff, out=self._tmp_un_weak_diff)
+        weak_sn_diff = self.mass_ops.M3.dot(
+            sn_diff, out=self._tmp_sn_weak_diff)
+        err_rho = weak_sn_diff.dot(sn_diff)
+        err_u = weak_un_diff.dot(mn_diff)
+        return max(err_rho, err_u)
 
-    def _get_error(self, un_diff, sn_diff):
+    def _get_error_picard(self, un_diff, sn_diff):
         weak_un_diff = self.mass_ops.Mv.dot(
             un_diff, out=self._tmp_un_weak_diff)
         weak_sn_diff = self.mass_ops.M3.dot(
             sn_diff, out=self._tmp_sn_weak_diff)
         err_s = weak_sn_diff.dot(sn_diff)
         err_u = weak_un_diff.dot(un_diff)
         return max(err_s, err_u)
-    
+
 
 class VariationalMagFieldEvolve(Propagator):
     r'''Crank-Nicolson step for the evolution of the magnetic field terms in fluids models,
 
     .. math::
 
-        \int_{\Omega} \partial_t \rho \mathbf u \cdot \mathbf v \, \textnormal d^3 \mathbf x 
-        - \int_{\Omega} \mathbf B \cdot \nabla \times (\mathbf B \times \mathbf v) \, \textnormal d^3 \mathbf x = 0 ~ ,
-
-        \partial_t \mathbf B + \nabla \times (\mathbf B \times \mathbf u) = 0 ~ ,
+        \begin{align}
+        &\int_{\hat{\Omega}} \partial_t ( \hat{\rho}^3  \hat{\mathbf{u}}) \cdot G \hat{\mathbf{v}} \, \textrm d \boldsymbol \eta  
+        - \int_{\hat{\Omega}} \hat{\mathbf{B}}^2 \cdot G \,\nabla \times (\hat{\mathbf{B}}^2 \times \hat{\mathbf{v}}) \,\frac{1}{\sqrt g}\, \textrm d \boldsymbol \eta = 0 ~ ,
+        \\[2mm]
+        &\partial_t \hat{\mathbf{B}}^2 + \nabla \times (\hat{\mathbf{B}}^2 \times \hat{\mathbf{u}}) = 0 ~ .
+        \end{align}
 
     It is discretized as
 
     .. math::
 
-        \mathbb M_v[\rho^{n}]\frac{\mathbf u^{n+1}- \mathbf u^n}{\Delta t} -
-        (\mathbb C \hat{\Pi}^{X->1}[\mathbf B^{n+1/2}])^\top \mathbb M_2 B^{n+\frac{1}{2}} \big) = 0 ~ ,
+        \begin{align}
+        &\mathbb M^v[\hat{\rho}_h^{n}] \frac{ \mathbf u^{n+1}-\mathbf u^n}{\Delta t}
+        - (\mathbb C \hat{\Pi}^{1}[\hat{\mathbf{B}}_h^{n} \cdot \vec{\boldsymbol \Lambda}^v])^\top \mathbb M^2 B^{n+\frac{1}{2}} \big) = 0 ~ ,
+        \\[2mm]
+        &\frac{\mathbf b^{n+1}- \mathbf b^n}{\Delta t} + \mathbb C \hat{\Pi}^{1}[\hat{\mathbf{B}}_h^{n} \cdot \vec{\boldsymbol \Lambda}^v]] \mathbf u^{n+1/2} = 0 ~ ,
+        \end{align}
+
+    and the weights in the the :class:`~struphy.feec.basis_projection_ops.BasisProjectionOperator` and the :class:`~struphy.feec.mass.WeightedMassOperator` are given by
+
+    .. math::
+
+        \hat{\mathbf{B}}_h^{n+1/2} = (\mathbf{b}^{n+1/2})^\top \vec{\boldsymbol \Lambda}^2 \in V_h^2 \, \qquad \hat{\rho}_h^{n} = (\boldsymbol \rho^{n})^\top \vec{\boldsymbol \Lambda}^3 \in V_h^3 \,.
 
-        \frac{\mathbf B^{n+1}- \mathbf B^n}{\Delta t} + \mathbb C \hat{\Pi}^{X->1}[\mathbf B^{n+1/2}] \mathbf u^{n+1/2} = 0 ~ ,
 
     Parameters
     ----------
     b : psydac.linalg.stencil.Vector
         FE coefficients of a discrete field, magnetic field of the solution.
 
     u : psydac.linalg.stencil.BlockVector
@@ -3457,20 +4265,23 @@
     '''
 
     def __init__(self, b, u, **params):
 
         super().__init__(b, u)
 
         # parameters
-        params_default = {'tol': 1e-8,
-                          'maxiter': 100,
-                          'type_linear_solver': ('pcg', 'MassMatrixPreconditioner'),
+        params_default = {'linear_tol': 1e-12,
+                          'non_linear_tol': 1e-8,
+                          'linear_maxiter': 500,
+                          'non_linear_maxiter': 100,
+                          'type_linear_solver': ('pcg', 'MassMatrixDiagonalPreconditioner'),
+                          'non_linear_solver': 'Newton',
                           'info': False,
                           'verbose': False,
-                          'mass_ops' : None}
+                          'mass_ops': None}
 
         assert 'mass_ops' in params
 
         params = set_defaults(params, params_default)
 
         self._params = params
 
@@ -3481,72 +4292,157 @@
 
         self.uf = self.derham.create_field("uf", "H1vec")
         self.uf1 = self.derham.create_field("uf1", "H1vec")
 
         # Projector
         self._initialize_projectors_and_mass()
 
-        # gradient of the component of the vector field
-        self.curl = self.derham.curl
-
-        # Initialize the transport operator and transposed
-        self.curlPib = self.curl @ self.Pib
-        self.curlPibT = self.PibT @ self.curl.T
-
         # bunch of temporaries to avoid allocating in the loop
         self._tmp_un1 = u.space.zeros()
         self._tmp_un2 = u.space.zeros()
         self._tmp_un12 = u.space.zeros()
         self._tmp_bn1 = b.space.zeros()
         self._tmp_bn12 = b.space.zeros()
         self._tmp_un_diff = u.space.zeros()
         self._tmp_bn_diff = b.space.zeros()
         self._tmp_un_weak_diff = u.space.zeros()
         self._tmp_bn_weak_diff = b.space.zeros()
         self._tmp_mn = u.space.zeros()
         self._tmp_mn1 = u.space.zeros()
+        self._tmp_mn_diff = u.space.zeros()
         self._tmp_advection = u.space.zeros()
         self._tmp_b_advection = b.space.zeros()
         self._linear_form_dl_db = b.space.zeros()
 
     def __call__(self, dt):
+        if self._params['non_linear_solver'] == 'Newton':
+            self.__call_newton(dt)
+        elif self._params['non_linear_solver'] == 'Picard':
+            self.__call_picard(dt)
+
+    def __call_newton(self, dt):
+        """Solve the non linear system for updating the variables using Newton iteration method"""
+        # Initialize variable for Newton iteration
+
+        bn = self.feec_vars[0]
+        bn1 = bn.copy(out=self._tmp_bn1)
+        self.bf.vector = bn
+        self._update_all_weights()
+        self.pc.update_mass_operator(self._Mrho)
+
+        un = self.feec_vars[1]
+        self.uf.vector = un
+        mn = self._Mrho.dot(un, out=self._tmp_mn)
+        un1 = un.copy(out=self._tmp_un1)
+        mn1 = mn.copy(out=self._tmp_mn1)
+        tol = self._params['non_linear_tol']
+        err = tol+1
+
+        inv_derivative = inverse(self._Jacobian,
+                                 'gmres',
+                                 tol=self._params['linear_tol'],
+                                 maxiter=self._params['linear_maxiter'],
+                                 verbose=self._params['verbose'],
+                                 recycle = True)
+
+        for it in range(self._params['non_linear_maxiter']):
+
+            # Newton iteration
+            # half time step approximation
+            bn12 = bn.copy(out=self._tmp_bn12)
+            bn12 += bn1
+            bn12 *= 0.5
+
+            un12 = un.copy(out=self._tmp_un12)
+            un12 += un1
+            un12 *= 0.5
+
+            # Update the linear form
+            self.uf1.vector = un1
+            self._update_linear_form_u2()
+
+            # Compute the advection terms
+            advection = self.curlPibT.dot(
+                self._linear_form_dl_db, out=self._tmp_advection)
+            advection *= dt
+
+            b_advection = self.curlPib.dot(
+                un12, out=self._tmp_b_advection)
+            b_advection *= dt
+
+            # Get diff 
+            bn_diff = bn1.copy(out=self._tmp_bn_diff)
+            bn_diff -= bn
+            bn_diff += b_advection
+
+            mn_diff = mn1.copy(out=self._tmp_mn_diff)
+            mn_diff -= mn
+            mn_diff += advection
+
+            # Get error
+            err = self._get_error_newton(mn_diff, bn_diff)
+
+            if err < tol**2:
+                break
+
+            # Derivative for Newton
+            self._get_jacobian(dt)
+
+            # Newton step
+            f0 = self.pc.dot(mn_diff, out = self._tmp_f[0])
+            self._tmp_f[1] = bn_diff
+
+            incr = inv_derivative.dot(self._tmp_f, out = self._tmp_incr)
+
+            un1 -= incr[0]
+            bn1 -= incr[1]
+
+            # Multiply by the mass matrix to get the momentum
+            mn1 = self._Mrho.dot(un1, out = self._tmp_mn1)
+
+        if it == self._params['non_linear_maxiter']-1:
+            print(
+                f'!!!Warning: Maximum iteration in VariationalDensityEvolve reached - not converged:\n {err = } \n {tol**2 = }')
+
+        self.feec_vars_update(bn1, un1)
+
+    def __call_picard(self, dt):
 
         # Initialize variable for Picard iteration
 
         bn = self.feec_vars[0]
         bn1 = bn.copy(out=self._tmp_bn1)
         self.bf.vector = bn
+        self._update_all_weights()
 
         un = self.feec_vars[1]
         un1 = un.copy(out=self._tmp_un1)
         un2 = un1.copy(out=self._tmp_un2)
 
         mn = self._Mrho.dot(un, out=self._tmp_mn)
         mn1 = mn.copy(out=self._tmp_mn1)
 
-        tol = self._params['tol']
+        self.pc.update_mass_operator(self._Mrho)
+
+        tol = self._params['non_linear_tol']
         err = tol+1
-        for it in range(self._params['maxiter']):
+        for it in range(self._params['non_linear_maxiter']):
 
             # Picard iteration
             if err < tol**2:
                 break
             # half time step approximation
             bn12 = bn.copy(out=self._tmp_bn12)
             bn12 += bn1
             bn12 *= 0.5
 
             un12 = un.copy(out=self._tmp_un12)
             un12 += un1
             un12 *= 0.5
 
-            # Update the BasisProjectionOperators
-            self.bf.vector = bn12
-            self._update_all_weights()
-
             self._update_linear_form_u2()
 
             # Compute the advection terms
             advection = self.curlPibT.dot(
                 self._linear_form_dl_db, out=self._tmp_advection)
             advection *= dt
 
@@ -3564,126 +4460,245 @@
             mn1 -= advection
 
             # Update : b^{n+1,r+1} = b^n-b_avection
             bn1 = bn.copy(out=self._tmp_bn1)
             bn1 -= b_advection
 
             # Inverse the mass matrix to get the velocity
-            self._Mrhoinv._options['x0'] = un1
             un1 = self._Mrhoinv.dot(mn1, out=self._tmp_un1)
 
             # get the error
             un_diff = un1.copy(out=self._tmp_un_diff)
             un_diff -= un2
             un2 = un1.copy(out=self._tmp_un2)
 
-            err = self._get_error(un_diff, bn_diff)
+            err = self._get_error_picard(un_diff, bn_diff)
+
+            if it == self._params['non_linear_maxiter']-1:
+                print(
+                    f'!!!Warning: Maximum iteration in VariationalMagFieldEvolve reached - not converged:\n {err = } \n {tol**2 = }')
 
         self.feec_vars_update(bn1, un1)
 
     @classmethod
     def options(cls):
         dct = {}
-        dct['solver'] = {'tol': 1e-8,
-                         'maxiter': 3000,
-                         'type_linear_solver': [('pcg', 'MassMatrixPreconditioner'),
+        dct['solver'] = {'linear_tol': 1e-12,
+                         'non_linear_tol': 1e-8,
+                         'linear_maxiter': 500,
+                         'non_linear_maxiter': 100,
+                         'type_linear_solver': [('pcg', 'MassMatrixDiagonalPreconditioner'),
                                                 ('cg', None)],
+                         'non_linear_solver': ['Newton', 'Picard'],
                          'info': False,
-                         'verbose': False,}
+                         'verbose': False, }
         return dct
 
     def _initialize_projectors_and_mass(self):
         """Initialization of all the `BasisProjectionOperator` and needed to compute the bracket term"""
-        
+
         # Get the projector and the spaces
         P1 = self.derham.P['1']
 
         Xh = self.derham.Vh_fem['v']
 
         # Initialize the BasisProjectionOperators
         self.Pib = BasisProjectionOperator(
             P1, Xh, [[None, None, None],
                      [None, None, None],
                      [None, None, None]],
             transposed=False, use_cache=True)
 
         self.PibT = self.Pib.T
 
+        # gradient of the component of the vector field
+        self.curl = self.derham.curl
+
+        # Initialize the transport operator and transposed
+        self.curlPib = self.curl @ self.Pib
+        self.curlPibT = self.PibT @ self.curl.T
+
         hist_grid = self.derham.proj_grid_pts['1']
 
         hist_grid_0 = [pts.flatten()
-                                    for pts in hist_grid[0]]
+                       for pts in hist_grid[0]]
         hist_grid_1 = [pts.flatten()
-                                    for pts in hist_grid[1]]
+                       for pts in hist_grid[1]]
         hist_grid_2 = [pts.flatten()
-                                    for pts in hist_grid[2]]
-        
-        self.hist_grid_0_spans, self.hist_grid_0_bn, self.hist_grid_0_bd = self.derham.prepare_eval_tp_fixed(hist_grid_0)
-        self.hist_grid_1_spans, self.hist_grid_1_bn, self.hist_grid_1_bd = self.derham.prepare_eval_tp_fixed(hist_grid_1)
-        self.hist_grid_2_spans, self.hist_grid_2_bn, self.hist_grid_2_bd = self.derham.prepare_eval_tp_fixed(hist_grid_2)
+                       for pts in hist_grid[2]]
+
+        self.hist_grid_0_spans, self.hist_grid_0_bn, self.hist_grid_0_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_0)
+        self.hist_grid_1_spans, self.hist_grid_1_bn, self.hist_grid_1_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_1)
+        self.hist_grid_2_spans, self.hist_grid_2_bn, self.hist_grid_2_bd = self.derham.prepare_eval_tp_fixed(
+            hist_grid_2)
 
         grid_shape = tuple([len(loc_grid)
                            for loc_grid in hist_grid_0])
-        self._bf0_values = [np.zeros(grid_shape, dtype=float) for i in range(3)]
+        self._bf0_values = [np.zeros(grid_shape, dtype=float)
+                            for i in range(3)]
         self.hist_grid_0_b = [[self.hist_grid_0_bn[0], self.hist_grid_0_bd[1], self.hist_grid_0_bd[2]],
-                                       [self.hist_grid_0_bd[0], self.hist_grid_0_bn[1], self.hist_grid_0_bd[2]],
-                                       [self.hist_grid_0_bd[0], self.hist_grid_0_bd[1], self.hist_grid_0_bn[2]]]
+                              [self.hist_grid_0_bd[0], self.hist_grid_0_bn[1],
+                                  self.hist_grid_0_bd[2]],
+                              [self.hist_grid_0_bd[0], self.hist_grid_0_bd[1], self.hist_grid_0_bn[2]]]
         grid_shape = tuple([len(loc_grid)
                            for loc_grid in hist_grid_1])
-        self._bf1_values = [np.zeros(grid_shape, dtype=float) for i in range(3)]
+        self._bf1_values = [np.zeros(grid_shape, dtype=float)
+                            for i in range(3)]
         self.hist_grid_1_b = [[self.hist_grid_1_bn[0], self.hist_grid_1_bd[1], self.hist_grid_1_bd[2]],
-                                       [self.hist_grid_1_bd[0], self.hist_grid_1_bn[1], self.hist_grid_1_bd[2]],
-                                       [self.hist_grid_1_bd[0], self.hist_grid_1_bd[1], self.hist_grid_1_bn[2]]]
+                              [self.hist_grid_1_bd[0], self.hist_grid_1_bn[1],
+                                  self.hist_grid_1_bd[2]],
+                              [self.hist_grid_1_bd[0], self.hist_grid_1_bd[1], self.hist_grid_1_bn[2]]]
 
         grid_shape = tuple([len(loc_grid)
                            for loc_grid in hist_grid_2])
-        self._bf2_values = [np.zeros(grid_shape, dtype=float) for i in range(3)]
+        self._bf2_values = [np.zeros(grid_shape, dtype=float)
+                            for i in range(3)]
         self.hist_grid_2_b = [[self.hist_grid_2_bn[0], self.hist_grid_2_bd[1], self.hist_grid_2_bd[2]],
-                                       [self.hist_grid_2_bd[0], self.hist_grid_2_bn[1], self.hist_grid_2_bd[2]],
-                                       [self.hist_grid_2_bd[0], self.hist_grid_2_bd[1], self.hist_grid_2_bn[2]]]
+                              [self.hist_grid_2_bd[0], self.hist_grid_2_bn[1],
+                                  self.hist_grid_2_bd[2]],
+                              [self.hist_grid_2_bd[0], self.hist_grid_2_bd[1], self.hist_grid_2_bn[2]]]
 
         # weighted mass matrix to go from m to u
         self._Mrho = self.WMM
 
         # Inverse weighted mass matrix
         if self._params['type_linear_solver'][1] is None:
-            pc = None
+            self.pc = None
         else:
             pc_class = getattr(
                 preconditioner, self._params['type_linear_solver'][1])
-            pc = pc_class(self.mass_ops.Mv)
+            self.pc = pc_class(self.mass_ops.Mv)
 
         self._Mrhoinv = inverse(self._Mrho,
                                 self._params['type_linear_solver'][0],
-                                pc=pc,
-                                tol=1e-30,
-                                maxiter=self._params['maxiter'],
-                                verbose=self._params['verbose'])
+                                pc=self.pc,
+                                tol=self._params['linear_tol'],
+                                maxiter=self._params['linear_maxiter'],
+                                verbose=self._params['verbose'],
+                                recycle = True)
+        
+
+        Jacs = BlockVectorSpace(self.derham.Vh['v'],self.derham.Vh['2'])
+
+        self._tmp_f = Jacs.zeros()
+        self._tmp_incr = Jacs.zeros()
+
+        self._Jacobian = BlockLinearOperator(Jacs, Jacs)
+        
+        self._I2 = IdentityOperator(self.derham.Vh['2'])
+
+        #local version to avoid creating new version of LinearOperator every time
+        self._mdt2_pc_curlPibT_M = 2 * (self.pc @ self.curlPibT@self.mass_ops.M2)
+        self._dt2_curlPib = 2 * self.curlPib
+        
+        self._Jacobian[0,0] = self.pc @ self._Mrho
+        self._Jacobian[0,1] = self._mdt2_pc_curlPibT_M
+        self._Jacobian[1,0] = self._dt2_curlPib
+        self._Jacobian[1,1] = self._I2
 
     def _update_all_weights(self,):
         """Update the weights of the `BasisProjectionOperator` appearing in the equations"""
 
-        bf0_values = self.bf.eval_tp_fixed_loc(self.hist_grid_0_spans, self.hist_grid_0_b, out=self._bf0_values)
-        bf1_values = self.bf.eval_tp_fixed_loc(self.hist_grid_1_spans, self.hist_grid_1_b, out=self._bf1_values)
-        bf2_values = self.bf.eval_tp_fixed_loc(self.hist_grid_2_spans, self.hist_grid_2_b, out=self._bf2_values)
+        bf0_values = self.bf.eval_tp_fixed_loc(
+            self.hist_grid_0_spans, self.hist_grid_0_b, out=self._bf0_values)
+        bf1_values = self.bf.eval_tp_fixed_loc(
+            self.hist_grid_1_spans, self.hist_grid_1_b, out=self._bf1_values)
+        bf2_values = self.bf.eval_tp_fixed_loc(
+            self.hist_grid_2_spans, self.hist_grid_2_b, out=self._bf2_values)
 
         self.Pib.update_weights([[None, -bf0_values[2], bf0_values[1]],
                                  [bf1_values[2], None, -bf1_values[0]],
                                  [-bf2_values[1], bf2_values[0], None]])
-        
+
         self.PibT.update_weights([[None, -bf0_values[2], bf0_values[1]],
                                   [bf1_values[2], None, -bf1_values[0]],
                                   [-bf2_values[1], bf2_values[0], None]])
 
     def _update_linear_form_u2(self,):
         """Update the linearform representing integration in V2 derivative of the lagrangian"""
-        M2 = -self.mass_ops.M2
-        wb = M2.dot(self._tmp_bn12, out = self._linear_form_dl_db)
+        wb = self.mass_ops.M2.dot(self._tmp_bn12, out=self._linear_form_dl_db)
+        wb *= -1
+
+    def _get_error_newton(self, mn_diff, bn_diff):
+        inv_Mv = inverse(self.mass_ops.Mv, 'cg', tol=1e-16, maxiter = 1000)
+        weak_un_diff = inv_Mv.dot(
+            mn_diff, out=self._tmp_un_weak_diff)
+        weak_bn_diff = self.mass_ops.M2.dot(
+            bn_diff, out=self._tmp_bn_weak_diff)
+        err_b = weak_bn_diff.dot(bn_diff)
+        err_u = weak_un_diff.dot(mn_diff)
+        return max(err_b, err_u)
 
-    def _get_error(self, un_diff, bn_diff):
+    def _get_error_picard(self, un_diff, bn_diff):
         weak_un_diff = self.mass_ops.Mv.dot(
             un_diff, out=self._tmp_un_weak_diff)
         weak_bn_diff = self.mass_ops.M2.dot(
             bn_diff, out=self._tmp_bn_weak_diff)
         err_b = weak_bn_diff.dot(bn_diff)
         err_u = weak_un_diff.dot(un_diff)
         return max(err_b, err_u)
+    
+    def _get_jacobian(self,dt):
+        self._mdt2_pc_curlPibT_M._scalar = -dt/2
+        self._dt2_curlPib._scalar = dt/2
+
+
+class TimeDependentSource(Propagator):
+    r'''Propagates a source term :math:`S(t) \in V_h^n` of the form
+
+    .. math::
+
+        S(t) = \sum_{ijk} c_{ijk} \Lambda^n_{ijk} * h(\omega t)\,,
+
+    where :math:`h(\omega t)` is one of the functions in Notes.
+
+    Notes
+    -----
+
+    * :math:`h(\omega t) = \cos(\omega t)` (default)
+    * :math:`h(\omega t) = \sin(\omega t)` 
+
+    Parameters
+    ----------
+    c : psydac.linalg.stencil.StencilVector or psydac.linalg.block.BlockVector
+        FE coefficients at t=0.
+
+    **params : dict
+        Solver- and/or other parameters for this splitting step.
+    '''
+
+    def __init__(self, c, omega=1., hfun='cos'):
+
+        super().__init__(c)
+
+        if hfun == 'cos':
+            def hfun(t):
+                return np.cos(omega*t)
+        elif hfun == 'sin':
+            def hfun(t):
+                return np.sin(omega*t)
+        else:
+            raise NotImplementedError(f'{hfun = } not implemented.')
+
+        self._hfun = hfun
+
+    def __call__(self, dt):
+
+        print(f'{self.time_state[0] = }')
+        if self.time_state[0] == 0.:
+            self._c0 = self.feec_vars[0].copy()
+            print('Initial source coeffs set.')
+
+        # new coeffs
+        cn1 = self._c0 * self._hfun(self.time_state[0])
+
+        # write new coeffs into self.feec_vars
+        max_dc = self.feec_vars_update(cn1)
+
+    @classmethod
+    def options(cls):
+        dct = {}
+        dct['omega'] = 1.
+        dct['hfun'] = ['cos', 'sin']
+        return dct
```

### Comparing `struphy-2.2.0/src/struphy/propagators/propagators_markers.py` & `struphy-2.3.0/src/struphy/propagators/propagators_markers.py`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,14 @@
 from psydac.linalg.block import BlockVector
 
 from struphy.polar.basic import PolarVector
 from struphy.propagators.base import Propagator
 from struphy.pic.pushing.pusher import Pusher
 from struphy.pic.pushing.pusher import ButcherTableau
 from struphy.fields_background.mhd_equil.equils import set_defaults
-from struphy.kinetic_background.maxwellians import Maxwellian6DUniform
 
 
 class PushEta(Propagator):
     r"""Solves
 
     .. math::
 
@@ -433,15 +432,15 @@
         dct = {}
         dct['use_perp_model'] = [True, False]
         dct['u_space'] = ['Hcurl', 'Hdiv', 'H1vec']
         return dct
 
 
 class PushGuidingCenterbxEstar(Propagator):
-    r"""Particle pushing step for the :math:`\mathbf b_ \times \mathbf E^*` guiding center drift part in `DriftKinetic <https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.toy.DriftKinetic>`_ model,
+    r"""Particle pushing step for the :math:`\mathbf b_ \times \mathbf E^*` guiding center drift part in :class:`~struphy.models.toy.DriftKinetic`,
 
     Equation:
 
     .. math::
 
         \left\{ 
             \begin{aligned} 
@@ -631,15 +630,15 @@
                        'tol': 1e-7,
                        'mpi_sort': 'each',
                        'verbose': False}
         return dct
 
 
 class PushGuidingCenterBstar(Propagator):
-    r"""Particle pushing step for the :math:`\mathbf B^*` guiding center drift part in `DriftKinetic <https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.toy.DriftKinetic>`_ model,
+    r"""Particle pushing step for the :math:`\mathbf B^*` guiding center drift part in :class:`~struphy.models.toy.DriftKinetic`,
 
     Equation:
 
     .. math::
 
         \left\{ 
             \begin{aligned} 
@@ -969,15 +968,15 @@
                      self._loc1, self._loc2, self._loc3, self._weight1, self._weight2, self._weight3,
                      self._e_field.blocks[0]._data, self._e_field.blocks[1]._data, self._e_field.blocks[2]._data,
                      self.kappa,
                      array([1e-10, 1e-10]), 100)
 
 
 class PushDriftKineticbxGradB(Propagator):
-    r"""Particle pushing step for the :math:`\mathbf b_0 \times \nabla B_\parallel` driftkinetic part in `LinearMHDDriftkineticCC <https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.hybrid.LinearMHDDriftkineticCC>`_ model,
+    r"""Particle pushing step for the :math:`\mathbf b_0 \times \nabla B_\parallel` driftkinetic part in :class:`~struphy.models.hybrid.LinearMHDDriftkineticCC`,
 
     Equation:
 
     .. math::
 
         \left\{ 
             \begin{aligned} 
@@ -1197,15 +1196,15 @@
                        'tol': 1e-7,
                        'mpi_sort': 'each',
                        'verbose': False}
         return dct
 
 
 class PushDriftKineticBstar(Propagator):
-    r"""Particle pushing step for the :math:`\mathbf B^*` driftkinetic part in `LinearMHDDriftkineticCC <https://struphy.pages.mpcdf.de/struphy/sections/models.html#struphy.models.hybrid.LinearMHDDriftkineticCC>`_ model,
+    r"""Particle pushing step for the :math:`\mathbf B^*` driftkinetic part in :class:`~struphy.models.hybrid.LinearMHDDriftkineticCC`,
 
     Equation:
 
     .. math::
 
         \left\{ 
             \begin{aligned}
```

### Comparing `struphy-2.2.0/src/struphy/psydac-0.1.9-py3-none-any.whl` & `struphy-2.3.0/src/struphy/psydac-0.1.12-py3-none-any.whl`

 * *Files 12% similar despite different names*

#### zipinfo {}

```diff
@@ -1,226 +1,226 @@
-Zip file size: 618985 bytes, number of entries: 224
--rw-rw-r--  2.0 unx      410 b- defN 24-Jan-11 07:23 psydac/__init__.py
--rw-rw-r--  2.0 unx       20 b- defN 24-Jan-11 07:23 psydac/version.py
--rw-rw-r--  2.0 unx      335 b- defN 24-Jan-11 07:23 psydac/api/__init__.py
--rw-rw-r--  2.0 unx    11533 b- defN 24-Jan-11 07:23 psydac/api/basic.py
--rw-rw-r--  2.0 unx    20091 b- defN 24-Jan-11 07:23 psydac/api/discretization.py
--rw-rw-r--  2.0 unx     8339 b- defN 24-Jan-11 07:23 psydac/api/equation.py
--rw-rw-r--  2.0 unx     9435 b- defN 24-Jan-11 07:23 psydac/api/essential_bc.py
--rw-rw-r--  2.0 unx     5152 b- defN 24-Jan-11 07:23 psydac/api/expr.py
--rw-rw-r--  2.0 unx     5403 b- defN 24-Jan-11 07:23 psydac/api/feec.py
--rw-rw-r--  2.0 unx    69052 b- defN 24-Jan-11 07:23 psydac/api/fem.py
--rw-rw-r--  2.0 unx    21262 b- defN 24-Jan-11 07:23 psydac/api/glt.py
--rw-rw-r--  2.0 unx     9392 b- defN 24-Jan-11 07:23 psydac/api/grid.py
--rw-rw-r--  2.0 unx   125554 b- defN 24-Jan-11 07:23 psydac/api/postprocessing.py
--rw-rw-r--  2.0 unx     1857 b- defN 24-Jan-11 07:23 psydac/api/settings.py
--rw-rw-r--  2.0 unx     2045 b- defN 24-Jan-11 07:23 psydac/api/utilities.py
--rw-rw-r--  2.0 unx      237 b- defN 24-Jan-11 07:23 psydac/api/ast/__init__.py
--rw-rw-r--  2.0 unx     2052 b- defN 24-Jan-11 07:23 psydac/api/ast/basic.py
--rw-rw-r--  2.0 unx    13497 b- defN 24-Jan-11 07:23 psydac/api/ast/evaluation.py
--rw-rw-r--  2.0 unx    17993 b- defN 24-Jan-11 07:23 psydac/api/ast/expr.py
--rw-rw-r--  2.0 unx    81291 b- defN 24-Jan-11 07:23 psydac/api/ast/fem.py
--rw-rw-r--  2.0 unx    25475 b- defN 24-Jan-11 07:23 psydac/api/ast/glt.py
--rw-rw-r--  2.0 unx    26193 b- defN 24-Jan-11 07:23 psydac/api/ast/linalg.py
--rw-rw-r--  2.0 unx     9259 b- defN 24-Jan-11 07:23 psydac/api/ast/linalg_kernels.py
--rw-rw-r--  2.0 unx    67015 b- defN 24-Jan-11 07:23 psydac/api/ast/nodes.py
--rw-rw-r--  2.0 unx    83536 b- defN 24-Jan-11 07:23 psydac/api/ast/parser.py
--rw-rw-r--  2.0 unx    31637 b- defN 24-Jan-11 07:23 psydac/api/ast/utilities.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/api/ast/tests/__init__.py
--rw-rw-r--  2.0 unx     2265 b- defN 24-Jan-11 07:23 psydac/api/ast/tests/boundary.py
--rw-rw-r--  2.0 unx     2563 b- defN 24-Jan-11 07:23 psydac/api/ast/tests/poisson.py
--rw-rw-r--  2.0 unx     2697 b- defN 24-Jan-11 07:23 psydac/api/ast/tests/system_1.py
--rw-rw-r--  2.0 unx     2274 b- defN 24-Jan-11 07:23 psydac/api/ast/tests/system_2.py
--rw-rw-r--  2.0 unx     1854 b- defN 24-Jan-11 07:23 psydac/api/ast/tests/system_3.py
--rw-rw-r--  2.0 unx    17349 b- defN 24-Jan-11 07:23 psydac/api/ast/tests/test_nodes.py
--rw-rw-r--  2.0 unx       39 b- defN 24-Jan-11 07:23 psydac/api/printing/__init__.py
--rw-rw-r--  2.0 unx     5947 b- defN 24-Jan-11 07:23 psydac/api/printing/pycode.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/api/tests/__init__.py
--rw-rw-r--  2.0 unx     9105 b- defN 24-Jan-11 07:23 psydac/api/tests/build_domain.py
--rw-rw-r--  2.0 unx     5762 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_biharmonic.py
--rw-rw-r--  2.0 unx    19250 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_complex.py
--rw-rw-r--  2.0 unx     4697 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_laplace.py
--rw-rw-r--  2.0 unx     7561 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_mapping_biharmonic.py
--rw-rw-r--  2.0 unx     6501 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_mapping_laplace.py
--rw-rw-r--  2.0 unx    31950 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_mapping_poisson.py
--rw-rw-r--  2.0 unx    10465 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_multipatch_mapping_maxwell.py
--rw-rw-r--  2.0 unx    15593 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_multipatch_mapping_poisson.py
--rw-rw-r--  2.0 unx     7170 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_multipatch_poisson.py
--rw-rw-r--  2.0 unx    16354 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_navier_stokes.py
--rw-rw-r--  2.0 unx    15404 b- defN 24-Jan-11 07:23 psydac/api/tests/test_2d_poisson.py
--rw-rw-r--  2.0 unx     2628 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_1d_compatible_spaces.py
--rw-rw-r--  2.0 unx    19393 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_2d_compatible_spaces.py
--rw-rw-r--  2.0 unx    11809 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_2d_fields.py
--rw-rw-r--  2.0 unx     2740 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_2d_scalar_analytical_mapping.py
--rw-rw-r--  2.0 unx     4875 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_2d_system.py
--rw-rw-r--  2.0 unx     2990 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_2d_vector.py
--rw-rw-r--  2.0 unx     3947 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_2d_vector_mapping.py
--rw-rw-r--  2.0 unx     3701 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_2d_vector_multipatch_mapping.py
--rw-rw-r--  2.0 unx    10726 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_3d_scalar.py
--rw-rw-r--  2.0 unx    16969 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_3d_scalar_mapping.py
--rw-rw-r--  2.0 unx     3169 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_3d_vector.py
--rw-rw-r--  2.0 unx     4162 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_3d_vector_mapping.py
--rw-rw-r--  2.0 unx     1520 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_expr_2d_scalar.py
--rw-rw-r--  2.0 unx    24942 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_feec_1d.py
--rw-rw-r--  2.0 unx    32543 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_feec_2d.py
--rw-rw-r--  2.0 unx    12336 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_feec_3d.py
--rw-rw-r--  2.0 unx     6286 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_glt_2d_scalar.py
--rw-rw-r--  2.0 unx     3255 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_glt_2d_scalar_mapping.py
--rw-rw-r--  2.0 unx     2226 b- defN 24-Jan-11 07:23 psydac/api/tests/test_api_glt_2d_vector.py
--rw-rw-r--  2.0 unx    16854 b- defN 24-Jan-11 07:23 psydac/api/tests/test_assembly.py
--rw-rw-r--  2.0 unx     2138 b- defN 24-Jan-11 07:23 psydac/api/tests/test_equation.py
--rw-rw-r--  2.0 unx    34228 b- defN 24-Jan-11 07:23 psydac/api/tests/test_postprocessing.py
--rw-rw-r--  2.0 unx     1554 b- defN 24-Jan-11 07:23 psydac/api/tests/test_quadorder.py
--rw-rw-r--  2.0 unx      669 b- defN 24-Jan-11 07:23 psydac/api/tests/utils.py
--rw-rw-r--  2.0 unx      161 b- defN 24-Jan-11 07:23 psydac/cad/__init__.py
--rw-rw-r--  2.0 unx     6786 b- defN 24-Jan-11 07:23 psydac/cad/cad.py
--rw-rw-r--  2.0 unx     5485 b- defN 24-Jan-11 07:23 psydac/cad/gallery.py
--rw-rw-r--  2.0 unx    28452 b- defN 24-Jan-11 07:23 psydac/cad/geometry.py
--rw-rw-r--  2.0 unx     4774 b- defN 24-Jan-11 07:23 psydac/cad/multipatch.py
--rw-rw-r--  2.0 unx     1242 b- defN 24-Jan-11 07:23 psydac/cad/utils.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/cad/tests/__init__.py
--rw-rw-r--  2.0 unx      981 b- defN 24-Jan-11 07:23 psydac/cad/tests/geo_Lshaped_C1.txt
--rw-rw-r--  2.0 unx     9881 b- defN 24-Jan-11 07:23 psydac/cad/tests/test_geometry.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/cmd/__init__.py
--rw-rw-r--  2.0 unx     3629 b- defN 24-Jan-11 07:23 psydac/cmd/mesh.py
--rw-rw-r--  2.0 unx      210 b- defN 24-Jan-11 07:23 psydac/core/__init__.py
--rw-rw-r--  2.0 unx     2163 b- defN 24-Jan-11 07:23 psydac/core/arrays.py
--rw-rw-r--  2.0 unx    34731 b- defN 24-Jan-11 07:23 psydac/core/bsplines.py
--rw-rw-r--  2.0 unx    37821 b- defN 24-Jan-11 07:23 psydac/core/bsplines_pyccel.py
--rw-rw-r--  2.0 unx   210566 b- defN 24-Feb-14 08:55 psydac/core/kernels.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/core/tests/__init__.py
--rw-rw-r--  2.0 unx      585 b- defN 24-Jan-11 07:23 psydac/core/tests/test_arrays.py
--rw-rw-r--  2.0 unx     9356 b- defN 24-Jan-11 07:23 psydac/core/tests/test_bsplines.py
--rw-rw-r--  2.0 unx    33374 b- defN 24-Jan-11 07:23 psydac/core/tests/test_bsplines_pyccel.py
--rw-rw-r--  2.0 unx    31846 b- defN 24-Jan-11 07:23 psydac/core/tests/test_kernels.py
--rw-rw-r--  2.0 unx       48 b- defN 24-Jan-11 07:23 psydac/ddm/__init__.py
--rw-rw-r--  2.0 unx     2508 b- defN 24-Jan-11 07:23 psydac/ddm/basic.py
--rw-rw-r--  2.0 unx    13337 b- defN 24-Jan-11 07:23 psydac/ddm/blocking_data_exchanger.py
--rw-rw-r--  2.0 unx    74194 b- defN 24-Jan-11 07:23 psydac/ddm/cart.py
--rw-rw-r--  2.0 unx     4780 b- defN 24-Jan-11 07:23 psydac/ddm/interface_data_exchanger.py
--rw-rw-r--  2.0 unx    12936 b- defN 24-Jan-11 07:23 psydac/ddm/nonblocking_data_exchanger.py
--rw-rw-r--  2.0 unx     6571 b- defN 24-Jan-11 07:23 psydac/ddm/partition.py
--rw-rw-r--  2.0 unx     3356 b- defN 24-Jan-11 07:23 psydac/ddm/petsc.py
--rw-rw-r--  2.0 unx     1044 b- defN 24-Jan-11 07:23 psydac/ddm/utilities.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/ddm/tests/__init__.py
--rw-rw-r--  2.0 unx     4673 b- defN 24-Jan-11 07:23 psydac/ddm/tests/test_cart_1d.py
--rw-rw-r--  2.0 unx     5522 b- defN 24-Jan-11 07:23 psydac/ddm/tests/test_cart_2d.py
--rw-rw-r--  2.0 unx     5579 b- defN 24-Jan-11 07:23 psydac/ddm/tests/test_cart_3d.py
--rw-rw-r--  2.0 unx     7558 b- defN 24-Jan-11 07:23 psydac/ddm/tests/test_multicart_2d.py
--rw-rw-r--  2.0 unx     4012 b- defN 24-Jan-11 07:23 psydac/ddm/tests/test_partition.py
--rw-rw-r--  2.0 unx       63 b- defN 24-Jan-11 07:23 psydac/feec/__init__.py
--rw-rw-r--  2.0 unx    25809 b- defN 24-Jan-16 07:14 psydac/feec/derivatives.py
--rw-rw-r--  2.0 unx     8012 b- defN 24-Jan-11 07:23 psydac/feec/dof_kernels.py
--rw-rw-r--  2.0 unx    41057 b- defN 24-Jan-11 07:23 psydac/feec/global_projectors.py
--rw-rw-r--  2.0 unx    13609 b- defN 24-Jan-11 07:23 psydac/feec/pull_push.py
--rw-rw-r--  2.0 unx    19543 b- defN 24-Jan-11 07:23 psydac/feec/pushforward.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/__init__.py
--rw-rw-r--  2.0 unx    10466 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/api.py
--rw-rw-r--  2.0 unx     6652 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/fem_linear_operators.py
--rw-rw-r--  2.0 unx    30966 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/multipatch_domain_utilities.py
--rw-rw-r--  2.0 unx    40305 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/operators.py
--rw-rw-r--  2.0 unx    15055 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/plotting_utilities.py
--rw-rw-r--  2.0 unx     2821 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/utilities.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/utils_conga_2d.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/examples/__init__.py
--rw-rw-r--  2.0 unx    10277 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/examples/h1_source_pbms_conga_2d.py
--rw-rw-r--  2.0 unx     9531 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/examples/hcurl_eigen_pbms_conga_2d.py
--rw-rw-r--  2.0 unx    13635 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/examples/hcurl_source_pbms_conga_2d.py
--rw-rw-r--  2.0 unx    16876 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/examples/mixed_source_pbms_conga_2d.py
--rw-rw-r--  2.0 unx    12371 b- defN 24-Jan-11 07:23 psydac/feec/multipatch/examples/ppc_test_cases.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/feec/tests/__init__.py
--rw-rw-r--  2.0 unx      928 b- defN 24-Jan-11 07:23 psydac/feec/tests/test_axis_projection.py
--rw-rw-r--  2.0 unx    16911 b- defN 24-Jan-11 07:23 psydac/feec/tests/test_commuting_projections.py
--rw-rw-r--  2.0 unx    36496 b- defN 24-Jan-11 07:23 psydac/feec/tests/test_differentiation_matrices.py
--rw-rw-r--  2.0 unx     3361 b- defN 24-Jan-11 07:23 psydac/feec/tests/test_global_projectors.py
--rw-rw-r--  2.0 unx     6435 b- defN 24-Jan-11 07:23 psydac/feec/tests/test_projections_parallel.py
--rw-rw-r--  2.0 unx      212 b- defN 24-Jan-11 07:23 psydac/fem/__init__.py
--rw-rw-r--  2.0 unx     9768 b- defN 24-Jan-11 07:23 psydac/fem/basic.py
--rw-rw-r--  2.0 unx     2047 b- defN 24-Jan-11 07:23 psydac/fem/context.py
--rw-rw-r--  2.0 unx     5208 b- defN 24-Jan-11 07:23 psydac/fem/grid.py
--rw-rw-r--  2.0 unx    17099 b- defN 24-Jan-11 07:23 psydac/fem/partitioning.py
--rw-rw-r--  2.0 unx     3856 b- defN 24-Jan-11 07:23 psydac/fem/projectors.py
--rw-rw-r--  2.0 unx    17236 b- defN 24-Jan-16 07:14 psydac/fem/splines.py
--rw-rw-r--  2.0 unx    47037 b- defN 24-Jan-11 07:23 psydac/fem/tensor.py
--rw-rw-r--  2.0 unx    25381 b- defN 24-Jan-11 07:23 psydac/fem/vector.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/fem/tests/__init__.py
--rw-rw-r--  2.0 unx     2576 b- defN 24-Jan-11 07:23 psydac/fem/tests/analytical_profiles_1d.py
--rw-rw-r--  2.0 unx      868 b- defN 24-Jan-11 07:23 psydac/fem/tests/analytical_profiles_base.py
--rw-rw-r--  2.0 unx     4862 b- defN 24-Jan-11 07:23 psydac/fem/tests/splines_error_bounds.py
--rw-rw-r--  2.0 unx     4703 b- defN 24-Jan-11 07:23 psydac/fem/tests/test_eval_fields_parallel.py
--rw-rw-r--  2.0 unx     2009 b- defN 24-Jan-11 07:23 psydac/fem/tests/test_product.py
--rw-rw-r--  2.0 unx     4087 b- defN 24-Jan-11 07:23 psydac/fem/tests/test_spline_histopolation.py
--rw-rw-r--  2.0 unx     6539 b- defN 24-Jan-11 07:23 psydac/fem/tests/test_spline_interpolation.py
--rw-rw-r--  2.0 unx     4491 b- defN 24-Jan-11 07:23 psydac/fem/tests/test_splines.py
--rw-rw-r--  2.0 unx     1270 b- defN 24-Jan-11 07:23 psydac/fem/tests/test_splines_par.py
--rw-rw-r--  2.0 unx     1352 b- defN 24-Jan-11 07:23 psydac/fem/tests/utilities.py
--rw-rw-r--  2.0 unx      274 b- defN 24-Jan-11 07:23 psydac/linalg/__init__.py
--rw-rw-r--  2.0 unx    30353 b- defN 24-Jan-11 07:23 psydac/linalg/basic.py
--rw-rw-r--  2.0 unx    55525 b- defN 24-Jan-11 07:23 psydac/linalg/block.py
--rw-rw-r--  2.0 unx     6068 b- defN 24-Jan-11 07:23 psydac/linalg/direct_solvers.py
--rw-rw-r--  2.0 unx    10230 b- defN 24-Jan-11 07:23 psydac/linalg/fft.py
--rw-rw-r--  2.0 unx     8086 b- defN 24-Jan-11 07:23 psydac/linalg/kernels.py
--rw-rw-r--  2.0 unx    30680 b- defN 24-Jan-11 07:23 psydac/linalg/kron.py
--rw-rw-r--  2.0 unx    61867 b- defN 24-Jan-11 07:23 psydac/linalg/solvers.py
--rw-rw-r--  2.0 unx    94871 b- defN 24-Jan-11 07:23 psydac/linalg/stencil.py
--rw-rw-r--  2.0 unx     3467 b- defN 24-Jan-11 07:23 psydac/linalg/topetsc.py
--rw-rw-r--  2.0 unx     6975 b- defN 24-Jan-11 07:23 psydac/linalg/utilities.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/linalg/tests/__init__.py
--rw-rw-r--  2.0 unx    47863 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_block.py
--rw-rw-r--  2.0 unx     3841 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_fft.py
--rw-rw-r--  2.0 unx    15009 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_kron_direct_solver.py
--rw-rw-r--  2.0 unx     3750 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_kron_stencil_matrix.py
--rw-rw-r--  2.0 unx    33513 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_linalg.py
--rw-rw-r--  2.0 unx     5850 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_solvers.py
--rw-rw-r--  2.0 unx    15175 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_stencil_interface_matrix.py
--rw-rw-r--  2.0 unx   111604 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_stencil_matrix.py
--rw-rw-r--  2.0 unx    27060 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_stencil_vector.py
--rw-rw-r--  2.0 unx    16477 b- defN 24-Jan-11 07:23 psydac/linalg/tests/test_stencil_vector_space.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/mapping/__init__.py
--rw-rw-r--  2.0 unx    53406 b- defN 24-Jan-11 07:23 psydac/mapping/discrete.py
--rw-rw-r--  2.0 unx     4471 b- defN 24-Jan-11 07:23 psydac/mapping/discrete_gallery.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/mapping/tests/__init__.py
--rw-rw-r--  2.0 unx    10865 b- defN 24-Jan-11 07:23 psydac/mapping/tests/test_discrete_mapping.py
--rw-rw-r--  2.0 unx     5604 b- defN 24-Jan-11 07:23 psydac/mapping/tests/visual_test_discrete_mapping_2d.py
--rw-rw-r--  2.0 unx     5063 b- defN 24-Jan-11 07:23 psydac/mapping/tests/visual_test_discrete_mapping_3d_surface.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/polar/__init__.py
--rw-rw-r--  2.0 unx     2690 b- defN 24-Jan-11 07:23 psydac/polar/c1_cart.py
--rw-rw-r--  2.0 unx    11111 b- defN 24-Jan-11 07:23 psydac/polar/c1_linops.py
--rw-rw-r--  2.0 unx     9617 b- defN 24-Jan-11 07:23 psydac/polar/c1_projections.py
--rw-rw-r--  2.0 unx     1651 b- defN 24-Jan-11 07:23 psydac/polar/c1_spaces.py
--rw-rw-r--  2.0 unx    11622 b- defN 24-Jan-11 07:23 psydac/polar/dense.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/polar/tests/__init__.py
--rw-rw-r--  2.0 unx     3537 b- defN 24-Jan-11 07:23 psydac/polar/tests/test_c1_linops.py
--rw-rw-r--  2.0 unx     5008 b- defN 24-Jan-11 07:23 psydac/polar/tests/test_c1_projections.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/pyccel/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/__init__.py
--rw-rw-r--  2.0 unx     1078 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/basic.py
--rw-rw-r--  2.0 unx    13580 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/builtins.py
--rw-rw-r--  2.0 unx   150848 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/core.py
--rw-rw-r--  2.0 unx     8608 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/datatypes.py
--rw-rw-r--  2.0 unx     1670 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/functionalexpr.py
--rw-rw-r--  2.0 unx     5716 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/mathext.py
--rw-rw-r--  2.0 unx     2399 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/numbers.py
--rw-rw-r--  2.0 unx    38628 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/numpyext.py
--rw-rw-r--  2.0 unx      295 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/singleton.py
--rw-rw-r--  2.0 unx     1398 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/type_inference.py
--rw-rw-r--  2.0 unx     8933 b- defN 24-Jan-11 07:23 psydac/pyccel/ast/utilities.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/pyccel/codegen/__init__.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/pyccel/codegen/printing/__init__.py
--rw-rw-r--  2.0 unx    12671 b- defN 24-Jan-11 07:23 psydac/pyccel/codegen/printing/pycode.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/pyccel/errors/__init__.py
--rw-rw-r--  2.0 unx    10046 b- defN 24-Jan-11 07:23 psydac/pyccel/errors/errors.py
--rw-rw-r--  2.0 unx     8262 b- defN 24-Jan-11 07:23 psydac/pyccel/errors/messages.py
--rw-rw-r--  2.0 unx        0 b- defN 24-Jan-11 07:23 psydac/pyccel/symbolic/__init__.py
--rw-rw-r--  2.0 unx     4084 b- defN 24-Jan-11 07:23 psydac/pyccel/symbolic/lambdify.py
--rw-rw-r--  2.0 unx       68 b- defN 24-Jan-11 07:23 psydac/utilities/__init__.py
--rw-rw-r--  2.0 unx     2487 b- defN 24-Jan-11 07:23 psydac/utilities/quadratures.py
--rw-rw-r--  2.0 unx     5432 b- defN 24-Jan-11 07:23 psydac/utilities/utils.py
--rw-rw-r--  2.0 unx     1994 b- defN 24-Jan-11 07:23 psydac/utilities/vtk.py
--rw-rw-r--  2.0 unx      287 b- defN 24-Feb-14 08:59 psydac-0.1.9.dist-info/AUTHORS
--rw-rw-r--  2.0 unx     1081 b- defN 24-Feb-14 08:59 psydac-0.1.9.dist-info/LICENSE
--rw-rw-r--  2.0 unx     7547 b- defN 24-Feb-14 08:59 psydac-0.1.9.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 24-Feb-14 08:59 psydac-0.1.9.dist-info/WHEEL
--rw-rw-r--  2.0 unx       53 b- defN 24-Feb-14 08:59 psydac-0.1.9.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx        7 b- defN 24-Feb-14 08:59 psydac-0.1.9.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    19966 b- defN 24-Feb-14 08:59 psydac-0.1.9.dist-info/RECORD
-224 files, 3148879 bytes uncompressed, 587405 bytes compressed:  81.4%
+Zip file size: 622468 bytes, number of entries: 224
+-rw-rw-r--  2.0 unx      410 b- defN 24-Feb-28 12:42 psydac/__init__.py
+-rw-rw-r--  2.0 unx       20 b- defN 24-Feb-28 12:42 psydac/version.py
+-rw-rw-r--  2.0 unx      335 b- defN 24-Feb-28 12:42 psydac/api/__init__.py
+-rw-rw-r--  2.0 unx    11533 b- defN 24-Feb-28 12:42 psydac/api/basic.py
+-rw-rw-r--  2.0 unx    20091 b- defN 24-Feb-28 12:42 psydac/api/discretization.py
+-rw-rw-r--  2.0 unx     8339 b- defN 24-Feb-28 12:42 psydac/api/equation.py
+-rw-rw-r--  2.0 unx     9435 b- defN 24-Feb-28 12:42 psydac/api/essential_bc.py
+-rw-rw-r--  2.0 unx     5152 b- defN 24-Feb-28 12:42 psydac/api/expr.py
+-rw-rw-r--  2.0 unx     5403 b- defN 24-Feb-28 12:42 psydac/api/feec.py
+-rw-rw-r--  2.0 unx    69052 b- defN 24-Feb-28 12:42 psydac/api/fem.py
+-rw-rw-r--  2.0 unx    21262 b- defN 24-Feb-28 12:42 psydac/api/glt.py
+-rw-rw-r--  2.0 unx     9392 b- defN 24-Feb-28 12:42 psydac/api/grid.py
+-rw-rw-r--  2.0 unx   125554 b- defN 24-Feb-28 12:42 psydac/api/postprocessing.py
+-rw-rw-r--  2.0 unx     1857 b- defN 24-Feb-28 12:42 psydac/api/settings.py
+-rw-rw-r--  2.0 unx     2045 b- defN 24-Feb-28 12:42 psydac/api/utilities.py
+-rw-rw-r--  2.0 unx      237 b- defN 24-Feb-28 12:42 psydac/api/ast/__init__.py
+-rw-rw-r--  2.0 unx     2052 b- defN 24-Feb-28 12:42 psydac/api/ast/basic.py
+-rw-rw-r--  2.0 unx    13497 b- defN 24-Feb-28 12:42 psydac/api/ast/evaluation.py
+-rw-rw-r--  2.0 unx    17993 b- defN 24-Feb-28 12:42 psydac/api/ast/expr.py
+-rw-rw-r--  2.0 unx    81291 b- defN 24-Feb-28 12:42 psydac/api/ast/fem.py
+-rw-rw-r--  2.0 unx    25475 b- defN 24-Feb-28 12:42 psydac/api/ast/glt.py
+-rw-rw-r--  2.0 unx    26193 b- defN 24-Feb-28 12:42 psydac/api/ast/linalg.py
+-rw-rw-r--  2.0 unx     9259 b- defN 24-Feb-28 12:42 psydac/api/ast/linalg_kernels.py
+-rw-rw-r--  2.0 unx    67015 b- defN 24-Feb-28 12:42 psydac/api/ast/nodes.py
+-rw-rw-r--  2.0 unx    83536 b- defN 24-Feb-28 12:42 psydac/api/ast/parser.py
+-rw-rw-r--  2.0 unx    31637 b- defN 24-Feb-28 12:42 psydac/api/ast/utilities.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/api/ast/tests/__init__.py
+-rw-rw-r--  2.0 unx     2265 b- defN 24-Feb-28 12:42 psydac/api/ast/tests/boundary.py
+-rw-rw-r--  2.0 unx     2563 b- defN 24-Feb-28 12:42 psydac/api/ast/tests/poisson.py
+-rw-rw-r--  2.0 unx     2697 b- defN 24-Feb-28 12:42 psydac/api/ast/tests/system_1.py
+-rw-rw-r--  2.0 unx     2274 b- defN 24-Feb-28 12:42 psydac/api/ast/tests/system_2.py
+-rw-rw-r--  2.0 unx     1854 b- defN 24-Feb-28 12:42 psydac/api/ast/tests/system_3.py
+-rw-rw-r--  2.0 unx    17349 b- defN 24-Feb-28 12:42 psydac/api/ast/tests/test_nodes.py
+-rw-rw-r--  2.0 unx       39 b- defN 24-Feb-28 12:42 psydac/api/printing/__init__.py
+-rw-rw-r--  2.0 unx     5947 b- defN 24-Feb-28 12:42 psydac/api/printing/pycode.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/api/tests/__init__.py
+-rw-rw-r--  2.0 unx     9105 b- defN 24-Feb-28 12:42 psydac/api/tests/build_domain.py
+-rw-rw-r--  2.0 unx     5762 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_biharmonic.py
+-rw-rw-r--  2.0 unx    19250 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_complex.py
+-rw-rw-r--  2.0 unx     4697 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_laplace.py
+-rw-rw-r--  2.0 unx     7561 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_mapping_biharmonic.py
+-rw-rw-r--  2.0 unx     6501 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_mapping_laplace.py
+-rw-rw-r--  2.0 unx    31950 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_mapping_poisson.py
+-rw-rw-r--  2.0 unx    10465 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_multipatch_mapping_maxwell.py
+-rw-rw-r--  2.0 unx    15593 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_multipatch_mapping_poisson.py
+-rw-rw-r--  2.0 unx     7170 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_multipatch_poisson.py
+-rw-rw-r--  2.0 unx    16354 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_navier_stokes.py
+-rw-rw-r--  2.0 unx    15404 b- defN 24-Feb-28 12:42 psydac/api/tests/test_2d_poisson.py
+-rw-rw-r--  2.0 unx     2628 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_1d_compatible_spaces.py
+-rw-rw-r--  2.0 unx    19393 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_2d_compatible_spaces.py
+-rw-rw-r--  2.0 unx    11809 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_2d_fields.py
+-rw-rw-r--  2.0 unx     2740 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_2d_scalar_analytical_mapping.py
+-rw-rw-r--  2.0 unx     4875 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_2d_system.py
+-rw-rw-r--  2.0 unx     2990 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_2d_vector.py
+-rw-rw-r--  2.0 unx     3947 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_2d_vector_mapping.py
+-rw-rw-r--  2.0 unx     3701 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_2d_vector_multipatch_mapping.py
+-rw-rw-r--  2.0 unx    10726 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_3d_scalar.py
+-rw-rw-r--  2.0 unx    16969 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_3d_scalar_mapping.py
+-rw-rw-r--  2.0 unx     3169 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_3d_vector.py
+-rw-rw-r--  2.0 unx     4162 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_3d_vector_mapping.py
+-rw-rw-r--  2.0 unx     1520 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_expr_2d_scalar.py
+-rw-rw-r--  2.0 unx    24942 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_feec_1d.py
+-rw-rw-r--  2.0 unx    32543 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_feec_2d.py
+-rw-rw-r--  2.0 unx    12336 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_feec_3d.py
+-rw-rw-r--  2.0 unx     6286 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_glt_2d_scalar.py
+-rw-rw-r--  2.0 unx     3255 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_glt_2d_scalar_mapping.py
+-rw-rw-r--  2.0 unx     2226 b- defN 24-Feb-28 12:42 psydac/api/tests/test_api_glt_2d_vector.py
+-rw-rw-r--  2.0 unx    16854 b- defN 24-Feb-28 12:42 psydac/api/tests/test_assembly.py
+-rw-rw-r--  2.0 unx     2138 b- defN 24-Feb-28 12:42 psydac/api/tests/test_equation.py
+-rw-rw-r--  2.0 unx    34228 b- defN 24-Feb-28 12:42 psydac/api/tests/test_postprocessing.py
+-rw-rw-r--  2.0 unx     1554 b- defN 24-Feb-28 12:42 psydac/api/tests/test_quadorder.py
+-rw-rw-r--  2.0 unx      669 b- defN 24-Feb-28 12:42 psydac/api/tests/utils.py
+-rw-rw-r--  2.0 unx      161 b- defN 24-Feb-28 12:42 psydac/cad/__init__.py
+-rw-rw-r--  2.0 unx     6786 b- defN 24-Feb-28 12:42 psydac/cad/cad.py
+-rw-rw-r--  2.0 unx     5485 b- defN 24-Feb-28 12:42 psydac/cad/gallery.py
+-rw-rw-r--  2.0 unx    28452 b- defN 24-Feb-28 12:42 psydac/cad/geometry.py
+-rw-rw-r--  2.0 unx     4774 b- defN 24-Feb-28 12:42 psydac/cad/multipatch.py
+-rw-rw-r--  2.0 unx     1242 b- defN 24-Feb-28 12:42 psydac/cad/utils.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/cad/tests/__init__.py
+-rw-rw-r--  2.0 unx      981 b- defN 24-Feb-28 12:42 psydac/cad/tests/geo_Lshaped_C1.txt
+-rw-rw-r--  2.0 unx     9881 b- defN 24-Feb-28 12:42 psydac/cad/tests/test_geometry.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/cmd/__init__.py
+-rw-rw-r--  2.0 unx     3629 b- defN 24-Feb-28 12:42 psydac/cmd/mesh.py
+-rw-rw-r--  2.0 unx      210 b- defN 24-Feb-28 12:42 psydac/core/__init__.py
+-rw-rw-r--  2.0 unx     2163 b- defN 24-Feb-28 12:42 psydac/core/arrays.py
+-rw-rw-r--  2.0 unx    34731 b- defN 24-Feb-28 12:42 psydac/core/bsplines.py
+-rw-rw-r--  2.0 unx    37821 b- defN 24-Feb-28 12:42 psydac/core/bsplines_pyccel.py
+-rw-rw-r--  2.0 unx   210566 b- defN 24-Feb-28 12:42 psydac/core/kernels.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/core/tests/__init__.py
+-rw-rw-r--  2.0 unx      585 b- defN 24-Feb-28 12:42 psydac/core/tests/test_arrays.py
+-rw-rw-r--  2.0 unx     9356 b- defN 24-Feb-28 12:42 psydac/core/tests/test_bsplines.py
+-rw-rw-r--  2.0 unx    33374 b- defN 24-Feb-28 12:42 psydac/core/tests/test_bsplines_pyccel.py
+-rw-rw-r--  2.0 unx    31846 b- defN 24-Feb-28 12:42 psydac/core/tests/test_kernels.py
+-rw-rw-r--  2.0 unx       48 b- defN 24-Feb-28 12:42 psydac/ddm/__init__.py
+-rw-rw-r--  2.0 unx     2508 b- defN 24-Feb-28 12:42 psydac/ddm/basic.py
+-rw-rw-r--  2.0 unx    13337 b- defN 24-Feb-28 12:42 psydac/ddm/blocking_data_exchanger.py
+-rw-rw-r--  2.0 unx    74194 b- defN 24-Feb-28 12:42 psydac/ddm/cart.py
+-rw-rw-r--  2.0 unx     4780 b- defN 24-Feb-28 12:42 psydac/ddm/interface_data_exchanger.py
+-rw-rw-r--  2.0 unx    12936 b- defN 24-Feb-28 12:42 psydac/ddm/nonblocking_data_exchanger.py
+-rw-rw-r--  2.0 unx     6571 b- defN 24-Feb-28 12:42 psydac/ddm/partition.py
+-rw-rw-r--  2.0 unx     3356 b- defN 24-Feb-28 12:42 psydac/ddm/petsc.py
+-rw-rw-r--  2.0 unx     1044 b- defN 24-Feb-28 12:42 psydac/ddm/utilities.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/ddm/tests/__init__.py
+-rw-rw-r--  2.0 unx     4673 b- defN 24-Feb-28 12:42 psydac/ddm/tests/test_cart_1d.py
+-rw-rw-r--  2.0 unx     5522 b- defN 24-Feb-28 12:42 psydac/ddm/tests/test_cart_2d.py
+-rw-rw-r--  2.0 unx     5579 b- defN 24-Feb-28 12:42 psydac/ddm/tests/test_cart_3d.py
+-rw-rw-r--  2.0 unx     7558 b- defN 24-Feb-28 12:42 psydac/ddm/tests/test_multicart_2d.py
+-rw-rw-r--  2.0 unx     4012 b- defN 24-Feb-28 12:42 psydac/ddm/tests/test_partition.py
+-rw-rw-r--  2.0 unx       63 b- defN 24-Feb-28 12:42 psydac/feec/__init__.py
+-rw-rw-r--  2.0 unx    25809 b- defN 24-Feb-28 12:42 psydac/feec/derivatives.py
+-rw-rw-r--  2.0 unx     8012 b- defN 24-Feb-28 12:42 psydac/feec/dof_kernels.py
+-rw-rw-r--  2.0 unx    41057 b- defN 24-Feb-28 12:42 psydac/feec/global_projectors.py
+-rw-rw-r--  2.0 unx    13609 b- defN 24-Feb-28 12:42 psydac/feec/pull_push.py
+-rw-rw-r--  2.0 unx    19543 b- defN 24-Feb-28 12:42 psydac/feec/pushforward.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/__init__.py
+-rw-rw-r--  2.0 unx    10466 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/api.py
+-rw-rw-r--  2.0 unx     6652 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/fem_linear_operators.py
+-rw-rw-r--  2.0 unx    30966 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/multipatch_domain_utilities.py
+-rw-rw-r--  2.0 unx    40305 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/operators.py
+-rw-rw-r--  2.0 unx    15055 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/plotting_utilities.py
+-rw-rw-r--  2.0 unx     2821 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/utilities.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/utils_conga_2d.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/examples/__init__.py
+-rw-rw-r--  2.0 unx    10277 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/examples/h1_source_pbms_conga_2d.py
+-rw-rw-r--  2.0 unx     9531 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/examples/hcurl_eigen_pbms_conga_2d.py
+-rw-rw-r--  2.0 unx    13635 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/examples/hcurl_source_pbms_conga_2d.py
+-rw-rw-r--  2.0 unx    16876 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/examples/mixed_source_pbms_conga_2d.py
+-rw-rw-r--  2.0 unx    12371 b- defN 24-Feb-28 12:42 psydac/feec/multipatch/examples/ppc_test_cases.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/feec/tests/__init__.py
+-rw-rw-r--  2.0 unx      928 b- defN 24-Feb-28 12:42 psydac/feec/tests/test_axis_projection.py
+-rw-rw-r--  2.0 unx    16911 b- defN 24-Feb-28 12:42 psydac/feec/tests/test_commuting_projections.py
+-rw-rw-r--  2.0 unx    36496 b- defN 24-Feb-28 12:42 psydac/feec/tests/test_differentiation_matrices.py
+-rw-rw-r--  2.0 unx     3361 b- defN 24-Feb-28 12:42 psydac/feec/tests/test_global_projectors.py
+-rw-rw-r--  2.0 unx     6435 b- defN 24-Feb-28 12:42 psydac/feec/tests/test_projections_parallel.py
+-rw-rw-r--  2.0 unx      212 b- defN 24-Feb-28 12:42 psydac/fem/__init__.py
+-rw-rw-r--  2.0 unx     9768 b- defN 24-Feb-28 12:42 psydac/fem/basic.py
+-rw-rw-r--  2.0 unx     2047 b- defN 24-Feb-28 12:42 psydac/fem/context.py
+-rw-rw-r--  2.0 unx     5208 b- defN 24-Feb-28 12:42 psydac/fem/grid.py
+-rw-rw-r--  2.0 unx    17099 b- defN 24-Feb-28 12:42 psydac/fem/partitioning.py
+-rw-rw-r--  2.0 unx     3856 b- defN 24-Feb-28 12:42 psydac/fem/projectors.py
+-rw-rw-r--  2.0 unx    17236 b- defN 24-Feb-28 12:42 psydac/fem/splines.py
+-rw-rw-r--  2.0 unx    47037 b- defN 24-Feb-28 12:42 psydac/fem/tensor.py
+-rw-rw-r--  2.0 unx    25381 b- defN 24-Feb-28 12:42 psydac/fem/vector.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/fem/tests/__init__.py
+-rw-rw-r--  2.0 unx     2576 b- defN 24-Feb-28 12:42 psydac/fem/tests/analytical_profiles_1d.py
+-rw-rw-r--  2.0 unx      868 b- defN 24-Feb-28 12:42 psydac/fem/tests/analytical_profiles_base.py
+-rw-rw-r--  2.0 unx     4862 b- defN 24-Feb-28 12:42 psydac/fem/tests/splines_error_bounds.py
+-rw-rw-r--  2.0 unx     4703 b- defN 24-Feb-28 12:42 psydac/fem/tests/test_eval_fields_parallel.py
+-rw-rw-r--  2.0 unx     2009 b- defN 24-Feb-28 12:42 psydac/fem/tests/test_product.py
+-rw-rw-r--  2.0 unx     4087 b- defN 24-Feb-28 12:42 psydac/fem/tests/test_spline_histopolation.py
+-rw-rw-r--  2.0 unx     6539 b- defN 24-Feb-28 12:42 psydac/fem/tests/test_spline_interpolation.py
+-rw-rw-r--  2.0 unx     4491 b- defN 24-Feb-28 12:42 psydac/fem/tests/test_splines.py
+-rw-rw-r--  2.0 unx     1270 b- defN 24-Feb-28 12:42 psydac/fem/tests/test_splines_par.py
+-rw-rw-r--  2.0 unx     1352 b- defN 24-Feb-28 12:42 psydac/fem/tests/utilities.py
+-rw-rw-r--  2.0 unx      274 b- defN 24-Feb-28 12:42 psydac/linalg/__init__.py
+-rw-rw-r--  2.0 unx    29704 b- defN 24-Mar-12 13:07 psydac/linalg/basic.py
+-rw-rw-r--  2.0 unx    57107 b- defN 24-Feb-28 14:21 psydac/linalg/block.py
+-rw-rw-r--  2.0 unx     6068 b- defN 24-Feb-28 12:42 psydac/linalg/direct_solvers.py
+-rw-rw-r--  2.0 unx    10230 b- defN 24-Feb-28 12:42 psydac/linalg/fft.py
+-rw-rw-r--  2.0 unx     8086 b- defN 24-Feb-28 12:42 psydac/linalg/kernels.py
+-rw-rw-r--  2.0 unx    30680 b- defN 24-Feb-28 12:42 psydac/linalg/kron.py
+-rw-rw-r--  2.0 unx    64554 b- defN 24-Mar-12 13:34 psydac/linalg/solvers.py
+-rw-rw-r--  2.0 unx   102348 b- defN 24-Feb-28 12:52 psydac/linalg/stencil.py
+-rw-rw-r--  2.0 unx     3467 b- defN 24-Feb-28 12:42 psydac/linalg/topetsc.py
+-rw-rw-r--  2.0 unx     6975 b- defN 24-Feb-28 12:42 psydac/linalg/utilities.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/linalg/tests/__init__.py
+-rw-rw-r--  2.0 unx    47863 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_block.py
+-rw-rw-r--  2.0 unx     3841 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_fft.py
+-rw-rw-r--  2.0 unx    15009 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_kron_direct_solver.py
+-rw-rw-r--  2.0 unx     3750 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_kron_stencil_matrix.py
+-rw-rw-r--  2.0 unx    33513 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_linalg.py
+-rw-rw-r--  2.0 unx     5850 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_solvers.py
+-rw-rw-r--  2.0 unx    15175 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_stencil_interface_matrix.py
+-rw-rw-r--  2.0 unx   111604 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_stencil_matrix.py
+-rw-rw-r--  2.0 unx    27060 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_stencil_vector.py
+-rw-rw-r--  2.0 unx    16477 b- defN 24-Feb-28 12:42 psydac/linalg/tests/test_stencil_vector_space.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/mapping/__init__.py
+-rw-rw-r--  2.0 unx    53406 b- defN 24-Feb-28 12:42 psydac/mapping/discrete.py
+-rw-rw-r--  2.0 unx     4471 b- defN 24-Feb-28 12:42 psydac/mapping/discrete_gallery.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/mapping/tests/__init__.py
+-rw-rw-r--  2.0 unx    10865 b- defN 24-Feb-28 12:42 psydac/mapping/tests/test_discrete_mapping.py
+-rw-rw-r--  2.0 unx     5604 b- defN 24-Feb-28 12:42 psydac/mapping/tests/visual_test_discrete_mapping_2d.py
+-rw-rw-r--  2.0 unx     5063 b- defN 24-Feb-28 12:42 psydac/mapping/tests/visual_test_discrete_mapping_3d_surface.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/polar/__init__.py
+-rw-rw-r--  2.0 unx     2690 b- defN 24-Feb-28 12:42 psydac/polar/c1_cart.py
+-rw-rw-r--  2.0 unx    11111 b- defN 24-Feb-28 12:42 psydac/polar/c1_linops.py
+-rw-rw-r--  2.0 unx     9617 b- defN 24-Feb-28 12:42 psydac/polar/c1_projections.py
+-rw-rw-r--  2.0 unx     1651 b- defN 24-Feb-28 12:42 psydac/polar/c1_spaces.py
+-rw-rw-r--  2.0 unx    11622 b- defN 24-Feb-28 12:42 psydac/polar/dense.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/polar/tests/__init__.py
+-rw-rw-r--  2.0 unx     3537 b- defN 24-Feb-28 12:42 psydac/polar/tests/test_c1_linops.py
+-rw-rw-r--  2.0 unx     5008 b- defN 24-Feb-28 12:42 psydac/polar/tests/test_c1_projections.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/pyccel/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/__init__.py
+-rw-rw-r--  2.0 unx     1078 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/basic.py
+-rw-rw-r--  2.0 unx    13580 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/builtins.py
+-rw-rw-r--  2.0 unx   150848 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/core.py
+-rw-rw-r--  2.0 unx     8608 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/datatypes.py
+-rw-rw-r--  2.0 unx     1670 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/functionalexpr.py
+-rw-rw-r--  2.0 unx     5716 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/mathext.py
+-rw-rw-r--  2.0 unx     2399 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/numbers.py
+-rw-rw-r--  2.0 unx    38628 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/numpyext.py
+-rw-rw-r--  2.0 unx      295 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/singleton.py
+-rw-rw-r--  2.0 unx     1398 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/type_inference.py
+-rw-rw-r--  2.0 unx     8933 b- defN 24-Feb-28 12:42 psydac/pyccel/ast/utilities.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/pyccel/codegen/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/pyccel/codegen/printing/__init__.py
+-rw-rw-r--  2.0 unx    12671 b- defN 24-Feb-28 12:42 psydac/pyccel/codegen/printing/pycode.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/pyccel/errors/__init__.py
+-rw-rw-r--  2.0 unx    10046 b- defN 24-Feb-28 12:42 psydac/pyccel/errors/errors.py
+-rw-rw-r--  2.0 unx     8262 b- defN 24-Feb-28 12:42 psydac/pyccel/errors/messages.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Feb-28 12:42 psydac/pyccel/symbolic/__init__.py
+-rw-rw-r--  2.0 unx     4084 b- defN 24-Feb-28 12:42 psydac/pyccel/symbolic/lambdify.py
+-rw-rw-r--  2.0 unx       68 b- defN 24-Feb-28 12:42 psydac/utilities/__init__.py
+-rw-rw-r--  2.0 unx     2487 b- defN 24-Feb-28 12:42 psydac/utilities/quadratures.py
+-rw-rw-r--  2.0 unx     6213 b- defN 24-Mar-12 13:16 psydac/utilities/utils.py
+-rw-rw-r--  2.0 unx     1994 b- defN 24-Feb-28 12:42 psydac/utilities/vtk.py
+-rw-rw-r--  2.0 unx      287 b- defN 24-Mar-12 13:35 psydac-0.1.12.dist-info/AUTHORS
+-rw-rw-r--  2.0 unx     1081 b- defN 24-Mar-12 13:35 psydac-0.1.12.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     7548 b- defN 24-Mar-12 13:35 psydac-0.1.12.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 24-Mar-12 13:35 psydac-0.1.12.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       53 b- defN 24-Mar-12 13:35 psydac-0.1.12.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx        7 b- defN 24-Mar-12 13:35 psydac-0.1.12.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    19974 b- defN 24-Mar-12 13:35 psydac-0.1.12.dist-info/RECORD
+224 files, 3160766 bytes uncompressed, 590874 bytes compressed:  81.3%
```

#### zipnote «TEMP»/diffoscope_8uf4hx9s_/tmpxuijwboz_.zip

```diff
@@ -645,29 +645,29 @@
 
 Filename: psydac/utilities/utils.py
 Comment: 
 
 Filename: psydac/utilities/vtk.py
 Comment: 
 
-Filename: psydac-0.1.9.dist-info/AUTHORS
+Filename: psydac-0.1.12.dist-info/AUTHORS
 Comment: 
 
-Filename: psydac-0.1.9.dist-info/LICENSE
+Filename: psydac-0.1.12.dist-info/LICENSE
 Comment: 
 
-Filename: psydac-0.1.9.dist-info/METADATA
+Filename: psydac-0.1.12.dist-info/METADATA
 Comment: 
 
-Filename: psydac-0.1.9.dist-info/WHEEL
+Filename: psydac-0.1.12.dist-info/WHEEL
 Comment: 
 
-Filename: psydac-0.1.9.dist-info/entry_points.txt
+Filename: psydac-0.1.12.dist-info/entry_points.txt
 Comment: 
 
-Filename: psydac-0.1.9.dist-info/top_level.txt
+Filename: psydac-0.1.12.dist-info/top_level.txt
 Comment: 
 
-Filename: psydac-0.1.9.dist-info/RECORD
+Filename: psydac-0.1.12.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

#### psydac/linalg/basic.py

```diff
@@ -827,50 +827,59 @@
             for i in range(self._factorial):
                 out = self._operator.dot(out)
         return out
 
 #===============================================================================
 class InverseLinearOperator(LinearOperator):
     """
-    Iterative solver for square linear system Ax=b, where x and b belong to (normed)
+    Abstract base class for the (approximate) inverse A_inv := A^{-1} of a
+    square matrix A. The result of A_inv.dot(b) is the (approximate) solution x
+    of the linear system A x = b, where x and b belong to the same (normed)
     vector space V.
-    
+
+    We assume that the linear system is solved by an iterative method, which
+    needs a first guess `x0` and an exit condition based on `tol` and `maxiter`.
+
+    Concrete subclasses of this class must implement the `dot` method and take
+    care of any internal storage which might be necessary.
+
     Parameters
     ----------
     A : psydac.linalg.basic.LinearOperator
         Left-hand-side matrix A of linear system.
-
+        
     x0 : psydac.linalg.basic.Vector
         First guess of solution for iterative solver (optional).
-
+        
     tol : float
         Absolute tolerance for L2-norm of residual r = A*x - b.
-
+        
     maxiter: int
         Maximum number of iterations.
-
+        
     verbose : bool
         If True, L2-norm of residual r is printed at each iteration.
     """
 
     def __init__(self, A, **kwargs):
-        
+
         assert isinstance(A, LinearOperator)
         assert A.domain.dimension == A.codomain.dimension
         domain = A.codomain
         codomain = A.domain
-        
+
         if kwargs['x0'] is None:
             kwargs['x0'] = codomain.zeros()
-        
+
         self._A = A
         self._domain = domain
         self._codomain = codomain
+
+        self._check_options(**kwargs)
         self._options = kwargs
-        self._check_options(**self._options)
 
     @property
     def domain(self):
         return self._domain
 
     @property
     def codomain(self):
@@ -878,36 +887,36 @@
 
     @property
     def dtype(self):
         return None
 
     @property
     def linop(self):
+        """
+        The linear operator L of which this object is the inverse L^{-1}.
+
+        The linear operator L can be modified in place, or replaced entirely
+        through the setter. A substitution should only be made in cases where
+        no other options are viable, as it breaks the one-to-one map between
+        the original linear operator L (passed to the constructor) and the
+        current `InverseLinearOperator` object L^{-1}. Use with extreme care!
+
+        """
         return self._A
     
     @linop.setter
     def linop(self, a):
         assert isinstance(a, LinearOperator)
         assert a.domain is self.domain
         assert a.codomain is self.codomain
         self._A = a
 
-    @property
-    def options(self):
-        return self._options
-    
-    @property
-    @abstractmethod
-    def solver(self):
-        "String that identifies the solver."
-        pass
-    
     def _check_options(self, **kwargs):
         for key, value in kwargs.items():
-            
+
             if key == 'x0':
                 if value is not None:
                     assert isinstance(value, Vector), "x0 must be a Vector or None"
                     assert value.space == self.codomain, "x0 belongs to the wrong VectorSpace"
             elif key == 'tol':
                 assert is_real(value), "tol must be a real number"
                 assert value > 0, "tol must be positive"
@@ -922,84 +931,47 @@
 
     def tosparse(self):
         raise NotImplementedError('tosparse() is not defined for InverseLinearOperators.')
 
     def get_info(self):
         return self._info
 
-    def get_options(self):
-        return self._options.copy()
+    def get_options(self, key=None):
+        """Get a copy of all the solver options, or a specific value of interest.
+
+        Parameters
+        ----------
+        key : str | None
+            Name of the specific option of interest (default: None).
+
+        Returns
+        -------
+        dict | type(self._options['key']) | None
+            If `key` is given, get the specific option of interest. If there is
+            no such option, `None` is returned instead. If `key` is not given,
+            get a copy of all the solver options in a dictionary.
+
+        """
+        if key is None:
+            return self._options.copy()
+        else:
+            return self._options.get(key)
 
     def set_options(self, **kwargs):
+        """Set the solver options by passing keyword arguments.
+        """
         self._check_options(**kwargs)
         self._options.update(kwargs)
 
     def transpose(self, conjugate=False):
-        from psydac.linalg.solvers import inverse
-        
-        At = self.linop.transpose(conjugate=conjugate)
-        solver = self.solver
+        cls     = type(self)
+        At      = self.linop.transpose(conjugate=conjugate)
         options = self._options
-        return inverse(At, solver, **options)
-
-    @staticmethod
-    def jacobi(A, b, out=None):
-        """
-        Jacobi preconditioner.
-
-        A : psydac.linalg.stencil.StencilMatrix | psydac.linalg.block.BlockLinearOperator
-            Left-hand-side matrix A of linear system.
-
-        b : psydac.linalg.stencil.StencilVector | psydac.linalg.block.BlockVector
-            Right-hand-side vector of linear system.
+        return cls(At, **options)
 
-        Returns
-        -------
-        x : psydac.linalg.stencil.StencilVector | psydac.linalg.block.BlockVector
-            Preconditioner solution
-
-        """
-        from psydac.linalg.block   import BlockLinearOperator, BlockVector
-        from psydac.linalg.stencil import StencilMatrix, StencilVector
-
-        # In case A is None we return a zero vector
-        if A is None:
-            return b.space.zeros()
-
-        # Sanity checks
-        assert isinstance(A, (StencilMatrix, BlockLinearOperator))
-        assert isinstance(b, (StencilVector, BlockVector))
-        assert A.codomain.dimension == A.domain.dimension
-        assert A.codomain == b.space
-
-        #-------------------------------------------------------------
-        # Handle the case of a block linear system
-        if isinstance(A, BlockLinearOperator):
-            if out is not None:
-                for i, bi in enumerate(b.blocks):
-                    InverseLinearOperator.jacobi(A[i,i], bi, out=out[i])
-                return out
-            else:
-                x = [InverseLinearOperator.jacobi(A[i, i], bi) for i, bi in enumerate(b.blocks)]
-                y = BlockVector(b.space, blocks=x)
-                return y
-        #-------------------------------------------------------------
-
-        V = b.space
-        i = tuple(slice(s, e + 1) for s, e in zip(V.starts, V.ends))
-
-        if out is not None:
-            b.copy(out=out)
-            out[i] /= A.diagonal()
-            out.update_ghost_regions()
-        else:
-            out = b.copy()
-            out[i] /= A.diagonal()
-            out.update_ghost_regions()
-            return out
 
 #===============================================================================
 class LinearSolver(ABC):
     """
     Solver for square linear system Ax=b, where x and b belong to (normed)
     vector space V.
```

#### psydac/linalg/block.py

```diff
@@ -742,14 +742,54 @@
             mat._blocks_as_args = [mat._blocks[key]._data for key in self._blocks]
             mat._backend = self._backend
         return mat
 
     #--------------------------------------
     # New properties/methods
     #--------------------------------------
+    def diagonal(self, *, inverse = False, sqrt = False, out = None):
+        """Get the coefficients on the main diagonal as another BlockLinearOperator object.
+        Parameters
+        ----------
+        inverse : bool
+            If True, get the inverse of the diagonal. (Default: False).
+        sqrt : bool
+            If True, get the square root of the diagonal. (Default: False).
+            Can be combined with inverse to get the inverse square root
+        out : BlockLinearOperator
+            If provided, write the diagonal entries into this matrix. (Default: None).
+        Returns
+        -------
+        BlockLinearOperator
+            The matrix which contains the main diagonal of self (or its inverse).
+        """
+        # Determine domain and codomain of result
+        V, W = self.domain, self.codomain
+        if inverse:
+            V, W = W, V
+
+        # Check the `out` argument, if `None` create a new BlockLinearOperator
+        if out is not None:
+            assert isinstance(out, BlockLinearOperator)
+            assert out.domain is V
+            assert out.codomain is W
+
+            # Set any off-diagonal blocks to zero
+            for i, j in out.nonzero_block_indices:
+                if i != j:
+                    out[i, j] = None
+        else:
+            out = BlockLinearOperator(V, W)
+
+        # Store the diagonal (or its inverse) into `out`
+        for i, j in self.nonzero_block_indices:
+            if i == j:
+                out[i, i] = self[i, i].diagonal(inverse = inverse, sqrt=sqrt, out = out[i, i])
+        return out
+    
     @property
     def blocks(self):
         """ Immutable 2D view (tuple of tuples) of the linear operator,
             including the empty blocks as 'None' objects.
         """
         return tuple(
                tuple(self._blocks.get((i, j), None) for j in range(self.n_block_cols))
```

#### psydac/linalg/solvers.py

```diff
@@ -1,24 +1,33 @@
 # coding: utf-8
 """
-This module provides iterative solvers and precondionners.
+This module provides iterative solvers and preconditioners.
 
 """
-from math import sqrt
 import numpy as np
+from math import sqrt
 
-from psydac.linalg.basic     import Vector, LinearOperator, InverseLinearOperator, IdentityOperator, ScaledLinearOperator
+from psydac.utilities.utils  import is_real
 from psydac.linalg.utilities import _sym_ortho
+from psydac.linalg.basic     import (Vector, LinearOperator,
+        InverseLinearOperator, IdentityOperator, ScaledLinearOperator)
 
-__all__ = ('ConjugateGradient', 'PConjugateGradient', 'BiConjugateGradient', 'BiConjugateGradientStabilized', 'MinimumResidual', 'LSMR', 'GMRES')
-
-def is_real(x):
-    from numbers import Number
-    return isinstance(x, Number) and np.isrealobj(x) and not isinstance(x, bool)
+__all__ = (
+    'inverse',
+    'ConjugateGradient',
+    'PConjugateGradient',
+    'BiConjugateGradient',
+    'BiConjugateGradientStabilized',
+    'PBiConjugateGradientStabilized',
+    'MinimumResidual',
+    'LSMR',
+    'GMRES'
+)
 
+#===============================================================================
 def inverse(A, solver, **kwargs):
     """
     A function to create objects of all InverseLinearOperator subclasses.
 
     These are, as of June 06, 2023:
     ConjugateGradient, PConjugateGradient, BiConjugateGradient,
     BiConjugateGradientStabilized, MinimumResidual, LSMR, GMRES.
@@ -30,60 +39,62 @@
     A : psydac.linalg.basic.LinearOperator
         Left-hand-side matrix A of linear system; individual entries A[i,j]
         can't be accessed, but A has 'shape' attribute and provides 'dot(p)'
         function (i.e. matrix-vector product A*p).
 
     solver : str
         Preferred iterative solver. Options are: 'cg', 'pcg', 'bicg',
-        'bicgstab', 'minres', 'lsmr', 'gmres'.
+        'bicgstab', 'pbicgstab', 'minres', 'lsmr', 'gmres'.
 
     Returns
     -------
     obj : psydac.linalg.basic.InverseLinearOperator
-        More specifically: Returns the chosen subclass, for example psydac.linalg.solvers.ConjugateGradient
-        A linear operator acting as the inverse of A.
+        A linear operator acting as the inverse of A, of the chosen subclass
+        (for example psydac.linalg.solvers.ConjugateGradient).
 
     """
+
+    # Map each possible value of the `solver` string with a specific
+    # `InverseLinearOperator` subclass in this module:
+    solvers_dict = {
+        'cg'       : ConjugateGradient,
+        'pcg'      : PConjugateGradient,
+        'bicg'     : BiConjugateGradient,
+        'bicgstab' : BiConjugateGradientStabilized,
+        'pbicgstab': PBiConjugateGradientStabilized,
+        'minres'   : MinimumResidual,
+        'lsmr'     : LSMR,
+        'gmres'    : GMRES,
+    }
+
     # Check solver input
-    solvers = ('cg', 'pcg', 'bicg', 'bicgstab', 'pbicgstab', 'minres', 'lsmr', 'gmres')
-    if solver not in solvers:
+    if solver not in solvers_dict:
         raise ValueError(f"Required solver '{solver}' not understood.")
 
     assert isinstance(A, LinearOperator)
+
     if isinstance(A, IdentityOperator):
         return A
     elif isinstance(A, ScaledLinearOperator):
         return ScaledLinearOperator(domain=A.codomain, codomain=A.domain, c=1/A.scalar, A=inverse(A, solver, **kwargs))
     elif isinstance(A, InverseLinearOperator):
         return A.linop
 
     # Instantiate object of correct solver class
-    if solver == 'cg':
-        obj = ConjugateGradient(A, **kwargs)
-    elif solver == 'pcg':
-        obj = PConjugateGradient(A, **kwargs)
-    elif solver == 'bicg':
-        obj = BiConjugateGradient(A, **kwargs)
-    elif solver == 'bicgstab':
-        obj = BiConjugateGradientStabilized(A, **kwargs)
-    elif solver == 'pbicgstab':
-        obj = PBiConjugateGradientStabilized(A, **kwargs)
-    elif solver == 'minres':
-        obj = MinimumResidual(A, **kwargs)
-    elif solver == 'lsmr':
-        obj = LSMR(A, **kwargs)
-    elif solver == 'gmres':
-        obj = GMRES(A, **kwargs)
+    cls = solvers_dict[solver]
+    obj = cls(A, **kwargs)
+
     return obj
 
 #===============================================================================
 class ConjugateGradient(InverseLinearOperator):
     """
-    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
+    Conjugate Gradient (CG).
 
+    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
     The .dot (and also the .solve) function are based on the 
     Conjugate gradient algorithm for solving linear system Ax=b.
     Implementation from [1], page 137.
 
     Parameters
     ----------
     A : psydac.linalg.basic.LinearOperator
@@ -99,22 +110,25 @@
 
     maxiter : int
         Maximum number of iterations.
 
     verbose : bool
         If True, L2-norm of residual r is printed at each iteration.
 
+    recycle : bool
+        Stores a copy of the output in x0 to speed up consecutive calculations of slightly altered linear systems
+
     References
     ----------
     [1] A. Maister, Numerik linearer Gleichungssysteme, Springer ed. 2015.
 
     """
-    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=1000, verbose=False):
+    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=1000, verbose=False, recycle=False):
 
-        self._options = {"x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose}
+        self._options = {"x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose, "recycle":recycle}
         
         super().__init__(A, **self._options)
         
         self._tmps = {key: self.domain.zeros() for key in ("v", "r", "p", "lp", "lv")}
         self._info = None
         
     @property
@@ -155,14 +169,15 @@
         domain = self._domain
         codomain = self._codomain
         options = self._options
         x0 = options["x0"]
         tol = options["tol"]
         maxiter = options["maxiter"]
         verbose = options["verbose"]
+        recycle = options["recycle"]
         
         assert isinstance(b, Vector)
         assert b.space is domain
 
         # First guess of solution
         if out is not None:
             assert isinstance(out, Vector)
@@ -217,53 +232,69 @@
 
         if verbose:
             print( "+---------+---------------------+")
 
         # Convergence information
         self._info = {'niter': m, 'success': am < tol_sqr, 'res_norm': sqrt(am) }
 
+        if recycle:
+            x.copy(out=self._options["x0"])
+
         return x
 
     def dot(self, b, out=None):
         return self.solve(b, out=out)
 
 #===============================================================================
 class PConjugateGradient(InverseLinearOperator):
     """
+    Preconditioned Conjugate Gradient (PCG).
+
     A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
     The .dot (and also the .solve) function are based on a preconditioned conjugate gradient method.
+    The Preconditioned Conjugate Gradient (PCG) algorithm solves the linear
+    system A x = b where A is a symmetric and positive-definite matrix, i.e.
+    A = A^T and y A y > 0 for any vector y. The preconditioner P is a matrix
+    which approximates the inverse of A. The algorithm assumes that P is also
+    symmetric and positive definite.
 
-    Preconditioned Conjugate Gradient (PCG) solves the symetric positive definte
-    system Ax = b. It assumes that pc.dot(r) returns the solution to Ps = r,
-    where P is positive definite.
+    Since this is a matrix-free iterative method, both A and P are provided as
+    `LinearOperator` objects which must implement the `dot` method.
 
     Parameters
     ----------
-    A : psydac.linalg.stencil.StencilMatrix
-        Left-hand-side matrix A of linear system
+    A : psydac.linalg.basic.LinearOperator
+        Left-hand-side matrix A of the linear system. This should be symmetric
+        and positive definite.
 
     pc: psydac.linalg.basic.LinearOperator
-        Preconditioner for A, it should approximate the inverse of A (can be None).
+        Preconditioner which should approximate the inverse of A (optional).
+        Like A, the preconditioner should be symmetric and positive definite.
 
     x0 : psydac.linalg.basic.Vector
         First guess of solution for iterative solver (optional).
 
     tol : float
-        Absolute tolerance for L2-norm of residual r = A*x - b.
+        Absolute tolerance for L2-norm of residual r = A x - b. (Default: 1e-6)
 
     maxiter: int
-        Maximum number of iterations.
+        Maximum number of iterations. (Default: 1000)
 
     verbose : bool
-        If True, L2-norm of residual r is printed at each iteration.
+        If True, the L2-norm of the residual r is printed at each iteration.
+        (Default: False)
+
+    recycle : bool
+        If True, a copy of the output is stored in x0 to speed up consecutive
+        calculations of slightly altered linear systems. (Default: False)
 
     """
-    def __init__(self, A, *, pc=None, x0=None, tol=1e-6, maxiter=1000, verbose=False):
+    def __init__(self, A, *, pc=None, x0=None, tol=1e-6, maxiter=1000, verbose=False, recycle=False):
 
-        self._options = {"pc":pc, "x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose}
+        self._options = {"x0":x0, "pc":pc, "tol":tol, "maxiter":maxiter, "verbose":verbose, "recycle":recycle}
         
         super().__init__(A, **self._options)
         
         if pc is None:
             self._options['pc'] = IdentityOperator(self.domain)
         else:
             assert isinstance(pc, LinearOperator)
@@ -305,14 +336,15 @@
         codomain = self._codomain
         options = self._options
         x0 = options["x0"]
         pc = options["pc"]
         tol = options["tol"]
         maxiter = options["maxiter"]
         verbose = options["verbose"]
+        recycle = options["recycle"]
 
         assert isinstance(b, Vector)
         assert b.space is domain
         
         assert isinstance(pc, LinearOperator)
 
         # First guess of solution
@@ -379,24 +411,28 @@
 
         if verbose:
             print( "+---------+---------------------+")
 
         # Convergence information
         self._info = {'niter': k, 'success': nrmr_sqr < tol_sqr, 'res_norm': sqrt(nrmr_sqr) }
 
+        if recycle:
+            x.copy(out=self._options["x0"])
+
         return x
 
     def dot(self, b, out=None):
         return self.solve(b, out=out)
 
 #===============================================================================
 class BiConjugateGradient(InverseLinearOperator):
     """
-    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
+    Biconjugate Gradient (BiCG).
 
+    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
     The .dot (and also the .solve) function are based on the 
     Biconjugate gradient (BCG) algorithm for solving linear system Ax=b.
     Implementation from [1], page 175.
 
     Parameters
     ----------
     A : psydac.linalg.basic.LinearOperator
@@ -412,22 +448,25 @@
 
     maxiter: int
         Maximum number of iterations.
 
     verbose : bool
         If True, 2-norm of residual r is printed at each iteration.
 
+    recycle : bool
+        Stores a copy of the output in x0 to speed up consecutive calculations of slightly altered linear systems
+
     References
     ----------
     [1] A. Maister, Numerik linearer Gleichungssysteme, Springer ed. 2015.
 
     """
-    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=1000, verbose=False):
+    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=1000, verbose=False, recycle=False):
 
-        self._options = {"x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose}
+        self._options = {"x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose, "recycle":recycle}
         
         super().__init__(A, **self._options)
         
         self._Ah = A.H
         self._tmps = {key: self.domain.zeros() for key in ("v", "r", "p", "vs", "rs", "ps")}
         self._info = None
 
@@ -469,14 +508,15 @@
         domain = self._domain
         codomain = self._codomain
         options = self._options
         x0 = options["x0"]
         tol = options["tol"]
         maxiter = options["maxiter"]
         verbose = options["verbose"]
+        recycle = options["recycle"]
 
         assert isinstance(b, Vector)
         assert b.space is domain
 
         # First guess of solution
         if out is not None:
             assert isinstance(out, Vector)
@@ -521,16 +561,14 @@
                 break
 
             #-----------------------
             # MATRIX-VECTOR PRODUCTS
             #-----------------------
             A.dot(p, out=v)
             Ah.dot(ps, out=vs)
-            #v  = A.dot(p , out=v) # overwriting v, then saving in v. Necessary?
-            #vs = At.dot(ps, out=vs) # same story
             #-----------------------
 
             # c := (rs, r)
             c = rs.dot(r)
 
             # a := (rs, r) / (ps, v)
             a = c / ps.dot(v)
@@ -570,24 +608,28 @@
 
         if verbose:
             print( "+---------+---------------------+")
 
         # Convergence information
         self._info = {'niter': m, 'success': res_sqr < tol_sqr, 'res_norm': sqrt(res_sqr)}
 
+        if recycle:
+            x.copy(out=self._options["x0"])
+
         return x
 
     def dot(self, b, out=None):
         return self.solve(b, out=out)
 
 #===============================================================================
 class BiConjugateGradientStabilized(InverseLinearOperator):
     """
-    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
+    Biconjugate Gradient Stabilized (BiCGStab).
 
+    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
     The .dot (and also the .solve) function are based on the
     Biconjugate gradient Stabilized (BCGSTAB) algorithm for solving linear system Ax=b.
     Implementation from [1], page 175.
 
     Parameters
     ----------
     A : psydac.linalg.basic.LinearOperator
@@ -603,22 +645,25 @@
 
     maxiter: int
         Maximum number of iterations.
 
     verbose : bool
         If True, 2-norm of residual r is printed at each iteration.
 
+    recycle : bool
+        Stores a copy of the output in x0 to speed up consecutive calculations of slightly altered linear systems
+
     References
     ----------
     [1] A. Maister, Numerik linearer Gleichungssysteme, Springer ed. 2015.
 
     """
-    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=1000, verbose=False):
+    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=1000, verbose=False, recycle=False):
 
-        self._options = {"x0": x0, "tol": tol, "maxiter": maxiter, "verbose": verbose}
+        self._options = {"x0": x0, "tol": tol, "maxiter": maxiter, "verbose": verbose, "recycle":recycle}
         
         super().__init__(A, **self._options)
         
         self._tmps = {key: self.domain.zeros() for key in ("v", "r", "p", "vs", "r0", "s")}
         self._info = None
         
     @property
@@ -666,14 +711,15 @@
         domain = self._domain
         codomain = self._codomain
         options = self._options
         x0 = options["x0"]
         tol = options["tol"]
         maxiter = options["maxiter"]
         verbose = options["verbose"]
+        recycle = options["recycle"]
 
         assert isinstance(b, Vector)
         assert b.space is domain
 
         # First guess of solution
         if out is not None:
             assert isinstance(out, Vector)
@@ -780,59 +826,57 @@
 
         if verbose:
             print("+---------+---------------------+")
 
         # Convergence information
         self._info = {'niter': m, 'success': res_sqr < tol_sqr, 'res_norm': sqrt(res_sqr)}
 
+        if recycle:
+            x.copy(out=self._options["x0"])
+
         return x
 
     def dot(self, b, out=None):
         return self.solve(b, out=out)
 
 #===============================================================================
 class PBiConjugateGradientStabilized(InverseLinearOperator):
     """
-    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
+    Preconditioned Biconjugate Gradient Stabilized (PBiCGStab).
 
+    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
     The .dot (and also the .solve) function are based on the
     preconditioned Biconjugate gradient Stabilized (PBCGSTAB) algorithm for solving linear system Ax=b.
     Implementation from [1], page 251.
 
     Parameters
     ----------
     A : psydac.linalg.basic.LinearOperator
         Left-hand-side matrix A of linear system; individual entries A[i,j]
         can't be accessed, but A has 'shape' attribute and provides 'dot(p)'
         function (i.e. matrix-vector product A*p).
-
     pc: psydac.linalg.basic.LinearOperator
         Preconditioner for A, it should approximate the inverse of A (can be None).
-
     x0 : psydac.linalg.basic.Vector
         First guess of solution for iterative solver (optional).
-
     tol : float
         Absolute tolerance for 2-norm of residual r = A*x - b.
-
     maxiter: int
         Maximum number of iterations.
-
     verbose : bool
         If True, 2-norm of residual r is printed at each iteration.
-
+    
     References
     ----------
     [1] A. Maister, Numerik linearer Gleichungssysteme, Springer ed. 2015.
-
     """
-    def __init__(self, A, *, pc=None, x0=None, tol=1e-6, maxiter=1000, verbose=False):
+    def __init__(self, A, *, pc=None, x0=None, tol=1e-6, maxiter=1000, verbose=False, recycle=False):
+
+        self._options = {"pc": pc, "x0": x0, "tol": tol, "maxiter": maxiter, "verbose": verbose, "recycle": recycle}
 
-        self._options = { "pc": pc, "x0": x0, "tol": tol, "maxiter": maxiter, "verbose": verbose}
-        
         super().__init__(A, **self._options)
         
         if pc is None:
             self._options['pc'] = IdentityOperator(self.domain)
         else:
             assert isinstance(pc, LinearOperator)
         
@@ -886,18 +930,19 @@
         codomain = self._codomain
         options = self._options
         pc = options["pc"]
         x0 = options["x0"]
         tol = options["tol"]
         maxiter = options["maxiter"]
         verbose = options["verbose"]
+        recycle = options["recycle"]
 
         assert isinstance(b, Vector)
         assert b.space is domain
-        
+
         assert isinstance(pc, LinearOperator)
 
         # first guess of solution
         if out is not None:
             assert isinstance(out, Vector)
             assert out.space == codomain
             out *= 0
@@ -1021,24 +1066,28 @@
         if verbose:
             print("+---------+---------------------+")
 
         # convergence information
         self._info = {'niter': niter, 'success': res_sqr <
                 tol_sqr, 'res_norm': sqrt(res_sqr)}
 
+        if recycle:
+            x.copy(out=self._options["x0"])
+
         return x
 
     def dot(self, b, out=None):
         return self.solve(b, out=out)
 
 #===============================================================================
 class MinimumResidual(InverseLinearOperator):
     """
-    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
+    Minimum Residual (MinRes).
 
+    A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
     The .dot (and also the .solve) function
     Use MINimum RESidual iteration to solve Ax=b
 
     MINRES minimizes norm(A*x - b) for a real symmetric matrix A.  Unlike
     the Conjugate Gradient method, A can be indefinite or singular.
 
     Parameters
@@ -1056,30 +1105,33 @@
 
     maxiter: int
         Maximum number of iterations.
 
     verbose : bool
         If True, 2-norm of residual r is printed at each iteration.
 
+    recycle : bool
+        Stores a copy of the output in x0 to speed up consecutive calculations of slightly altered linear systems
+
     Notes
     -----
     This is an adaptation of the MINRES Solver in Scipy, where the method is modified to accept Psydac data structures,
     https://github.com/scipy/scipy/blob/v1.7.1/scipy/sparse/linalg/isolve/minres.py
 
     References
     ----------
     Solution of sparse indefinite systems of linear equations,
     C. C. Paige and M. A. Saunders (1975),
     SIAM J. Numer. Anal. 12(4), pp. 617-629.
     https://web.stanford.edu/group/SOL/software/minres/
 
     """
-    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=1000, verbose=False):
+    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=1000, verbose=False, recycle=False):
 
-        self._options = {"x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose}
+        self._options = {"x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose, "recycle":recycle}
 
         super().__init__(A, **self._options)
 
         self._tmps = {key: self.domain.zeros() for key in ("res1", "res2", "w", "w2", "yc",
                       "v", "resc", "res2c", "ycc", "res1c", "wc", "w2c")}
         self._info = None
         
@@ -1133,14 +1185,15 @@
         domain = self._domain
         codomain = self._codomain
         options = self._options
         x0 = options["x0"]
         tol = options["tol"]
         maxiter = options["maxiter"]
         verbose = options["verbose"]
+        recycle = options["recycle"]
 
         assert isinstance(b, Vector)
         assert b.space is domain
 
         # First guess of solution
         if out is not None:
             assert isinstance(out, Vector)
@@ -1331,24 +1384,28 @@
 
         if verbose:
             print( "+---------+---------------------+")
 
         # Convergence information
         self._info = {'niter': itn, 'success': rnorm<tol, 'res_norm': rnorm }
 
+        if recycle:
+            x.copy(out=self._options["x0"])
+
         return x
 
     def dot(self, b, out=None):
         return self.solve(b, out=out)
 
 #===============================================================================
 class LSMR(InverseLinearOperator):
     """
+    Least Squares Minimal Residual (LSMR).
+    
     A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
-
     The .dot (and also the .solve) function are based on the 
     Iterative solver for least-squares problems.
     lsmr solves the system of linear equations ``Ax = b``. If the system
     is inconsistent, it solves the least-squares problem ``min ||b - Ax||_2``.
     ``A`` is a rectangular matrix of dimension m-by-n, where all cases are
     allowed: m = n, m > n, or m < n. ``b`` is a vector of length m.
     The matrix A may be dense or sparse (usually sparse).
@@ -1378,35 +1435,38 @@
     conlim : float
         lsmr terminates if an estimate of cond(A) exceeds
         conlim.
 
     verbose : bool
         If True, 2-norm of residual r is printed at each iteration.
 
+    recycle : bool
+        Stores a copy of the output in x0 to speed up consecutive calculations of slightly altered linear systems
+
     Notes
     -----
     This is an adaptation of the LSMR Solver in Scipy, where the method is modified to accept Psydac data structures,
     https://github.com/scipy/scipy/blob/v1.7.1/scipy/sparse/linalg/isolve/lsmr.py
 
     References
     ----------
     .. [1] D. C.-L. Fong and M. A. Saunders,
            "LSMR: An iterative algorithm for sparse least-squares problems",
            SIAM J. Sci. Comput., vol. 33, pp. 2950-2971, 2011.
            arxiv:`1006.0758`
     .. [2] LSMR Software, https://web.stanford.edu/group/SOL/software/lsmr/
     
     """
-    def __init__(self, A, *, x0=None, tol=None, atol=None, btol=None, maxiter=1000, conlim=1e8, verbose=False):
+    def __init__(self, A, *, x0=None, tol=None, atol=None, btol=None, maxiter=1000, conlim=1e8, verbose=False, recycle=False):
 
         self._options = {"x0":x0, "tol":tol, "atol":atol, "btol":btol,
-                         "maxiter":maxiter, "conlim":conlim, "verbose":verbose}
+                         "maxiter":maxiter, "conlim":conlim, "verbose":verbose, "recycle":recycle}
         
         super().__init__(A, **self._options)
-        
+
         # check additional options
         if atol is not None:
             assert is_real(atol), "atol must be a real number"
             assert atol >= 0, "atol must not be negative"
         if btol is not None:
             assert is_real(btol), "btol must be a real number"
             assert btol >= 0, "btol must not be negative"
@@ -1474,14 +1534,15 @@
         x0 = options["x0"]
         tol = options["tol"]
         atol = options["atol"]
         btol = options["btol"]
         maxiter = options["maxiter"]
         conlim = options["conlim"]
         verbose = options["verbose"]
+        recycle = options["recycle"]
 
         assert isinstance(b, Vector)
         assert b.space is domain
 
         # First guess of solution
         if out is not None:
             assert isinstance(out, Vector)
@@ -1709,24 +1770,28 @@
             print( "+---------+---------------------+")
 
         # Convergence information
         self._info = {'niter': itn, 'success': istop in [1,2,3], 'res_norm': normr }
         # Seems necessary, as algorithm might terminate even though rnorm > tol.
         self._successful = istop in [1,2,3]
 
+        if recycle:
+            x.copy(out=self._options["x0"])
+
         return x
 
     def dot(self, b, out=None):
         return self.solve(b, out=out)
 
 #===============================================================================
 class GMRES(InverseLinearOperator):
     """
+    Generalized Minimal Residual (GMRES).
+    
     A LinearOperator subclass. Objects of this class are meant to be created using :func:~`solvers.inverse`.
-
     The .dot (and also the .solve) function are based on the 
     generalized minimal residual algorithm for solving linear system Ax=b.
     Implementation from Wikipedia
 
     Parameters
     ----------
     A : psydac.linalg.basic.LinearOperator
@@ -1742,23 +1807,26 @@
 
     maxiter: int
         Maximum number of iterations.
 
     verbose : bool
         If True, L2-norm of residual r is printed at each iteration.
 
+    recycle : bool
+        Stores a copy of the output in x0 to speed up consecutive calculations of slightly altered linear systems
+
     References
     ----------
     [1] Y. Saad and M.H. Schultz, "GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems", SIAM J. Sci. Stat. Comput., 7:856–869, 1986.
 
     """
-    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=100, verbose=False):
+    def __init__(self, A, *, x0=None, tol=1e-6, maxiter=100, verbose=False, recycle=False):
+
+        self._options = {"x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose, "recycle":recycle}
 
-        self._options = {"x0":x0, "tol":tol, "maxiter":maxiter, "verbose":verbose}
-        
         super().__init__(A, **self._options)
         
         self._tmps = {key: self.domain.zeros() for key in ("r", "p", "v", "lv")}
 
         # Initialize upper Hessenberg matrix
         self._H = np.zeros((self._options["maxiter"] + 1, self._options["maxiter"]), dtype=A.dtype)
         self._Q = []
@@ -1801,14 +1869,15 @@
         domain = self._domain
         codomain = self._codomain
         options = self._options
         x0 = options["x0"]
         tol = options["tol"]
         maxiter = options["maxiter"]
         verbose = options["verbose"]
+        recycle = options["recycle"]
         
         assert isinstance(b, Vector)
         assert b.space is domain
 
         # First guess of solution
         if out is not None:
             assert isinstance(out, Vector)
@@ -1875,14 +1944,17 @@
             self._Q[i].copy(out=v)
             v *= y[i]
             x += v
 
         # Convergence information
         self._info = {'niter': k+1, 'success': am < tol, 'res_norm': am }
         
+        if recycle:
+            x.copy(out=self._options["x0"])
+
         return x
     
     def solve_triangular(self, T, d):
         # Backwards substitution. Assumes T is upper triangular
         k = T.shape[0]
         y = np.zeros((k,), dtype=self._A.dtype)
```

#### psydac/linalg/stencil.py

```diff
@@ -4,15 +4,15 @@
 
 import os
 import warnings
 
 import numpy as np
 
 from types        import MappingProxyType
-from scipy.sparse import coo_matrix
+from scipy.sparse import coo_matrix, diags as sp_diags
 from mpi4py       import MPI
 
 from psydac.linalg.basic   import VectorSpace, Vector, LinearOperator
 from psydac.ddm.cart       import find_mpi_type, CartDecomposition, InterfaceCartDecomposition
 from psydac.ddm.utilities  import get_data_exchanger
 from .kernels              import *
 
@@ -1345,35 +1345,68 @@
                 idx_back  = [slice(None)]*(ndim-direction-1)
 
                 # Copy data from left to right
                 idx_to   = tuple( idx_front + [slice( m*p, m*p+p)] + idx_back )
                 idx_from = tuple( idx_front + [ slice(-m*p,-m*p+p) if (-m*p+p)!=0 else slice(-m*p,None)] + idx_back )
                 self._data[idx_to] += self._data[idx_from]
 
-    def diagonal(self):
-        if self._diag_indices is None:
-            cm    = self.codomain.shifts
-            dm    = self.domain.shifts
-            ss    = self.codomain.starts
-            pp    = [compute_diag_len(p,mj,mi)-(p+1) for p,mi,mj in zip(self._pads, cm, dm)]
-            nrows = tuple(e-s+1 for s,e in zip(self.codomain.starts, self.codomain.ends))
-            indices = [np.zeros(np.product(nrows), dtype=int) for _ in range(2*len(nrows))]
-            l = 0
-            for xx in np.ndindex(*nrows):
-                ii = [m*p+x for m,p,x in zip(self.domain.shifts, self.domain.pads, xx)]
-                jj = [p+x+s-((x+s)//mi)*mj for (x,mi,mj,p,s) in zip(xx,cm,dm,pp,ss)]
-                for k in range(len(nrows)):
-                    indices[k][l] = ii[k]
-                    indices[k+len(nrows)][l] = jj[k]
-                l += 1
-            self._diag_indices = tuple(indices)
-        else:
-            nrows   = tuple(e-s+1 for s,e in zip(self.codomain.starts, self.codomain.ends))
+        # ...
+    def diagonal(self, *, inverse = False, sqrt = False, out = None):
+        """
+        Get the coefficients on the main diagonal as a StencilDiagonalMatrix object.
+        Parameters
+        ----------
+        inverse : bool
+            If True, get the inverse of the diagonal. (Default: False).
+        sqrt : bool
+            If True, get the square root of the diagonal. (Default: False).
+            Can be combined with inverse to get the inverse square root
+        out : StencilDiagonalMatrix
+            If provided, write the diagonal entries into this matrix. (Default: None).
+        Returns
+        -------
+        StencilDiagonalMatrix
+            The matrix which contains the main diagonal of self (or its inverse).
+        """
+        # Check `inverse` argument
+        assert isinstance(inverse, bool)
 
-        return self._data[self._diag_indices].reshape(nrows)
+        # Determine domain and codomain of the StencilDiagonalMatrix
+        V, W = self.domain, self.codomain
+        if inverse:
+            V, W = W, V
+
+        # Check `out` argument
+        if out is not None:
+            assert isinstance(out, StencilDiagonalMatrix)
+            assert out.domain is V
+            assert out.codomain is W
+
+
+        # Extract diagonal data from self and identify output array
+        diagonal_indices = self._get_diagonal_indices()
+        diag = self._data[diagonal_indices]
+        data = out._data if out else None
+
+        if sqrt:
+            diag = np.sqrt(diag)
+
+        # Calculate entries of StencilDiagonalMatrix
+        if inverse:
+            data = np.divide(1, diag, out=data)
+        elif out:
+            np.copyto(data, diag)
+        else:
+            data = diag.copy()
+
+        # If needed create a new StencilDiagonalMatrix object
+        if out is None:
+            out = StencilDiagonalMatrix(V, W, data)
+
+        return out
 
     # ...
     def topetsc( self ):
         """ Convert to petsc data structure.
         """
         from psydac.linalg.topetsc import mat_topetsc
         mat = mat_topetsc( self )
@@ -1874,14 +1907,222 @@
                 self._args.pop('gpads')
                 self._args.pop('pads')
                 self._args.pop('starts')
                 self._args.pop('dm')
                 self._args.pop('cm')
 
             self._func = dot.func
+            
+    # ...
+    def _get_diagonal_indices(self):
+        """
+        Compute the indices which should be applied to self._data in order to
+        get the matrix entries on the main diagonal. The result is also stored
+        in self._diag_indices, and retrieved from there on successive calls.
+        Returns
+        -------
+        tuple[numpy.ndarray, ndim]
+            The diagonal indices as a tuple of NumPy arrays of identical shape
+            (n1, n2, n3, ...).
+        """
+
+        if self._diag_indices is None:
+
+            dp    = self.domain.pads
+            dm    = self.domain.shifts
+            cm    = self.codomain.shifts
+            ss    = self.codomain.starts
+            pp    = [compute_diag_len(p, mj, mi) - p - 1 for p, mi, mj in zip(self._pads, cm, dm)]
+            nrows = [e - s + 1 for s, e in zip(self.codomain.starts, self.codomain.ends)]
+            ndim  = self.domain.ndim
+
+            indices = [np.zeros(np.product(nrows), dtype=int) for _ in range(2 * ndim)]
+
+            for l, xx in enumerate(np.ndindex(*nrows)):
+                ii = [m * p + x for m, p, x in zip(dm, dp, xx)]
+                jj = [p + x + s - ((x+s) // mi) * mj for x, mi, mj, p, s in zip(xx, cm, dm, pp, ss)]
+                for k in range(ndim):
+                    indices[k][l] = ii[k]
+                    indices[k + ndim][l] = jj[k]
+
+            self._diag_indices = tuple(idx.reshape(nrows) for idx in indices)
+
+        return self._diag_indices
+
+#===============================================================================
+class StencilDiagonalMatrix(LinearOperator):
+    """
+    Linear operator which operates between stencil vector spaces, and which can
+    be represented by a matrix with non-zero entries only on its main diagonal.
+    As such this operator is completely local and requires no data communication.
+    We assume that the vectors in the domain and the codomain have the same
+    shape and are distributed in the same way.
+    Parameters
+    ----------
+    V : psydac.linalg.stencil.StencilVectorSpace
+        Domain of the new linear operator.
+    W : psydac.linalg.stencil.StencilVectorSpace
+        Codomain of the new linear operator.
+    """
+    def __init__(self, V, W, data):
+
+        # Check domain and codomain
+        assert isinstance(V, StencilVectorSpace)
+        assert isinstance(W, StencilVectorSpace)
+        assert V.starts == W.starts
+        assert V.ends   == W.ends
+
+        data = np.asarray(data)
+
+        # Check shape of provided data
+        shape = tuple(e - s + 1 for s, e in zip(V.starts, V.ends))
+        assert data.shape == shape
+
+        # Store info in object
+        self._domain   = V
+        self._codomain = W
+        self._data     = data
+
+    #--------------------------------------
+    # Abstract interface
+    #--------------------------------------
+    @property
+    def domain(self):
+        return self._domain
+
+    @property
+    def codomain(self):
+        return self._codomain
+
+    @property
+    def dtype(self):
+        return self._data.dtype
+
+    def tosparse(self):
+        return sp_diags(self._data.ravel())
+
+    def toarray(self):
+        return self._data.copy()
+
+    def dot(self, v, out=None):
+
+        assert isinstance(v, StencilVector)
+        assert v.space is self.domain
+
+        if out is not None:
+            assert isinstance(out, StencilVector)
+            assert out.space is self.codomain
+        else:
+            out = self.codomain.zeros()
+
+        V = self.domain
+        i = tuple(slice(s, e + 1) for s, e in zip(V.starts, V.ends))
+        np.multiply(self._data, v[i], out=out[i])
+
+        out.ghost_regions_in_sync = False
+
+        return out
+
+    # ...
+    # TODO [YG 22.01.2024]: idot function will require a dedicated kernel
+    # ...
+
+    def transpose(self, *, conjugate=False, out=None):
+
+        assert isinstance(conjugate, bool)
+
+        if out is not None:
+            assert isinstance(out, StencilDiagonalMatrix)
+            assert out.domain is self.codomain
+            assert out.codomain is self.domain
+
+        if not (conjugate and self.dtype is complex):
+
+            if out is None:
+                data = self._data.copy()
+            else:
+                np.copyto(out._data, self._data, casting='no')
+
+        else:
+
+            if out is None:
+                data = np.conjugate(self._data, casting='no')
+            else:
+                np.conjugate(self._data, out=out._data, casting='no')
+
+        if out is None:
+            out = StencilDiagonalMatrix(self.codomain, self.domain, data)
+
+        return out
+
+    #--------------------------------------
+    # Other properties/methods
+    #--------------------------------------
+    def copy(self, *, out=None):
+
+        if out is self:
+            return self
+
+        if out is None:
+            data = self._data.copy()
+            out = StencilDiagonalMatrix(self.domain, self.codomain, data)
+        else:
+            assert isinstance(out, StencilDiagonalMatrix)
+            assert out.domain is self.domain
+            assert out.codomain is self.codomain
+            np.copyto(out._data, self._data, casting='no')
+
+        return out
+
+    def diagonal(self, *, inverse = False, out = None):
+        """
+        Get the coefficients on the main diagonal as a StencilDiagonalMatrix object.
+        In the default case (inverse=False, out=None) self is returned.
+        Parameters
+        ----------
+        inverse : bool
+            If True, get the inverse of the diagonal. (Default: False).
+        out : StencilDiagonalMatrix
+            If provided, write the diagonal entries into this matrix. (Default: None).
+        Returns
+        -------
+        StencilDiagonalMatrix
+            Either self, or another StencilDiagonalMatrix with the diagonal inverse.
+        """
+        # Check `inverse` argument
+        assert isinstance(inverse, bool)
+
+        # Determine domain and codomain of the `out` matrix
+        V, W = self.domain, self.codomain
+        if inverse:
+            V, W = W, V
+
+        # Check `out` argument and identify `data` array of output vector
+        if out is None:
+            data = None
+        else:
+            assert isinstance(out, StencilDiagonalMatrix)
+            assert out.domain is V
+            assert out.codomain is W
+            data = out._data
+
+        # Calculate entries, or set `out=self` in default case
+        if inverse:
+            data = np.divide(1, self._data, out=data)
+        elif out:
+            np.copyto(data, self._data)
+        else:
+            out = self
+
+        # If needed create a new StencilDiagonalMatrix object
+        if out is None:
+            out = StencilDiagonalMatrix(V, W, data)
+
+        return out
+
 
 #===============================================================================
 # TODO [YG, 28.01.2021]:
 # - Check if StencilMatrix should be subclassed
 # - Reimplement magic methods (some are simply copied from StencilMatrix)
 def flip_axis(index, n):
     s = n-index.start-1
```

#### psydac/utilities/utils.py

```diff
@@ -1,14 +1,37 @@
 # coding: utf-8
 #
 # Copyright 2018 Yaman Güçlü
 
 import numpy as np
+from numbers import Number
 
-__all__ = ('refine_array_1d', 'unroll_edges', 'split_space', 'split_field', 'animate_field')
+__all__ = (
+    'refine_array_1d',
+    'unroll_edges',
+    'split_space',
+    'split_field',
+    'animate_field'
+)
+
+#==============================================================================
+def is_real(x):
+    """Determine whether the given input represents a real number.
+
+    Parameters
+    ----------
+    x : Any
+
+    Returns
+    -------
+    bool
+        True if x is real, False otherwise.
+
+    """
+    return isinstance(x, Number) and np.isrealobj(x) and not isinstance(x, bool)
 
 #===============================================================================
 def refine_array_1d(x, n, remove_duplicates=True):
     """
     Refines a 1D array by subdividing each interval (x[i], x[i+1]) into n identical parts.
 
     Parameters
@@ -55,14 +78,25 @@
         return xgrid
 
     elif xgrid[0] != xA:
         return np.array([xgrid[-1] - (xB-xA), *xgrid])
 
     elif xgrid[-1] != xB:
         return np.array([*xgrid, xgrid[0] + (xB-xA)])
+
+#===============================================================================
+def roll_edges(domain, points):
+    """If necessary, "roll" back intervals that cross boundary of periodic domain.
+    Changes are made in place to avoid duplicating the array
+    """
+    xA, xB = domain
+    assert xA < xB
+    points -=xA
+    points %=(xB-xA)
+    points +=xA
 #===============================================================================
 def split_space(Xh):
     """Split the flattened fem spaces into
        a list of spaces that corresponds to the symbolic function spaces.
 
     Parameters
     ----------
@@ -155,8 +189,8 @@
         num2     = np.array( [[fields[i].fields[1]( e1,e2 ) for e2 in etas[1]] for e1 in etas[0]] )
         C        = np.hypot(num1, num2)
         quadmesh.set_array(C)
         pbar.update()
         if i == len(fields) - 1:
             pbar.close()
 
-    return animation.FuncAnimation(fig, anim_func, frames=len(fields), interval=interval)
+    return animation.FuncAnimation(fig, anim_func, frames=len(fields), interval=interval)
```

#### Comparing `psydac-0.1.9.dist-info/LICENSE` & `psydac-0.1.12.dist-info/LICENSE`

 * *Files identical despite different names*

#### Comparing `psydac-0.1.9.dist-info/METADATA` & `psydac-0.1.12.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: psydac
-Version: 0.1.9
+Version: 0.1.12
 Summary: Python package for isogeometric analysis (IGA)
 Author-email: Psydac development team <psydac@googlegroups.com>
 Maintainer: Said Hadjout
 Maintainer-email: Yaman Güçlü <yaman.guclu@gmail.com>, Ahmed Ratnani <ratnaniahmed@gmail.com>
 License: MIT License
         
         Copyright (c) 2018-2023, Psydac Developers.
```

#### Comparing `psydac-0.1.9.dist-info/RECORD` & `psydac-0.1.12.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -149,22 +149,22 @@
 psydac/fem/tests/test_product.py,sha256=ceatKxMegApXUvGGQtaXU9vp8DQkNsf3orDm8SfEppI,2009
 psydac/fem/tests/test_spline_histopolation.py,sha256=HouC2Kp8cm2X0pFDSoTN0L387hUja95Tq3bJINUXjMk,4087
 psydac/fem/tests/test_spline_interpolation.py,sha256=tJlx2aIhzjvX5kLmkNIGHVVff3PZCG6229aCFxwcx60,6539
 psydac/fem/tests/test_splines.py,sha256=ZZUZxYQ50e0JCV0ObZe20I7riE_QviNAEYy6ysGXqzg,4491
 psydac/fem/tests/test_splines_par.py,sha256=ehnem2v3GzAbh17vzd1lEoalA-Up4ktiwDR0JKF5xeI,1270
 psydac/fem/tests/utilities.py,sha256=FfCGEouNSdKaUVP03YlZ3so3BvHo4DAQ4NGx15taVWA,1352
 psydac/linalg/__init__.py,sha256=FhfrtxuN69aTv-uPbLhRprlGz0sqmm-HVO2kgRPDa-I,274
-psydac/linalg/basic.py,sha256=bbh-4Ju4j5n8qjzclZpFvotzM2rAaH_X_fGtTLrlhl8,30353
-psydac/linalg/block.py,sha256=ch0VYOnbf65wWjGnoA66wnIjDxGJfUwnalLUez9LHPA,55525
+psydac/linalg/basic.py,sha256=z_3GZAgjM5CoQYwCmBqln9jb-A8HrLmeRY00FmAvcLA,29704
+psydac/linalg/block.py,sha256=5rWKBvYMRi_YzXTohDx5i3ENyFcNoWo7WPXvRa1zOig,57107
 psydac/linalg/direct_solvers.py,sha256=60F7i6Qhhqx66CUh6-Z9P9gi5m0ITWlsYUXUAwGTS2U,6068
 psydac/linalg/fft.py,sha256=KhNO-kkIULh8REd_EEFSoB10b9S6Wir8rYDBEs8g7_w,10230
 psydac/linalg/kernels.py,sha256=h3aF0y4OyU2QWtnIqaFlxDusCd7RPE6S9HZHa1z-NQY,8086
 psydac/linalg/kron.py,sha256=MPiSUlUOnZdZ9hZ8C-wl60lcZJeN_E5rzweug6kaFZo,30680
-psydac/linalg/solvers.py,sha256=1wdtMB2GEdwsdBtoTyco549aiOIHMIR6SR4MzmAAzt4,61867
-psydac/linalg/stencil.py,sha256=SDAcJfjyLuTj7Q37RWzWzakt15pOpu_CLEGGvc-jBkQ,94871
+psydac/linalg/solvers.py,sha256=feeEMwQNz_b4crzMFD8P2RFt5BnWc33yDtbp7uf3lbI,64554
+psydac/linalg/stencil.py,sha256=LtL7mhQuCL-AK4BLZ_NDsbIkY2LRHACLtiqccf8etPU,102348
 psydac/linalg/topetsc.py,sha256=xuoYFRKLgz9MnTCTp9ePG-uEo72ZZHKPnxsWF_VCoSg,3467
 psydac/linalg/utilities.py,sha256=uK-gNWM2NZOEaxLoxOSjQ3bg4vGgLU8z0Nld8GBVQq4,6975
 psydac/linalg/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 psydac/linalg/tests/test_block.py,sha256=M1jyu4EBQRVRzq2vbCjcHx3aRk9vnMIFwQUqm422w_Y,47863
 psydac/linalg/tests/test_fft.py,sha256=kt0t-eBYYj4t5UDJegepSEuLUSZPIy-0Rq5oK8OjTwg,3841
 psydac/linalg/tests/test_kron_direct_solver.py,sha256=wW6cSA9u2V7mdiufHbs9WCwi0WXOtH181QTvMp1kfEg,15009
 psydac/linalg/tests/test_kron_stencil_matrix.py,sha256=ifzTWtKXyeOMpLUNQFQ3EEwCPQRITmbeVh_MtJq3VX8,3750
@@ -209,16 +209,16 @@
 psydac/pyccel/errors/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 psydac/pyccel/errors/errors.py,sha256=yAVf_OA7Ezo82h8tJwlGPHPVk6hTKFTYcAhJQimWVGE,10046
 psydac/pyccel/errors/messages.py,sha256=ZvMNnk2LLKcnpEHhueI57-oV4MW47gwjqJybbZfTXnk,8262
 psydac/pyccel/symbolic/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 psydac/pyccel/symbolic/lambdify.py,sha256=7u62Q7a32kyDRNkNZU5fOkDodXXhHo0jpNRhco0UMDI,4084
 psydac/utilities/__init__.py,sha256=2YqG2XRrcOEvgJOWgAbcrWjTwNOeHfg0l82Cw_ojV7M,68
 psydac/utilities/quadratures.py,sha256=HlG80UJdh6l1epD-wP5KGuCtiUFYbY7GYNCh7AOzKqY,2487
-psydac/utilities/utils.py,sha256=qRgiRbfYWVHPnO2PAVTZgMxi1BTSrTZnO0tij94iGlU,5432
+psydac/utilities/utils.py,sha256=spHBXI4ALSQh3vzF2HoDmjJr4hmvpNq-aUNdg99Sc9A,6213
 psydac/utilities/vtk.py,sha256=6Pe-xIGsnABTJSkk4W45dvpxP44slBRAgNpczVl1mvE,1994
-psydac-0.1.9.dist-info/AUTHORS,sha256=0D0LzhLi6CJ_fXHHMMMswctCIGAOX9I-WdQ0MKY8hNQ,287
-psydac-0.1.9.dist-info/LICENSE,sha256=E1UeOpPwmCqE57lN0WS24M0lYLNP3vi6dz41JlIZgBw,1081
-psydac-0.1.9.dist-info/METADATA,sha256=dqIWkfszgo3Sgxru5kQpMFYE0_K6MxqP7SnmSl0tj6k,7547
-psydac-0.1.9.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-psydac-0.1.9.dist-info/entry_points.txt,sha256=Sm8qxvADFYU0BUcDe7Isnx7ibcKQIbThzLDuCKvKMpM,53
-psydac-0.1.9.dist-info/top_level.txt,sha256=RRagwRqRL6uL-XyTU1Xq5iOGHcdD-prU9o8DSlET90g,7
-psydac-0.1.9.dist-info/RECORD,,
+psydac-0.1.12.dist-info/AUTHORS,sha256=0D0LzhLi6CJ_fXHHMMMswctCIGAOX9I-WdQ0MKY8hNQ,287
+psydac-0.1.12.dist-info/LICENSE,sha256=E1UeOpPwmCqE57lN0WS24M0lYLNP3vi6dz41JlIZgBw,1081
+psydac-0.1.12.dist-info/METADATA,sha256=ROqEqtXDaeINy7bg8dXvSJ_hPZNaB5ZfUKMuDF1Jfso,7548
+psydac-0.1.12.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+psydac-0.1.12.dist-info/entry_points.txt,sha256=Sm8qxvADFYU0BUcDe7Isnx7ibcKQIbThzLDuCKvKMpM,53
+psydac-0.1.12.dist-info/top_level.txt,sha256=RRagwRqRL6uL-XyTU1Xq5iOGHcdD-prU9o8DSlET90g,7
+psydac-0.1.12.dist-info/RECORD,,
```

### Comparing `struphy-2.2.0/src/struphy/tutorials/longer_examples/TAE_tokamak.py` & `struphy-2.3.0/src/struphy/tutorials/longer_examples/TAE_tokamak.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/tutorials/longer_examples/linearextendedmhd.py` & `struphy-2.3.0/src/struphy/tutorials/longer_examples/linearextendedmhd.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/tutorials/longer_examples/linearmhdvlasov_cc.py` & `struphy-2.3.0/src/struphy/tutorials/longer_examples/linearmhdvlasov_cc.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/tutorials/longer_examples/linearmhdvlasov_pc.py` & `struphy-2.3.0/src/struphy/tutorials/longer_examples/linearmhdvlasov_pc.py`

 * *Files identical despite different names*

### Comparing `struphy-2.2.0/src/struphy/tutorials/tests/test_tutorials.py` & `struphy-2.3.0/src/struphy/tutorials/tests/test_tutorials.py`

 * *Files 4% similar despite different names*

```diff
@@ -55,14 +55,14 @@
          os.path.join(i_path, 'tutorials', 'params_05a.yml'), 
          os.path.join(o_path, 'tutorial_05a'))
 
     comm.Barrier()
     if rank == 0:
         pproc_struphy.main(os.path.join(o_path, 'tutorial_05a'))
     
-    main('DriftKinetic', 
+    main('GuidingCenter', 
          os.path.join(i_path, 'tutorials', 'params_05b.yml'), 
          os.path.join(o_path, 'tutorial_05b'))
 
     comm.Barrier()
     if rank == 0:
         pproc_struphy.main(os.path.join(o_path, 'tutorial_05b'))
```

### Comparing `struphy-2.2.0/src/struphy.egg-info/PKG-INFO` & `struphy-2.3.0/src/struphy.egg-info/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 Metadata-Version: 2.1
 Name: struphy
-Version: 2.2.0
+Version: 2.3.0
 Summary: Multi-model plasma physics package
 Author: Max Planck Institute for Plasma Physics
 Author-email: stefan.possanner@ipp.mpg.de, eric.sonnendruecker@ipp.mpg.de
-License: Copyright (c) 2019-2023, Struphy developers, Max Planck Institute for Plasma Physics
+License: Copyright (c) 2019-2024, Struphy developers, Max Planck Institute for Plasma Physics
         
         Permission is hereby granted, free of charge, to any person obtaining a copy of this software and 
         associated documentation files (the "Software"), to deal in the Software without restriction, 
         including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
         and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, 
         subject to the following conditions:
         
@@ -27,38 +27,39 @@
 Project-URL: Bug Tracker, https://gitlab.mpcdf.mpg.de/struphy/struphy/-/issues
 Keywords: plasma physics, fusion, numerical modeling, partial differential equations, energetic particles
 Classifier: Programming Language :: Python :: 3
 Requires-Python: <3.12,>=3.7
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: PyYAML==6.0.1
-Requires-Dist: argcomplete==3.2.1
+Requires-Dist: argcomplete==3.2.3
 Requires-Dist: docutils==0.20.1
-Requires-Dist: gvec-to-python==1.2.0
+Requires-Dist: gvec-to-python==1.2.1
 Requires-Dist: h5py==3.10.0
-Requires-Dist: ipyparallel==8.6.1
+Requires-Dist: ipyparallel==8.7.0
+Requires-Dist: lxml_html_clean==0.1.0
 Requires-Dist: m2r2==0.3.3.post2
-Requires-Dist: matplotlib==3.8.2
+Requires-Dist: matplotlib==3.8.3
 Requires-Dist: mistune==0.8.4
 Requires-Dist: mpi4py==3.1.5
 Requires-Dist: myst-parser==2.0.0
 Requires-Dist: nbsphinx==0.9.3
-Requires-Dist: notebook==7.0.6
+Requires-Dist: notebook==7.1.2
 Requires-Dist: numpy==1.24.4
-Requires-Dist: pyccel==1.11.1
-Requires-Dist: pydata-sphinx-theme==0.15.1
-Requires-Dist: pytest==7.4.4
+Requires-Dist: pyccel==1.11.2
+Requires-Dist: pydata-sphinx-theme==0.15.2
+Requires-Dist: pytest==8.1.1
 Requires-Dist: pytest-monitor==1.6.6
 Requires-Dist: pytest-mpi==0.6
-Requires-Dist: scipy==1.11.4
+Requires-Dist: scipy==1.12.0
 Requires-Dist: Sphinx==7.2.6
 Requires-Dist: sphinxcontrib-napoleon==0.7
-Requires-Dist: tqdm==4.66.1
+Requires-Dist: tqdm==4.66.2
 Requires-Dist: vtk==9.3.0
-Requires-Dist: wheel==0.42.0
+Requires-Dist: wheel==0.43.0
 
 # Struphy - Structure-preserving hybrid codes
 
 A Python package for plasma physics PDEs.
 
 See the [Struphy documentation](https://struphy.pages.mpcdf.de/struphy/index.html) for details.
```

### Comparing `struphy-2.2.0/src/struphy.egg-info/SOURCES.txt` & `struphy-2.3.0/src/struphy.egg-info/SOURCES.txt`

 * *Files 5% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 pyproject.toml
 setup.cfg
 src/struphy/__init__.py
 src/struphy/compile_struphy.mk
 src/struphy/conftest.py
 src/struphy/dependencies.py
 src/struphy/main.py
-src/struphy/psydac-0.1.9-py3-none-any.whl
+src/struphy/psydac-0.1.12-py3-none-any.whl
 src/struphy.egg-info/PKG-INFO
 src/struphy.egg-info/SOURCES.txt
 src/struphy.egg-info/dependency_links.txt
 src/struphy.egg-info/entry_points.txt
 src/struphy.egg-info/requires.txt
 src/struphy.egg-info/top_level.txt
 src/struphy/bsplines/__init__.py
@@ -109,30 +109,28 @@
 src/struphy/feec/mass.py
 src/struphy/feec/mass_kernels.py
 src/struphy/feec/preconditioner.py
 src/struphy/feec/projectors.py
 src/struphy/feec/psydac_derham.py
 src/struphy/feec/utilities.py
 src/struphy/feec/utilities_kernels.py
+src/struphy/feec/variational_utilities.py
 src/struphy/feec/tests/__init__.py
 src/struphy/feec/tests/test_basis_operators.py
 src/struphy/feec/tests/test_basis_ops.py
 src/struphy/feec/tests/test_derham.py
 src/struphy/feec/tests/test_eval_field.py
+src/struphy/feec/tests/test_field_init.py
 src/struphy/feec/tests/test_l2_projectors.py
 src/struphy/feec/tests/test_lowdim_nel_is_1.py
 src/struphy/feec/tests/test_mass_matrices.py
-src/struphy/feec/tests/test_noise_init.py
 src/struphy/feec/tests/test_toarray_struphy.py
 src/struphy/feec/tests/test_tosparse_struphy.py
 src/struphy/feec/tests/xx_test_preconds.py
 src/struphy/fields_background/__init__.py
-src/struphy/fields_background/electric_equil/__init__.py
-src/struphy/fields_background/electric_equil/analytical.py
-src/struphy/fields_background/electric_equil/base.py
 src/struphy/fields_background/mhd_equil/__init__.py
 src/struphy/fields_background/mhd_equil/base.py
 src/struphy/fields_background/mhd_equil/equils.py
 src/struphy/fields_background/mhd_equil/eqdsk/__init__.py
 src/struphy/fields_background/mhd_equil/eqdsk/readeqdsk.py
 src/struphy/fields_background/mhd_equil/eqdsk/data/AUGNLED_g031213.00830.high
 src/struphy/fields_background/mhd_equil/eqdsk/data/__init__.py
@@ -192,14 +190,16 @@
 src/struphy/io/inp/tutorials/params_04b.yml
 src/struphy/io/inp/tutorials/params_05a.yml
 src/struphy/io/inp/tutorials/params_05b.yml
 src/struphy/io/out/__init__.py
 src/struphy/kinetic_background/__init__.py
 src/struphy/kinetic_background/base.py
 src/struphy/kinetic_background/maxwellians.py
+src/struphy/kinetic_background/tests/__init__.py
+src/struphy/kinetic_background/tests/test_maxwellians.py
 src/struphy/linear_algebra/__init__.py
 src/struphy/linear_algebra/linalg_kernels.py
 src/struphy/linear_algebra/linalg_kron.py
 src/struphy/linear_algebra/schur_solver.py
 src/struphy/linear_algebra/stencil_dot_kernels.py
 src/struphy/linear_algebra/stencil_transpose_kernels.py
 src/struphy/linear_algebra/tests/__init__.py
@@ -236,14 +236,15 @@
 src/struphy/pic/pushing/pusher.py
 src/struphy/pic/pushing/pusher_kernels.py
 src/struphy/pic/pushing/pusher_kernels_gc.py
 src/struphy/pic/pushing/pusher_utilities_kernels.py
 src/struphy/pic/tests/__init__.py
 src/struphy/pic/tests/test_accum_vec_H1.py
 src/struphy/pic/tests/test_accumulation.py
+src/struphy/pic/tests/test_binning.py
 src/struphy/pic/tests/test_draw_parallel.py
 src/struphy/pic/tests/test_mat_vec_filler.py
 src/struphy/pic/tests/test_pushers.py
 src/struphy/pic/tests/test_pic_legacy_files/__init__.py
 src/struphy/pic/tests/test_pic_legacy_files/accumulation.py
 src/struphy/pic/tests/test_pic_legacy_files/accumulation_kernels_3d.py
 src/struphy/pic/tests/test_pic_legacy_files/mappings_3d.py
@@ -269,15 +270,16 @@
 src/struphy/post_processing/tests/__init__.py
 src/struphy/propagators/__init__.py
 src/struphy/propagators/base.py
 src/struphy/propagators/propagators_coupling.py
 src/struphy/propagators/propagators_fields.py
 src/struphy/propagators/propagators_markers.py
 src/struphy/propagators/tests/__init__.py
-src/struphy/propagators/tests/test_fields_propagators.py
+src/struphy/propagators/tests/test_gyrokinetic_poisson.py
+src/struphy/propagators/tests/test_poisson.py
 src/struphy/tutorials/__init__.py
 src/struphy/tutorials/utilities.py
 src/struphy/tutorials/longer_examples/TAE_tokamak.py
 src/struphy/tutorials/longer_examples/__init__.py
 src/struphy/tutorials/longer_examples/linearextendedmhd.py
 src/struphy/tutorials/longer_examples/linearmhdvlasov_cc.py
 src/struphy/tutorials/longer_examples/linearmhdvlasov_pc.py
```

